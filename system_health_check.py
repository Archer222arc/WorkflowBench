#!/usr/bin/env python3
"""ç³»ç»Ÿå¥åº·æ£€æŸ¥è„šæœ¬ - æ·±å…¥æ£€æŸ¥æ½œåœ¨é—®é¢˜"""

import os
import sys
import json
import importlib
import traceback
from pathlib import Path
from datetime import datetime
import pandas as pd

def check_import_health():
    """æ£€æŸ¥å…³é”®æ¨¡å—æ˜¯å¦èƒ½æ­£ç¡®å¯¼å…¥"""
    print("\n=== æ¨¡å—å¯¼å…¥å¥åº·æ£€æŸ¥ ===")
    modules_to_check = [
        'batch_test_runner',
        'smart_batch_runner',
        'ultra_parallel_runner',
        'enhanced_cumulative_manager',
        'cumulative_test_manager',
        'parquet_cumulative_manager',
        'file_lock_manager'
    ]
    
    results = {}
    for module_name in modules_to_check:
        try:
            module = importlib.import_module(module_name)
            results[module_name] = "âœ… OK"
        except ImportError as e:
            results[module_name] = f"âŒ å¯¼å…¥å¤±è´¥: {e}"
        except Exception as e:
            results[module_name] = f"âš ï¸ å…¶ä»–é”™è¯¯: {e}"
    
    for module, status in results.items():
        print(f"  {module}: {status}")
    
    return all("âœ…" in status for status in results.values())

def check_critical_methods():
    """æ£€æŸ¥å…³é”®æ–¹æ³•æ˜¯å¦å­˜åœ¨"""
    print("\n=== å…³é”®æ–¹æ³•æ£€æŸ¥ ===")
    
    checks = []
    
    # æ£€æŸ¥BatchTestRunner
    try:
        from batch_test_runner import BatchTestRunner
        runner = BatchTestRunner(debug=False, silent=True)
        
        methods_to_check = [
            '_run_single_test_safe',
            'run_single_test',
            'run_batch_test',
            'get_smart_tasks'
        ]
        
        for method in methods_to_check:
            if hasattr(runner, method):
                print(f"  BatchTestRunner.{method}: âœ… å­˜åœ¨")
                checks.append(True)
            else:
                print(f"  BatchTestRunner.{method}: âŒ ä¸å­˜åœ¨")
                checks.append(False)
                
    except Exception as e:
        print(f"  BatchTestRunner: âŒ æ— æ³•æ£€æŸ¥ - {e}")
        checks.append(False)
    
    # æ£€æŸ¥Managerç±»
    try:
        from enhanced_cumulative_manager import EnhancedCumulativeManager
        manager = EnhancedCumulativeManager()
        
        methods_to_check = [
            'save_database',
            'add_test_result_with_classification',
            'get_runtime_summary'
        ]
        
        for method in methods_to_check:
            if hasattr(manager, method):
                print(f"  EnhancedCumulativeManager.{method}: âœ… å­˜åœ¨")
                checks.append(True)
            else:
                print(f"  EnhancedCumulativeManager.{method}: âŒ ä¸å­˜åœ¨")
                checks.append(False)
                
    except Exception as e:
        print(f"  EnhancedCumulativeManager: âŒ æ— æ³•æ£€æŸ¥ - {e}")
        checks.append(False)
    
    return all(checks)

def check_data_consistency():
    """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
    print("\n=== æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ ===")
    
    # æ£€æŸ¥JSONæ•°æ®åº“
    json_path = Path('pilot_bench_cumulative_results/master_database.json')
    json_data = None
    if json_path.exists():
        with open(json_path, 'r') as f:
            json_data = json.load(f)
        
        json_tests = json_data.get('summary', {}).get('total_tests', 0)
        json_models = len(json_data.get('models', {}))
        print(f"  JSONæ•°æ®åº“: {json_tests} æµ‹è¯•, {json_models} æ¨¡å‹")
    else:
        print(f"  JSONæ•°æ®åº“: âŒ æ–‡ä»¶ä¸å­˜åœ¨")
    
    # æ£€æŸ¥Parquetæ•°æ®
    parquet_path = Path('pilot_bench_parquet_data/test_results.parquet')
    parquet_data = None
    if parquet_path.exists():
        parquet_data = pd.read_parquet(parquet_path)
        parquet_tests = len(parquet_data)
        parquet_models = parquet_data['model'].nunique() if 'model' in parquet_data.columns else 0
        print(f"  Parquetæ•°æ®: {parquet_tests} è®°å½•, {parquet_models} æ¨¡å‹")
    else:
        print(f"  Parquetæ•°æ®: âŒ æ–‡ä»¶ä¸å­˜åœ¨")
    
    # æ£€æŸ¥ä¸€è‡´æ€§
    if json_data and parquet_data is not None:
        if json_tests == parquet_tests:
            print(f"  æ•°æ®ä¸€è‡´æ€§: âœ… åŒ¹é… ({json_tests} = {parquet_tests})")
            return True
        else:
            print(f"  æ•°æ®ä¸€è‡´æ€§: âš ï¸ ä¸åŒ¹é… (JSON:{json_tests} â‰  Parquet:{parquet_tests})")
            return False
    
    return None

def check_potential_issues():
    """æ£€æŸ¥æ½œåœ¨é—®é¢˜"""
    print("\n=== æ½œåœ¨é—®é¢˜æ£€æŸ¥ ===")
    
    issues = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰Pythonç¼“å­˜æ–‡ä»¶
    cache_files = list(Path('__pycache__').glob('*.pyc')) if Path('__pycache__').exists() else []
    if cache_files:
        print(f"  âš ï¸ å‘ç° {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶ï¼Œå»ºè®®æ¸…ç†")
        issues.append("cache_files")
    else:
        print(f"  âœ… æ²¡æœ‰Pythonç¼“å­˜æ–‡ä»¶")
    
    # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
    log_dir = Path('logs')
    if log_dir.exists():
        log_files = list(log_dir.glob('*.log'))
        large_logs = [f for f in log_files if f.stat().st_size > 10 * 1024 * 1024]  # >10MB
        if large_logs:
            print(f"  âš ï¸ å‘ç° {len(large_logs)} ä¸ªå¤§æ—¥å¿—æ–‡ä»¶ (>10MB)")
            issues.append("large_logs")
        else:
            print(f"  âœ… æ—¥å¿—æ–‡ä»¶å¤§å°æ­£å¸¸")
    
    # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶
    temp_files = list(Path('.').glob('*.tmp')) + list(Path('.').glob('*.backup*'))
    if temp_files:
        print(f"  âš ï¸ å‘ç° {len(temp_files)} ä¸ªä¸´æ—¶/å¤‡ä»½æ–‡ä»¶")
        issues.append("temp_files")
    else:
        print(f"  âœ… æ²¡æœ‰ä¸´æ—¶æ–‡ä»¶")
    
    # æ£€æŸ¥è¿›ç¨‹
    import subprocess
    try:
        result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)
        python_processes = [line for line in result.stdout.split('\n') 
                          if 'python' in line and ('batch' in line or 'smart' in line or 'ultra' in line)]
        if python_processes:
            print(f"  âš ï¸ å‘ç° {len(python_processes)} ä¸ªè¿è¡Œä¸­çš„æµ‹è¯•è¿›ç¨‹")
            issues.append("running_processes")
        else:
            print(f"  âœ… æ²¡æœ‰è¿è¡Œä¸­çš„æµ‹è¯•è¿›ç¨‹")
    except:
        print(f"  âš« æ— æ³•æ£€æŸ¥è¿›ç¨‹çŠ¶æ€")
    
    return issues

def check_return_statements():
    """æ£€æŸ¥å…³é”®æ–¹æ³•æ˜¯å¦æœ‰returnè¯­å¥"""
    print("\n=== Returnè¯­å¥æ£€æŸ¥ ===")
    
    critical_files = [
        ('batch_test_runner.py', ['_run_single_test_safe', 'run_single_test']),
        ('smart_batch_runner.py', ['run_batch', 'commit_to_database']),
        ('enhanced_cumulative_manager.py', ['save_database', 'add_test_result_with_classification'])
    ]
    
    issues = []
    for filename, methods in critical_files:
        file_path = Path(filename)
        if not file_path.exists():
            print(f"  {filename}: âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            continue
        
        with open(file_path, 'r') as f:
            content = f.read()
        
        for method in methods:
            # ç®€å•æ£€æŸ¥æ–¹æ³•å®šä¹‰å’Œreturn
            method_def = f"def {method}"
            if method_def in content:
                # æ‰¾åˆ°æ–¹æ³•çš„å¤§è‡´ä½ç½®
                method_start = content.index(method_def)
                # æ£€æŸ¥æ¥ä¸‹æ¥1000ä¸ªå­—ç¬¦å†…æ˜¯å¦æœ‰return
                method_content = content[method_start:method_start+2000]
                
                # ç»Ÿè®¡returnè¯­å¥ï¼ˆæ’é™¤æ³¨é‡Šä¸­çš„ï¼‰
                returns = []
                for line in method_content.split('\n'):
                    stripped = line.strip()
                    if stripped.startswith('return') and not stripped.startswith('#'):
                        returns.append(line)
                
                if returns:
                    print(f"  {filename}.{method}: âœ… æœ‰{len(returns)}ä¸ªreturnè¯­å¥")
                else:
                    print(f"  {filename}.{method}: âš ï¸ æ²¡æœ‰æ‰¾åˆ°returnè¯­å¥")
                    issues.append(f"{filename}.{method}")
            else:
                print(f"  {filename}.{method}: âŒ æ–¹æ³•ä¸å­˜åœ¨")
                issues.append(f"{filename}.{method}")
    
    return issues

def main():
    """è¿è¡Œå®Œæ•´çš„ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    print("=" * 60)
    print("ç³»ç»Ÿå¥åº·æ£€æŸ¥æŠ¥å‘Š")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    all_good = True
    
    # 1. æ¨¡å—å¯¼å…¥æ£€æŸ¥
    if not check_import_health():
        all_good = False
    
    # 2. å…³é”®æ–¹æ³•æ£€æŸ¥
    if not check_critical_methods():
        all_good = False
    
    # 3. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
    consistency = check_data_consistency()
    if consistency is False:
        all_good = False
    
    # 4. æ½œåœ¨é—®é¢˜æ£€æŸ¥
    issues = check_potential_issues()
    if issues:
        all_good = False
    
    # 5. Returnè¯­å¥æ£€æŸ¥
    return_issues = check_return_statements()
    if return_issues:
        all_good = False
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æ€»ä½“å¥åº·çŠ¶æ€:")
    if all_good:
        print("ğŸ‰ ç³»ç»Ÿå¥åº·ï¼Œæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
    else:
        print("âš ï¸ å‘ç°ä¸€äº›é—®é¢˜éœ€è¦å…³æ³¨ï¼š")
        if issues:
            print(f"  - æ½œåœ¨é—®é¢˜: {', '.join(issues)}")
        if return_issues:
            print(f"  - Returnè¯­å¥é—®é¢˜: {', '.join(return_issues)}")
    
    print("=" * 60)
    
    return 0 if all_good else 1

if __name__ == "__main__":
    sys.exit(main())