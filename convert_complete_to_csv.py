#!/usr/bin/env python3
"""
å°†master_database.jsonå®Œæ•´è½¬æ¢ä¸ºCSVæ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰å­—æ®µ
"""

import json
import csv
from pathlib import Path
from datetime import datetime

print('ğŸ”„ å¼€å§‹å®Œæ•´è½¬æ¢JSONåˆ°CSVæ ¼å¼ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰...')
print('=' * 80)

# è¯»å–JSONæ•°æ®
json_path = Path('pilot_bench_cumulative_results/master_database.json')
with open(json_path, 'r') as f:
    db = json.load(f)

print(f'âœ… è¯»å–JSONæ•°æ®æˆåŠŸ')
print(f'  - æ¨¡å‹æ•°é‡: {len(db.get("models", {}))}')

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = Path('pilot_bench_csv_data')
output_dir.mkdir(exist_ok=True)

# å‡†å¤‡CSVæ•°æ®
rows = []
models_data = db.get('models', {})

# æ‰€æœ‰å¯èƒ½çš„å­—æ®µï¼ˆåŸºäºæ‚¨é€‰ä¸­çš„å†…å®¹ï¼‰
all_fields = [
    # åŸºæœ¬ç»´åº¦
    'model', 'prompt_type', 'tool_success_rate', 'difficulty', 'task_type',
    
    # åŸºæœ¬ç»Ÿè®¡
    'total', 'success', 'partial', 'failed',
    'success_rate', 'partial_rate', 'failure_rate',
    'weighted_success_score', 'full_success_rate', 'partial_success_rate',
    
    # æ‰§è¡ŒæŒ‡æ ‡
    'avg_execution_time', 'avg_turns', 'avg_tool_calls', 'tool_coverage_rate',
    
    # è´¨é‡åˆ†æ•°
    'avg_workflow_score', 'avg_phase2_score', 'avg_quality_score', 'avg_final_score',
    
    # é”™è¯¯ç»Ÿè®¡
    'total_errors',
    'tool_call_format_errors', 'timeout_errors', 'dependency_errors',
    'parameter_config_errors', 'tool_selection_errors', 
    'sequence_order_errors', 'max_turns_errors', 'other_errors',
    
    # é”™è¯¯ç‡
    'tool_selection_error_rate', 'parameter_error_rate', 'sequence_error_rate',
    'dependency_error_rate', 'timeout_error_rate', 'format_error_rate',
    'max_turns_error_rate', 'other_error_rate',
    
    # è¾…åŠ©ç›¸å…³
    'assisted_failure', 'assisted_success', 'total_assisted_turns',
    'tests_with_assistance', 'avg_assisted_turns', 
    'assisted_success_rate', 'assistance_rate',
    
    # é¢å¤–å­—æ®µï¼ˆå¯èƒ½å­˜åœ¨ï¼‰
    'full_success', 'partial_success',
    
    # å…ƒæ•°æ®
    'timestamp'
]

for model_name, model_data in models_data.items():
    by_prompt = model_data.get('by_prompt_type', {})
    
    for prompt_type, prompt_data in by_prompt.items():
        by_rate = prompt_data.get('by_tool_success_rate', {})
        
        for rate, rate_data in by_rate.items():
            by_diff = rate_data.get('by_difficulty', {})
            
            for difficulty, diff_data in by_diff.items():
                by_task = diff_data.get('by_task_type', {})
                
                for task_type, task_data in by_task.items():
                    # åˆ›å»ºè¡Œæ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰å­—æ®µ
                    row = {
                        'model': model_name,
                        'prompt_type': prompt_type,
                        'tool_success_rate': float(rate),
                        'difficulty': difficulty,
                        'task_type': task_type,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    # æ·»åŠ æ‰€æœ‰ä»»åŠ¡æ•°æ®å­—æ®µ
                    for field in all_fields:
                        if field not in ['model', 'prompt_type', 'tool_success_rate', 
                                        'difficulty', 'task_type', 'timestamp']:
                            row[field] = task_data.get(field, '')
                    
                    rows.append(row)

print(f'âœ… å±•å¹³æ•°æ®å®Œæˆï¼Œå…±{len(rows)}æ¡è®°å½•')

# è·å–æ‰€æœ‰å”¯ä¸€å­—æ®µå
if rows:
    all_fieldnames = []
    seen = set()
    
    # ä¿æŒé¡ºåºï¼šå…ˆåŠ ç»´åº¦å­—æ®µï¼Œå†åŠ å…¶ä»–å­—æ®µ
    for field in ['model', 'prompt_type', 'tool_success_rate', 'difficulty', 'task_type']:
        if field not in seen:
            all_fieldnames.append(field)
            seen.add(field)
    
    # æ·»åŠ å…¶ä»–å­—æ®µ
    for row in rows:
        for key in row.keys():
            if key not in seen:
                all_fieldnames.append(key)
                seen.add(key)
    
    print(f'âœ… æ£€æµ‹åˆ°{len(all_fieldnames)}ä¸ªå­—æ®µ')

    # å†™å…¥CSVæ–‡ä»¶
    output_file = output_dir / f'test_results_complete_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=all_fieldnames, restval='')
        writer.writeheader()
        writer.writerows(rows)
    
    print(f'âœ… æˆåŠŸä¿å­˜åˆ°: {output_file}')
    print(f'  - æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.1f} KB')
    print(f'  - è®°å½•æ•°: {len(rows)}')
    print(f'  - å­—æ®µæ•°: {len(all_fieldnames)}')
    
    # ä¿å­˜ä¸€ä¸ªå­—æ®µåˆ—è¡¨æ–‡ä»¶
    fields_file = output_dir / 'field_descriptions.txt'
    with open(fields_file, 'w', encoding='utf-8') as f:
        f.write('CSVæ–‡ä»¶å­—æ®µè¯´æ˜\n')
        f.write('=' * 60 + '\n\n')
        f.write('ç»´åº¦å­—æ®µ:\n')
        f.write('  - model: æ¨¡å‹åç§°\n')
        f.write('  - prompt_type: æç¤ºç±»å‹\n')
        f.write('  - tool_success_rate: å·¥å…·æˆåŠŸç‡\n')
        f.write('  - difficulty: éš¾åº¦ç­‰çº§\n')
        f.write('  - task_type: ä»»åŠ¡ç±»å‹\n\n')
        f.write('ç»Ÿè®¡å­—æ®µ:\n')
        f.write('  - total/success/partial/failed: æ€»æ•°/æˆåŠŸ/éƒ¨åˆ†/å¤±è´¥\n')
        f.write('  - *_rate: å„ç§æ¯”ç‡\n')
        f.write('  - avg_*: å¹³å‡å€¼æŒ‡æ ‡\n')
        f.write('  - *_errors: é”™è¯¯è®¡æ•°\n')
        f.write('  - *_error_rate: é”™è¯¯ç‡\n')
        f.write('  - assisted_*: è¾…åŠ©ç›¸å…³æŒ‡æ ‡\n')
        f.write('  - full_success/partial_success: å®Œå…¨æˆåŠŸ/éƒ¨åˆ†æˆåŠŸæ•°\n')
    
    print(f'âœ… å­—æ®µè¯´æ˜å·²ä¿å­˜åˆ°: {fields_file}')
    
    # æ˜¾ç¤ºæ‘˜è¦
    print('\nğŸ“Š æ•°æ®æ‘˜è¦:')
    model_totals = {}
    for row in rows:
        model = row['model']
        if model not in model_totals:
            model_totals[model] = 0
        model_totals[model] += row.get('total', 0)
    
    for model, total in sorted(model_totals.items()):
        print(f'  {model}: {total}ä¸ªæµ‹è¯•')
    
    # ä¹Ÿä¿å­˜ä¸ºlatestç‰ˆæœ¬
    latest_file = output_dir / 'test_results_complete_latest.csv'
    with open(latest_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=all_fieldnames, restval='')
        writer.writeheader()
        writer.writerows(rows)
    print(f'\nâœ… åŒæ—¶ä¿å­˜ä¸º: {latest_file}')
    
else:
    print('âš ï¸ æ²¡æœ‰æ•°æ®å¯è½¬æ¢')
