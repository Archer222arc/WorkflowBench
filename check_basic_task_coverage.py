#!/usr/bin/env python3
"""
æ£€æŸ¥æ‰€æœ‰æ¨¡å‹çš„basic_taskæµ‹è¯•è¦†ç›–æƒ…å†µ
éªŒè¯æ˜¯å¦çœŸçš„ç¼ºå¤±basic_taskæµ‹è¯•
"""

import json
from pathlib import Path
from collections import defaultdict
import pandas as pd

def check_json_database():
    """æ£€æŸ¥JSONæ•°æ®åº“ä¸­çš„basic_taskè¦†ç›–"""
    
    db_path = Path("pilot_bench_cumulative_results/master_database.json")
    if not db_path.exists():
        print("âŒ JSONæ•°æ®åº“ä¸å­˜åœ¨")
        return None
    
    with open(db_path, 'r', encoding='utf-8') as f:
        db = json.load(f)
    
    print("=" * 60)
    print("JSONæ•°æ®åº“ - basic_taskè¦†ç›–åˆ†æ")
    print("=" * 60)
    
    # å®šä¹‰æ‰€æœ‰ä»»åŠ¡ç±»å‹
    all_task_types = [
        "simple_task",
        "basic_task",  # ä¹‹å‰è¢«é”™è¯¯åœ°ç§°ä¸ºfile_processing
        "multi_step_task", 
        "complex_branching",
        "multi_stage_pipeline"
    ]
    
    task_coverage = defaultdict(lambda: defaultdict(int))
    missing_basic_task_models = []
    
    # éå†æ‰€æœ‰æ¨¡å‹
    for model_name, model_data in db.get('models', {}).items():
        print(f"\nğŸ“Š {model_name}:")
        
        model_has_basic_task = False
        
        # éå†æ‰€æœ‰prompt_type
        if 'by_prompt_type' in model_data:
            for prompt_type, prompt_data in model_data['by_prompt_type'].items():
                # éå†tool_success_rateå±‚çº§
                if 'by_tool_success_rate' in prompt_data:
                    for rate, rate_data in prompt_data['by_tool_success_rate'].items():
                        # éå†difficultyå±‚çº§
                        if 'by_difficulty' in rate_data:
                            for difficulty, diff_data in rate_data['by_difficulty'].items():
                                # éå†task_typeå±‚çº§
                                if 'by_task_type' in diff_data:
                                    task_types = diff_data['by_task_type'].keys()
                                    for task_type in task_types:
                                        task_data = diff_data['by_task_type'][task_type]
                                        total = task_data.get('total', 0)
                                        if total > 0:
                                            task_coverage[model_name][task_type] += total
                                            if task_type == "basic_task":
                                                model_has_basic_task = True
        
        # æ˜¾ç¤ºè¯¥æ¨¡å‹çš„ä»»åŠ¡ç±»å‹è¦†ç›–
        if task_coverage[model_name]:
            print("  ä»»åŠ¡ç±»å‹è¦†ç›–:")
            for task_type in all_task_types:
                count = task_coverage[model_name].get(task_type, 0)
                if count > 0:
                    print(f"    âœ… {task_type}: {count} ä¸ªæµ‹è¯•")
                else:
                    print(f"    âŒ {task_type}: 0 ä¸ªæµ‹è¯•ï¼ˆç¼ºå¤±ï¼‰")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰basic_task
            if not model_has_basic_task:
                missing_basic_task_models.append(model_name)
                print(f"  âš ï¸ è­¦å‘Šï¼šç¼ºå°‘basic_taskæµ‹è¯•ï¼")
        else:
            print("  æ— æµ‹è¯•æ•°æ®")
    
    return missing_basic_task_models, task_coverage

def check_parquet_database():
    """æ£€æŸ¥Parquetæ•°æ®åº“ä¸­çš„basic_taskè¦†ç›–"""
    
    parquet_path = Path("pilot_bench_parquet_data/test_results.parquet")
    if not parquet_path.exists():
        print("\nâŒ Parquetæ•°æ®åº“ä¸å­˜åœ¨")
        return None
    
    print("\n" + "=" * 60)
    print("Parquetæ•°æ®åº“ - basic_taskè¦†ç›–åˆ†æ")
    print("=" * 60)
    
    try:
        df = pd.read_parquet(parquet_path)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰task_typeåˆ—
        if 'task_type' not in df.columns:
            print("âš ï¸ Parquetä¸­æ²¡æœ‰task_typeåˆ—")
            return None
        
        # æŒ‰æ¨¡å‹å’Œä»»åŠ¡ç±»å‹åˆ†ç»„
        task_summary = df.groupby(['model', 'task_type']).size().unstack(fill_value=0)
        
        print("\nä»»åŠ¡ç±»å‹åˆ†å¸ƒï¼š")
        print(task_summary)
        
        # æ‰¾å‡ºç¼ºå°‘basic_taskçš„æ¨¡å‹
        if 'basic_task' not in task_summary.columns:
            print("\nâŒ æ‰€æœ‰æ¨¡å‹éƒ½ç¼ºå°‘basic_taskï¼")
            return list(task_summary.index)
        else:
            missing_models = task_summary[task_summary['basic_task'] == 0].index.tolist()
            if missing_models:
                print(f"\nâš ï¸ ç¼ºå°‘basic_taskçš„æ¨¡å‹: {missing_models}")
            else:
                print("\nâœ… æ‰€æœ‰æ¨¡å‹éƒ½æœ‰basic_taskæµ‹è¯•")
            return missing_models
            
    except Exception as e:
        print(f"âŒ åˆ†æParquetå¤±è´¥: {e}")
        return None

def check_test_logs():
    """æ£€æŸ¥æµ‹è¯•æ—¥å¿—ä¸­æ˜¯å¦æœ‰file_processingç›¸å…³çš„è­¦å‘Š"""
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ—¥å¿—åˆ†æ")
    print("=" * 60)
    
    log_dir = Path("logs")
    if not log_dir.exists():
        print("âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾åŒ…å«file_processingè­¦å‘Šçš„æ—¥å¿—
    warning_count = 0
    for log_file in log_dir.glob("batch_test_*.log"):
        try:
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                if "No tasks found for type 'file_processing'" in content:
                    warning_count += 1
                    print(f"  âš ï¸ {log_file.name}: å‘ç°file_processingè­¦å‘Š")
                    # åªæ˜¾ç¤ºå‰3ä¸ª
                    if warning_count >= 3:
                        break
        except:
            pass
    
    if warning_count > 0:
        print(f"\nå‘ç° {warning_count}+ ä¸ªæ—¥å¿—åŒ…å«file_processingè­¦å‘Š")
        print("è¿™è¯å®äº†file_processing vs basic_taskçš„æ··æ·†é—®é¢˜")

def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 60)
    print("Basic Task è¦†ç›–æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥JSONæ•°æ®åº“
    missing_json, task_coverage = check_json_database()
    
    # æ£€æŸ¥Parquetæ•°æ®åº“
    missing_parquet = check_parquet_database()
    
    # æ£€æŸ¥æ—¥å¿—
    check_test_logs()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š åˆ†ææ€»ç»“")
    print("=" * 60)
    
    if missing_json:
        print(f"\nâŒ JSONæ•°æ®åº“ä¸­ç¼ºå°‘basic_taskçš„æ¨¡å‹æ•°: {len(missing_json)}")
        print("ç¼ºå¤±çš„æ¨¡å‹:")
        for model in missing_json[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  - {model}")
        if len(missing_json) > 10:
            print(f"  ... ä»¥åŠå…¶ä»– {len(missing_json)-10} ä¸ªæ¨¡å‹")
    else:
        print("\nâœ… JSONæ•°æ®åº“ä¸­æ‰€æœ‰æ¨¡å‹éƒ½æœ‰basic_taskæµ‹è¯•")
    
    # è®¡ç®—æ€»ä½“è¦†ç›–ç‡
    if task_coverage:
        total_basic_task = sum(cov.get('basic_task', 0) for cov in task_coverage.values())
        total_all_tasks = sum(sum(cov.values()) for cov in task_coverage.values())
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  - basic_taskæµ‹è¯•æ€»æ•°: {total_basic_task}")
        print(f"  - æ‰€æœ‰æµ‹è¯•æ€»æ•°: {total_all_tasks}")
        if total_all_tasks > 0:
            print(f"  - basic_taskå æ¯”: {total_basic_task/total_all_tasks*100:.1f}%")
            
            # é¢„æœŸbasic_taskåº”è¯¥å 20%ï¼ˆ5ç§ä»»åŠ¡ç±»å‹ä¹‹ä¸€ï¼‰
            expected_percentage = 20
            actual_percentage = total_basic_task/total_all_tasks*100
            
            if actual_percentage < expected_percentage * 0.5:  # å¦‚æœå®é™…å æ¯”å°äºé¢„æœŸçš„ä¸€åŠ
                print(f"\nâš ï¸ basic_taskä¸¥é‡ä¸è¶³ï¼é¢„æœŸçº¦{expected_percentage}%ï¼Œå®é™…åªæœ‰{actual_percentage:.1f}%")
                print("å»ºè®®ï¼šéœ€è¦ä¸ºæ‰€æœ‰æ¨¡å‹è¡¥å……basic_taskæµ‹è¯•")
            elif actual_percentage < expected_percentage * 0.9:
                print(f"\nâš ï¸ basic_taskç•¥æœ‰ä¸è¶³ã€‚é¢„æœŸçº¦{expected_percentage}%ï¼Œå®é™…{actual_percentage:.1f}%")
            else:
                print(f"\nâœ… basic_taskè¦†ç›–æ­£å¸¸")

if __name__ == "__main__":
    main()