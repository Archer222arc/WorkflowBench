# å¯ç”¨æ‰€æœ‰ç»Ÿè®¡å­—æ®µè®¡ç®—çš„å®æ–½æ–¹æ¡ˆ

## ğŸ”´ å½“å‰é—®é¢˜

### 1. è´¨é‡åˆ†æ•°å­—æ®µï¼ˆ4ä¸ªï¼‰- ç›®å‰å…¨éƒ¨ä¸ºnull
- `avg_workflow_score` - å·¥ä½œæµæ‰§è¡Œè´¨é‡
- `avg_phase2_score` - ç¬¬äºŒé˜¶æ®µè´¨é‡  
- `avg_quality_score` - æ•´ä½“è´¨é‡è¯„åˆ†
- `avg_final_score` - æœ€ç»ˆç»¼åˆåˆ†æ•°

**é—®é¢˜**ï¼šè¿™äº›åˆ†æ•°åªåœ¨WorkflowQualityTesterä¸­è®¡ç®—ï¼Œæ™®é€šæµ‹è¯•ä¸è®¡ç®—

### 2. é”™è¯¯ç»Ÿè®¡å­—æ®µï¼ˆ9ä¸ªï¼‰- å¤§éƒ¨åˆ†ä¸ºnull
- `total_errors` - æ€»é”™è¯¯æ•°
- `tool_call_format_errors` - æ ¼å¼é”™è¯¯
- `timeout_errors` - è¶…æ—¶é”™è¯¯
- `dependency_errors` - ä¾èµ–é”™è¯¯
- `parameter_config_errors` - å‚æ•°é…ç½®é”™è¯¯
- `tool_selection_errors` - å·¥å…·é€‰æ‹©é”™è¯¯
- `sequence_order_errors` - åºåˆ—é¡ºåºé”™è¯¯
- `max_turns_errors` - è¶…è¿‡æœ€å¤§è½®æ•°é”™è¯¯
- `other_errors` - å…¶ä»–é”™è¯¯

**é—®é¢˜**ï¼šä¾èµ–AIåˆ†ç±»å™¨ï¼Œä½†AIåˆ†ç±»å™¨ç»å¸¸æœªå¯ç”¨æˆ–å¤±è´¥

### 3. å·¥å…·è¦†ç›–ç‡ç»Ÿè®¡ - éƒ¨åˆ†ç¼ºå¤±
- `tool_coverage_rate` - å·¥å…·è¦†ç›–ç‡
- `avg_tool_calls` - å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°

**é—®é¢˜**ï¼šéœ€è¦æ¯”è¾ƒrequired_toolså’Œexecuted_tools

### 4. è¾…åŠ©ç»Ÿè®¡ï¼ˆ7ä¸ªï¼‰- å…¨éƒ¨ä¸ºnull
- `assisted_failure` - è¾…åŠ©åä»å¤±è´¥
- `assisted_success` - è¾…åŠ©åæˆåŠŸ
- `total_assisted_turns` - æ€»è¾…åŠ©è½®æ•°
- `tests_with_assistance` - éœ€è¦è¾…åŠ©çš„æµ‹è¯•æ•°
- `avg_assisted_turns` - å¹³å‡è¾…åŠ©è½®æ•°
- `assisted_success_rate` - è¾…åŠ©æˆåŠŸç‡
- `assistance_rate` - éœ€è¦è¾…åŠ©çš„æ¯”ä¾‹

**é—®é¢˜**ï¼šè¾…åŠ©æœºåˆ¶æœªæ­£ç¡®å®ç°

## âœ… è§£å†³æ–¹æ¡ˆ

### 1. ä¸ºæ‰€æœ‰æµ‹è¯•å¯ç”¨è´¨é‡è¯„åˆ†

```python
# åœ¨batch_test_runner.pyçš„run_single_testä¸­æ·»åŠ è´¨é‡è¯„åˆ†è®¡ç®—
def calculate_quality_scores(result, task_data):
    """ä¸ºæ‰€æœ‰æµ‹è¯•è®¡ç®—è´¨é‡åˆ†æ•°"""
    
    # 1. Workflow Score - åŸºäºå·¥å…·æ‰§è¡Œçš„æ­£ç¡®æ€§
    required_tools = task_data.get('required_tools', [])
    executed_tools = result.get('executed_tools', [])
    
    if required_tools:
        correct_tools = len(set(required_tools) & set(executed_tools))
        workflow_score = correct_tools / len(required_tools)
    else:
        workflow_score = 1.0 if result['success'] else 0.0
    
    # 2. Phase2 Score - åŸºäºæ‰§è¡Œæ•ˆç‡
    max_turns = task_data.get('max_turns', 30)
    actual_turns = result.get('turns', 0)
    phase2_score = max(0, 1 - (actual_turns / max_turns))
    
    # 3. Quality Score - åŸºäºé”™è¯¯æ•°é‡
    error_count = result.get('error_count', 0)
    quality_score = max(0, 1 - (error_count * 0.2))  # æ¯ä¸ªé”™è¯¯æ‰£0.2åˆ†
    
    # 4. Final Score - ç»¼åˆè¯„åˆ†
    final_score = (workflow_score * 0.4 + 
                   phase2_score * 0.3 + 
                   quality_score * 0.3)
    
    return {
        'workflow_score': workflow_score,
        'phase2_score': phase2_score,
        'quality_score': quality_score,
        'final_score': final_score
    }
```

### 2. å¼ºåˆ¶å¯ç”¨AIé”™è¯¯åˆ†ç±»å™¨

```python
# åœ¨enhanced_cumulative_manager.pyä¸­
def ensure_ai_classifier(self):
    """ç¡®ä¿AIåˆ†ç±»å™¨å§‹ç»ˆå¯ç”¨"""
    if not hasattr(self, 'ai_classifier') or self.ai_classifier is None:
        from enhanced_ai_classifier import EnhancedAIErrorClassifier
        self.ai_classifier = EnhancedAIErrorClassifier(
            enable_gpt_classification=True,  # å¼ºåˆ¶å¯ç”¨
            fallback_on_failure=True
        )
```

### 3. å®ç°å·¥å…·è¦†ç›–ç‡è®¡ç®—

```python
def calculate_tool_coverage(result, task_data):
    """è®¡ç®—å·¥å…·è¦†ç›–ç‡"""
    required_tools = task_data.get('required_tools', [])
    executed_tools = result.get('executed_tools', [])
    
    if not required_tools:
        return 1.0  # æ²¡æœ‰è¦æ±‚æ—¶é»˜è®¤100%
    
    covered = len(set(required_tools) & set(executed_tools))
    return covered / len(required_tools)
```

### 4. å®ç°è¾…åŠ©ç»Ÿè®¡

```python
def track_assistance(result):
    """è·Ÿè¸ªè¾…åŠ©ä¿¡æ¯"""
    assistance_data = {
        'needed_assistance': False,
        'assistance_turns': 0,
        'assistance_type': None
    }
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ ¼å¼é”™è¯¯éœ€è¦è¾…åŠ©
    if result.get('format_error_count', 0) > 0:
        assistance_data['needed_assistance'] = True
        assistance_data['assistance_turns'] = result['format_error_count']
        assistance_data['assistance_type'] = 'format_correction'
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¯•
    if result.get('retry_count', 0) > 0:
        assistance_data['needed_assistance'] = True
        assistance_data['assistance_turns'] += result['retry_count']
        assistance_data['assistance_type'] = 'retry_assistance'
    
    return assistance_data
```

## ğŸ“‹ å®æ–½æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šä¿®æ”¹batch_test_runner.py
1. åœ¨`run_single_test`æ–¹æ³•ä¸­æ·»åŠ è´¨é‡åˆ†æ•°è®¡ç®—
2. ç¡®ä¿æ‰€æœ‰æµ‹è¯•éƒ½è¿”å›å®Œæ•´çš„ç»Ÿè®¡æ•°æ®
3. æ·»åŠ å·¥å…·è¦†ç›–ç‡è®¡ç®—

### ç¬¬äºŒæ­¥ï¼šä¿®æ”¹enhanced_cumulative_manager.py
1. å¼ºåˆ¶å¯ç”¨AIåˆ†ç±»å™¨
2. æ”¹è¿›fallbacké”™è¯¯åˆ†ç±»é€»è¾‘
3. ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½è¢«åˆå§‹åŒ–å’Œæ›´æ–°

### ç¬¬ä¸‰æ­¥ï¼šæ·»åŠ è¾…åŠ©ç»Ÿè®¡è·Ÿè¸ª
1. åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­è®°å½•è¾…åŠ©ä¿¡æ¯
2. ç»Ÿè®¡è¾…åŠ©æˆåŠŸ/å¤±è´¥æ¡ˆä¾‹
3. è®¡ç®—è¾…åŠ©ç›¸å…³çš„æ¯”ç‡

### ç¬¬å››æ­¥ï¼šéªŒè¯
1. è¿è¡Œå°æ‰¹é‡æµ‹è¯•éªŒè¯æ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼
2. æ£€æŸ¥Parquetå’ŒJSONä¸­æ²¡æœ‰nullå­—æ®µ
3. ç¡®è®¤ç»Ÿè®¡æ•°æ®çš„å‡†ç¡®æ€§

## ğŸ¯ é¢„æœŸç»“æœ

å®Œæˆåï¼Œæ‰€æœ‰æµ‹è¯•éƒ½å°†åŒ…å«ï¼š
- âœ… å®Œæ•´çš„è´¨é‡è¯„åˆ†ï¼ˆ4ä¸ªåˆ†æ•°ï¼‰
- âœ… è¯¦ç»†çš„é”™è¯¯åˆ†ç±»ï¼ˆ9ç§é”™è¯¯ç±»å‹ï¼‰
- âœ… å‡†ç¡®çš„å·¥å…·è¦†ç›–ç‡
- âœ… å…¨é¢çš„è¾…åŠ©ç»Ÿè®¡
- âœ… æ²¡æœ‰nullå­—æ®µçš„å®Œæ•´æ•°æ®

## ğŸ“Š å½±å“èŒƒå›´

- éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶ï¼š3ä¸ª
  - batch_test_runner.py
  - enhanced_cumulative_manager.py
  - cumulative_test_manager.pyï¼ˆå¯é€‰ï¼‰
  
- å½±å“çš„æµ‹è¯•ï¼šæ‰€æœ‰æœªæ¥çš„æµ‹è¯•
- å†å²æ•°æ®ï¼šå¯é€šè¿‡é‡æ–°è®¡ç®—ä¿®å¤