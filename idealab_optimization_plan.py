#!/usr/bin/env python3
"""
IdealLabå¼€æºæ¨¡å‹å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆ - ç»“åˆåŠ¨æ€é‡æ˜ å°„å’Œæ¨¡å‹çº§å¹¶å‘
"""

from typing import List, Dict, Tuple
import random
from dataclasses import dataclass

@dataclass
class OptimizationPlan:
    """ä¼˜åŒ–æ–¹æ¡ˆæ•°æ®ç»“æ„"""
    model: str
    prompt_type: str
    api_key_index: int
    shard_id: str
    
class IdealLabOptimizer:
    """IdealLabå¼€æºæ¨¡å‹å¹¶å‘ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        # 3ä¸ªAPI keys
        self.api_keys = [0, 1, 2]
        
        # åŸå§‹çš„prompt typeåˆ°keyçš„æ˜ å°„
        self.default_mapping = {
            'baseline': 0,
            'cot': 1,
            'optimal': 2,
            # flawedç±»å‹è½®è¯¢
        }
        
        # è½®è¯¢è®¡æ•°å™¨
        self.rotate_counter = 0
        
    def optimize_task_distribution(self, models: List[str], prompt_types: List[str], 
                                  num_instances: int) -> List[OptimizationPlan]:
        """
        ä¼˜åŒ–ä»»åŠ¡åˆ†é…ç­–ç•¥
        
        Args:
            models: è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼Œå¦‚ ['qwen2.5-72b', 'qwen2.5-7b']
            prompt_types: è¦æµ‹è¯•çš„promptç±»å‹ï¼Œå¦‚ ['optimal'] æˆ– ['flawed_sequence_disorder', ...]
            num_instances: æ¯ä¸ªç»„åˆçš„å®ä¾‹æ•°
            
        Returns:
            ä¼˜åŒ–åçš„ä»»åŠ¡åˆ†é…è®¡åˆ’
        """
        
        plans = []
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºå•ä¸€prompt typeåœºæ™¯ï¼ˆå¦‚5.1/5.2åªæµ‹optimalï¼‰
        is_single_prompt = len(prompt_types) == 1
        
        if is_single_prompt:
            # åœºæ™¯ï¼š5.1/5.2æµ‹è¯•ï¼ˆåªæœ‰optimalï¼‰
            return self._optimize_single_prompt(models, prompt_types[0], num_instances)
        else:
            # åœºæ™¯ï¼š5.3ï¼ˆå¤šä¸ªflawedï¼‰æˆ–5.5ï¼ˆbaseline/cot/optimalï¼‰
            return self._optimize_multi_prompt(models, prompt_types, num_instances)
    
    def _optimize_single_prompt(self, models: List[str], prompt_type: str, 
                               num_instances: int) -> List[OptimizationPlan]:
        """
        ä¼˜åŒ–å•ä¸€prompt typeçš„åˆ†é…ï¼ˆå¦‚5.1/5.2åªæµ‹optimalï¼‰
        
        ç­–ç•¥ï¼š
        1. å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹åˆ†é…ç»™ä¸åŒçš„keyï¼ˆæ¨¡å‹çº§å¹¶å‘ï¼‰
        2. å¦‚æœæ¨¡å‹æ•°>3ï¼Œå¾ªç¯åˆ†é…
        3. åŒä¸€æ¨¡å‹çš„å¤šä¸ªå®ä¾‹ä¹Ÿè½®è¯¢åˆ†é…åˆ°3ä¸ªkey
        """
        plans = []
        
        # ç­–ç•¥1ï¼šä¸åŒæ¨¡å‹åˆ†é…åˆ°ä¸åŒkeyï¼ˆåˆ©ç”¨æ¨¡å‹é—´ç‹¬ç«‹é™é€Ÿï¼‰
        model_to_keys = {}
        for i, model in enumerate(models):
            # æ¯ä¸ªæ¨¡å‹ä¼˜å…ˆåˆ†é…åˆ°ä¸åŒçš„key
            preferred_key = i % 3
            model_to_keys[model] = preferred_key
            
        # ç­–ç•¥2ï¼šåŒä¸€æ¨¡å‹çš„å¤šä¸ªå®ä¾‹ä¹Ÿåˆ†æ•£åˆ°ä¸åŒkey
        for model in models:
            base_key = model_to_keys[model]
            
            for instance_id in range(num_instances):
                # å®ä¾‹è½®è¯¢åˆ†é…åˆ°3ä¸ªkeyï¼Œä»æ¨¡å‹çš„base_keyå¼€å§‹
                key_index = (base_key + instance_id) % 3
                
                plan = OptimizationPlan(
                    model=model,
                    prompt_type=prompt_type,
                    api_key_index=key_index,
                    shard_id=f"{model}_{prompt_type}_{instance_id}_key{key_index}"
                )
                plans.append(plan)
                
        return plans
    
    def _optimize_multi_prompt(self, models: List[str], prompt_types: List[str], 
                              num_instances: int) -> List[OptimizationPlan]:
        """
        ä¼˜åŒ–å¤šprompt typeçš„åˆ†é…ï¼ˆå¦‚5.3çš„flawedæˆ–5.5çš„baseline/cot/optimalï¼‰
        
        ç­–ç•¥ï¼š
        1. éflawedç±»å‹æŒ‰é»˜è®¤æ˜ å°„ï¼ˆbaselineâ†’0, cotâ†’1, optimalâ†’2ï¼‰
        2. flawedç±»å‹è½®è¯¢åˆ†é…
        3. åŒæ—¶è€ƒè™‘æ¨¡å‹çº§å¹¶å‘
        """
        plans = []
        
        for model in models:
            for prompt_type in prompt_types:
                # ç¡®å®šè¯¥prompt_typeåº”è¯¥ç”¨å“ªä¸ªkey
                if prompt_type in self.default_mapping:
                    base_key = self.default_mapping[prompt_type]
                elif prompt_type.startswith('flawed_'):
                    # flawedç±»å‹è½®è¯¢
                    base_key = self.rotate_counter % 3
                    self.rotate_counter += 1
                else:
                    # æœªçŸ¥ç±»å‹ï¼Œè½®è¯¢
                    base_key = self.rotate_counter % 3
                    self.rotate_counter += 1
                
                # ä¸ºè¯¥ç»„åˆåˆ›å»ºå¤šä¸ªå®ä¾‹
                for instance_id in range(num_instances):
                    # å¦‚æœæ˜¯flawedï¼Œå®ä¾‹ä¹Ÿè¦åˆ†æ•£
                    if prompt_type.startswith('flawed_'):
                        key_index = (base_key + instance_id) % 3
                    else:
                        # éflawedä¿æŒå›ºå®šæ˜ å°„ï¼Œä½†å®ä¾‹å¯ä»¥è½®è¯¢
                        if num_instances > 3:
                            # å®ä¾‹å¤ªå¤šæ—¶ä¹Ÿè¦åˆ†æ•£
                            key_index = (base_key + instance_id) % 3
                        else:
                            # å®ä¾‹å°‘æ—¶ä¿æŒåŸæ˜ å°„
                            key_index = base_key
                    
                    plan = OptimizationPlan(
                        model=model,
                        prompt_type=prompt_type,
                        api_key_index=key_index,
                        shard_id=f"{model}_{prompt_type}_{instance_id}_key{key_index}"
                    )
                    plans.append(plan)
                    
        return plans
    
    def calculate_concurrency(self, plans: List[OptimizationPlan]) -> Dict:
        """è®¡ç®—å¹¶å‘åº¦ç»Ÿè®¡"""
        key_usage = {0: [], 1: [], 2: []}
        
        for plan in plans:
            key_usage[plan.api_key_index].append(f"{plan.model}_{plan.prompt_type}")
        
        # ç»Ÿè®¡æ¯ä¸ªkeyçš„è´Ÿè½½
        stats = {
            'key0_tasks': len(key_usage[0]),
            'key1_tasks': len(key_usage[1]),
            'key2_tasks': len(key_usage[2]),
            'max_concurrency': max(len(key_usage[0]), len(key_usage[1]), len(key_usage[2])),
            'min_concurrency': min(len(key_usage[0]), len(key_usage[1]), len(key_usage[2])),
            'balance_ratio': min(len(key_usage[0]), len(key_usage[1]), len(key_usage[2])) / 
                           max(len(key_usage[0]), len(key_usage[1]), len(key_usage[2])) 
                           if max(len(key_usage[0]), len(key_usage[1]), len(key_usage[2])) > 0 else 1
        }
        
        return stats

def demonstrate_optimization():
    """æ¼”ç¤ºä¼˜åŒ–æ•ˆæœ"""
    optimizer = IdealLabOptimizer()
    
    print("=" * 70)
    print("IdealLabå¼€æºæ¨¡å‹å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆæ¼”ç¤º")
    print("=" * 70)
    
    # åœºæ™¯1ï¼š5.1/5.2æµ‹è¯•ï¼ˆåªæµ‹optimalï¼‰
    print("\nğŸ“Š åœºæ™¯1ï¼š5.1/5.2æµ‹è¯• - åªæµ‹optimal")
    print("-" * 50)
    
    models_5_1 = ['qwen2.5-72b-instruct', 'qwen2.5-32b-instruct', 'qwen2.5-14b-instruct']
    prompt_types_5_1 = ['optimal']
    
    plans_5_1 = optimizer.optimize_task_distribution(models_5_1, prompt_types_5_1, num_instances=3)
    
    print("\nä¼˜åŒ–å‰ï¼šæ‰€æœ‰ä»»åŠ¡éƒ½ç”¨Key2ï¼ˆoptimalçš„é»˜è®¤keyï¼‰")
    print("- Key0: ç©ºé—² âŒ")
    print("- Key1: ç©ºé—² âŒ")
    print("- Key2: æ‰€æœ‰9ä¸ªä»»åŠ¡ä¸²è¡Œ âŒ")
    
    print("\nä¼˜åŒ–åï¼šä»»åŠ¡åˆ†æ•£åˆ°3ä¸ªkey")
    key_distribution = {0: 0, 1: 0, 2: 0}
    for plan in plans_5_1:
        key_distribution[plan.api_key_index] += 1
    
    for key_idx in range(3):
        tasks = [p for p in plans_5_1 if p.api_key_index == key_idx]
        print(f"- Key{key_idx}: {len(tasks)}ä¸ªä»»åŠ¡")
        for task in tasks[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
            print(f"    â€¢ {task.model} ({task.prompt_type})")
        if len(tasks) > 2:
            print(f"    â€¢ ... å…±{len(tasks)}ä¸ªä»»åŠ¡")
    
    stats = optimizer.calculate_concurrency(plans_5_1)
    print(f"\nå¹¶å‘åº¦æå‡ï¼š1 â†’ 3 (æå‡3å€)")
    print(f"è´Ÿè½½å‡è¡¡åº¦ï¼š{stats['balance_ratio']:.2%}")
    
    # åœºæ™¯2ï¼š5.3æµ‹è¯•ï¼ˆå¤šä¸ªflawedï¼‰
    print("\n\nğŸ“Š åœºæ™¯2ï¼š5.3æµ‹è¯• - å¤šä¸ªflawedç±»å‹")
    print("-" * 50)
    
    models_5_3 = ['qwen2.5-72b-instruct', 'qwen2.5-7b-instruct']
    prompt_types_5_3 = ['flawed_sequence_disorder', 'flawed_tool_misuse', 'flawed_parameter_error']
    
    plans_5_3 = optimizer.optimize_task_distribution(models_5_3, prompt_types_5_3, num_instances=2)
    
    print("\nflawedç±»å‹è½®è¯¢åˆ†é…åˆ°3ä¸ªkeyï¼š")
    for key_idx in range(3):
        tasks = [p for p in plans_5_3 if p.api_key_index == key_idx]
        print(f"- Key{key_idx}: {len(tasks)}ä¸ªä»»åŠ¡")
        for task in tasks[:3]:
            print(f"    â€¢ {task.model} ({task.prompt_type})")
        if len(tasks) > 3:
            print(f"    â€¢ ... å…±{len(tasks)}ä¸ªä»»åŠ¡")
    
    stats = optimizer.calculate_concurrency(plans_5_3)
    print(f"\nè´Ÿè½½å‡è¡¡åº¦ï¼š{stats['balance_ratio']:.2%}")
    
    # åœºæ™¯3ï¼š5.5æµ‹è¯•ï¼ˆbaseline/cot/optimalï¼‰
    print("\n\nğŸ“Š åœºæ™¯3ï¼š5.5æµ‹è¯• - baseline/cot/optimal")
    print("-" * 50)
    
    models_5_5 = ['qwen2.5-72b-instruct']
    prompt_types_5_5 = ['baseline', 'cot', 'optimal']
    
    plans_5_5 = optimizer.optimize_task_distribution(models_5_5, prompt_types_5_5, num_instances=5)
    
    print("\nå›ºå®šæ˜ å°„ä½†å®ä¾‹åˆ†æ•£ï¼š")
    for key_idx in range(3):
        tasks = [p for p in plans_5_5 if p.api_key_index == key_idx]
        print(f"- Key{key_idx}: {len(tasks)}ä¸ªä»»åŠ¡")
        prompt_counts = {}
        for task in tasks:
            prompt_counts[task.prompt_type] = prompt_counts.get(task.prompt_type, 0) + 1
        for prompt_type, count in prompt_counts.items():
            print(f"    â€¢ {prompt_type}: {count}ä¸ªå®ä¾‹")
    
    stats = optimizer.calculate_concurrency(plans_5_5)
    print(f"\nè´Ÿè½½å‡è¡¡åº¦ï¼š{stats['balance_ratio']:.2%}")
    
    print("\n" + "=" * 70)
    print("æ€»ç»“ï¼š")
    print("âœ… 5.1/5.2åœºæ™¯ï¼šä»1ä¸ªå¹¶å‘æå‡åˆ°3ä¸ªå¹¶å‘ï¼ˆ3å€æå‡ï¼‰")
    print("âœ… 5.3åœºæ™¯ï¼šä¿æŒ3ä¸ªå¹¶å‘ï¼Œè´Ÿè½½å‡è¡¡")
    print("âœ… 5.5åœºæ™¯ï¼šä¿æŒ3ä¸ªå¹¶å‘ï¼ŒæŒ‰prompt typeåˆ†ç»„")
    print("âœ… æ‰€æœ‰åœºæ™¯éƒ½å……åˆ†åˆ©ç”¨3ä¸ªAPI keys")
    print("=" * 70)

if __name__ == "__main__":
    demonstrate_optimization()