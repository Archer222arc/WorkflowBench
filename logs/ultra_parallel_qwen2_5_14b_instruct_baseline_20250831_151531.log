=== 测试开始时间: 2025年 8月31日 星期日 16时10分33秒 EDT ===
=== 执行命令: python3 ./ultra_parallel_runner.py --model qwen2.5-14b-instruct --prompt-types baseline --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 3 ===
INFO:__main__:初始化实例池: 17个实例 (2个Azure + 6个IdealLab)
INFO:__main__:📜 使用传统数据库写入模式
INFO:__main__:资源池状态: 17个实例, 容量1306
INFO:__main__:
🎯 检测到Qwen模型，使用队列调度器
INFO:__main__:   模型: qwen2.5-14b-instruct → Key2
INFO:__main__:   Prompt类型: baseline
INFO:__main__:   难度: easy
INFO:__main__:🔄 Key2: 执行 qwen2.5-14b-instruct-easy
INFO:__main__:🎯 使用qwen智能分片策略: qwen2.5-14b-instruct
INFO:__main__:🔄 真正多Key并发策略:
INFO:__main__:   模型: qwen2.5-14b-instruct (规模: 14b)
INFO:__main__:   使用Keys: key0, key1, key2
INFO:__main__:   总实例数: 20
INFO:__main__:   分片数: 3 (每个key独立分片)
INFO:__main__:   实例分配: [7, 7, 6]
INFO:__main__:   🚀 启用3倍API并发！
INFO:__main__:🚀 启动3个分片并发执行
INFO:__main__:  IdealLab qwen模型限制: qwen-key0 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 0
INFO:__main__:🚀 启动分片 qwen2.5-14b-instruct_easy_baseline_key0: qwen-key0
INFO:__main__:   实例数: 7, 模型: qwen2.5-14b-instruct
INFO:__main__:   设置STORAGE_FORMAT=json给子进程
INFO:__main__:   设置USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   设置TASK_LOAD_COUNT=20给子进程
INFO:__main__:   设置SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   设置USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   设置KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片1: qwen-key0 (7个实例)
INFO:__main__:  IdealLab qwen模型限制: qwen-key1 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 1
INFO:__main__:🚀 启动分片 qwen2.5-14b-instruct_easy_baseline_key1: qwen-key1
INFO:__main__:   实例数: 7, 模型: qwen2.5-14b-instruct
INFO:__main__:   设置STORAGE_FORMAT=json给子进程
INFO:__main__:   设置USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   设置TASK_LOAD_COUNT=20给子进程
INFO:__main__:   设置SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   设置USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   设置KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片2: qwen-key1 (7个实例)
INFO:__main__:  使用IdealLab API Key 2
INFO:__main__:🚀 启动分片 qwen2.5-14b-instruct_easy_baseline_key2: qwen-key2
INFO:__main__:   实例数: 6, 模型: qwen2.5-14b-instruct
INFO:__main__:   设置STORAGE_FORMAT=json给子进程
INFO:__main__:   设置USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   设置TASK_LOAD_COUNT=20给子进程
INFO:__main__:   设置SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   设置USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   设置KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片3: qwen-key2 (6个实例)
INFO:__main__:等待分片1完成（20实例×50workers，最多等待50分钟）...
2025-08-31 16:10:34,237 - faiss.loader - INFO - Loading faiss.
2025-08-31 16:10:34,237 - faiss.loader - INFO - Loading faiss.
2025-08-31 16:10:34,237 - faiss.loader - INFO - Loading faiss.
2025-08-31 16:10:34,259 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 16:10:34,259 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 16:10:34,259 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 16:10:35,030 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-31 16:10:35,030 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-31 16:10:35,030 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-31 16:10:35,030 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-31 16:10:35,030 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-31 16:10:35,030 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-31 16:10:35,030 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-31 16:10:35,030 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-31 16:10:35,030 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-31 16:10:35,031 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-31 16:10:35,031 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-31 16:10:35,031 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-31 16:10:35,031 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-31 16:10:35,031 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-31 16:10:35,031 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-31 16:10:35,031 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-31 16:10:35,031 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-31 16:10:35,031 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-31 16:10:35,032 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-31 16:10:35,032 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-31 16:10:35,032 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-31 16:10:35,032 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 16:10:35,032 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-31 16:10:35,032 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-31 16:10:35,032 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-31 16:10:35,032 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 16:10:35,032 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-31 16:10:35,032 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-31 16:10:35,032 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-31 16:10:35,033 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 16:10:35,081 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:10:35,081 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:10:35,081 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:10:35,081 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-31 16:10:35,081 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-31 16:10:35,081 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-31 16:10:35,081 - batch_test_runner - INFO - ============================================================
2025-08-31 16:10:35,081 - batch_test_runner - INFO - ============================================================
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 16:10:35,081 - batch_test_runner - INFO - ============================================================
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_161035.log
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 16:10:35,081 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_161035.log
2025-08-31 16:10:35,082 - batch_test_runner - INFO - ============================================================
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_161035.log
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-31 16:10:35,082 - batch_test_runner - INFO - ============================================================
2025-08-31 16:10:35,082 - batch_test_runner - INFO - ============================================================
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Initializing test components...
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Initializing test components...
2025-08-31 16:10:35,082 - batch_test_runner - INFO - Initializing test components...
2025-08-31 16:10:35,629 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 16:10:35,634 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 16:10:35,634 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 16:10:35,642 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 16:10:35,644 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 16:10:35,646 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 16:10:35,646 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 16:10:35,647 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 16:10:35,647 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 16:10:35,648 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 16:10:35,648 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 16:10:35,650 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 16:10:36,158 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:36,167 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:36,185 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:36,305 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:10:36,305 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:10:36,306 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:10:36,785 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:10:36,785 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:10:36,785 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:10:37,198 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 16:10:37,198 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 16:10:37,231 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 16:10:37,231 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 16:10:37,235 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 16:10:37,235 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 16:10:37,273 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:10:37,328 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:10:37,341 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:10:37,355 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:10:37,447 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:10:37,452 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:10:37,735 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 16:10:37,735 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:37,823 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 16:10:37,824 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:37,825 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 16:10:37,826 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:38,063 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:38,063 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:38,063 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:38,074 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 16:10:38,076 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:10:38,076 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:10:38,084 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 16:10:38,084 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 16:10:38,085 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 16:10:38,085 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 16:10:38,125 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:38,125 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:38,125 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:38,137 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:38,137 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:38,137 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:38,142 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 16:10:38,142 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:10:38,143 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:10:38,145 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 16:10:38,145 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 16:10:38,145 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 16:10:38,145 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 16:10:38,159 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 16:10:38,165 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:10:38,165 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:10:38,184 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 16:10:38,184 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 16:10:38,184 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 16:10:38,184 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 16:10:40,625 - unified_training_manager - INFO - Using device: cpu
2025-08-31 16:10:40,625 - unified_training_manager - INFO - Using device: cpu
2025-08-31 16:10:40,625 - unified_training_manager - INFO - Using device: cpu
2025-08-31 16:10:41,823 - unified_training_manager - INFO - Task filtering results:
2025-08-31 16:10:41,823 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 16:10:41,823 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 16:10:41,823 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 16:10:41,823 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 16:10:41,823 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 16:10:41,823 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 16:10:41,823 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 16:10:41,827 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 16:10:41,834 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 16:10:41,834 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-31 16:10:41,834 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-31 16:10:41,834 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-31 16:10:41,834 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-31 16:10:41,834 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 16:10:41,834 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 16:10:41,880 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:10:41,882 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-31 16:10:41,882 - result_merger - INFO - ResultMerger初始化完成
2025-08-31 16:10:41,883 - merger_lock - INFO - 获得合并器锁 (PID: 40038)
2025-08-31 16:10:41,883 - result_merger - INFO - 🚀 启动ResultMerger，合并间隔: 10秒
2025-08-31 16:10:41,883 - result_merger - INFO - ResultMerger开始运行，智能停止阈值: 3轮
2025-08-31 16:10:41,883 - result_merger - INFO - ✅ ResultMerger后台线程已启动，支持智能停止机制
2025-08-31 16:10:41,889 - unified_training_manager - INFO - Task filtering results:
2025-08-31 16:10:41,889 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 16:10:41,889 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 16:10:41,889 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 16:10:41,889 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 16:10:41,889 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 16:10:41,889 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 16:10:41,889 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 16:10:41,893 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 16:10:41,899 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 16:10:41,899 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 16:10:41,900 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 16:10:41,901 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-31 16:10:41,901 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-31 16:10:41,901 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-31 16:10:41,901 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-31 16:10:41,901 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 16:10:41,901 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 16:10:41,950 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:10:41,954 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-31 16:10:41,954 - result_merger - INFO - ResultMerger初始化完成
2025-08-31 16:10:41,955 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-31 16:10:41,960 - unified_training_manager - INFO - Task filtering results:
2025-08-31 16:10:41,961 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 16:10:41,961 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 16:10:41,961 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 16:10:41,961 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 16:10:41,961 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 16:10:41,961 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 16:10:41,961 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 16:10:41,964 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 16:10:41,968 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 16:10:41,968 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-31 16:10:41,968 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-31 16:10:41,968 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-31 16:10:41,968 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-31 16:10:41,968 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 16:10:41,968 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 16:10:41,969 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 16:10:41,969 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 16:10:42,013 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:10:42,014 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-31 16:10:42,014 - result_merger - INFO - ResultMerger初始化完成
2025-08-31 16:10:42,015 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-31 16:10:42,029 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 16:10:42,029 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 16:10:42,402 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 16:10:42,402 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 16:10:42,447 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 16:10:42,447 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 16:10:42,461 - batch_test_runner - INFO - Initialization complete
2025-08-31 16:10:42,490 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 16:10:42,490 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 16:10:42,510 - batch_test_runner - INFO - Initialization complete
2025-08-31 16:10:42,556 - batch_test_runner - INFO - Initialization complete
2025-08-31 16:10:42,587 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-31 16:10:42,587 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 16:10:42,587 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-31 16:10:42,588 - smart_model_router - INFO - Using idealab for qwen2.5-14b-instruct
2025-08-31 16:10:42,595 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:42,596 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:42,596 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:42,597 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:42,634 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-31 16:10:42,634 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 16:10:42,635 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-31 16:10:42,636 - smart_model_router - INFO - Using idealab for qwen2.5-14b-instruct
2025-08-31 16:10:42,643 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:42,643 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:42,643 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:42,644 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:42,650 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:42,650 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:42,650 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:42,659 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:42,659 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:42,659 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:42,672 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-31 16:10:42,672 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 16:10:42,673 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-31 16:10:42,673 - smart_model_router - INFO - Using idealab for qwen2.5-14b-instruct
2025-08-31 16:10:42,679 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:42,679 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:42,679 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:42,679 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:42,680 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:42,680 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:42,681 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:42,700 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:42,700 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:42,700 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:42,726 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:42,726 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:42,726 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:42,736 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:42,736 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:42,736 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:44,142 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:44,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:44,344 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:44,369 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:44,399 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:44,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:45,226 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:45,621 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:45,643 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:45,645 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:45,880 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:45,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:46,214 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:46,696 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:46,712 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:46,720 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:47,135 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:47,174 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:47,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:47,745 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:47,753 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:47,771 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:48,204 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:48,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:48,409 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:48,680 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:48,717 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:48,896 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:49,550 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:49,625 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:49,637 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:49,750 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:49,831 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:49,918 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:50,637 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:50,691 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:50,724 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:51,135 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:51,172 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:51,289 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:51,710 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:51,713 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:51,729 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:52,200 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:52,234 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:52,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:52,728 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:52,787 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:52,851 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:53,255 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:53,305 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:53,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:53,830 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:53,845 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:54,031 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:54,045 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:54,046 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:54,069 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:54,069 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:54,069 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:54,984 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:54,995 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:54,995 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:55,018 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:55,018 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:55,018 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:55,056 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:55,066 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:55,066 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:55,087 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:55,087 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:55,087 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:55,116 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:55,125 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:55,125 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:55,170 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:55,170 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:55,170 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:55,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:55,191 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:55,191 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:55,214 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:55,215 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:55,215 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:55,215 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:55,231 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:10:55,231 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:10:55,279 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:10:55,279 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:10:55,279 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:10:55,317 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:56,216 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:56,364 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-14b-instruct (idealab)
Prompt types: ['baseline']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x10712b9b0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[INFO] 后台合并进程已启动（每10秒合并一次）2025-08-31 16:10:56,406 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:56,781 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:56,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:56,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:57,187 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-14b-instruct (idealab)
Prompt types: ['baseline']
难度: easy
目标: 每种配置 6 个实例
============================================================
○ simple_task         :   0/  6 已完成 (需要补充 6 个)
○ basic_task          :   0/  6 已完成 (需要补充 6 个)
○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
○ api_integration     :   0/  6 已完成 (需要补充 6 个)
○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)

⏳ 需要运行 30 个新测试

▶ 准备 simple_task (6 个实例)...

▶ 准备 basic_task (6 个实例)...

▶ 准备 data_pipeline (6 个实例)...

▶ 准备 api_integration (6 个实例)...

▶ 准备 multi_stage_pipeline (6 个实例)...

▶ 开始执行 30 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x110a73900>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[INFO] 后台合并进程已启动（每10秒合并一次）2025-08-31 16:10:57,426 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-14b-instruct (idealab)
Prompt types: ['baseline']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x113b6fe50>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[INFO] 后台合并进程已启动（每10秒合并一次）2025-08-31 16:10:57,536 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,002 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,026 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,240 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,354 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,507 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,631 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:58,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:59,007 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:59,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:59,398 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:10:59,527 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:00,064 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:00,066 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:00,227 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:00,347 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:00,425 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:00,447 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:00,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:00,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:00,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:01,085 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:01,085 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:01,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:01,608 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:01,608 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:01,970 - result_merger - INFO - 🛑 连续3轮无新文件，自动停止合并器防止hang住
2025-08-31 16:11:01,970 - result_merger - INFO - 🏁 ResultMerger合并循环已结束
2025-08-31 16:11:02,213 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:02,226 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:02,658 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:02,658 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:02,732 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:02,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:03,344 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:03,379 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:03,705 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:03,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:03,774 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:04,484 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:04,501 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:04,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:04,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:04,844 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:04,883 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:04,885 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:05,085 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:05,621 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:05,693 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:05,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:05,966 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:05,974 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:06,008 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:06,008 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:06,008 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:06,069 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:06,094 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:06,095 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:06,112 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:06,124 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:06,125 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:06,125 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:06,126 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:06,126 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:06,166 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:06,167 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:06,167 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:06,442 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:06,708 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:06,724 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:06,725 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:06,755 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:06,756 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:06,756 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:06,851 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:06,863 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:06,864 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:06,906 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:06,906 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:06,907 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:07,115 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:07,238 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:07,534 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:07,534 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:08,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:08,140 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:08,685 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:08,697 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:08,757 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:08,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:09,254 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:09,295 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:09,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:09,699 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:09,724 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:10,213 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:10,428 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:10,840 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:10,896 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:10,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:11,046 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:11,192 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:11,571 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:11,735 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:11,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:11,917 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:11,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:12,329 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:12,620 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:12,636 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:12,810 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:12,973 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:13,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:13,142 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:13,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:13,319 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:13,384 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:13,479 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:13,491 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:13,492 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:13,530 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:13,531 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:13,531 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:13,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:13,882 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x114ebdc90>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24481
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24481
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator2025-08-31 16:11:14,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:14,588 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x136cf2280>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24533
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24533
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser2025-08-31 16:11:14,801 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:14,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:15,059 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:15,363 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:15,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:16,092 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:16,399 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:16,846 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:16,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x140f30500>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24179
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24179
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct2025-08-31 16:11:16,928 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:17,382 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:17,441 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:17,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:17,973 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:18,544 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:19,244 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:19,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:19,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:20,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:21,026 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:21,046 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:21,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:21,087 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:21,088 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:21,118 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:21,118 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:21,119 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:21,867 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:22,414 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:22,425 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:22,425 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:22,453 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:22,453 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:22,453 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:22,743 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:22,754 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:22,754 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:22,778 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:22,778 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:22,778 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:22,993 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:23,001 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:23,001 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:23,041 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:23,041 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:23,041 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:23,141 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:23,467 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:23,516 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:23,526 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:23,531 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:23,531 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:23,555 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:23,555 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:23,555 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:24,153 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:24,162 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:24,162 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:24,193 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:24,193 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:24,193 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:24,247 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:24,251 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:24,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:24,577 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:25,051 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:25,304 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:25,936 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:25,968 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:26,462 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:26,468 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:26,950 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:27,434 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:27,443 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:27,951 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24784
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24784
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23858
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23858
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566710728928506e8984'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566710734033065ee8e6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566710738956101e7f60'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.87
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21909
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True2025-08-31 16:11:28,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:28,529 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:28,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:29,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"


[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24891
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24891
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24509
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24509
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24879
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24879
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566710726145813e3f34'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007617566710731891031e11c6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566710736931804eed7c'}2025-08-31 16:11:29,519 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:30,104 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:30,968 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:30,979 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:30,979 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:31,004 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:31,004 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:31,004 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24199
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24199
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24825
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24825
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.92
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566710731271082eed3a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 28092
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=28092
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data_processing_validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150436a17566710748574183e2414'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043b17566710753824342e2430'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e03e217566710767306912e1ef8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching2025-08-31 16:11:31,029 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:31,676 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:31,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:31,851 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:31,861 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:31,861 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:31,887 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:31,887 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:31,887 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:32,338 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:32,348 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:32,349 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:32,373 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:32,374 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:32,374 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:32,554 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:32,585 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:33,104 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:33,473 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:33,591 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:33,600 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:33,601 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:33,625 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:33,625 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:33,625 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:34,212 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:34,311 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:34,638 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:34,843 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:34,972 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:34,980 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:34,981 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:35,004 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:35,004 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:35,004 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:35,345 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:35,353 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:35,353 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:35,375 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:35,375 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:35,375 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:35,755 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:35,851 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:35,910 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:36,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:36,085 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:36,362 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:36,553 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:37,119 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:37,138 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:37,344 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:37,847 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:38,071 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:38,471 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:38,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:38,877 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:39,418 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:39,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:40,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:41,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:42,052 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:42,062 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:42,062 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:42,085 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:42,085 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:42,085 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:42,306 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:42,334 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:42,344 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:42,344 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:42,367 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:42,367 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:42,367 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:42,855 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150460e17566710746234739e7937'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150438d17566710759077308e2e8a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.87
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045b717566710771801475e8177'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007e17566710776891115eee6b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416017566710797734531eefbd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566710822072938eed19'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17859
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17859
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007d17566710829484138ef1f1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215040c017566710833274197edf9f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566710840573016ee627'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006f17566710843286348ee7d2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566710857734778eeb59'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566710862803170e815b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566710878223483e792d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566710883333461e846d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18508
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18508
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-31 16:11:43,124 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:43,131 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:43,139 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:43,139 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:43,161 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:43,161 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:43,161 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:43,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:11:43,280 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:43,281 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:43,302 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:43,302 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:43,302 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007f17566710772374321eeac9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417917566710790501615eeda8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416417566710798207447e1325'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215041de17566710808227644e361c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006a17566710825432780ee341'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18378
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18378
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045af17566710832834298e806b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150456117566710838765770e7fa1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041717566710843828418e9711'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007a17566710851125388ee4a5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566710862648062e8024'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566710867633576e6fc9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007b17566710886726510eee9b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566710893001483e818a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007917566710907367013eea24'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-31 16:11:43,561 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:43,561 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:43,586 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:43,586 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:43,586 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:44,600 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:44,641 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:44,673 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:44,673 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:44,695 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:44,695 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:44,695 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:45,124 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:45,180 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:45,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:45,478 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

  - ai_classifier=True
  - txt_content_len=21909
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150436817566710751464533e1e21'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e05ab17566710762084471e36bc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150409b17566710767261955e09a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566710777736510e3fb8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150456317566710783412695e7f25'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150452b17566710808798769e78d3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 19108
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19108
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566710816721478e818a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566710827952198ee98b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417717566710833168942eda30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417d17566710840301669e10ac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006d17566710848484975e11b4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566710857373949e7ada'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17717
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17717
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006b17566710872471273eed11'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043b17566710877612287e2559'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...2025-08-31 16:11:45,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:45,678 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:46,417 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:46,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:46,508 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:46,532 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:46,698 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:46,698 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:47,009 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:47,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:47,465 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:47,491 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:47,984 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:48,004 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:48,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:48,366 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:48,794 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:48,809 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:48,947 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:49,010 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:49,131 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:49,685 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:49,884 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:49,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:50,086 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:50,201 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:50,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:50,591 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:50,684 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:50,932 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:50,958 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:51,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:51,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:51,650 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:51,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:52,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:52,048 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:52,465 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:52,519 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:52,622 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:53,051 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:53,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:53,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:53,147 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:53,531 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:53,592 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:53,823 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:54,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:54,109 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:54,158 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:54,576 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:54,601 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:54,613 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:54,614 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:54,617 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:54,617 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:54,652 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:54,652 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:54,652 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:54,672 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:54,672 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:54,672 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:54,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:55,087 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:55,102 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:55,103 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:55,136 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:55,136 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:55,136 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:55,206 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:55,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:55,486 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:55,612 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:55,613 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:55,658 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:55,658 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:55,658 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:55,921 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:55,934 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:56,136 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:56,146 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:56,147 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:56,171 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:56,171 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:56,171 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:56,372 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:56,473 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:56,484 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:11:56,484 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:11:56,508 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:11:56,508 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:11:56,508 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:11:56,827 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:57,022 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:57,709 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:57,709 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:57,709 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:57,851 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:11:57,927 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:57,962 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:58,234 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:58,664 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:58,829 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:58,846 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:59,420 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:59,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:59,806 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:59,806 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:59,892 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:11:59,990 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:00,138 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:00,402 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:00,701 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:00,855 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:00,995 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:01,379 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:01,379 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:01,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:01,687 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:01,904 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:01,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566710916505118e8248'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566710921555172e8270'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566710929121440e813e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566710946532566e81f0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065a17566710951597632e8106'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3477
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3477
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065017566710958884168e7e45'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566710961622776e810e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150435d17566710969488192e2025'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566710986833700e7b5e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059717566710992261046e35ef'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566711008507242e8732'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566711018538595e8a42'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3446
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3446
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043b17566711026492231e2328'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching2025-08-31 16:12:01,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:02,327 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:02,427 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:02,638 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:02,952 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:02,952 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:03,475 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:03,521 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:03,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11116
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11116
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566710914686211e8176'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065017566710923376746e7fb2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566710932757210e897a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e080f17566710947762731e0cc4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045ee17566710955393314e787d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066317566710957287167e809b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150414417566710971454055edc7f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566710976454815e7635'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.64
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3214
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3214
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566710982765503e8385'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566711000862746e7a6c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a017566711021216390e769b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566711029255766e8bb5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066d17566711030733248e7fba'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-31 16:12:03,626 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:03,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:03,888 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:04,209 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:04,423 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:04,681 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:04,698 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:05,049 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:05,167 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:05,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:05,400 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:05,650 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:05,706 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:06,100 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:06,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566710899038248e8058'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566710916518426e83cf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006017566710923864598edfe2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566710933533470e815d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3155
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3155
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150415b17566710940892562ee641'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e081017566710943634631e0b6f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566710958258074e8024'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150454117566710963536961e7793'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150438d17566710969295361e2d61'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006f17566710982814432ee76e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 5.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c817566710993848610e80cc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.722025-08-31 16:12:06,320 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:06,340 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:06,341 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:06,379 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:06,379 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:06,379 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:06,622 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:06,639 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:06,639 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:06,665 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:06,672 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:06,673 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:06,673 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:06,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:06,751 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:06,752 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:06,781 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:06,781 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:06,781 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:06,936 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:07,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:07,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:07,309 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:07,309 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:07,345 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:07,345 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:07,345 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:07,672 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:07,953 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:07,979 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:07,980 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:08,001 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:08,019 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:08,019 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:08,019 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:08,194 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:08,374 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:08,392 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:08,393 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:08,446 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:08,446 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:08,446 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:08,801 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:08,820 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:09,023 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:09,246 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:09,324 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:09,449 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:09,628 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:09,765 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:09,844 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:10,292 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:10,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:10,401 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:10,498 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:10,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:10,980 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:11,048 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:11,232 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:11,653 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:11,702 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:11,940 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:12,233 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:12,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:12,505 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:12,611 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:12,738 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:13,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:13,215 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:13,295 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:13,323 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:13,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:13,551 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:13,673 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:13,679 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:13,758 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:13,819 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:14,050 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:14,162 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:14,919 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:15,113 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:15,230 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:15,409 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:15,613 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:15,750 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:15,760 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:15,889 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:16,233 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:16,829 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:17,167 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:17,334 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:17,630 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:18,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:18,340 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e00cd17566711029208854e9736'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3502
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3502
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3377
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected2025-08-31 16:12:18,498 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:19,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:20,446 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:20,549 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3338
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3338
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3476
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3476
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3463
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3463
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
2025-08-31 16:12:20,776 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:21,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:21,140 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:21,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:21,827 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:22,064 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:22,086 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:22,087 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:22,153 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:22,153 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:22,153 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:22,352 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:22,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:23,619 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3404
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3404
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3450
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3450
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3472
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3472
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct2025-08-31 16:12:23,628 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:23,629 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:23,677 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:23,677 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:23,677 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:23,993 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:24,002 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:24,003 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:24,028 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:24,028 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:24,028 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:24,415 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:24,486 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:24,791 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:25,189 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:25,203 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:25,204 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:25,263 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:25,263 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:25,263 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:25,600 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:25,613 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:25,613 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:25,627 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:25,646 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:25,647 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:25,653 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:25,653 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:25,654 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:25,679 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:25,679 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:25,679 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:25,926 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:26,100 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:26,184 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:26,358 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:26,623 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:26,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:27,102 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:27,264 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:27,593 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:27,604 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:27,696 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:27,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:28,449 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:28,982 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:29,165 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:29,690 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:29,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:30,338 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:30,859 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:31,509 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:32,161 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:33,169 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:33,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:33,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:33,997 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:34,016 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:34,017 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:34,054 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:34,054 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:34,054 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23542
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23542
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [PARSE] Fuzzy matched 'file_operations_reader(source="data/input.json")' to 'file_operations_reader'
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006017566711329575139ee00c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566711336266562e6e80'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566711349271089e8a81'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566711354302666e3d30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.9
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23999
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23999
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066d17566711366317075e7fbc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e05ab17566711371268587e3429'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566711382953354e7f9b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566711390853086e822b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类2025-08-31 16:12:34,089 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:34,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:35,794 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:35,806 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:35,806 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:35,831 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:35,831 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:35,831 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:36,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:36,510 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:36,510 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:36,522 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct


[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 10/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23310
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23310
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader for json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23979
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23979
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007517566711334738229eeeec'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043517566711339731777e2c8c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062b17566711350181025e7e44'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566711355217356e0de5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22632
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22632
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417c17566711374058605eeeef'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566711380906126e89e9'}2025-08-31 16:12:36,522 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:36,555 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:36,555 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:36,555 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:36,845 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:36,861 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:36,862 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:36,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:36,899 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:36,899 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:36,899 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:37,182 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:37,204 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:37,205 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:37,240 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:37,241 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:37,241 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:37,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:37,719 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:38,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:38,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:38,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:38,772 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23950
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23950
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23580
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23580
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065917566711333603474e8241'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e03d917566711338642763e213b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566711352032862e158e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566711357005811e8a29'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566711369601694e89c6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045b817566711378324402e8155'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150414417566711404396077edca0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566711409436251e3be4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23718
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23718
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566711434096555e7fc0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 16:12:38,781 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:38,781 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:38,804 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:38,804 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:38,804 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:38,947 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:39,176 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:39,472 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:40,001 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:40,175 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:40,399 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:40,544 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:40,783 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:41,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:42,089 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:42,174 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:42,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:42,684 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:42,708 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:42,798 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:12:45,076 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:45,180 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:45,181 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:45,208 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:45,208 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:45,208 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:45,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:45,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:46,468 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:46,584 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:46,768 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:47,230 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:47,649 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:47,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:47,929 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:48,040 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:48,253 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:48,438 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:48,865 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:48,961 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:48,969 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:49,359 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:49,614 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:49,676 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:49,679 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:49,997 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:50,139 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:50,139 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:50,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:50,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:50,806 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:51,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:51,218 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:51,407 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:51,711 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:52,029 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:52,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:52,294 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:52,376 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:52,758 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:52,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:53,176 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:53,282 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:53,534 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:53,630 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:54,089 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:54,191 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:54,235 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:54,333 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:54,333 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[AI_DEBUG] 生成的txt_content长度: 23334
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23334
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045af17566711409922954e80cd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e00cd17566711418614180e94e4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064717566711425925504e8ac5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059d17566711442642696e334c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566711449856581e3fb8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566711457286012e89fd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e04ea17566711459922437e3613'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.9
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23856
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23856
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007a17566711474152676ee400'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566711487848759e0a88'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043117566711495752002e205f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17311
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17311
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150414417566711532832862edc1c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006a17566711537921700ee3a4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-31 16:12:54,370 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:54,448 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:54,457 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:54,458 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:54,482 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:54,482 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:54,482 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:54,672 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:55,205 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:55,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:55,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:55,700 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:55,795 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150460817566711402492279e7acd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065a17566711409338062e82b6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23624
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23624
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566711437915424e82a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e058a17566711445953387e33a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c217566711454178925e8022'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043517566711461728804e2e7b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566711464191841e8956'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566711470711607ee668'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18694
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18694
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007317566711489367200ee356'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043b17566711494434170e238b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045b017566711513014300e8093'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150415c17566711519553645eeb69'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566711562552348e3d24'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct2025-08-31 16:12:56,019 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:56,430 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:56,430 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:56,662 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:56,678 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:56,679 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:56,713 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:56,713 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:56,714 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:56,739 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:56,748 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:56,749 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:56,783 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:56,783 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:56,783 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:56,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:12:57,022 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:57,044 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066317566711441455095e830d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566711454144545e7fd7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041717566711459017704e985b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566711466933516e7b1c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23989
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23989
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059d17566711477496716e359e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065a17566711482575715e8127'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066e17566711501553164e7e5c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064e17566711506613753e81e3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150449017566711529737692e80a5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.5s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15447
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15447
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566711555986322e1297'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566711562578820e80fc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007b17566711578363005eeba4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e080f17566711585782767e0bdc'}2025-08-31 16:12:57,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:57,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:57,554 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:57,555 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:57,591 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:57,591 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:57,591 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:58,001 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:58,001 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:58,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:58,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:58,554 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:58,563 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:58,563 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:58,591 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:58,591 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:58,591 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:58,854 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:59,052 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:59,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:59,267 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:59,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:12:59,643 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:12:59,644 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:12:59,669 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:12:59,669 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:12:59,669 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:12:59,966 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:00,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:00,479 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:00,522 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:00,625 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:00,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:01,026 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:01,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:01,783 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:01,789 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:01,850 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:02,198 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:02,280 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:02,366 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:02,472 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:02,719 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:02,759 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:02,929 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:03,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:03,324 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:03,633 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:03,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:04,294 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:04,294 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:04,460 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:04,477 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:04,818 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:05,164 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:05,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:05,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:05,520 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:06,006 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:06,199 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:06,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:06,401 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:06,402 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:06,427 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:06,427 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:06,427 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:06,623 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:06,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:07,033 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:07,515 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:07,714 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:07,839 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:07,963 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:07,963 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:08,332 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:08,606 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:09,012 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:09,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:09,048 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:09,048 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:09,074 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:09,074 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:09,074 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:09,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:09,312 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:09,343 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:09,535 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:09,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:10,326 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:10,585 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:10,851 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:11,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:11,776 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:11,810 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:11,922 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:11,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:12,003 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:12,003 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:12,035 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:12,036 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:12,036 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:12,036 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:12,685 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,104 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,216 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,220 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,230 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:13,231 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:13,233 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566711545687981e8453'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e00cd17566711561198915e9736'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566711566492189eea72'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215041e117566711574015152e32cf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e004f17566711578478610ee6da'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566711587453893e7fa2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e004f17566711599618171ee90b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566711605858659e8a42'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006d17566711625425056e11b4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.2s before retry...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15588
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15588
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3382
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3382
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-31 16:13:13,233 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:13,265 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:13,265 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:13,265 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:13,267 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:13,267 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:13,267 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:13,437 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,825 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:13,930 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:13,941 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:13,941 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:13,967 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:13,967 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:13,967 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:14,128 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:14,256 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:14,410 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:14,492 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:14,781 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:14,784 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18436
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18436
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566711569824410e80fa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007f17566711574821120eec55'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566711579808425e8004'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007517566711589815900eef0d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007f17566711598014415eeac9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006c17566711602147596e148f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566711618991452e8134'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566711624817841e8018'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.8s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3386
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3386
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3352
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3352
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct2025-08-31 16:13:14,788 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194787766.json
2025-08-31 16:13:14,789 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194788843.json
2025-08-31 16:13:14,789 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194789420.json
2025-08-31 16:13:14,789 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194789702.json
2025-08-31 16:13:14,790 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194789927.json
2025-08-31 16:13:14,792 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194790207.json
2025-08-31 16:13:14,792 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194792240.json
2025-08-31 16:13:14,792 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194792528.json
2025-08-31 16:13:14,792 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194792770.json
2025-08-31 16:13:14,793 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194793014.json
2025-08-31 16:13:14,793 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194793511.json
2025-08-31 16:13:14,794 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194793897.json
2025-08-31 16:13:14,794 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194794136.json
2025-08-31 16:13:14,794 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194794328.json
2025-08-31 16:13:14,794 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194794542.json
2025-08-31 16:13:14,795 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194794745.json
2025-08-31 16:13:14,795 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194795278.json
2025-08-31 16:13:14,795 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194795578.json
2025-08-31 16:13:14,796 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194796009.json
2025-08-31 16:13:14,796 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671194796197.json
2025-08-31 16:13:14,859 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:14,903 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:15,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:15,304 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:15,437 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:15,442 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:15,661 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:16,469 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:16,693 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:16,701 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042b17566711592746657e1de4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566711603161653ee668'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007217566711608638333eec07'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17153
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17153
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007917566711620021294eebc2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007b17566711625092928eed72'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [PARSE] Fuzzy matched 'file_operations_reader(source="data/input.json")' to 'file_operations_reader'
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3330
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3330
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[ERROR] Empty message content from API
[DEBUG] Response finish_reason: stop
[DEBUG] Token usage - prompt: 2498, completion: 0
[DEBUG] Model: qwen2.5-14b-instruct
[DEBUG] Message fields: dict_keys(['content', 'refusal', 'role', 'annotations', 'audio', 'function_call', 'tool_calls'])
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3370
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3370
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...
2025-08-31 16:13:16,979 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:17,220 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:17,610 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:18,117 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:18,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:18,493 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:18,689 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:18,994 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:18,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:19,001 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199000575.json
2025-08-31 16:13:19,001 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199001177.json
2025-08-31 16:13:19,001 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199001579.json
2025-08-31 16:13:19,003 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199001858.json
2025-08-31 16:13:19,003 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199003677.json
2025-08-31 16:13:19,004 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199003958.json
2025-08-31 16:13:19,004 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199004267.json
2025-08-31 16:13:19,004 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199004552.json
2025-08-31 16:13:19,005 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199004985.json
2025-08-31 16:13:19,005 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199005244.json
2025-08-31 16:13:19,005 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199005466.json
2025-08-31 16:13:19,005 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199005676.json
2025-08-31 16:13:19,006 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199005949.json
2025-08-31 16:13:19,006 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199006252.json
2025-08-31 16:13:19,006 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199006660.json
2025-08-31 16:13:19,007 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199007000.json
2025-08-31 16:13:19,007 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199007303.json
2025-08-31 16:13:19,007 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199007608.json
2025-08-31 16:13:19,008 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199007912.json
2025-08-31 16:13:19,008 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671199008320.json
2025-08-31 16:13:19,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:19,879 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:21,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:21,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:21,074 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:21,601 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:21,687 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:22,212 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:22,240 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:22,241 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:22,284 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:22,284 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:22,284 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:22,726 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:23,204 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:23,214 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:23,215 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:23,256 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:23,256 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:23,256 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:23,692 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:23,852 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:23,865 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:23,867 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:23,923 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:23,924 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:23,924 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:23,924 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:24,048 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:24,591 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:24,595 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:24,603 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:24,603 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:24,651 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:24,651 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:24,651 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:24,798 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:24,860 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:24,868 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:24,868 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:24,903 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:24,903 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:24,903 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:25,303 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:25,471 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:25,525 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:25,527 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205527195.json
2025-08-31 16:13:25,528 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205527940.json
2025-08-31 16:13:25,528 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205528302.json
2025-08-31 16:13:25,529 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205528591.json
2025-08-31 16:13:25,529 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205529101.json
2025-08-31 16:13:25,529 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205529475.json
2025-08-31 16:13:25,529 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205529739.json
2025-08-31 16:13:25,530 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205529994.json
2025-08-31 16:13:25,530 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205530249.json
2025-08-31 16:13:25,530 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205530504.json
2025-08-31 16:13:25,531 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205530738.json
2025-08-31 16:13:25,531 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205531076.json
2025-08-31 16:13:25,532 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205531998.json
2025-08-31 16:13:25,533 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205532699.json
2025-08-31 16:13:25,533 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205533296.json
2025-08-31 16:13:25,533 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205533689.json
2025-08-31 16:13:25,534 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205533985.json
2025-08-31 16:13:25,534 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205534278.json
2025-08-31 16:13:25,534 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205534559.json
2025-08-31 16:13:25,535 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671205534786.json
2025-08-31 16:13:25,601 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:25,608 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:25,622 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:25,631 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:25,631 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:25,664 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:25,664 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:25,665 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:25,955 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:26,315 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:26,315 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [PARSE] Fuzzy matched 'network_fetcher(source="https://api.example.com/data")' to 'network_fetcher'
  [EXECUTING] network_fetcher
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3324
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3324
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [INFO] Tool info request: data_processing_parser

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566711887605718e7f5e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3488
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3488
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)2025-08-31 16:13:26,342 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [PARSE] Fuzzy matched 'network_fetcher(source="https://api.example.com/data", timeout=30, retry_count=3, options={})' to 'network_fetcher'
  [EXECUTING] network_fetcher
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 25697
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25697
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: data transformation

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006c17566711888775888e12c1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 25476
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25476
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG RAG] network_poster semantically matched with network_fetcher (score: 0.627)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.852025-08-31 16:13:26,862 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:27,363 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:27,721 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:28,013 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:28,599 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:28,935 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:29,281 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:30,096 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:30,594 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:31,213 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data transformation

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20631
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20631
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 24036
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24036
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007a17566711939254047ee2d7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566711946634551e76ae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065017566711952384096e815d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007c17566711965166029eef6c'}2025-08-31 16:13:31,266 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:31,670 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:32,082 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:32,189 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:32,620 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:33,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:33,654 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:33,784 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:33,797 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:33,797 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:33,825 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:33,826 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:33,826 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:34,511 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:34,747 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:34,759 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:34,760 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:34,787 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:34,787 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:34,787 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:35,228 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:35,228 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:35,238 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:35,239 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:35,251 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:35,252 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:35,266 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:35,271 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:35,272 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:35,272 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:35,276 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:35,277 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:35,282 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:35,282 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:35,282 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:35,302 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:35,302 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:35,302 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:35,856 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:35,900 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:36,006 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:36,129 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:36,503 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:36,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:37,421 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:37,429 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:37,429 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:37,454 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:37,454 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:37,454 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:37,518 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:37,740 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:37,850 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:38,178 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:38,373 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:38,402 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:38,699 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:38,951 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:39,505 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:39,808 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:40,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:40,295 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:40,470 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:40,814 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:40,995 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:41,517 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:41,942 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:42,167 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:42,937 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566711945558426e8749'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566711952342099e2003'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a017566711962693697e767a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043a17566711967737229e206c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e011517566711981995016e92f3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23458
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23458
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e04ea17566711988922523e3613'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06ba17566712008208108e886f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064617566712025205937e0d06'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066417566712036526783e815a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566712043935041e83f0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066d17566712046645299e81ac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 1)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23618
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23618
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566712054138198e8024'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e069217566712060343907e8109'}2025-08-31 16:13:43,316 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:44,217 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:44,229 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:44,229 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:44,263 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:44,263 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:44,263 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:44,358 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:44,369 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:44,369 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:44,397 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:44,397 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:44,397 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e004f17566711973983713ee5d1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566711979222552e7f32'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 1)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22723
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22723
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566711996646363e79d2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007917566712014077778ee972'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c317566712020071696e7b38'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566712038382296e15d0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566712043935866e83c7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566712051082576e81b1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 36543
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=36543
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007d17566712054055915ef2b7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566712060476789e828a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566712078163009e7f50'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041917566712086606231e2b55'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18648
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18648
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-31 16:13:45,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 32894
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=32894
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e011517566711946633368e9188'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566711954492160e7f5a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566711964956946e823b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006017566711970176014ee217'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c217566711982761281e814a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059d17566711987961544e351a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566712008327098e3ffa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 37543
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=37543
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566712014834331e7a77'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a017566712030003294e76dd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566712037307575e8243'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566712046022222e721b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065017566712054155716e7f4e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12207
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12207
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062017566712061522031e8046'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching2025-08-31 16:13:45,012 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:45,500 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:45,849 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:46,236 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:46,257 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:46,597 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:46,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:13:46,666 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:46,666 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:46,691 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:46,691 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:46,691 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:46,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:47,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:48,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:48,234 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:48,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:48,389 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:48,921 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:49,014 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:49,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:49,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:49,435 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:49,446 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:49,476 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:49,825 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:49,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:50,200 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:50,275 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:50,277 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:50,316 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:50,316 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:50,316 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:50,434 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:50,751 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:50,760 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:51,227 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:51,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:51,526 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:51,682 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:51,834 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:52,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:52,214 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:52,289 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:52,596 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:52,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:52,954 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:53,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:53,406 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:53,580 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:53,795 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:53,821 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:54,103 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:54,309 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:54,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:54,843 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:54,878 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:54,882 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:55,385 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:55,445 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:55,847 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:55,900 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,243 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,338 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:56,362 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,473 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,484 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:56,484 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:56,486 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,507 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:56,507 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:56,507 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:56,756 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:56,917 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:56,917 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:56,949 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:56,949 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:56,949 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:57,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:57,487 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:57,499 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:57,500 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:57,522 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:57,522 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:57,522 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566712071118305e8a84'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566712084116116e88b7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007617566712090741117e1143'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062017566712110678952e833f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566712118256413e8b93'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 32572
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=32572
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566712145586205e89e9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042b17566712150561475e1b30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e058a17566712157923295e36e1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059d17566712163074017e334b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059717566712176427108e3864'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566712181507398e3e2c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006717566712196064197edf6a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566712201096346e3be4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 25933
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25933
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566712217434110ee49a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066417566712227415174e8208'}2025-08-31 16:13:57,619 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:57,772 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:57,773 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:57,773 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:13:57,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:58,162 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:58,731 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:58,940 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:59,022 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:59,035 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:59,035 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:59,063 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:59,063 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:59,063 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:59,143 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:59,154 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:13:59,154 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:13:59,189 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:13:59,189 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:13:59,189 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:13:59,244 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:59,360 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:59,778 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:13:59,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:00,278 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:00,394 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:00,443 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:00,812 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:00,826 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:00,919 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:01,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:01,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:01,572 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:01,968 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:02,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:02,150 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:02,259 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:02,339 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:03,015 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:03,015 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:03,199 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:03,396 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:03,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:03,648 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:03,703 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:03,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:04,223 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:04,272 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:04,402 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:04,615 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:05,002 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:05,215 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:05,238 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:05,530 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:05,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:06,007 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:06,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:06,163 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062b17566712114744157e811b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566712119841617e7fa3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065917566712135888635e8262'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041717566712143206830e9819'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043b17566712149262404e24d5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e004f17566712156554684ee6b9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007517566712159311808ef151'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566712173113968e6ee9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12183
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12183
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066d17566712182137166e7fbc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566712187468562e885b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566712200857039e8bb6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566712206128805e8325'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3136
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3136
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150439017566712241448867e24c3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-31 16:14:06,173 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:06,707 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:06,735 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:07,052 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:07,210 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:07,210 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:07,734 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:07,734 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:07,746 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:14:07,747 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:14:07,791 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:14:07,791 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:14:07,791 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:14:08,257 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:08,257 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:08,274 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:14:08,275 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:14:08,306 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:14:08,307 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:14:08,307 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:14:08,782 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:08,887 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:09,307 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:09,479 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:09,732 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:09,744 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:14:09,745 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:14:09,772 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:14:09,772 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:14:09,772 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:14:09,830 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:10,355 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:10,366 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:14:10,366 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:14:10,394 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:14:10,394 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:14:10,394 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:14:10,631 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:10,880 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:10,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:11,021 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566712066723662e78e0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007217566712075292391eed0f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a017566712098973307e76dd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566712104024761e8726'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.74
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14229
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14229
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c817566712133748760e80cc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043517566712149791292e2f62'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566712157024414eee4b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064e17566712167163827e830c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007e17566712172285479eef38'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066417566712179905725e81ae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566712185113537e7fe3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566712193126103e8b21'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566712202326371e0c78'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566712212938107e7e48'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3239
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3239
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416417566712248096030e1070'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 16:14:11,058 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:11,628 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:11,701 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:12,027 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:12,068 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:12,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:12,597 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:12,836 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:13,089 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:13,176 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:13,500 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:13,812 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:14,234 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:14,316 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:14,756 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:14,802 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:15,377 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:15,401 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:15,821 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:15,837 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:16,283 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:16,317 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:16,400 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:16,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417917566712240183073eec3c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150415b17566712248044519ee59c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150436a17566712264544360e2414'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12326
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12326
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17199
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17199
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-31 16:14:16,980 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:16,986 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:17,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:17,389 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:17,984 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:18,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:18,408 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:18,444 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:19,063 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:19,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:19,441 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:20,116 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:20,144 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:20,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:20,615 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct
2025-08-31 16:14:20,615 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:14:20,638 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:14:20,638 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:14:20,638 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:14:21,084 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:21,092 - api_client_manager - INFO - Created idealab client for model qwen2.5-14b-instruct


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566712256623510e80c4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566712263973244e0b91'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12183
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12183
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3178
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3178
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.722025-08-31 16:14:21,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:14:21,119 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:14:21,119 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:14:21,119 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:14:21,216 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:21,722 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:22,519 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:23,054 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:23,059 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263056762.json
2025-08-31 16:14:23,061 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263059847.json
2025-08-31 16:14:23,064 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263061411.json
2025-08-31 16:14:23,065 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263064269.json
2025-08-31 16:14:23,066 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263065303.json
2025-08-31 16:14:23,067 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263066212.json
2025-08-31 16:14:23,068 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263067426.json
2025-08-31 16:14:23,068 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263068142.json
2025-08-31 16:14:23,070 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263069174.json
2025-08-31 16:14:23,070 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263070256.json
2025-08-31 16:14:23,071 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-14b-instruct:30)
2025-08-31 16:14:23,076 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 30 个结果到收集器: qwen2.5-14b-instruct_40039_1756671263071740.json
2025-08-31 16:14:23,076 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-14b-instruct:30)
2025-08-31 16:14:23,214 - batch_test_runner - INFO - Database saved successfully
2025-08-31 16:14:23,215 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 16:14:23,215 - batch_test_runner - INFO - ============================================================
2025-08-31 16:14:23,215 - batch_test_runner - INFO - Batch test completed at 2025-08-31T16:14:23.215528
2025-08-31 16:14:23,215 - batch_test_runner - INFO - Summary:
2025-08-31 16:14:23,215 - batch_test_runner - INFO -   - Total tests: 30
2025-08-31 16:14:23,215 - batch_test_runner - INFO -   - Successful: 1
2025-08-31 16:14:23,215 - batch_test_runner - INFO -   - Failed: 29
2025-08-31 16:14:23,215 - batch_test_runner - INFO -   - Success rate: 3.3%
2025-08-31 16:14:23,215 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_161035.log
2025-08-31 16:14:23,215 - batch_test_runner - INFO - ============================================================
2025-08-31 16:14:23,215 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-31 16:14:23,215 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-31 16:14:23,216 - result_merger - INFO - 发现71个新的结果文件
2025-08-31 16:14:23,269 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:14:23,270 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-31 16:14:23,656 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:14:24,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:24,677 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:24,742 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:25,176 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:26,648 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:27,178 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:28,230 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:28,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:30,800 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:32,184 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:32,188 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The failure is reported as an Unknown error with no tool trace or task details. This most often indicates the agent passed incorrect or missing 
2025-08-31 16:14:32,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:32,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:14:33,937 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:37,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:39,495 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:40,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:40,774 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected and no plan was formed due to unknown task context; the agent effectively failed to make a tool-choosing decision, which is a
2025-08-31 16:14:43,062 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:45,993 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:48,089 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:48,091 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is unknown; there is insufficient evidence to attribute a specific agent decision error (tool selection/parameter/sequ
2025-08-31 16:14:49,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:51,812 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:53,639 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:53,641 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to execute the required workflow steps; no tools were selected or run, effectively skipping the task sequence (no initial step pe
2025-08-31 16:14:56,259 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:57,942 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:57,946 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297945117.json
2025-08-31 16:14:57,947 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297946922.json
2025-08-31 16:14:57,948 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297947708.json
2025-08-31 16:14:57,950 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297949363.json
2025-08-31 16:14:57,951 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297950798.json
2025-08-31 16:14:57,952 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297952087.json
2025-08-31 16:14:57,953 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297952708.json
2025-08-31 16:14:57,953 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297953112.json
2025-08-31 16:14:57,956 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297953436.json
2025-08-31 16:14:57,957 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297956409.json
2025-08-31 16:14:57,957 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297957247.json
2025-08-31 16:14:57,958 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297957883.json
2025-08-31 16:14:57,959 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297958524.json
2025-08-31 16:14:57,960 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297959097.json
2025-08-31 16:14:57,960 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297960350.json
2025-08-31 16:14:57,961 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-14b-instruct:35)
2025-08-31 16:14:57,966 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 35 个结果到收集器: qwen2.5-14b-instruct_40037_1756671297961792.json
2025-08-31 16:14:57,966 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-14b-instruct:35)
2025-08-31 16:14:58,038 - batch_test_runner - INFO - Database saved successfully
2025-08-31 16:14:58,038 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 16:14:58,038 - batch_test_runner - INFO - ============================================================
2025-08-31 16:14:58,038 - batch_test_runner - INFO - Batch test completed at 2025-08-31T16:14:58.038544
2025-08-31 16:14:58,038 - batch_test_runner - INFO - Summary:
2025-08-31 16:14:58,038 - batch_test_runner - INFO -   - Total tests: 35
2025-08-31 16:14:58,038 - batch_test_runner - INFO -   - Successful: 1
2025-08-31 16:14:58,038 - batch_test_runner - INFO -   - Failed: 34
2025-08-31 16:14:58,038 - batch_test_runner - INFO -   - Success rate: 2.9%
2025-08-31 16:14:58,038 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_161035.log
2025-08-31 16:14:58,038 - batch_test_runner - INFO - ============================================================
2025-08-31 16:14:58,039 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-31 16:14:58,039 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-31 16:14:58,039 - result_merger - INFO - 发现16个新的结果文件
2025-08-31 16:14:58,068 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:14:58,068 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-31 16:14:59,137 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:14:59,138 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any appropriate tool for the basic_task task; no tools were executed and no action was taken. This represents a 
2025-08-31 16:15:01,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:04,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:04,901 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or actions planned because the Task is Unknown/unclear, causing an agent decision to skip tool usage. This constitutes a to

[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 26434
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=26434
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: data parsing tool

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.87
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23346
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23346
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22244
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22244
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5435162928)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 16:15:07,266 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:07,270 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent did not execute any tools and did not establish or respect the necessary pipeline dependencies (e.g., data loading before analysis). No outputs 
2025-08-31 16:15:08,149 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:08,161 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308159186.json
2025-08-31 16:15:08,163 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308162260.json
2025-08-31 16:15:08,164 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308163756.json
2025-08-31 16:15:08,165 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308164372.json
2025-08-31 16:15:08,165 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308165293.json
2025-08-31 16:15:08,166 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308165823.json
2025-08-31 16:15:08,167 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308166518.json
2025-08-31 16:15:08,168 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308167305.json
2025-08-31 16:15:08,168 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308168264.json
2025-08-31 16:15:08,169 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308169101.json
2025-08-31 16:15:08,169 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308169586.json
2025-08-31 16:15:08,170 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308169995.json
2025-08-31 16:15:08,171 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308170589.json
2025-08-31 16:15:08,171 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308171109.json
2025-08-31 16:15:08,172 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 1 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308171627.json
2025-08-31 16:15:08,172 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-14b-instruct:35)
2025-08-31 16:15:08,177 - result_collector - INFO - 📤 已提交 qwen2.5-14b-instruct 的 35 个结果到收集器: qwen2.5-14b-instruct_40038_1756671308173451.json
2025-08-31 16:15:08,177 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-14b-instruct:35)
2025-08-31 16:15:08,262 - batch_test_runner - INFO - Database saved successfully
2025-08-31 16:15:08,263 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 16:15:08,263 - batch_test_runner - INFO - ============================================================
2025-08-31 16:15:08,263 - batch_test_runner - INFO - Batch test completed at 2025-08-31T16:15:08.263320
2025-08-31 16:15:08,263 - batch_test_runner - INFO - Summary:
2025-08-31 16:15:08,263 - batch_test_runner - INFO -   - Total tests: 35
2025-08-31 16:15:08,263 - batch_test_runner - INFO -   - Successful: 2
2025-08-31 16:15:08,263 - batch_test_runner - INFO -   - Failed: 33
2025-08-31 16:15:08,263 - batch_test_runner - INFO -   - Success rate: 5.7%
2025-08-31 16:15:08,263 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_161035.log
2025-08-31 16:15:08,263 - batch_test_runner - INFO - ============================================================
2025-08-31 16:15:08,263 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-31 16:15:08,263 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-31 16:15:08,264 - result_merger - INFO - 发现16个新的结果文件
2025-08-31 16:15:08,294 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:15:08,294 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-31 16:15:10,203 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:10,209 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to handle the (unknown) task, effectively choosing no tool when a tool was required, indicating a wron
2025-08-31 16:15:11,903 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:11,905 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of an agent decision error (no tool selections, parameters, or sequence were attempted). The task shows zero tool usage and an 'Unknow
2025-08-31 16:15:12,581 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:12,582 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The task metadata provides no executed tools and the error is d
2025-08-31 16:15:15,351 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:15,353 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of an agent decision (no tools were executed). The error message indicates a general tool/system failure ('Unknown error'), which is n
2025-08-31 16:15:17,972 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:17,974 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to resolve task dependencies due to an unknown task context, resulting in no tool selection or parameter configuration. Without a defined
2025-08-31 16:15:19,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:19,427 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of any agent decision (tool selection, parameter config, sequence, or dependencies) since no tools were executed and the error is labeled 'Unkn
2025-08-31 16:15:20,795 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:20,797 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initiated for the multi_stage_pipeline, resulting in zero executed steps. This indicates an incorrect initial tool decis
2025-08-31 16:15:24,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:24,014 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected. The task required no tools (coverage 0/0) and there is an 'Unknown error' indicating a system-level failure rather than a
2025-08-31 16:15:24,693 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:24,697 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and/or initialize the required tools for the multi_stage_pipeline; no tools were executed, indicating a decision to abs
2025-08-31 16:15:25,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:25,062 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there were no required tools and no tool usage planned or executed. The failure is attributed to an unknown system error 
2025-08-31 16:15:28,461 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:28,464 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool(s) required to perform the data_pipeline task; no tools were invoked, indicating a missing or incorrec
2025-08-31 16:15:29,370 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:29,371 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any tool appropriate for the api_integration task; no tools were executed, indicating a wrong or missing too
2025-08-31 16:15:31,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:31,620 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The API integration task requires an HTTP/API client tool, but the agent did not select or initialize any appropriate tool, resulting in 0% tool c
2025-08-31 16:15:32,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:32,667 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to initiate or follow the required workflow sequence (no tools invoked / no steps executed), effectively breaking the execution order
2025-08-31 16:15:36,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:36,022 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the multi_stage_pipeline; the agent failed to choose the required tools (i.e., failed to select data loadin
2025-08-31 16:15:38,487 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:38,499 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "unknown_error",
  "reason": "Insufficient information to identify a specific agent decision error. No tools were executed, and there are no defined parameters, sequence, or dependenci
2025-08-31 16:15:38,501 - focused_ai_classifier - WARNING - Unknown category from AI: unknown_error, defaulting to OTHER
2025-08-31 16:15:39,009 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:39,012 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to perform any actionable steps or follow the required task workflow for a simple_task (no tools selected or actions taken). This
2025-08-31 16:15:40,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:40,301 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No data_pipeline tools were selected or invoked; the agent effectively chose not to perform any steps, resulting in a stalled workflow. This is a 
2025-08-31 16:15:43,515 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:43,516 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the task (0% coverage), indicating the agent failed to choose an appropriate tool or initiate tooling for t
2025-08-31 16:15:45,238 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:45,240 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or propose any tool for the unknown task, effectively skipping tool invocation. This indicates a tool-selection/plan-form
2025-08-31 16:15:46,873 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:46,874 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a tool-selection, parameter, sequence, or dependency mistake by the agent. The run shows 0 executed tools and an 'Unknown error', which poin
2025-08-31 16:15:48,985 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:48,987 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected or executed and there is insufficient information to attribute a wrong agent decision. The error message is 'Unknown error', so there 
2025-08-31 16:15:50,480 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:50,483 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong tool choice, incorrect parameters, improper sequence, or unmet dependencies. The error message is 'Unknown error' with no tool execu
2025-08-31 16:15:52,619 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:52,620 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any tool for the task, effectively skipping processing. This is a tool-selection decision error (no tool chosen)

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3241
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3241
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5150162784)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3244
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3244
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 9 format helps, final result: failure
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23954
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23954
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 28381
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=28381
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-31 16:15:52,943 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:52,944 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task; the agent did not choose a required tool or configure any workflow steps, effectivel

[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23915
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23915
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
Progress: 30/30 (Success: 1)
💾 智能Checkpoint: 保存10个结果...
   触发原因: 数量=10, 时间=68.3s, 强制=True
✅ Checkpoint完成: 成功保存 10/10 个结果

[INFO] Batch writing 30 records to database (qwen2.5-14b-instruct:30)
[INFO] Successfully wrote 30/30 records (qwen2.5-14b-instruct:30)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_161423.json
[SAVE_ENHANCED] 开始增强保存，时间: 16:14:23
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: parameter_config_errors (confidence: 0.48) - The failure is reported as an Unknown error with n
[V3_UPDATE] 创建新prompt类型结构: qwen2.5-14b-instruct -> baseline
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-14b-instruct -> baseline -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.62) - No tool was selected and no plan was formed due to
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.65) - No tools were executed and the error is unknown; t
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: dependency_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.85) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.72) - No evidence of any agent decision (tool selection,
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error detected. The task require
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 2)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.60) - The agent did not select or propose any tool for t
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 6)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.55)
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 8)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors2025-08-31 16:15:54,853 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:54,854 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identifiable: no tools were chosen or executed due to an unknown system error; cannot assess tool selection, parameter choices, seq
2025-08-31 16:15:58,623 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:58,628 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error is reported as Unknown error. There is no evidence of a wrong tool choice, incorrect parameters, incorrect
2025-08-31 16:15:58,870 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:58,872 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any required tools for the api_integration task, effectively skipping tool selection; no tools were execute
2025-08-31 16:15:59,138 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:15:59,139 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required API integration actions/tools, but no tools were selected or executed (no tool usage, no parameters). This indicates an incorrec
2025-08-31 16:16:05,000 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:05,006 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent failed to initialize and execute any stages; no required tools were invoked, effectively ignoring the prerequisites and dependencies of the 
2025-08-31 16:16:05,492 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:05,494 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of incorrect agent decisions (tool choice, parameters, sequence, or dependencies). The error is an Unknown error with no tools executed, sugges
2025-08-31 16:16:09,488 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:09,492 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "In a multi_stage_pipeline task, the complete failure with no tools executed suggests the agent did not follow the required stage order or failed t
2025-08-31 16:16:11,830 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:11,862 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent did not establish or respect dependencies for a multi-stage pipeline: no stages or execution plan were defined, so prerequisites and executi
2025-08-31 16:16:11,875 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:11,878 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Task requires no tools (0/0 coverage). The agent selected or planned to use a tool despite there being no required tools, which is an incorrect de
2025-08-31 16:16:13,693 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:13,695 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent actions or tool usage were observed; the failure appears to be an external/unknown error not caused by incorrect tool choice, parameterization, se
2025-08-31 16:16:16,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:16,818 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent tool selections or executions are observable in the provided trace; there is no evidence of incorrect tool choice, wrong parameters, improper sequ

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3280
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3280
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-14b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-14b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5471131920)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [SEARCH] Query: file reader for json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3161
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3161
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3172
2025-08-31 16:16:17,874 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:17,877 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute the required data_pipeline steps in the correct sequence (no steps were performed). This indicates a failure to initiali
2025-08-31 16:16:18,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:18,180 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were used and required tools coverage is 0%, indicating the agent failed to select or apply the appropriate tool for the (unknown) task. 
2025-08-31 16:16:23,824 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:23,828 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initiate any tool appropriate for the API integration task; no tools were used, indicating a missing or incorrect tool c
2025-08-31 16:16:23,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:23,899 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error. There is no record of tool usage, parameter choices, or execution sequence; the error
2025-08-31 16:16:23,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:23,910 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision mistakes can be identified: no tools were selected or invoked, and there is no evidence of mis-sequencing, wrong parameters, or improper 
2025-08-31 16:16:28,753 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:28,755 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool for the multi_stage_pipeline task, resulting in zero tool usage and no progression. This constitut

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066e17566712610254144e7e5d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063717566712615428938e8a36'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150455f17566712623335521e81aa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566712638386181e7155'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045b417566712644857140e812e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417c17566712649867270ef1a3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
Progress: 30/35 (Success: 1)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21972
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21972
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042f17566712669798817e24b6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059717566712680348611e3674'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e081017566712685793709e0bf4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566712722074823e83ae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06ba17566712727048099e8b05'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23327
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23327
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21222
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21222
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3240
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3240
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11160
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11160
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
💾 智能Checkpoint: 保存15个结果...
   触发原因: 数量=15, 时间=98.9s, 强制=True
✅ Checkpoint完成: 成功保存 15/15 个结果

[INFO] Batch writing 35 records to database (qwen2.5-14b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-14b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_161457.json
[SAVE_ENHANCED] 开始增强保存，时间: 16:14:57
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65) - No tools were selected or actions planned because 2025-08-31 16:16:29,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:29,156 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence to classify under tool_selection_errors, parameter_config_errors, sequence_order_errors, or dependency_errors. The task shows Un

[V3_UPDATE] 创建新prompt类型结构: qwen2.5-14b-instruct -> baseline
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-14b-instruct -> baseline -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60) - The agent did not select or invoke any tool to han
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.80) - There is no evidence of an agent decision (no tool
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.20) - Insufficient information to identify a specific ag
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65) - No tools were selected or executed for the task (0
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No tool was selected or executed and there is insu
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.42)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.85) - No agent actions or tool usage were observed; the 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - No tools were used and required tools coverage is 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 4)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...2025-08-31 16:16:30,226 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:30,230 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected. There were no tool selections or executions (coverage 0%), and the error message is Unknown error, indicating a system/to
2025-08-31 16:16:33,471 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:33,473 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed; the agent failed to choose the required tooling for the multi-stage pipeline, effectively halting before any p
2025-08-31 16:16:34,132 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:34,132 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any appropriate tool for the api_integration task; no tools were executed. This represents a wrong decision at 
2025-08-31 16:16:35,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:35,363 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Task failed due to an unknown internal error with no tools executed; no agent decision could be evaluated, so no tool selection, parameter, sequence, or de
2025-08-31 16:16:37,788 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:37,792 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API integration tool was selected or executed; the agent failed to choose the required tool(s) for an api_integration task, leading to complete
2025-08-31 16:16:39,947 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:39,950 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize an actionable tool/path to start the multi-stage pipeline (no tools executed). With an unknown task and no 
2025-08-31 16:16:41,583 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:41,584 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools, yet the agent behavior implied tool usage. This indicates a wrong tool selection decision or applying tools in a scena
2025-08-31 16:16:44,721 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:44,721 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the multi_stage_pipeline task, resulting in 0% tool coverage. The agent failed to initiate the required too
2025-08-31 16:16:47,101 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:47,101 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to define or execute the required multi-stage pipeline steps in the defined order; no stages were executed, breaking the expected
2025-08-31 16:16:48,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:48,245 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed for a task that required action; the agent effectively chose 'no tool', which is an incorrect tool selection/no-o
2025-08-31 16:16:50,606 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:50,607 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the multi_stage_pipeline task. The agent effectively omitted required tooling, resulting in no progress. Th
2025-08-31 16:16:54,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:54,518 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or invoke any tool to perform the task (no tools executed). This represents a tool-selection/decision error: no action 
2025-08-31 16:16:57,238 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:57,239 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or actions taken for an api_integration task, and the task context is Unknown. This indicates the agent failed to choose an
2025-08-31 16:16:58,637 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:58,639 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions/tools were executed and no execution sequence was established for the api_integration task. The agent failed to define or follow a cohe
2025-08-31 16:16:59,159 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:16:59,159 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions were observed (no tool selections, parameter configurations, or execution sequence were made) due to an unknown/system error. This is no
2025-08-31 16:17:03,662 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:03,662 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision can be identified. No tools were selected or executed (tool coverage 0%), and the error message 'Unknown error' indicates a sy
2025-08-31 16:17:03,764 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:03,765 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error reported is 'Unknown error', indicating a system/tool-level failure rather than a wrong agent decision (no
2025-08-31 16:17:07,359 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:07,360 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Error appears to be a system-level unknown failure with no discernible agent tool selection, parameterization, sequence, or dependency decision evident. Si
2025-08-31 16:17:08,235 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:08,235 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error with no tool executions or discernible agent decisions available. Cannot attribute failure to tool_selection, parameter_config, sequence_orde
2025-08-31 16:17:08,978 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:08,978 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool executions occurred and the error message is 'Unknown error', indicating a system/tool-level failure rather than a mis-decision by the agent. Witho
2025-08-31 16:17:14,199 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:14,200 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or engage any necessary tool for the api_integration task; no tools were executed despite the task requiring integration tool
2025-08-31 16:17:14,888 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:14,889 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and there is no identifiable agent decision path to evaluate (no tool choices, parameters, or sequence to critique). The
2025-08-31 16:17:14,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:14,899 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task requires an API interaction tool (HTTP client). The agent did not select or execute any API tool, effectively choosing no tool and stalli
2025-08-31 16:17:18,558 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:18,559 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize the required tools for the multi_stage_pipeline (no tools were chosen, resulting in 0% tool coverage). This
2025-08-31 16:17:20,143 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:20,144 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and execute any required tool for the api_integration task; no tools were invoked (0% coverage), indicating a missing tool-
2025-08-31 16:17:21,030 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:21,031 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no steps were performed, indicating the agent failed to initiate or follow the required execution sequence for the api_
2025-08-31 16:17:21,737 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:21,737 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required tool to execute the multi_stage_pipeline; no tools were invoked, preventing progress and indicatin
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3172
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-14b-instruct, API name: qwen2.5-14b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.66
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3242
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3242
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22253
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22253
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
Progress: 30/35 (Success: 2)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23180
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23180
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23481
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23481
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23471
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23471
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23180
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23180
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23943
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23943
  - task_model=qwen2.5-14b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
💾 智能Checkpoint: 保存15个结果...
   触发原因: 数量=15, 时间=102.6s, 强制=True
✅ Checkpoint完成: 成功保存 15/15 个结果

[INFO] Batch writing 35 records to database (qwen2.5-14b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-14b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_161508.json
[SAVE_ENHANCED] 开始增强保存，时间: 16:15:08
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-14b-instruct的新prompt_type: baseline
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.72) - There is no evidence of an agent decision error (n
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.68) - Agent failed to resolve task dependencies due to a
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.62) - No agent decision error detected: there were no re
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.70)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.09s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of a tool-selection, parameter, sequen
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No evidence of a wrong tool choice, incorrect para
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision error identifiable: no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.72) - No agent tool selections or executions are observa
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.72) - No agent decision mistakes can be identified: no t
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - No agent decision error detected. There were no to
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: sequence_order_errors (confidence: 0.62) - No actions/tools were executed and no execution se
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No actionable agent decision can be identified. No
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - Unknown error with no tool executions or discernib
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 6)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...2025-08-31 16:17:25,374 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:25,374 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any tool for the api_integration task, effectively halting progress due to a planning/selection misstep. No r
2025-08-31 16:17:27,486 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:27,487 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error is reported as Unknown error. There is insufficient evidence to attribute any specific agent decision erro
2025-08-31 16:17:27,874 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:27,876 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools or steps were executed; there is effectively no workflow sequence to follow, indicating the agent failed to initiate or carry out the req
2025-08-31 16:17:31,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:31,242 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage observed and no identifiable agent decision error (tool selection, parameter config, sequence, or dependencies). The error message is Unknown
2025-08-31 16:17:34,012 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:34,012 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no observable agent decision path (no tools executed; required tools coverage is 0/0). With the absence of evidence for toolS
2025-08-31 16:17:35,506 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:35,507 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no required tools or steps for this task (0/0). No agent decision (tool choice, parameterization, or sequence) could reasonably be evaluated, ye
2025-08-31 16:17:39,570 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:39,571 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any tool for the API integration task (no tools were executed). This constitutes a wrong tool decision, effectively choos
2025-08-31 16:17:39,572 - result_merger - INFO - 模型qwen2.5-14b-instruct保存50/50条记录
2025-08-31 16:17:39,584 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-31 16:17:39,585 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-31 16:17:39,589 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65) - No tools were selected or executed; the agent fail
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.63) - The agent did not select or initialize an actionab
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.80)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.63) - No tools were selected or actions taken for an api
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.75) - No tools were selected or executed and the error r
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.60) - No tool executions occurred and the error message 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.10s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No tool usage observed and no identifiable agent d
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65) - The agent did not select any tool for the API inte
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 27)
[INFO] 最终合并完成: 16 个文件
2025-08-31 16:17:39,764 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-31 16:17:39,764 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-31 16:17:40,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:40,292 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked; the workflow did not map the unknown task to any data_pipeline tool, effectively making a tool-selection decisi
2025-08-31 16:17:40,936 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:40,939 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Insufficient tool usage information and an unknown tool result; given zero required tool coverage and partial success with quality issues, the mos
INFO:__main__:✅ 分片1完成
INFO:__main__:等待分片2完成（20实例×50workers，最多等待50分钟）...
2025-08-31 16:17:44,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:44,249 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool to address the task (task context is unknown and no required tools were chosen). This indicates a tool
2025-08-31 16:17:45,298 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:45,299 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision or tool usage; the failure is an unknown/system-level error rather than a misdecision (tool choice, parameters, sequence, or d
2025-08-31 16:17:45,302 - result_merger - INFO - 模型qwen2.5-14b-instruct保存50/50条记录
2025-08-31 16:17:45,310 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-31 16:17:45,312 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-31 16:17:45,315 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 14)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 24)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No tools were selected or executed and the error i
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.62) - Insufficient tool usage information and an unknown
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.80) - No observable agent decision or tool usage; the fa
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 26)
[INFO] 最终合并完成: 16 个文件
2025-08-31 16:17:45,530 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-31 16:17:45,531 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片2完成
INFO:__main__:等待分片3完成（20实例×50workers，最多等待50分钟）...
2025-08-31 16:17:52,233 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:17:52,235 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or decision path available to assess against tool_selection, parameter_config, sequence_order, or dependency errors. The error message 'Unkno
2025-08-31 16:18:02,665 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:02,667 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no workflow steps were invoked. This effectively means the agent did not establish a valid execution sequence or fail-s
2025-08-31 16:18:10,330 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:10,332 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were required for the task (0/0 coverage). The agent failed to produce any final result/output, effectively skipping the finalization ste
2025-08-31 16:18:16,109 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:16,110 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked to execute the basic_task, resulting in no output. This indicates a wrong initial tool/flow decision by the agen
2025-08-31 16:18:25,347 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:25,355 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there is no evidence of tool selection, parameter configuration, sequence ordering, or dependency issues. The failure app
2025-08-31 16:18:31,962 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:31,964 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decisions could be identified because no tools were executed and no specific tool-related decisions (selection, parameters, sequence, depend
2025-08-31 16:18:36,858 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:36,859 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision can be evaluated: there were no tools selected or executed and the error is unspecified. Without tool usage, tool selection, p
2025-08-31 16:18:42,975 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:42,982 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initiate any appropriate data_pipeline tooling for the task, effectively using no tool where a data processing tool should
2025-08-31 16:18:48,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:48,410 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select and execute any tool to perform the API integration task. No tools were invoked and no steps defined, indicating a tool-s
2025-08-31 16:18:56,271 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:18:56,271 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps or invoke any tools, effectively breaking the expected execution sequence for the task. With 0 required tools,
2025-08-31 16:19:01,682 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:01,682 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "An unknown system-level error prevented any tool execution; there were no agent decisions (tool selection, parameter config, sequence, or dependencies) to 
2025-08-31 16:19:05,657 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:05,658 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The error is reported as an unknown error with no tools execute
2025-08-31 16:19:15,999 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:16,001 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No workflow steps were executed and the task failed with an unknown error, indicating a misstep in flow control or sequencing (i.e., the agent did
2025-08-31 16:19:22,917 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:22,918 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps or produce output, effectively failing to execute the required workflow in the correct order (no steps A→B→C o
2025-08-31 16:19:30,710 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:30,710 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required for the basic_task and there is no explicit error message or any executed steps. The failure appears to be inaction or an undefined 
2025-08-31 16:19:35,668 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:35,669 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the data_pipeline task, so the agent effectively halted before any processing. In a data_pipeline task, 

[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 6)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 2)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-14b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 2)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors2025-08-31 16:19:40,116 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:40,117 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any tools or chose none suitable for the unknown task, resulting in 0% tool coverage. This is a tool_selection error (abs
2025-08-31 16:19:46,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:46,412 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any tool or identify required tooling due to an unknown task; effectively a tool-selection decision error (no appropriate too
2025-08-31 16:19:52,412 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:52,412 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be evaluated because no tools were executed and the error is labeled as Unknown error. There is no evidence of a token decision error
2025-08-31 16:19:56,729 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:19:56,730 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select any required tool(s) and did not establish the necessary tool sequence for the multi_stage_pipeline task, resulting in comp
2025-08-31 16:20:00,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:00,829 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task; the agent failed to pick the appropriate data processing tool(s), resulting in zero
2025-08-31 16:20:06,855 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:06,856 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for the data_pipeline task, effectively failing to choose the appropriate tool/plan to proceed. This 
2025-08-31 16:20:11,877 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:11,878 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked for a task that required tool execution, indicating a wrong tool decision (tool_selection_errors).",
  "confidence
2025-08-31 16:20:19,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:19,778 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for the data_pipeline task (no tools were chosen; Executed Tools: none; Error message: Unknown error)
2025-08-31 16:20:24,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:24,776 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there were no tools required or executed for the task, and the error appears to be an unknown/system issue rather than a 
2025-08-31 16:20:35,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:35,254 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any tools or steps, effectively yielding an empty execution sequence. This indicates a failure to initiate/complete the 
2025-08-31 16:20:39,362 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:39,363 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initiate any appropriate tool for the data_pipeline task (no tools used), resulting in zero execution steps. This is a 
2025-08-31 16:20:49,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:49,597 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error could be identified: there were no tools required (or executed), and the agent did not proceed with any actions. This appe
2025-08-31 16:20:54,324 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:54,325 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error can be identified: there were no tool selections, parameters, sequences, or dependencies executed (the task context is unk
2025-08-31 16:20:59,077 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:20:59,078 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no agent decisions (no tool selections, parameters, or sequence) to evaluate. The error is reported as Unknown error with no actionable steps, s
2025-08-31 16:21:03,037 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:03,038 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked to attempt the task, despite the task requiring tool usage. The agent failed to choose an appropriate tool (e.g., 
2025-08-31 16:21:09,275 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:09,275 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select/initialize any tools to execute the required multi_stage_pipeline; no tools were invoked despite the task needing sequentia
2025-08-31 16:21:17,635 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:17,636 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task required no tools and should have produced a result directly. The agent did not perform any steps and produced a complete failure, indica
2025-08-31 16:21:25,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:25,076 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps of the workflow; there is an implied initial action in the task, but the agent produced a no-op and failed to 
2025-08-31 16:21:34,629 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:34,631 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable evidence of any agent decision (no tools were executed; error is unspecified). Without tool usage or explicit missteps, cannot classify as to
2025-08-31 16:21:42,815 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:42,816 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision or tool execution occurred; error appears to be a system-level unknown error rather than a wrong tool choice, incorrect parameters, misor
2025-08-31 16:21:47,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:47,020 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any applicable tool (or selected an inappropriate one) for the data_pipeline task, resulting in zero tool coverage and partia
2025-08-31 16:21:51,792 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:51,792 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any of the necessary API integration tools for the api_integration task, resulting in zero tool execution an
2025-08-31 16:21:57,892 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:21:57,893 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed or selected for the task, indicating the agent failed to choose or apply an appropriate tool/path for progression (tool dec
2025-08-31 16:22:04,299 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:04,299 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute the data_pipeline steps in the correct sequential order, leading to incomplete data processing and quality issues. Essen
2025-08-31 16:22:09,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:09,619 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed; the agent failed to choose any appropriate tool for a multi-stage pipeline, effectively stalling at the decisi
2025-08-31 16:22:14,593 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:14,594 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error (not tool_selection_errors, parameter_config_errors, sequence_order_errors, or dependency_errors). The error message '
2025-08-31 16:22:22,247 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:22,251 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool/approach for the unknown task, effectively making a tool-selection decision error by choosing to p
2025-08-31 16:22:26,489 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:26,489 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or used incorrect tools for the multi_stage_pipeline task, resulting in 0% tool coverage and no proper execution sequence (no
2025-08-31 16:22:35,427 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:35,428 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps or invoke any tool, effectively omitting the required workflow. Without executing the required sequence, the t
2025-08-31 16:22:42,966 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:42,967 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "There is no evidence of any actions executed; the agent did not perform tasks in any sequence, effectively breaking the required workflow. This is
2025-08-31 16:22:51,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:51,127 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed (executed tools field is empty) and there is an 'Unknown error'. This suggests the agent failed to select or in
2025-08-31 16:22:55,997 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:22:55,997 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions are evidenced since no tools were executed and the error is 'Unknown error'. This failure is not attributable to tool selection, paramet
2025-08-31 16:23:03,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:03,798 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or propose any tool to handle the task (task context is unknown), resulting in zero tooling being executed and no progres
2025-08-31 16:23:10,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:10,360 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to execute the required task steps; no tool was selected or action taken, effectively breaking the expected execution sequence. Inact
2025-08-31 16:23:16,420 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:16,422 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and execute any tool for a task that required action; effectively omitted an essential step, indicating a wrong tool choice
2025-08-31 16:23:22,942 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:22,943 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or attempt any tool to perform the basic_task (no tools executed). With no required tools to cover and no actions taken, 
2025-08-31 16:23:28,343 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:28,345 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked; required tools coverage is 0%, indicating the agent failed to choose an appropriate tool to begin the task. Thi
2025-08-31 16:23:34,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:34,452 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: no tools were selected or executed (tool coverage 0/0); the failure appears to be a system-level/unknown error rather tha
2025-08-31 16:23:41,000 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:41,003 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute to any agent decision error. The error appears to be a system-level/unknown failure with no tools executed or observa
2025-08-31 16:23:47,523 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:47,524 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were executed and no workflow steps were performed; the agent failed to satisfy preconditions/dependencies of the task (action not taken), in

[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - No tools were selected or executed and the error i
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.72) - No evidence of incorrect agent decisions (tool cho
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.60) - Insufficient information to identify a specific ag
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.65) - No agent decision evidence to classify under tool_
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.70) - Task failed due to an unknown internal error with 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 20)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.85) - No agent decisions were observed (no tool selectio
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.62) - Error appears to be a system-level unknown failure
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - No tools were selected or executed and there is no
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.52)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.55) - No tools were selected or invoked; the workflow di
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.85) - Agent did not select or initialize any tool to add
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.72) - No tool usage or decision path available to assess
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 24)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: sequence_order_errors (confidence: 0.56)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent decision error detected: there is no evid
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.75) - No agent-level decisions could be identified becau
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.65) - No actionable agent decision can be evaluated: the
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - An unknown system-level error prevented any tool e
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.85) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: sequence_order_errors (confidence: 0.52) - No workflow steps were executed and the task faile
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...2025-08-31 16:23:52,444 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:23:52,445 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any appropriate tool for the data_pipeline task (no data_loader/pdf_reader/etc. chosen), leading to zero tool
2025-08-31 16:24:00,979 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:00,980 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No action was taken and no steps were executed to complete the simple_task; the agent failed to follow an execution sequence or provide the requir
2025-08-31 16:24:07,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:07,505 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient data to attribute a specific agent decision error. There were no tools executed and no task requirements to evaluate tool selection, parameter
2025-08-31 16:24:12,723 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:12,724 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated due to lack of tool execution and an unknown error; there is no evidence of wrong tool choice, incorrect parameters, i
2025-08-31 16:24:17,713 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:17,714 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or an appropriate tool could be determined for an unknown task; the agent failed to establish a proper tool strategy or req
2025-08-31 16:24:22,595 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:22,597 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool for the api_integration task, effectively failing to choose the required integration tool(s); this rep
2025-08-31 16:24:34,135 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:34,140 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision can be identified: the task specifies zero required tools and there is no tool execution or parameter data. The failure appears 
2025-08-31 16:24:40,418 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:40,419 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the basic_task; there were no executed tools despite the task requiring action, indicating 
2025-08-31 16:24:47,294 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:47,295 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error: no tools were selected or executed due to lack of task details; the failure appears external/unknown rather than a wron
2025-08-31 16:24:51,246 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:51,248 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for a multi-stage_pipeline task; the agent failed to initialize or choose the required toolchain, resulting in 0
2025-08-31 16:24:55,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:24:55,970 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or use any data_pipeline tools, effectively making a tool-choice decision error by failing to choose an appropriate tool 
2025-08-31 16:25:00,454 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:00,456 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No execution data and no explicit error; cannot identify a specific agent decision error. Insufficient information to attribute failure to tool_selection_e
2025-08-31 16:25:05,584 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:05,586 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any required tools for the multi_stage_pipeline task; there is no executed tool or step, indicating a wrong too
2025-08-31 16:25:09,989 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:09,991 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and/or initiate any data-pipeline tools. No tools were executed despite the task requiring a sequence of data-processing st
2025-08-31 16:25:15,973 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:15,975 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is reported as 'Unknown error'. There is no evidence of a deliberate wrong tool choice, incorrect parameters, wrong ex
2025-08-31 16:25:21,931 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:21,934 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence (no tools chosen, no parameters set, and no sequence executed) to attribute to a misdecision. The error appears to be a systemic
2025-08-31 16:25:28,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:28,831 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed due to an unknown error. With 0/0 tool coverage and an 'Unknown error' message, the primary agent decision erro
2025-08-31 16:25:33,543 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:33,545 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any appropriate tool for the simple_task; no tools were executed (Executed Tools is empty) despite the task requ
2025-08-31 16:25:42,434 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:42,436 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "For a simple_task with no required tools, the failure implies an incorrect tool decision—either selecting a tool unnecessarily or failing to proce
2025-08-31 16:25:50,179 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:50,182 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool/action for the task, effectively performing no operation. This constitutes an incorrect/tool-choice d
2025-08-31 16:25:57,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:25:57,272 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Primary decision error: the agent did not select or invoke any tool to perform the basic_task, effectively resulting in a 'do nothing' action due 
2025-08-31 16:26:03,080 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:03,081 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is insufficient evidence of a specific agent decision error (tool selection, parameter config, sequence order, or dependencies). The task shows an un
2025-08-31 16:26:09,375 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:09,377 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required for this task (0/0). The error message is Unknown error with no actionable agent decision path (no tool selection, parameters, or se
2025-08-31 16:26:17,949 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:17,951 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or invoke any tools for a basic_task, effectively failing to follow the expected workflow sequence. There is n
2025-08-31 16:26:22,131 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:22,132 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tools and failed to define the multi_stage_pipeline steps, resulting in zero executed actions. This is 
2025-08-31 16:26:26,631 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:26,632 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and execute any required tool for the data_pipeline task, effectively skipping actionable steps. No tools were executed and
2025-08-31 16:26:33,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:33,455 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No starting tool was selected or clarifying information requested; with an unknown task, the agent failed to choose an initial tool (tool selectio
2025-08-31 16:26:42,372 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:42,374 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not define or follow the required end-to-end data_pipeline sequence (no tools executed, no steps completed), resulting in partial qu
2025-08-31 16:26:47,615 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:47,616 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a wrong agent decision (no tools selected or executed). The error is reported as 'Unknown error' with no task details, so the failu
2025-08-31 16:26:53,064 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:53,066 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate or sequence any pipeline steps (no tools selected or executed), effectively breaking the required A→B→C workflow. This 
2025-08-31 16:26:57,477 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:26:57,479 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Partial success with data quality issues indicates the agent likely used incorrect or missing parameters/configuration for a tool in the pipelin
2025-08-31 16:27:06,938 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:06,940 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools (no dependencies), but the agent did not perform any step or select any tool. The primary agent decision error is an ab
2025-08-31 16:27:11,320 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:11,321 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a wrong agent decision. No tools were selected or executed, and the error message is generic ('Unknown error'). Without tool usage,
2025-08-31 16:27:18,012 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:18,016 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of an incorrect tool choice, wrong parameters, wrong sequence, or unmet dependencies. The error message is 'Unknown error' with no too
2025-08-31 16:27:22,673 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:22,675 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision or tool execution (no executed tools, unknown task, unknown error). Without execution data, we cannot attribute 
2025-08-31 16:27:28,191 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:28,193 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision data available: no tools were executed (Required Tools: 0; Executed Tools: 0), so cannot attribute failure to a wrong tool choic
2025-08-31 16:27:32,559 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:32,560 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initiate the appropriate data processing tool(s) for the data_pipeline task, resulting in zero tool execution and failure 
2025-08-31 16:27:38,987 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:38,989 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: the task (basic_task) required zero tools, so there was no tool selection, parameterization, or sequencing for the agent 
2025-08-31 16:27:43,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:43,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a specific agent decision error (no tool chosen, no parameters set, no sequence or dependency issue) and the error is described as 
2025-08-31 16:27:51,386 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:51,391 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error. The task shows an unknown tool execution issue with partial success (quality issues) but there is no evidence of the 
2025-08-31 16:27:56,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:27:56,774 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No task details and no tools were executed; error is reported as 'Unknown error' at a system level rather than a demonstrable agent decision. Therefore, th

[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.80) - The agent did not select any tools or chose none s
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.60) - Agent did not select any tool or identify required
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.72) - No agent decision can be evaluated because no tool
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 26)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.09s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85) - No tool was selected or invoked for a task that re
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.62) - The agent did not select or execute any tool for t
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.85) - No agent decision error detected: there were no to
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.64)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No concrete agent decision error can be identified
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.85) - There were no agent decisions (no tool selections,
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 33)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85) - No tool was selected or invoked to attempt the tas
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 29)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.60) - No actionable evidence of any agent decision (no t
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.75) - No agent decision or tool execution occurred; erro
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.75) - Agent did not select any applicable tool (or selec
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: sequence_order_errors (confidence: 0.58)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.78) - No tools were selected or executed; the agent fail
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - No identifiable agent decision error (not tool_sel
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 33)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.64) - The agent did not select or initialize any tool/ap
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.65) - No tools were selected or executed (executed tools
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - No agent decisions are evidenced since no tools we
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 36)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.75) - The agent did not select or propose any tool to ha
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 37)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.85) - No tools were selected or invoked; required tools 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.75) - No agent decision error detected: no tools were se
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 33)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.62) - Insufficient information to attribute to any agent
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: dependency_errors (confidence: 0.55)2025-08-31 16:28:04,530 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:04,532 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any tool appropriate for an API integration task (no HTTP/API client or integration tool was chosen), effectively failing
2025-08-31 16:28:10,660 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:10,662 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The partial success likely stems from the agent not handling prerequisite steps for the API integration (e.g., authentication token retrieval, config 
2025-08-31 16:28:18,427 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:18,429 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identifiable: the task is a basic_task with no required tools, and no tools were executed; the failure seems to be due to inaction 
2025-08-31 16:28:26,203 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:26,205 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The task context is Unknown, and the agent did not attempt to clarify, extract requirements, or establish any prerequisites. This prevented correct to
2025-08-31 16:28:32,967 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:32,968 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool to handle the (unknown) data_pipeline task, effectively making a missing/incorrect tool choice which
2025-08-31 16:28:37,548 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:37,553 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select any required tool for a basic_task, effectively making an incorrect tool-selection decision by not initiating the appropria
2025-08-31 16:28:48,954 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:48,956 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "no_agent_error",
  "reason": "The task did not require any tools to be invoked (Required Tools: none). Therefore the agent did not make a decision (no tool selection, parameterization
2025-08-31 16:28:48,956 - focused_ai_classifier - WARNING - Unknown category from AI: no_agent_error, defaulting to OTHER
2025-08-31 16:28:55,748 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:28:55,749 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No pipeline steps were executed; there is no evidence of a valid A→B→C data_pipeline sequence being followed, indicating the agent failed to defin
2025-08-31 16:29:05,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:05,393 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task resulted in complete inactivity; no steps were executed, indicating the agent failed to initiate or follow the required workflow sequence
2025-08-31 16:29:11,781 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:11,782 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no observable agent decision (no tools executed; error is 'Unknown error'), and insufficient task/tool details to attribute to tool_selection_erro
2025-08-31 16:29:11,783 - result_merger - INFO - 模型qwen2.5-14b-instruct保存100/100条记录
2025-08-31 16:29:11,792 - result_merger - INFO - 合并完成，共处理71个文件，保存100条记录
2025-08-31 16:29:11,796 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-31 16:29:11,802 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: sequence_order_errors (confidence: 0.53)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.62) - Insufficient data to attribute a specific agent de
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision could be evaluated due to lack o
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.72) - No tools were selected or an appropriate tool coul
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.85) - No observable agent decision error: no tools were 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - No tools were selected or invoked for a multi-stag
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.75) - The agent did not select or use any data_pipeline 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 36)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.60) - No tools were executed and the error is reported a
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 43)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.60) - No agent decision evidence (no tools chosen, no pa
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 44)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.60) - No tools were selected or executed due to an unkno
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 45)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.85) - Primary decision error: the agent did not select o
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 43)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - There is insufficient evidence of a specific agent
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.60) - No tools were required for this task (0/0). The er
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - No starting tool was selected or clarifying inform
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: sequence_order_errors (confidence: 0.85) - The agent did not define or follow the required en
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.70) - There is no evidence of a wrong agent decision (no
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 49)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: parameter_config_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct simple_task: tool_selection_errors (confidence: 0.42)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.70) - There is no evidence of a wrong agent decision. No
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 43)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.85) - There is no evidence of an incorrect tool choice, 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 44)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.85) - There is no evidence of any agent decision or tool
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 45)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.70)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.68) - There is no evidence of a specific agent decision 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct api_integration: other_errors (confidence: 0.60) - No identifiable agent decision error. The task sho
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> api_integration (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.65) - No task details and no tools were executed; error 
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 47)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct api_integration: dependency_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: dependency_errors (confidence: 0.62) - The task context is Unknown, and the agent did not
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 49)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct data_pipeline: tool_selection_errors (confidence: 0.58) - Agent failed to select or initialize any tool to h
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> data_pipeline (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct basic_task: tool_selection_errors (confidence: 0.60) - Agent failed to select any required tool for a bas
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> basic_task (total: 50)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: other_errors (confidence: 0.20)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-14b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-14b-instruct simple_task: other_errors (confidence: 0.65) - There is no observable agent decision (no tools ex
[V3_UPDATE] 更新统计完成: qwen2.5-14b-instruct -> baseline -> simple_task (total: 51)
[INFO] 最终合并完成: 71 个文件
2025-08-31 16:29:11,980 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-31 16:29:11,980 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片3完成
INFO:__main__:📊 并发执行结果: 3/3 分片成功
INFO:__main__:✅ Key2: 完成 qwen2.5-14b-instruct-easy
INFO:__main__:最终利用率: 1.1%
=== 测试结束时间: 2025年 8月31日 星期日 16时29分14秒 EDT ===
=== 测试用时: 1121秒 ===
