=== æµ‹è¯•å¼€å§‹æ—¶é—´: 2025å¹´ 8æœˆ29æ—¥ æ˜ŸæœŸäº” 00æ—¶56åˆ†18ç§’ EDT ===
=== ç¯å¢ƒå˜é‡ ===
USE_RESULT_COLLECTOR=true
STORAGE_FORMAT=json
CUSTOM_WORKERS=50
=== å‘½ä»¤æ‰§è¡Œ ===
INFO:__main__:ä½¿ç”¨ç¯å¢ƒå˜é‡ RATE_MODE: fixed
INFO:__main__:åˆå§‹åŒ–å®ä¾‹æ± : 17ä¸ªå®ä¾‹ (2ä¸ªAzure + 6ä¸ªIdealLab)
INFO:result_collector:ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
INFO:result_collector:ResultAggregatoråˆå§‹åŒ–
INFO:__main__:ğŸ†• å¯ç”¨ResultCollectoræ¨¡å¼ï¼Œæ”¯æŒé›¶å†²çªå¹¶å‘
INFO:__main__:èµ„æºæ± çŠ¶æ€: 17ä¸ªå®ä¾‹, å®¹é‡1306
INFO:__main__:
ğŸ¯ æ£€æµ‹åˆ°Qwenæ¨¡å‹ï¼Œä½¿ç”¨é˜Ÿåˆ—è°ƒåº¦å™¨
INFO:__main__:   æ¨¡å‹: qwen2.5-72b-instruct â†’ Key0
INFO:__main__:   Promptç±»å‹: flawed_sequence_disorder
INFO:__main__:   éš¾åº¦: easy
INFO:__main__:ğŸ”„ Key0: æ‰§è¡Œ qwen2.5-72b-instruct-easy
INFO:__main__:ğŸ¯ ä½¿ç”¨qwenæ™ºèƒ½åˆ†ç‰‡ç­–ç•¥: qwen2.5-72b-instruct
INFO:__main__:ğŸ”„ çœŸæ­£å¤šKeyå¹¶å‘ç­–ç•¥:
INFO:__main__:   æ¨¡å‹: qwen2.5-72b-instruct (è§„æ¨¡: 72b)
INFO:__main__:   ä½¿ç”¨Keys: key0, key1, key2
INFO:__main__:   æ€»å®ä¾‹æ•°: 20
INFO:__main__:   åˆ†ç‰‡æ•°: 3 (æ¯ä¸ªkeyç‹¬ç«‹åˆ†ç‰‡)
INFO:__main__:   å®ä¾‹åˆ†é…: [7, 7, 6]
INFO:__main__:   ğŸš€ å¯ç”¨3å€APIå¹¶å‘ï¼
INFO:__main__:ğŸš€ å¯åŠ¨3ä¸ªåˆ†ç‰‡å¹¶å‘æ‰§è¡Œ
INFO:__main__:  IdealLab qwenæ¨¡å‹é™åˆ¶: qwen-key0 å¼ºåˆ¶ä½¿ç”¨ max_workers=1, qps=10
INFO:__main__:    æ³¨æ„: IdealLab APIå¹¶å‘é™åˆ¶ä¸¥æ ¼ï¼Œå¿½ç•¥--max-workersè®¾ç½®
INFO:__main__:  ä½¿ç”¨IdealLab API Key 0
INFO:__main__:ğŸš€ å¯åŠ¨åˆ†ç‰‡ qwen2.5-72b-instruct_easy_flawed_sequence_disorder_key0: qwen-key0
INFO:__main__:   å®ä¾‹æ•°: 7, æ¨¡å‹: qwen2.5-72b-instruct
INFO:__main__:   ä¼ é€’STORAGE_FORMAT=jsonç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’USE_PARTIAL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’TASK_LOAD_COUNT=20ç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’SKIP_MODEL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’USE_RESULT_COLLECTOR=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’KMP_DUPLICATE_LIB_OK=TRUEç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®PYTHONMALLOC=mallocç»™å­è¿›ç¨‹
INFO:__main__:   åˆ†ç‰‡1: qwen-key0 (7ä¸ªå®ä¾‹)
INFO:__main__:  IdealLab qwenæ¨¡å‹é™åˆ¶: qwen-key1 å¼ºåˆ¶ä½¿ç”¨ max_workers=1, qps=10
INFO:__main__:    æ³¨æ„: IdealLab APIå¹¶å‘é™åˆ¶ä¸¥æ ¼ï¼Œå¿½ç•¥--max-workersè®¾ç½®
INFO:__main__:  ä½¿ç”¨IdealLab API Key 1
INFO:__main__:ğŸš€ å¯åŠ¨åˆ†ç‰‡ qwen2.5-72b-instruct_easy_flawed_sequence_disorder_key1: qwen-key1
INFO:__main__:   å®ä¾‹æ•°: 7, æ¨¡å‹: qwen2.5-72b-instruct
INFO:__main__:   ä¼ é€’STORAGE_FORMAT=jsonç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’USE_PARTIAL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’TASK_LOAD_COUNT=20ç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’SKIP_MODEL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’USE_RESULT_COLLECTOR=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’KMP_DUPLICATE_LIB_OK=TRUEç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®PYTHONMALLOC=mallocç»™å­è¿›ç¨‹
INFO:__main__:   åˆ†ç‰‡2: qwen-key1 (7ä¸ªå®ä¾‹)
INFO:__main__:  ä½¿ç”¨IdealLab API Key 2
INFO:__main__:ğŸš€ å¯åŠ¨åˆ†ç‰‡ qwen2.5-72b-instruct_easy_flawed_sequence_disorder_key2: qwen-key2
INFO:__main__:   å®ä¾‹æ•°: 6, æ¨¡å‹: qwen2.5-72b-instruct
INFO:__main__:   ä¼ é€’STORAGE_FORMAT=jsonç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’USE_PARTIAL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’TASK_LOAD_COUNT=20ç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’SKIP_MODEL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’USE_RESULT_COLLECTOR=trueç»™å­è¿›ç¨‹
INFO:__main__:   ä¼ é€’KMP_DUPLICATE_LIB_OK=TRUEç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®PYTHONMALLOC=mallocç»™å­è¿›ç¨‹
INFO:__main__:   åˆ†ç‰‡3: qwen-key2 (6ä¸ªå®ä¾‹)
2025-08-29 00:56:19,066 - faiss.loader - INFO - Loading faiss.
2025-08-29 00:56:19,066 - faiss.loader - INFO - Loading faiss.
2025-08-29 00:56:19,066 - faiss.loader - INFO - Loading faiss.
2025-08-29 00:56:19,077 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-29 00:56:19,078 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-29 00:56:19,078 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-29 00:56:19,713 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
2025-08-29 00:56:19,713 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
2025-08-29 00:56:19,713 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
2025-08-29 00:56:19,713 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
2025-08-29 00:56:19,713 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
2025-08-29 00:56:19,713 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
2025-08-29 00:56:19,714 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
2025-08-29 00:56:19,714 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
2025-08-29 00:56:19,715 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
2025-08-29 00:56:19,715 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
2025-08-29 00:56:19,715 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
2025-08-29 00:56:19,769 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
2025-08-29 00:56:19,769 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
2025-08-29 00:56:19,769 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,769 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,769 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Batch test runner initialized
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Batch test runner initialized
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Batch test runner initialized
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Log file: logs/batch_test_20250829_005619.log
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Log file: logs/batch_test_20250829_005619.log
2025-08-29 00:56:19,770 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Log file: logs/batch_test_20250829_005619.log
2025-08-29 00:56:19,770 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-29 00:56:19,770 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Initializing test components...
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Initializing test components...
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Initializing test components...
2025-08-29 00:56:20,252 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-29 00:56:20,253 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-29 00:56:20,253 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
2025-08-29 00:56:20,254 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-29 00:56:20,256 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-29 00:56:20,256 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-29 00:56:20,256 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
2025-08-29 00:56:20,257 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-29 00:56:20,290 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-29 00:56:20,291 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-29 00:56:20,291 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
2025-08-29 00:56:20,292 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-29 00:56:20,789 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:56:20,797 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:56:20,803 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:56:20,903 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:20,903 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:20,903 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:21,363 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:21,363 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:21,365 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:21,847 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-29 00:56:21,847 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-29 00:56:21,852 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-29 00:56:21,853 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-29 00:56:21,862 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-29 00:56:21,862 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-29 00:56:21,944 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:21,957 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:21,961 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:22,066 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:22,082 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:22,085 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:22,425 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-29 00:56:22,425 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:22,445 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-29 00:56:22,445 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:22,452 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-29 00:56:22,453 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:22,454 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:22,454 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:22,454 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:22,465 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-29 00:56:22,466 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,466 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,471 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:22,471 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:22,471 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-29 00:56:22,492 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-29 00:56:22,493 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:22,493 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:22,493 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:22,494 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,495 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,499 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-29 00:56:22,500 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-29 00:56:22,500 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-29 00:56:22,500 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-29 00:56:22,504 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-29 00:56:22,506 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,506 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,509 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-29 00:56:22,510 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-29 00:56:22,510 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-29 00:56:22,510 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-29 00:56:25,805 - unified_training_manager - INFO - Using device: cpu
2025-08-29 00:56:25,805 - unified_training_manager - INFO - Using device: cpu
2025-08-29 00:56:25,805 - unified_training_manager - INFO - Using device: cpu
2025-08-29 00:56:27,391 - unified_training_manager - INFO - Task filtering results:
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-29 00:56:27,391 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-29 00:56:27,394 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-29 00:56:27,398 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-29 00:56:27,398 - batch_test_runner - INFO - âœ… MDPWorkflowGenerator initialized successfully:
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - task_manager: âœ“
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - output_verifier: âœ“
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - embedding_manager: âœ“
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-29 00:56:27,403 - unified_training_manager - INFO - Task filtering results:
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-29 00:56:27,403 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-29 00:56:27,406 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-29 00:56:27,409 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:27,410 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-29 00:56:27,410 - batch_test_runner - INFO - âœ… MDPWorkflowGenerator initialized successfully:
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - task_manager: âœ“
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - output_verifier: âœ“
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - embedding_manager: âœ“
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-29 00:56:27,411 - result_collector - INFO - ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
2025-08-29 00:56:27,411 - result_merger - INFO - ResultMergeråˆå§‹åŒ–å®Œæˆ
2025-08-29 00:56:27,411 - result_merger - WARNING - å¦ä¸€ä¸ªåˆå¹¶å™¨å·²åœ¨è¿è¡Œ (PID: -1)
2025-08-29 00:56:27,419 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:27,420 - result_collector - INFO - ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
2025-08-29 00:56:27,420 - result_merger - INFO - ResultMergeråˆå§‹åŒ–å®Œæˆ
2025-08-29 00:56:27,420 - result_merger - WARNING - å¦ä¸€ä¸ªåˆå¹¶å™¨å·²åœ¨è¿è¡Œ (PID: -1)
2025-08-29 00:56:27,424 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-29 00:56:27,424 - unified_training_manager - INFO - Task filtering results:
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-29 00:56:27,424 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-29 00:56:27,424 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-29 00:56:27,428 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-29 00:56:27,440 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-29 00:56:27,440 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-29 00:56:27,444 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-29 00:56:27,444 - batch_test_runner - INFO - âœ… MDPWorkflowGenerator initialized successfully:
2025-08-29 00:56:27,444 - batch_test_runner - INFO -   - task_manager: âœ“
2025-08-29 00:56:27,444 - batch_test_runner - INFO -   - output_verifier: âœ“
2025-08-29 00:56:27,445 - batch_test_runner - INFO -   - embedding_manager: âœ“
2025-08-29 00:56:27,445 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-29 00:56:27,445 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-29 00:56:27,465 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:27,469 - result_collector - INFO - ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
2025-08-29 00:56:27,469 - result_merger - INFO - ResultMergeråˆå§‹åŒ–å®Œæˆ
2025-08-29 00:56:27,470 - result_merger - WARNING - å¦ä¸€ä¸ªåˆå¹¶å™¨å·²åœ¨è¿è¡Œ (PID: -1)
2025-08-29 00:56:27,490 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-29 00:56:27,490 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-29 00:56:27,933 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-29 00:56:27,933 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-29 00:56:27,942 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-29 00:56:27,942 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-29 00:56:27,968 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-29 00:56:27,968 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-29 00:56:27,992 - batch_test_runner - INFO - Initialization complete
2025-08-29 00:56:28,006 - batch_test_runner - INFO - Initialization complete
2025-08-29 00:56:28,031 - batch_test_runner - INFO - Initialization complete
2025-08-29 00:56:28,079 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-29 00:56:28,079 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-29 00:56:28,080 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-29 00:56:28,102 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-29 00:56:28,102 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-29 00:56:28,102 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-29 00:56:28,103 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-29 00:56:28,109 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,109 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,110 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,110 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,125 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-29 00:56:28,127 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-29 00:56:28,127 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-29 00:56:28,128 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-29 00:56:28,134 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,134 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,134 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,134 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,158 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-29 00:56:28,163 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,163 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,163 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,167 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,167 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,167 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,168 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,172 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,172 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,172 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,177 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,178 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,178 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,202 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,202 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,202 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,217 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,217 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,217 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,227 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,227 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,227 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:29,649 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,102 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,118 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,325 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:30,486 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:31,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:31,052 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:31,538 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:32,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:32,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:32,043 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:33,055 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:33,119 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:33,306 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:34,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:34,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:34,227 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:35,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:35,069 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:35,617 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:36,090 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:36,344 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:36,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:37,500 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:37,569 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:38,005 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:38,007 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:38,045 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:38,521 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:39,004 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:39,021 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:40,024 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:40,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:40,663 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:40,927 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:41,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:41,284 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:41,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:41,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:42,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:42,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:42,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:43,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼

============================================================
æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_sequence_disorder']
éš¾åº¦: easy
ç›®æ ‡: æ¯ç§é…ç½® 7 ä¸ªå®ä¾‹
============================================================
â—‹ simple_task         :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ basic_task          :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ data_pipeline       :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ api_integration     :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ multi_stage_pipeline:   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)

â³ éœ€è¦è¿è¡Œ 35 ä¸ªæ–°æµ‹è¯•

â–¶ å‡†å¤‡ simple_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ basic_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ data_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ api_integration (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ multi_stage_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å¼€å§‹æ‰§è¡Œ 35 ä¸ªæµ‹è¯•...
ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x10a2ed470>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] âš¡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[INFO] âš¡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[INFO] æ£€æµ‹åˆ°å¹¶å‘ç¯å¢ƒï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨æ¨¡å¼ï¼ˆResultCollectorï¼‰2025-08-29 00:56:43,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:43,933 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:43,966 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:43,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼

============================================================
æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_sequence_disorder']
éš¾åº¦: easy
ç›®æ ‡: æ¯ç§é…ç½® 6 ä¸ªå®ä¾‹
============================================================
â—‹ simple_task         :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ basic_task          :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ data_pipeline       :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ api_integration     :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ multi_stage_pipeline:   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)

â³ éœ€è¦è¿è¡Œ 30 ä¸ªæ–°æµ‹è¯•

â–¶ å‡†å¤‡ simple_task (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ basic_task (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ data_pipeline (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ api_integration (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ multi_stage_pipeline (6 ä¸ªå®ä¾‹)...

â–¶ å¼€å§‹æ‰§è¡Œ 30 ä¸ªæµ‹è¯•...
ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1038465a0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] âš¡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[INFO] âš¡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[INFO] æ£€æµ‹åˆ°å¹¶å‘ç¯å¢ƒï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨æ¨¡å¼ï¼ˆResultCollectorï¼‰2025-08-29 00:56:45,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:45,141 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:45,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼

============================================================
æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_sequence_disorder']
éš¾åº¦: easy
ç›®æ ‡: æ¯ç§é…ç½® 7 ä¸ªå®ä¾‹
============================================================
â—‹ simple_task         :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ basic_task          :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ data_pipeline       :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ api_integration     :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ multi_stage_pipeline:   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)

â³ éœ€è¦è¿è¡Œ 35 ä¸ªæ–°æµ‹è¯•

â–¶ å‡†å¤‡ simple_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ basic_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ data_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ api_integration (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ multi_stage_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å¼€å§‹æ‰§è¡Œ 35 ä¸ªæµ‹è¯•...
ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x110366a00>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] âš¡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[INFO] âš¡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[INFO] æ£€æµ‹åˆ°å¹¶å‘ç¯å¢ƒï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨æ¨¡å¼ï¼ˆResultCollectorï¼‰2025-08-29 00:56:45,901 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:45,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:46,899 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:46,906 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:47,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:47,036 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:47,896 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:47,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:48,469 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:48,752 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:48,908 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:48,933 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:49,744 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:49,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:49,929 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:50,115 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:50,610 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:51,145 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:51,163 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:51,163 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:51,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:51,197 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:51,197 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:51,197 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:51,948 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:52,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:52,641 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:52,947 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:53,142 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:53,253 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:54,145 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:54,164 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:54,248 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:54,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:55,224 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:55,959 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:55,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:56,176 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:56,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:56:56,683 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:56,691 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:57,164 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:57,191 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:57,665 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:57,681 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:58,939 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:59,069 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:59,090 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:59,091 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:59,123 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:59,123 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:59,123 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:59,744 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:59,961 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:00,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:00,286 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:00,897 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:01,029 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:01,167 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:01,699 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:01,808 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:02,047 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:02,746 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:03,040 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:03,254 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:03,318 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:03,549 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:03,572 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:04,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:04,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:04,643 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:04,878 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:05,043 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:05,057 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:05,563 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:05,591 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:06,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:06,232 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:06,247 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:06,268 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:06,268 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:06,300 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:06,300 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:06,300 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[INFO] åå°åˆå¹¶è¿›ç¨‹å·²å¯åŠ¨ï¼ˆæ¯10ç§’åˆå¹¶ä¸€æ¬¡ï¼‰
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x144df9fd0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c52db0ec-f61c-90a3-8116-5b3fcc45dbd5"}, traceId: 215045c117564433898247862e7f62'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"14600fa2-d4a2-921f-96aa-1460f8c9d537"}, traceId: 2150449017564433907756140e7ffa'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"628ea318-0f51-92d8-af2c-4349146d2298"}, traceId: 215045c117564433912797871e7f62'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"681361b5-78dd-96c1-9dea-8c5ad1e147a6"}, traceId: 2150449017564433917816144e7ffa'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e217a755-5ef4-9396-a26a-97d6b1a1fc9e"}, traceId: 215045c117564433937977883e7f62'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4bc279f4-cf67-9314-97a2-d0cdac0de1cd"}, traceId: 215045c117564433977537910e7f62'}
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43b61445-b97a-907f-87ea-9b8c8d2bcafd"}, traceId: 2150449017564433982616169e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54a0c2c6-db75-9e1a-8727-1d310c8f9471"}, traceId: 2150449017564434016656182e7ffa'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8b1430e-7967-9977-bc9b-e03a1ef01579"}, traceId: 2150449017564434036726187e7ffa'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"201d7fdf-9520-9712-a838-1f3fe858b9dc"}, traceId: 215045c117564434056297949e7f62'}2025-08-29 00:57:07,103 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] åå°åˆå¹¶è¿›ç¨‹å·²å¯åŠ¨ï¼ˆæ¯10ç§’åˆå¹¶ä¸€æ¬¡ï¼‰
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x12edab4e0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b3b6cf4-0c6d-9bd1-aa8a-73ac8b0c408e"}, traceId: 2150458717564433898408646e7eec'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9cc53e45-cdc5-93a6-8566-8f1a647c87d6"}, traceId: 2150454117564433907771611e789c'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83e8e3c0-a87d-9787-85c3-269765ca6cb5"}, traceId: 2150454117564433927881620e789c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c8c401c-fcb7-97d8-bcd7-922d61a6a9f6"}, traceId: 2150458717564433948098689e7eec'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed314e3f-7d47-9fe4-ad63-4ec8e628fd8d"}, traceId: 2150454117564433972461639e789c'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93d215ba-faa4-9966-a5c4-49e71f4ab23e"}, traceId: 2150458717564433977508716e7eec'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a921964f-28f7-9716-965f-b7f65fb89328"}, traceId: 2150458717564433997688743e7eec'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f62024d0-9f06-9a08-a072-725fa2760e17"}, traceId: 2150454117564434016621665e789c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"feca5ea5-c5b7-9c19-b2f2-a0d39f664e72"}, traceId: 2150458717564434026688770e7eec'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"644c3313-5524-9257-bb06-eb599671472a"}, traceId: 2150454117564434036711675e789c'}2025-08-29 00:57:07,767 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:07,806 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:07,907 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:07,942 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:08,245 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:08,785 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:08,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:09,503 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:09,517 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:09,518 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:09,540 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:09,540 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:09,540 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:09,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:09,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:10,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:10,783 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:10,783 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:10,813 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:10,813 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:10,813 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:10,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:10,918 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:11,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:11,681 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:11,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:11,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:11,899 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:12,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:12,865 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:13,000 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:13,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:13,852 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:14,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:14,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:14,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:14,867 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:14,867 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:14,898 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:14,898 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:14,898 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:15,144 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:15,342 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:15,463 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:15,773 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:16,033 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:16,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:16,454 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:16,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:16,836 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:16,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:17,357 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:18,042 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:18,186 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:18,199 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:18,199 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:18,226 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:18,226 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:18,226 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:18,859 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:18,886 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:18,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:19,325 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:19,513 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:19,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:20,116 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:20,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:21,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:21,388 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:21,485 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:21,691 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:21,835 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:21,850 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:21,875 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:21,955 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:22,604 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:22,837 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:22,880 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:22,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:23,093 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] åå°åˆå¹¶è¿›ç¨‹å·²å¯åŠ¨ï¼ˆæ¯10ç§’åˆå¹¶ä¸€æ¬¡ï¼‰
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x160560320>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3fdf53ae-f04d-96d6-a247-531065c88652"}, traceId: 2150452b17564433893827248e7891'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18cad6a7-0670-9984-91f3-db2865f4acd4"}, traceId: 215041e117564433898488614e33b8'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a6c30b4-454b-9956-8dc0-df81c36039e5"}, traceId: 215041e117564433917928627e33b8'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e2a6b0a1-ecda-9d57-932c-3959d2eedad1"}, traceId: 2150452b17564433937997263e7891'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a78e93d3-2317-9df1-b296-adc92bf33244"}, traceId: 215041e117564433948168642e33b8'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20a820ca-5d7c-97fd-b8d6-bffa75f86cc0"}, traceId: 2150452b17564433958227272e7891'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7076d9f-5071-9766-a7c8-99d528bb2dc7"}, traceId: 2150452b17564433987617293e7891'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24100e49-5e96-9389-a7d2-a8da351bcd75"}, traceId: 2150452b17564434006577303e7891'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d78c75fc-46de-9e63-8c08-728a446dcbd2"}, traceId: 215041e117564434026758717e33b8'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b56e2db-409e-9466-9d50-4d6eb999b4c1"}, traceId: 215041e117564434036798721e33b8'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0fb6c68f-f83e-9a6c-a9e7-2b426df8eb1b"}, traceId: 2150452b17564434056327343e7891'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c87b2bad-21bb-9c7e-89fc-48ff043a2557"}, traceId: 215041e117564434076548773e33b8'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"672f8f80-071e-9683-9512-6393e35306f6"}, traceId: 215041e117564434096718792e33b8'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa9cf9b5-9bcc-972d-b0f6-cf8b966d1949"}, traceId: 2150452b17564434123747391e7891'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29c1b5ed-a1f5-9568-b375-f7252f0eb413"}, traceId: 215041e117564434128848819e33b8'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"573a3f24-78cc-9386-ad23-2f0d9d04640b"}, traceId: 2150452b17564434138897404e7891'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"85dcb68d-477c-9a2c-a113-851ffa93cef8"}, traceId: 2150452b17564434164077432e7891'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1519def9-cc47-9b7a-9937-85724e00c5a2"}, traceId: 215041e117564434169188900e33b8'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25572
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25572
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c74c84a-39d1-9309-9837-fcbf21176543"}, traceId: 213e041717564434214898236e96ae'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83caf7d2-7b98-9ffc-b1a2-bd9213df34b0"}, traceId: 213e059717564434228014088e34e8'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b61e23ce-57a5-996e-a4d5-ecd26caf543e"}, traceId: 215041e117564434238008991e33b8'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51473c63-91af-9fa2-9990-4d112ff3d9f0"}, traceId: 213e066e17564434248331460e7f01'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1cccbf22-95c3-9978-9df8-526d43757457"}, traceId: 215041e117564434253148999e33b8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...2025-08-29 00:57:23,637 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:23,886 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:24,829 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:25,030 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:25,318 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:25,831 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:25,834 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:25,839 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:25,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:26,058 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:26,824 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:27,354 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:27,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:27,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:27,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:27,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e810b310-2894-9ad7-bf3b-7ae9948c6ef8"}, traceId: 2150449017564434066366197e7ffa'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e509c200-b25f-9170-b974-416a067c6ea6"}, traceId: 215045c117564434076467954e7f62'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b4c9d9f-24f4-9e3c-b4cd-f5aa5125c0e6"}, traceId: 2150449017564434086586201e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c54591a3-b847-9844-bb7c-2d12eded0eaf"}, traceId: 215045c117564434096627967e7f62'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7bc6d10e-baf6-9d87-9840-99d739a46bd6"}, traceId: 2150449017564434103526209e7ffa'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"14e5bae6-8679-935d-bde9-1cb709353051"}, traceId: 215045c117564434123717981e7f62'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a14290b8-ea77-9c0d-929f-0d582727a540"}, traceId: 2150449017564434148936225e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f9031b0-3a61-9a69-8101-ccdd6780b0d6"}, traceId: 2150449017564434169116231e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f517759e-c48c-97ef-8c4f-c5260abbe374"}, traceId: 215045c117564434174148003e7f62'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1edefdf5-43ba-9a33-b683-9029e32f1d55"}, traceId: 215045c117564434207718019e7f62'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ed98ba9-ba75-975d-b706-ffc27ec570f6"}, traceId: 2150449017564434217826246e7ffa'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd3a119a-2f33-9960-9fe2-fc915fd220d5"}, traceId: 2150449017564434232866255e7ffa'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7802c825-f109-95e3-811d-eb590e0fe695"}, traceId: 215045c117564434237948030e7f62'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"add06014-8166-98f8-8178-79284a908d12"}, traceId: 215045c117564434258118041e7f62'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25584
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25584
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]2025-08-29 00:57:28,006 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ee5b9147-d7cc-932f-a7d3-8cd7d8c5cc4f"}, traceId: 2150458717564434066368840e7eec'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"48ef3909-b638-973c-bac2-82d7ff5369bf"}, traceId: 2150454117564434086531707e789c'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d5e9d250-32cc-9bc5-833e-c735c3c9c0f4"}, traceId: 2150454117564434098461713e789c'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cebf0241-ea8f-9490-a6e3-97e1fd574561"}, traceId: 2150458717564434108568951e7eec'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14536
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14536
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"228c224e-2a60-9591-aff1-2aa0f072ad0d"}, traceId: 2150454117564434138821728e789c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99475f12-39f5-9548-b0a7-4fb51bdf908a"}, traceId: 2150454117564434159001741e789c'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac691f18-b1c5-9715-9f2c-5cf3b28fcda8"}, traceId: 213e007b17564434164381762eebc5'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"923d2ff2-f551-9cc0-92f4-b380ce2e5d12"}, traceId: 2150454117564434174121756e789c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9730a0a-2bcb-9c8e-8fc3-48311f769255"}, traceId: 213e062017564434197347903e808b'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"37b054e5-3ee8-9435-87b1-5d31a521358f"}, traceId: 2150454117564434197601798e789c'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e0befef-db78-937d-a571-6391a960f218"}, traceId: 213e06c217564434233058856e837b'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=sequence_order_errors, confidence=0.79
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c451c13-3a14-93e8-bd55-f837e2f994f3"}, traceId: 213e01f617564434248228224e1294'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': 'æ¨¡å‹æä¾›æ–¹é™æµ', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cd176221-9f36-9f30-81dd-0a2e168c4474"}, traceId: 2150454117564434268121888e789c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...2025-08-29 00:57:28,980 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:29,255 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:29,388 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:29,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:29,866 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:29,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
