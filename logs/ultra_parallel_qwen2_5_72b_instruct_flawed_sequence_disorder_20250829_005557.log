=== 测试开始时间: 2025年 8月29日 星期五 00时56分18秒 EDT ===
=== 环境变量 ===
USE_RESULT_COLLECTOR=true
STORAGE_FORMAT=json
CUSTOM_WORKERS=50
=== 命令执行 ===
INFO:__main__:使用环境变量 RATE_MODE: fixed
INFO:__main__:初始化实例池: 17个实例 (2个Azure + 6个IdealLab)
INFO:result_collector:ResultCollector初始化，临时目录: temp_results
INFO:result_collector:ResultAggregator初始化
INFO:__main__:🆕 启用ResultCollector模式，支持零冲突并发
INFO:__main__:资源池状态: 17个实例, 容量1306
INFO:__main__:
🎯 检测到Qwen模型，使用队列调度器
INFO:__main__:   模型: qwen2.5-72b-instruct → Key0
INFO:__main__:   Prompt类型: flawed_sequence_disorder
INFO:__main__:   难度: easy
INFO:__main__:🔄 Key0: 执行 qwen2.5-72b-instruct-easy
INFO:__main__:🎯 使用qwen智能分片策略: qwen2.5-72b-instruct
INFO:__main__:🔄 真正多Key并发策略:
INFO:__main__:   模型: qwen2.5-72b-instruct (规模: 72b)
INFO:__main__:   使用Keys: key0, key1, key2
INFO:__main__:   总实例数: 20
INFO:__main__:   分片数: 3 (每个key独立分片)
INFO:__main__:   实例分配: [7, 7, 6]
INFO:__main__:   🚀 启用3倍API并发！
INFO:__main__:🚀 启动3个分片并发执行
INFO:__main__:  IdealLab qwen模型限制: qwen-key0 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 0
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_sequence_disorder_key0: qwen-key0
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片1: qwen-key0 (7个实例)
INFO:__main__:  IdealLab qwen模型限制: qwen-key1 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 1
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_sequence_disorder_key1: qwen-key1
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片2: qwen-key1 (7个实例)
INFO:__main__:  使用IdealLab API Key 2
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_sequence_disorder_key2: qwen-key2
INFO:__main__:   实例数: 6, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片3: qwen-key2 (6个实例)
2025-08-29 00:56:19,066 - faiss.loader - INFO - Loading faiss.
2025-08-29 00:56:19,066 - faiss.loader - INFO - Loading faiss.
2025-08-29 00:56:19,066 - faiss.loader - INFO - Loading faiss.
2025-08-29 00:56:19,077 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-29 00:56:19,078 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-29 00:56:19,078 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-29 00:56:19,713 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-29 00:56:19,713 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-29 00:56:19,713 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-29 00:56:19,713 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-29 00:56:19,713 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-29 00:56:19,713 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-29 00:56:19,713 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-29 00:56:19,714 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-29 00:56:19,714 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-29 00:56:19,714 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-29 00:56:19,714 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-29 00:56:19,715 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-29 00:56:19,715 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-29 00:56:19,715 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-29 00:56:19,769 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-29 00:56:19,769 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-29 00:56:19,769 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-29 00:56:19,769 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,769 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,769 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Batch test runner initialized
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Batch test runner initialized
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Batch test runner initialized
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-29 00:56:19,769 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Log file: logs/batch_test_20250829_005619.log
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Log file: logs/batch_test_20250829_005619.log
2025-08-29 00:56:19,770 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Log file: logs/batch_test_20250829_005619.log
2025-08-29 00:56:19,770 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-29 00:56:19,770 - batch_test_runner - INFO - ============================================================
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Initializing test components...
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Initializing test components...
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-29 00:56:19,770 - batch_test_runner - INFO - Initializing test components...
2025-08-29 00:56:20,252 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-29 00:56:20,253 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-29 00:56:20,253 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-29 00:56:20,254 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-29 00:56:20,256 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-29 00:56:20,256 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-29 00:56:20,256 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-29 00:56:20,257 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-29 00:56:20,290 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-29 00:56:20,291 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-29 00:56:20,291 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-29 00:56:20,292 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-29 00:56:20,789 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:56:20,797 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:56:20,803 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:56:20,903 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:20,903 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:20,903 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:21,363 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:21,363 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:21,365 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:21,847 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-29 00:56:21,847 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-29 00:56:21,852 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-29 00:56:21,853 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-29 00:56:21,862 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-29 00:56:21,862 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-29 00:56:21,944 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:21,957 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:21,961 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-29 00:56:22,066 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:22,082 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:22,085 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-29 00:56:22,425 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-29 00:56:22,425 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:22,445 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-29 00:56:22,445 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:22,452 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-29 00:56:22,453 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:22,454 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:22,454 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:22,454 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:22,465 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-29 00:56:22,466 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,466 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,471 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:22,471 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:22,471 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-29 00:56:22,480 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-29 00:56:22,492 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-29 00:56:22,493 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:22,493 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:22,493 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:22,494 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,495 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,499 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-29 00:56:22,500 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-29 00:56:22,500 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-29 00:56:22,500 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-29 00:56:22,504 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-29 00:56:22,506 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,506 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-29 00:56:22,509 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-29 00:56:22,510 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-29 00:56:22,510 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-29 00:56:22,510 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-29 00:56:25,805 - unified_training_manager - INFO - Using device: cpu
2025-08-29 00:56:25,805 - unified_training_manager - INFO - Using device: cpu
2025-08-29 00:56:25,805 - unified_training_manager - INFO - Using device: cpu
2025-08-29 00:56:27,391 - unified_training_manager - INFO - Task filtering results:
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-29 00:56:27,391 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-29 00:56:27,391 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-29 00:56:27,394 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-29 00:56:27,398 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-29 00:56:27,398 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-29 00:56:27,398 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-29 00:56:27,403 - unified_training_manager - INFO - Task filtering results:
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-29 00:56:27,403 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-29 00:56:27,403 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-29 00:56:27,406 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-29 00:56:27,409 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:27,410 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-29 00:56:27,410 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-29 00:56:27,410 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-29 00:56:27,411 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-29 00:56:27,411 - result_merger - INFO - ResultMerger初始化完成
2025-08-29 00:56:27,411 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-29 00:56:27,419 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:27,420 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-29 00:56:27,420 - result_merger - INFO - ResultMerger初始化完成
2025-08-29 00:56:27,420 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-29 00:56:27,424 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-29 00:56:27,424 - unified_training_manager - INFO - Task filtering results:
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-29 00:56:27,424 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-29 00:56:27,424 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-29 00:56:27,424 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-29 00:56:27,428 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-29 00:56:27,440 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-29 00:56:27,440 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-29 00:56:27,444 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-29 00:56:27,444 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-29 00:56:27,444 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-29 00:56:27,444 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-29 00:56:27,445 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-29 00:56:27,445 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-29 00:56:27,445 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-29 00:56:27,465 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-29 00:56:27,469 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-29 00:56:27,469 - result_merger - INFO - ResultMerger初始化完成
2025-08-29 00:56:27,470 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-29 00:56:27,490 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-29 00:56:27,490 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-29 00:56:27,933 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-29 00:56:27,933 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-29 00:56:27,942 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-29 00:56:27,942 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-29 00:56:27,968 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-29 00:56:27,968 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-29 00:56:27,992 - batch_test_runner - INFO - Initialization complete
2025-08-29 00:56:28,006 - batch_test_runner - INFO - Initialization complete
2025-08-29 00:56:28,031 - batch_test_runner - INFO - Initialization complete
2025-08-29 00:56:28,079 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-29 00:56:28,079 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-29 00:56:28,080 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-29 00:56:28,102 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-29 00:56:28,102 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-29 00:56:28,102 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-29 00:56:28,103 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-29 00:56:28,109 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,109 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,110 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,110 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,125 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-29 00:56:28,127 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-29 00:56:28,127 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-29 00:56:28,128 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-29 00:56:28,134 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,134 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,134 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,134 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,158 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-29 00:56:28,163 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,163 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,163 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,167 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,167 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:28,167 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,168 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:28,172 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,172 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,172 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,177 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,178 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,178 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,202 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,202 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,202 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,217 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,217 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,217 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:28,227 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:28,227 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:28,227 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:29,649 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,102 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,118 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:30,325 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:30,486 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:31,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:31,052 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:31,538 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:32,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:32,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:32,043 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:33,055 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:33,119 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:33,306 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:34,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:34,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:34,227 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:35,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:35,069 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:35,617 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:36,090 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:36,344 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:36,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:37,500 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:37,569 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:38,005 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:38,007 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:38,045 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:38,521 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:39,004 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:39,021 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:40,024 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:40,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:40,663 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:40,927 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:41,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:41,284 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:41,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:41,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:42,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:42,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:42,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:43,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_sequence_disorder']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x10a2ed470>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-29 00:56:43,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:43,933 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:43,966 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:43,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_sequence_disorder']
难度: easy
目标: 每种配置 6 个实例
============================================================
○ simple_task         :   0/  6 已完成 (需要补充 6 个)
○ basic_task          :   0/  6 已完成 (需要补充 6 个)
○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
○ api_integration     :   0/  6 已完成 (需要补充 6 个)
○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)

⏳ 需要运行 30 个新测试

▶ 准备 simple_task (6 个实例)...

▶ 准备 basic_task (6 个实例)...

▶ 准备 data_pipeline (6 个实例)...

▶ 准备 api_integration (6 个实例)...

▶ 准备 multi_stage_pipeline (6 个实例)...

▶ 开始执行 30 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1038465a0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-29 00:56:45,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:45,141 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:45,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_sequence_disorder']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x110366a00>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-29 00:56:45,901 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:45,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:46,899 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:46,906 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:47,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:47,036 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:47,896 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:47,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:48,469 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:48,752 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:48,908 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:48,933 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:49,744 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:49,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:49,929 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:50,115 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:50,610 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:51,145 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:51,163 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:51,163 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:51,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:51,197 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:51,197 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:51,197 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:51,948 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:52,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:52,641 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:52,947 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:53,142 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:53,253 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:54,145 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:54,164 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:54,248 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:54,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:55,224 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:55,959 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:55,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:56,176 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:56,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:56:56,683 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:56,691 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:57,164 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:57,191 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:57,665 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:57,681 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:56:58,939 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:56:59,069 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:59,090 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:56:59,091 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:56:59,123 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:56:59,123 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:56:59,123 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:56:59,744 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:56:59,961 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:00,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:00,286 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:00,897 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:01,029 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:01,167 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:01,699 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:01,808 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:02,047 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:02,746 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:03,040 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:03,254 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:03,318 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:03,549 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:03,572 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:04,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:04,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:04,643 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:04,878 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:05,043 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:05,057 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:05,563 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:05,591 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:06,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:06,232 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:06,247 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:06,268 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:06,268 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:06,300 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:06,300 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:06,300 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x144df9fd0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c52db0ec-f61c-90a3-8116-5b3fcc45dbd5"}, traceId: 215045c117564433898247862e7f62'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"14600fa2-d4a2-921f-96aa-1460f8c9d537"}, traceId: 2150449017564433907756140e7ffa'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"628ea318-0f51-92d8-af2c-4349146d2298"}, traceId: 215045c117564433912797871e7f62'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"681361b5-78dd-96c1-9dea-8c5ad1e147a6"}, traceId: 2150449017564433917816144e7ffa'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e217a755-5ef4-9396-a26a-97d6b1a1fc9e"}, traceId: 215045c117564433937977883e7f62'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4bc279f4-cf67-9314-97a2-d0cdac0de1cd"}, traceId: 215045c117564433977537910e7f62'}
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43b61445-b97a-907f-87ea-9b8c8d2bcafd"}, traceId: 2150449017564433982616169e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54a0c2c6-db75-9e1a-8727-1d310c8f9471"}, traceId: 2150449017564434016656182e7ffa'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8b1430e-7967-9977-bc9b-e03a1ef01579"}, traceId: 2150449017564434036726187e7ffa'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"201d7fdf-9520-9712-a838-1f3fe858b9dc"}, traceId: 215045c117564434056297949e7f62'}2025-08-29 00:57:07,103 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x12edab4e0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b3b6cf4-0c6d-9bd1-aa8a-73ac8b0c408e"}, traceId: 2150458717564433898408646e7eec'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9cc53e45-cdc5-93a6-8566-8f1a647c87d6"}, traceId: 2150454117564433907771611e789c'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83e8e3c0-a87d-9787-85c3-269765ca6cb5"}, traceId: 2150454117564433927881620e789c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c8c401c-fcb7-97d8-bcd7-922d61a6a9f6"}, traceId: 2150458717564433948098689e7eec'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed314e3f-7d47-9fe4-ad63-4ec8e628fd8d"}, traceId: 2150454117564433972461639e789c'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93d215ba-faa4-9966-a5c4-49e71f4ab23e"}, traceId: 2150458717564433977508716e7eec'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a921964f-28f7-9716-965f-b7f65fb89328"}, traceId: 2150458717564433997688743e7eec'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f62024d0-9f06-9a08-a072-725fa2760e17"}, traceId: 2150454117564434016621665e789c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"feca5ea5-c5b7-9c19-b2f2-a0d39f664e72"}, traceId: 2150458717564434026688770e7eec'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"644c3313-5524-9257-bb06-eb599671472a"}, traceId: 2150454117564434036711675e789c'}2025-08-29 00:57:07,767 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:07,806 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:07,907 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:07,942 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:08,245 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:08,785 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:08,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:09,503 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:09,517 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:09,518 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:09,540 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:09,540 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:09,540 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:09,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:09,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:10,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:10,783 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:10,783 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:10,813 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:10,813 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:10,813 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:10,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:10,918 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:11,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:11,681 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:11,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:11,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:11,899 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:12,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:12,865 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:13,000 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:13,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:13,852 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:14,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:14,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:14,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:14,867 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:14,867 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:14,898 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:14,898 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:14,898 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:15,144 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:15,342 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:15,463 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:15,773 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:16,033 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:16,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:16,454 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:16,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:16,836 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:16,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:17,357 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:18,042 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:18,186 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:18,199 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-29 00:57:18,199 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-29 00:57:18,226 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-29 00:57:18,226 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-29 00:57:18,226 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-29 00:57:18,859 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:18,886 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:18,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:19,325 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:19,513 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:19,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:20,116 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:20,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:21,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:21,388 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:21,485 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:21,691 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:21,835 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:21,850 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:21,875 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:21,955 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:22,604 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:22,837 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:22,880 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:22,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:23,093 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x160560320>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3fdf53ae-f04d-96d6-a247-531065c88652"}, traceId: 2150452b17564433893827248e7891'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18cad6a7-0670-9984-91f3-db2865f4acd4"}, traceId: 215041e117564433898488614e33b8'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a6c30b4-454b-9956-8dc0-df81c36039e5"}, traceId: 215041e117564433917928627e33b8'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e2a6b0a1-ecda-9d57-932c-3959d2eedad1"}, traceId: 2150452b17564433937997263e7891'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a78e93d3-2317-9df1-b296-adc92bf33244"}, traceId: 215041e117564433948168642e33b8'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20a820ca-5d7c-97fd-b8d6-bffa75f86cc0"}, traceId: 2150452b17564433958227272e7891'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7076d9f-5071-9766-a7c8-99d528bb2dc7"}, traceId: 2150452b17564433987617293e7891'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24100e49-5e96-9389-a7d2-a8da351bcd75"}, traceId: 2150452b17564434006577303e7891'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d78c75fc-46de-9e63-8c08-728a446dcbd2"}, traceId: 215041e117564434026758717e33b8'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b56e2db-409e-9466-9d50-4d6eb999b4c1"}, traceId: 215041e117564434036798721e33b8'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0fb6c68f-f83e-9a6c-a9e7-2b426df8eb1b"}, traceId: 2150452b17564434056327343e7891'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c87b2bad-21bb-9c7e-89fc-48ff043a2557"}, traceId: 215041e117564434076548773e33b8'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"672f8f80-071e-9683-9512-6393e35306f6"}, traceId: 215041e117564434096718792e33b8'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa9cf9b5-9bcc-972d-b0f6-cf8b966d1949"}, traceId: 2150452b17564434123747391e7891'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29c1b5ed-a1f5-9568-b375-f7252f0eb413"}, traceId: 215041e117564434128848819e33b8'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"573a3f24-78cc-9386-ad23-2f0d9d04640b"}, traceId: 2150452b17564434138897404e7891'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"85dcb68d-477c-9a2c-a113-851ffa93cef8"}, traceId: 2150452b17564434164077432e7891'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1519def9-cc47-9b7a-9937-85724e00c5a2"}, traceId: 215041e117564434169188900e33b8'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 25572
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25572
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5919319872)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c74c84a-39d1-9309-9837-fcbf21176543"}, traceId: 213e041717564434214898236e96ae'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83caf7d2-7b98-9ffc-b1a2-bd9213df34b0"}, traceId: 213e059717564434228014088e34e8'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b61e23ce-57a5-996e-a4d5-ecd26caf543e"}, traceId: 215041e117564434238008991e33b8'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51473c63-91af-9fa2-9990-4d112ff3d9f0"}, traceId: 213e066e17564434248331460e7f01'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1cccbf22-95c3-9978-9df8-526d43757457"}, traceId: 215041e117564434253148999e33b8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...2025-08-29 00:57:23,637 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:23,886 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:24,829 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:25,030 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:25,318 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:25,831 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:25,834 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:25,839 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:25,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:26,058 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:26,824 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:27,354 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:27,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-29 00:57:27,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:27,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:27,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e810b310-2894-9ad7-bf3b-7ae9948c6ef8"}, traceId: 2150449017564434066366197e7ffa'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e509c200-b25f-9170-b974-416a067c6ea6"}, traceId: 215045c117564434076467954e7f62'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b4c9d9f-24f4-9e3c-b4cd-f5aa5125c0e6"}, traceId: 2150449017564434086586201e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c54591a3-b847-9844-bb7c-2d12eded0eaf"}, traceId: 215045c117564434096627967e7f62'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7bc6d10e-baf6-9d87-9840-99d739a46bd6"}, traceId: 2150449017564434103526209e7ffa'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"14e5bae6-8679-935d-bde9-1cb709353051"}, traceId: 215045c117564434123717981e7f62'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a14290b8-ea77-9c0d-929f-0d582727a540"}, traceId: 2150449017564434148936225e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f9031b0-3a61-9a69-8101-ccdd6780b0d6"}, traceId: 2150449017564434169116231e7ffa'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f517759e-c48c-97ef-8c4f-c5260abbe374"}, traceId: 215045c117564434174148003e7f62'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1edefdf5-43ba-9a33-b683-9029e32f1d55"}, traceId: 215045c117564434207718019e7f62'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ed98ba9-ba75-975d-b706-ffc27ec570f6"}, traceId: 2150449017564434217826246e7ffa'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd3a119a-2f33-9960-9fe2-fc915fd220d5"}, traceId: 2150449017564434232866255e7ffa'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7802c825-f109-95e3-811d-eb590e0fe695"}, traceId: 215045c117564434237948030e7f62'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"add06014-8166-98f8-8178-79284a908d12"}, traceId: 215045c117564434258118041e7f62'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 25584
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25584
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5220216528)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]2025-08-29 00:57:28,006 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ee5b9147-d7cc-932f-a7d3-8cd7d8c5cc4f"}, traceId: 2150458717564434066368840e7eec'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"48ef3909-b638-973c-bac2-82d7ff5369bf"}, traceId: 2150454117564434086531707e789c'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d5e9d250-32cc-9bc5-833e-c735c3c9c0f4"}, traceId: 2150454117564434098461713e789c'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cebf0241-ea8f-9490-a6e3-97e1fd574561"}, traceId: 2150458717564434108568951e7eec'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14536
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14536
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5300620368)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"228c224e-2a60-9591-aff1-2aa0f072ad0d"}, traceId: 2150454117564434138821728e789c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99475f12-39f5-9548-b0a7-4fb51bdf908a"}, traceId: 2150454117564434159001741e789c'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac691f18-b1c5-9715-9f2c-5cf3b28fcda8"}, traceId: 213e007b17564434164381762eebc5'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"923d2ff2-f551-9cc0-92f4-b380ce2e5d12"}, traceId: 2150454117564434174121756e789c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9730a0a-2bcb-9c8e-8fc3-48311f769255"}, traceId: 213e062017564434197347903e808b'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"37b054e5-3ee8-9435-87b1-5d31a521358f"}, traceId: 2150454117564434197601798e789c'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e0befef-db78-937d-a571-6391a960f218"}, traceId: 213e06c217564434233058856e837b'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.79
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c451c13-3a14-93e8-bd55-f837e2f994f3"}, traceId: 213e01f617564434248228224e1294'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cd176221-9f36-9f30-81dd-0a2e168c4474"}, traceId: 2150454117564434268121888e789c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...2025-08-29 00:57:28,980 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-29 00:57:29,255 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:29,388 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-29 00:57:29,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-29 00:57:29,866 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-29 00:57:29,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
