===== ÂàÜÁâá DeepSeek-R1-0528_easy_0 =====
Êó∂Èó¥: 2025-08-20T01:58:19.926138
Ê®°Âûã: deepseek-r1-0528
ÂÆû‰æã: DeepSeek-R1-0528
ÂëΩ‰ª§: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528 --prompt-types optimal --difficulty easy --task-types all --num-instances 6 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
ÁéØÂ¢ÉÂèòÈáè:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[01:58:21.759] 2025-08-20 01:58:21,759 - faiss.loader - INFO - Loading faiss.
[01:58:21.774] 2025-08-20 01:58:21,774 - faiss.loader - INFO - Successfully loaded faiss.
[01:58:22.764] [INFO] ‰ΩøÁî®ParquetÂ≠òÂÇ®Ê†ºÂºè
[01:58:23.131] [INFO] ‰ΩøÁî®ParquetÂ≠òÂÇ®Ê†ºÂºè
[01:58:23.133] [INFO] ‰ΩøÁî®PARQUETÂ≠òÂÇ®Ê†ºÂºè
[01:58:23.134] 
[01:58:23.134] ============================================================
[01:58:23.134] Êô∫ËÉΩÊâπÊµãËØï: deepseek-r1-0528 (idealab)
[01:58:23.134] Prompt types: ['optimal']
[01:58:23.134] ÈöæÂ∫¶: easy
[01:58:23.134] ÁõÆÊ†á: ÊØèÁßçÈÖçÁΩÆ 6 ‰∏™ÂÆû‰æã
[01:58:23.134] ============================================================
[01:58:23.134] ‚óã simple_task         :   0/  6 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 6 ‰∏™)
[01:58:23.134] ‚óã basic_task          :   0/  6 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 6 ‰∏™)
[01:58:23.134] ‚óã data_pipeline       :   0/  6 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 6 ‰∏™)
[01:58:23.134] ‚óã api_integration     :   0/  6 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 6 ‰∏™)
[01:58:23.134] ‚óã multi_stage_pipeline:   0/  6 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 6 ‰∏™)
[01:58:23.134] 
[01:58:23.134] ‚è≥ ÈúÄË¶ÅËøêË°å 30 ‰∏™Êñ∞ÊµãËØï
[01:58:23.134] 
[01:58:23.134] ‚ñ∂ ÂáÜÂ§á simple_task (6 ‰∏™ÂÆû‰æã)...
[01:58:23.134] 
[01:58:23.134] ‚ñ∂ ÂáÜÂ§á basic_task (6 ‰∏™ÂÆû‰æã)...
[01:58:23.134] 
[01:58:23.134] ‚ñ∂ ÂáÜÂ§á data_pipeline (6 ‰∏™ÂÆû‰æã)...
[01:58:23.134] 
[01:58:23.134] ‚ñ∂ ÂáÜÂ§á api_integration (6 ‰∏™ÂÆû‰æã)...
[01:58:23.134] 
[01:58:23.134] ‚ñ∂ ÂáÜÂ§á multi_stage_pipeline (6 ‰∏™ÂÆû‰æã)...
[01:58:23.134] 
[01:58:23.134] ‚ñ∂ ÂºÄÂßãÊâßË°å 30 ‰∏™ÊµãËØï...
[01:58:23.134] üì¶ ÊâπÈáèÊèê‰∫§Ê®°ÂºèÔºöÊØè20‰∏™ÊµãËØï‰øùÂ≠ò‰∏ÄÊ¨°
[01:58:23.134] üöÄ Ê£ÄÊµãÂà∞Azure APIÔºå‰ΩøÁî®Ë∂ÖÈ´òÂπ∂Âèë: workers=100, qps=200.0
[01:58:23.136] 2025-08-20 01:58:23,136 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for gpt-5-nano
[01:58:23.196] 2025-08-20 01:58:23,196 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[01:58:23.196] [AI_DEBUG] AIÂàÜÁ±ªÂô®ÂàùÂßãÂåñÊàêÂäü: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x17eb511f0>
[01:58:23.196] 2025-08-20 01:58:23,196 - batch_test_runner - INFO - Âü∫‰∫éTXTÊñá‰ª∂ÁöÑAIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî® (‰ΩøÁî®gpt-5-nano)
[01:58:23.196] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[01:58:23.203] 2025-08-20 01:58:23,203 - batch_test_runner - INFO - ============================================================
[01:58:23.204] 2025-08-20 01:58:23,204 - batch_test_runner - INFO - Batch test runner initialized
[01:58:23.204] 2025-08-20 01:58:23,204 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[01:58:23.204] 2025-08-20 01:58:23,204 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_015823.log
[01:58:23.204] 2025-08-20 01:58:23,204 - batch_test_runner - INFO - ============================================================
[01:58:23.204] 2025-08-20 01:58:23,204 - batch_test_runner - INFO - Running 30 tests with 100 workers, QPS limit: 200.0
[01:58:23.204] 2025-08-20 01:58:23,204 - batch_test_runner - INFO - Initializing test components...
[01:58:23.523] 2025-08-20 01:58:23,523 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[01:58:23.523] 2025-08-20 01:58:23,523 - batch_test_runner - INFO - ‚ö° [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[01:58:23.523] 2025-08-20 01:58:23,523 - batch_test_runner - INFO - ‚ö° This saves ~350MB memory while keeping all functionality intact
[01:58:23.523] [DEBUG] Creating new ToolCapabilityManager instance
[01:58:23.523] [OperationEmbeddingIndex] Initializing with unified API client manager
[01:58:23.523] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[01:58:23.523] 2025-08-20 01:58:23,523 - api_client_manager - INFO - Loaded configuration from config/config.json
[01:58:23.530] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[01:58:23.530] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[01:58:23.530] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[01:58:24.354] 2025-08-20 01:58:24,353 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[01:58:24.356] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[01:58:24.401] [INFO] Loaded 4150 embeddings from persistent cache
[01:58:24.401] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[01:58:24.402] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[01:58:24.402] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[01:58:24.402] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[01:58:24.410] [INFO] Successfully loaded FAISS index with dimension 3072
[01:58:24.410] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[01:58:24.410] [INFO] Loaded 15 operations with dimension 3072
[01:58:24.410] [INFO] Successfully loaded cached index
[01:58:24.410] [INFO] Operation semantic index initialized
[01:58:24.410] [INFO] Using device: cpu
[01:58:24.411] [INFO] Initialized tool success tracking attributes
[01:58:24.411] [INFO] Initializing embedding manager for enhanced tool selection
[01:58:24.411] [MCPEmbeddingManager] Creating new singleton instance
[01:58:24.411] [MCPEmbeddingManager] Initializing with unified API client manager
[01:58:24.420] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[01:58:24.420] [MCPEmbeddingManager] Client initialized successfully
[01:58:24.420] 2025-08-20 01:58:24,420 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:58:24.555] 2025-08-20 01:58:24,555 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:58:24.801] 2025-08-20 01:58:24,801 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[01:58:24.801] 2025-08-20 01:58:24,801 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[01:58:24.825] 2025-08-20 01:58:24,825 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:58:24.898] 2025-08-20 01:58:24,898 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:58:25.143] 2025-08-20 01:58:25,143 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[01:58:25.143] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[01:58:25.143] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[01:58:25.143] 2025-08-20 01:58:25,143 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:25.164] 2025-08-20 01:58:25,164 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:25.164] 2025-08-20 01:58:25,164 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:25.164] 2025-08-20 01:58:25,164 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:25.166] [SUCCESS] Loaded 30 tool embeddings
[01:58:25.166] 2025-08-20 01:58:25,166 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[01:58:25.166] [SUCCESS] Embedding manager initialized with 30 tools
[01:58:25.166] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[01:58:25.166] [INFO] Loading full MCP protocol registry...
[01:58:25.168] 2025-08-20 01:58:25,168 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:25.168] [INFO] Loaded full tool registry with 30 tools
[01:58:25.168] 2025-08-20 01:58:25,168 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:58:25.168] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:58:25.169] [INFO] Embedding manager ready with 30 tools
[01:58:25.169] [WARNING] Embedding manager exists but has no embeddings
[01:58:25.169] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[01:58:25.169] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:25.170] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:25.170] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:25.170] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[01:58:25.170] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[01:58:25.170] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:25.170] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:25.170] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:25.170] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:25.170] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:25.170] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:25.170] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:25.170] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:25.170] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:25.170] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:25.170] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:25.170] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:25.170] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:25.170] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:25.170] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:25.170] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:25.170] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:25.170] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[01:58:25.170] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[01:58:25.170] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[01:58:25.170] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[01:58:25.170] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[01:58:25.170] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[01:58:25.170] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[01:58:25.170] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[01:58:25.170] 2025-08-20 01:58:25,170 - mdp_workflow_generator - INFO - Loaded 30 tools
[01:58:25.170] [INFO] Setting default state_dim based on loaded tools
[01:58:25.170] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[01:58:25.170] 2025-08-20 01:58:25,170 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[01:58:25.170] [INFO] Setting default action_dim based on loaded tools
[01:58:25.170] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[01:58:25.170] 2025-08-20 01:58:25,170 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[01:58:25.170] [INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping neural network model loading
[01:58:25.170] [INFO] ‚ö° Memory optimization: Saving ~350MB by not loading model
[01:58:25.170] [INFO] ‚ö° Will use pre-generated workflows or random policy
[01:58:25.170] 2025-08-20 01:58:25,170 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[01:58:25.170] [INFO] Initializing TaskManager...
[01:58:26.715] 2025-08-20 01:58:26,715 - unified_training_manager - INFO - Using device: cpu
[01:58:26.827] 2025-08-20 01:58:26,826 - unified_training_manager - INFO - Task filtering results:
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO -   Total: 5040 -> 5040
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO -   simple_task: 320 -> 320
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[01:58:26.827] 2025-08-20 01:58:26,827 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[01:58:26.829] 2025-08-20 01:58:26,828 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[01:58:26.829] [TaskManager] Difficulty level 'easy': 1096 tasks
[01:58:26.829] [TaskManager] Difficulty level 'very_easy': 856 tasks
[01:58:26.829] [TaskManager] Difficulty level 'medium': 1136 tasks
[01:58:26.829] [TaskManager] Difficulty level 'hard': 1096 tasks
[01:58:26.829] [TaskManager] Difficulty level 'very_hard': 856 tasks
[01:58:26.831] [INFO] TaskManager initialized with 5040 tasks
[01:58:26.831] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:58:26.831] [INFO] Initializing ToolCallVerifier...
[01:58:26.831] [INFO] ToolCallVerifier initialized with 30 tools
[01:58:26.831] [INFO] Output tools identified: 1
[01:58:26.831] [INFO] Component initialization status:
[01:58:26.831]   - embedding_manager: initialized
[01:58:26.831]   - task_manager: initialized
[01:58:26.831]   - output_verifier: initialized
[01:58:26.831]   - tool_capability_manager: initialized
[01:58:26.831]   - tool_success_rates: initialized with 0 entries
[01:58:26.831] [INFO] MDPWorkflowGenerator initialization complete
[01:58:26.831] 2025-08-20 01:58:26,831 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[01:58:26.831] 2025-08-20 01:58:26,831 - batch_test_runner - INFO - ‚úÖ MDPWorkflowGenerator initialized successfully:
[01:58:26.831] 2025-08-20 01:58:26,831 - batch_test_runner - INFO -   - task_manager: ‚úì
[01:58:26.831] 2025-08-20 01:58:26,831 - batch_test_runner - INFO -   - output_verifier: ‚úì
[01:58:26.832] 2025-08-20 01:58:26,831 - batch_test_runner - INFO -   - embedding_manager: ‚úì
[01:58:26.832] 2025-08-20 01:58:26,831 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[01:58:26.832] 2025-08-20 01:58:26,831 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[01:58:26.832] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:26.832] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:26.832] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:58:26.832] [FlawedWorkflowGenerator] RAG support: disabled
[01:58:26.832] DEBUG: Checking generator attributes
[01:58:26.832]   - has tool_capabilities: True
[01:58:26.832]   - has tool_capability_manager: True
[01:58:26.832]   - has task_manager: True
[01:58:26.832] [INFO] Loaded 30 tools from generator
[01:58:26.832] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[01:58:26.832] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:26.832] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:26.832] [INFO] Initializing LLM client using APIClientManager
[01:58:26.840] [INFO] Using Azure OpenAI client
[01:58:26.840] [DEBUG] Checking if generator has tool_capability_manager attribute
[01:58:26.840] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[01:58:26.840] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:26.840] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:26.840] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:58:26.840] [FlawedWorkflowGenerator] RAG support: enabled
[01:58:26.840] [INFO] FlawedWorkflowGenerator initialized successfully
[01:58:26.840] [INFO] Initializing StableScorer for Phase 2 scoring
[01:58:26.840] <tool_capability_manager.ToolCapabilityManager object at 0x324b59f70>
[01:58:26.840] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:26.840] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:26.840] [INFO] Loaded tool success history for 0 tools
[01:58:26.840] [INFO] StableScorer initialized with semantic capability
[01:58:26.840] [INFO] StableScorer initialized successfully
[01:58:26.840] [INFO] Loading task instances...
[01:58:26.840] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[01:58:26.848] [INFO] Loaded 630 task instances
[01:58:26.848] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:58:26.848] 2025-08-20 01:58:26,848 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[01:58:26.848] 2025-08-20 01:58:26,848 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[01:58:27.143] 2025-08-20 01:58:27,143 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[01:58:27.144] 2025-08-20 01:58:27,143 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[01:58:27.161] 2025-08-20 01:58:27,161 - batch_test_runner - INFO - Initialization complete
[01:58:27.194] 2025-08-20 01:58:27,194 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[01:58:27.194] 2025-08-20 01:58:27,194 - batch_test_runner - INFO - Starting batch test with 30 tasks, 100 workers
[01:58:27.194] 2025-08-20 01:58:27,194 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[01:58:27.197] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.199] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.199] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.199] 
[01:58:27.199] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.200] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.222] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.222] 2025-08-20 01:58:27,222 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for DeepSeek-R1-0528
[01:58:27.225] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.226] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.226] 
[01:58:27.226] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.226] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.233] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.233] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.233] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.233] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.233] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.233] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.234] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.234] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.234] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.234] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.234] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.234] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.234] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.234] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.234] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.234] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.234] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.235] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.235] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.235] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.236] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.237] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.238] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.238] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.238] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.238] 2025-08-20 01:58:27,237 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.238] 
[01:58:27.240] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.240] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.240] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.240] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.240] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.240] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.240] 2025-08-20 01:58:27,239 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.242] 2025-08-20 01:58:27,242 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.243] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.243] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.243] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.243] 2025-08-20 01:58:27,243 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.244] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.244] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.244] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.244] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.244] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.244] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.244] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.244] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.245] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.245] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.245] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.245] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.246] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.246] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.247] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.247] 2025-08-20 01:58:27,246 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.248] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.248] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.248] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.249] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.249] 2025-08-20 01:58:27,248 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.252] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.252] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.252] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.252] 2025-08-20 01:58:27,252 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.252] [InteractiveExecutor] API model name: DeepSeek-R1-0528[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.252] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.253] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.254] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.254] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.254] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.254] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.255] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.255] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.255] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.255] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.256] 
[01:58:27.256] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.256] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.256] 
[01:58:27.256] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.256] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.257] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.257] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)[InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.257] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.257] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.257] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.257] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.257] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.257] 2025-08-20 01:58:27,257 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.259] 
[01:58:27.261] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.261] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.261] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.261] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.262] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.262] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.264] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.264] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.264] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.265] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.265] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.265] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.266] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.267] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.267] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.267] 2025-08-20 01:58:27,258 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.267] 2025-08-20 01:58:27,262 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.267] 2025-08-20 01:58:27,262 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.267] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.267] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.267] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.268] 
[01:58:27.268] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.268] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.268] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.269] 2025-08-20 01:58:27,262 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.270] 2025-08-20 01:58:27,264 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.271] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.271] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.273] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.273] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.275] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.275] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.275] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.279] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.279] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.289] 2025-08-20 01:58:27,289 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.289] 2025-08-20 01:58:27,289 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.289] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.289] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.293] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.297] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.297] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.297] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.300] 2025-08-20 01:58:27,299 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.301] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.301] 2025-08-20 01:58:27,301 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.301] 2025-08-20 01:58:27,301 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.301] 2025-08-20 01:58:27,301 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.301] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.302] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.302] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.304] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.304] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.304] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.305] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.307] 2025-08-20 01:58:27,306 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.307] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.307] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.310] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.310] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.310] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.321] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.321] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.321] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.327] 2025-08-20 01:58:27,327 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.344] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.344] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.344] [MCPEmbeddingManager] Current cache size: 12 embeddings
[01:58:27.359] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.359] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.360] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.360] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.360] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.361] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.361] 2025-08-20 01:58:27,348 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.386] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:27.398] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-05282025-08-20 01:58:27,349 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.408] 
[01:58:27.409] 2025-08-20 01:58:27,351 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.416] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.416] 2025-08-20 01:58:27,352 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.416] 2025-08-20 01:58:27,361 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.418] 2025-08-20 01:58:27,361 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.433] 2025-08-20 01:58:27,394 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.434] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.435] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.453] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.455] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.455] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.478] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.478] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.478] [MCPEmbeddingManager] Current cache size: 2 embeddings
[01:58:27.494] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.495] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.501] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.501] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.501] [MCPEmbeddingManager] Current cache size: 14 embeddings
[01:58:27.502] 2025-08-20 01:58:27,416 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.504] [INFO] Tool embedding index loaded successfully
[01:58:27.506] 2025-08-20 01:58:27,416 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.512] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:58:27.512] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:27.519] 2025-08-20 01:58:27,418 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.525] 2025-08-20 01:58:27,433 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.540] 2025-08-20 01:58:27,453 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.541] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.541] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.541] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.552] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:58:27.553] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13510458976)
[01:58:27.553] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:27.560] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.560] 2025-08-20 01:58:27,478 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.560] 2025-08-20 01:58:27,501 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.560] 2025-08-20 01:58:27,505 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.592] 2025-08-20 01:58:27,519 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:58:27.594] [INFO] Tool embedding index loaded successfully
[01:58:27.602] 2025-08-20 01:58:27,519 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.608] 2025-08-20 01:58:27,525 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:58:27.616] [INFO] Tool embedding index loaded successfully
[01:58:27.617] [INFO] Operation semantic index initialized
[01:58:27.618] 
[01:58:27.618] [TURN 1/10]
[01:58:27.623] 2025-08-20 01:58:27,535 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.634] 2025-08-20 01:58:27,560 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.647] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.653] [INFO] Operation semantic index initialized
[01:58:27.653] 
[01:58:27.653] [TURN 1/10]
[01:58:27.678] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.695] 2025-08-20 01:58:27,560 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.697] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.700] 2025-08-20 01:58:27,572 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.701] [INFO] Operation semantic index initialized
[01:58:27.701] 2025-08-20 01:58:27,596 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.702] 
[01:58:27.703] [TURN 1/10]2025-08-20 01:58:27,602 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.704] 
[01:58:27.711] 2025-08-20 01:58:27,618 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:27.716] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.723] 2025-08-20 01:58:27,618 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.730] 2025-08-20 01:58:27,623 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.730] 2025-08-20 01:58:27,730 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.732] [INFO] Tool embedding index loaded successfully
[01:58:27.733] 2025-08-20 01:58:27,642 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.734] 2025-08-20 01:58:27,648 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.735] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.736] 2025-08-20 01:58:27,652 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.738] 2025-08-20 01:58:27,676 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.764] 2025-08-20 01:58:27,697 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.784] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.796] 2025-08-20 01:58:27,698 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.802] 2025-08-20 01:58:27,698 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.808] [INFO] Operation semantic index initialized
[01:58:27.808] 
[01:58:27.808] [TURN 1/10]
[01:58:27.808] 2025-08-20 01:58:27,700 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.809] 2025-08-20 01:58:27,703 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.819] [INFO] Tool embedding index loaded successfully2025-08-20 01:58:27,724 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.820] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.821] 
[01:58:27.831] 2025-08-20 01:58:27,729 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.832] 2025-08-20 01:58:27,634 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.834] [INFO] Tool embedding index loaded successfully
[01:58:27.835] 2025-08-20 01:58:27,733 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.836] 2025-08-20 01:58:27,734 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.837] 2025-08-20 01:58:27,735 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.840] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-20 01:58:27,736 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.840] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.841] 
[01:58:27.841] 2025-08-20 01:58:27,756 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.841] 2025-08-20 01:58:27,764 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.841] [INFO] Operation semantic index initialized
[01:58:27.842] [INFO] Operation semantic index initialized
[01:58:27.842] 
[01:58:27.842] [TURN 1/10]
[01:58:27.842] 
[01:58:27.843] [TURN 1/10]2025-08-20 01:58:27,774 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.843] 
[01:58:27.845] 2025-08-20 01:58:27,789 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.847] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.849] 2025-08-20 01:58:27,796 - mcp_embedding_manager - INFO - Index loaded successfully: 21 tools
[01:58:27.852] [INFO] Tool embedding index loaded successfully
[01:58:27.852] 2025-08-20 01:58:27,802 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.852] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.854] 2025-08-20 01:58:27,808 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.856] [INFO] Tool embedding index loaded successfully
[01:58:27.858] 2025-08-20 01:58:27,808 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.864] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.870] 2025-08-20 01:58:27,819 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.874] 2025-08-20 01:58:27,820 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.886] [INFO] Operation semantic index initialized
[01:58:27.887] 
[01:58:27.887] [TURN 1/10]
[01:58:27.887] 2025-08-20 01:58:27,828 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.887] 2025-08-20 01:58:27,887 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.894] 2025-08-20 01:58:27,828 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.925] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.933] 2025-08-20 01:58:27,832 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.933] [INFO] Operation semantic index initialized
[01:58:27.933] 
[01:58:27.933] [TURN 1/10]
[01:58:27.934] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-05282025-08-20 01:58:27,835 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.938] [INFO] Tool embedding index loaded successfully
[01:58:27.938] 
[01:58:27.938] 2025-08-20 01:58:27,836 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.941] [INFO] Tool embedding index loaded successfully
[01:58:27.942] 2025-08-20 01:58:27,840 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.943] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.949] 2025-08-20 01:58:27,841 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.952] [INFO] Tool embedding index loaded successfully
[01:58:27.952] 2025-08-20 01:58:27,841 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.954] [INFO] Tool embedding index loaded successfully
[01:58:27.958] 2025-08-20 01:58:27,842 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.960] [INFO] Tool embedding index loaded successfully
[01:58:27.960] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.961] 2025-08-20 01:58:27,844 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.962] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.962] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.962] 2025-08-20 01:58:27,845 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.962] [INFO] Operation semantic index initialized
[01:58:27.962] 
[01:58:27.962] [TURN 1/10]
[01:58:27.962] [INFO] Operation semantic index initialized
[01:58:27.962] 2025-08-20 01:58:27,852 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.965] [INFO] Tool embedding index loaded successfully
[01:58:27.965] 
[01:58:27.965] [TURN 1/10]
[01:58:27.965] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.966] [INFO] Operation semantic index initialized
[01:58:27.966] 
[01:58:27.966] [TURN 1/10]
[01:58:27.966] 2025-08-20 01:58:27,858 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.966] [INFO] Operation semantic index initialized
[01:58:27.966] 
[01:58:27.966] [TURN 1/10][INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.966] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.967] 2025-08-20 01:58:27,870 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.967] 
[01:58:27.968] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.968] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.969] 2025-08-20 01:58:27,874 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.970] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.970] [INFO] Operation semantic index initialized2025-08-20 01:58:27,887 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.970] 2025-08-20 01:58:27,970 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.970] 2025-08-20 01:58:27,970 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.970] 
[01:58:27.970] 
[01:58:27.970] [TURN 1/10]
[01:58:27.972] [INFO] Tool embedding index loaded successfully
[01:58:27.972] 2025-08-20 01:58:27,831 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.975] [INFO] Tool embedding index loaded successfully
[01:58:27.975] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.976] [INFO] Operation semantic index initialized
[01:58:27.976] 
[01:58:27.976] [TURN 1/10]
[01:58:27.976] 2025-08-20 01:58:27,933 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.976] 2025-08-20 01:58:27,933 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.976] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:27.977] 2025-08-20 01:58:27,933 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.977] 2025-08-20 01:58:27,977 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.977] 2025-08-20 01:58:27,941 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.977] 2025-08-20 01:58:27,977 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:27.977] 2025-08-20 01:58:27,961 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.979] [INFO] Tool embedding index loaded successfully
[01:58:27.979] 2025-08-20 01:58:27,962 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.982] [INFO] Tool embedding index loaded successfully
[01:58:27.982] 2025-08-20 01:58:27,965 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:27.982] 2025-08-20 01:58:27,966 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.985] [INFO] Tool embedding index loaded successfully
[01:58:27.985] 2025-08-20 01:58:27,967 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.987] [INFO] Tool embedding index loaded successfully
[01:58:27.988] 2025-08-20 01:58:27,969 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.988] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.988] [INFO] Operation semantic index initialized
[01:58:27.988] 
[01:58:27.988] [TURN 1/10]
[01:58:27.989] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.991] [INFO] Tool embedding index loaded successfully
[01:58:27.992] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.992] [INFO] Operation semantic index initialized
[01:58:27.992] 
[01:58:27.992] [TURN 1/10]
[01:58:27.992] [INFO] Operation semantic index initialized2025-08-20 01:58:27,894 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:58:27.995] [INFO] Tool embedding index loaded successfully
[01:58:27.995] 2025-08-20 01:58:27,887 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:27.995] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.996] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.996] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:27.999] [INFO] Tool embedding index loaded successfully
[01:58:28.000] 2025-08-20 01:58:27,976 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:28.000] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.000] 
[01:58:28.001] [INFO] Operation semantic index initialized
[01:58:28.001] 
[01:58:28.001] [TURN 1/10]
[01:58:28.001] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.002] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.002] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.003] 
[01:58:28.003] [INFO] Operation semantic index initialized
[01:58:28.003] [TURN 1/10]
[01:58:28.003] [INFO] Operation semantic index initialized
[01:58:28.003] 
[01:58:28.003] [TURN 1/10]
[01:58:28.003] 2025-08-20 01:58:27,976 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.006] [INFO] Tool embedding index loaded successfully
[01:58:28.006] [INFO] Operation semantic index initialized
[01:58:28.006] 
[01:58:28.006] [TURN 1/10]
[01:58:28.006] 
[01:58:28.006] 2025-08-20 01:58:27,977 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.009] [INFO] Tool embedding index loaded successfully
[01:58:28.009] 
[01:58:28.009] [TURN 1/10]
[01:58:28.009] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.010] [INFO] Operation semantic index initialized
[01:58:28.011] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.012] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.012] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.013] 2025-08-20 01:58:27,942 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.015] [INFO] Tool embedding index loaded successfully
[01:58:28.016] [INFO] Operation semantic index initialized
[01:58:28.016] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.017] 2025-08-20 01:58:27,977 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.020] [INFO] Tool embedding index loaded successfully
[01:58:28.020] 
[01:58:28.020] [TURN 1/10]
[01:58:28.020] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.021] 
[01:58:28.021] [TURN 1/10]
[01:58:28.021] 2025-08-20 01:58:27,961 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:28.021] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.022] [INFO] Operation semantic index initialized
[01:58:28.022] 
[01:58:28.022] [TURN 1/10]
[01:58:28.022] 2025-08-20 01:58:27,982 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:28.023] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.023] 2025-08-20 01:58:28,000 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.025] [INFO] Tool embedding index loaded successfully
[01:58:28.026] 2025-08-20 01:58:28,021 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:28.026] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.026] 2025-08-20 01:58:28,023 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.029] [INFO] Tool embedding index loaded successfully
[01:58:28.029] [INFO] Operation semantic index initialized
[01:58:28.029] 2025-08-20 01:58:28,026 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:28.032] [INFO] Tool embedding index loaded successfully
[01:58:28.032] [INFO] Operation semantic index initialized
[01:58:28.032] 
[01:58:28.032] [TURN 1/10]
[01:58:28.033] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.033] 
[01:58:28.033] [TURN 1/10]
[01:58:28.033] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.034] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.035] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.035] [INFO] Operation semantic index initialized
[01:58:28.035] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.036] 
[01:58:28.036] [TURN 1/10]
[01:58:28.036] [INFO] Operation semantic index initialized
[01:58:28.036] 
[01:58:28.036] [TURN 1/10]
[01:58:28.036] [INFO] Operation semantic index initialized
[01:58:28.036] 
[01:58:28.036] [TURN 1/10]
[01:58:28.037] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:28.037] 
[01:58:28.038] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.038] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.039] [INFO] Operation semantic index initialized
[01:58:28.039] 
[01:58:28.039] [TURN 1/10]
[01:58:28.040] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528[LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.040] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:58:28.041] 
[01:58:28.042] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:59:12.355] 2025-08-20 01:59:12,354 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:12.360]   [SEARCH] Query: file_operations_reader
[01:59:12.361] 
[01:59:12.361] [TURN 2/10]
[01:59:12.361] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:59:20.137] 2025-08-20 01:59:20,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:20.152]   [SEARCH] Query: file reader
[01:59:20.154] 
[01:59:20.154] [TURN 2/10]
[01:59:20.156] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:00:26.602] 2025-08-20 02:00:26,601 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:26.605]   [SEARCH] Query: file reader
[02:00:26.607] 
[02:00:26.607] [TURN 2/10]
[02:00:26.609] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:00:28.099] 2025-08-20 02:00:28,099 - openai._base_client - INFO - Retrying request to /chat/completions in 0.449693 seconds
[02:00:28.124] 2025-08-20 02:00:28,123 - openai._base_client - INFO - Retrying request to /chat/completions in 0.494365 seconds
[02:00:28.124] 2025-08-20 02:00:28,123 - openai._base_client - INFO - Retrying request to /chat/completions in 0.429992 seconds
[02:00:28.148] 2025-08-20 02:00:28,147 - openai._base_client - INFO - Retrying request to /chat/completions in 0.455583 seconds
[02:00:28.165] 2025-08-20 02:00:28,165 - openai._base_client - INFO - Retrying request to /chat/completions in 0.453621 seconds
[02:00:28.204] 2025-08-20 02:00:28,204 - openai._base_client - INFO - Retrying request to /chat/completions in 0.453928 seconds
[02:00:28.215] 2025-08-20 02:00:28,214 - openai._base_client - INFO - Retrying request to /chat/completions in 0.439790 seconds
[02:00:28.231] 2025-08-20 02:00:28,230 - openai._base_client - INFO - Retrying request to /chat/completions in 0.379205 seconds
[02:00:28.240] 2025-08-20 02:00:28,239 - openai._base_client - INFO - Retrying request to /chat/completions in 0.413042 seconds
[02:00:28.240] 2025-08-20 02:00:28,240 - openai._base_client - INFO - Retrying request to /chat/completions in 0.430510 seconds
[02:00:28.252] 2025-08-20 02:00:28,251 - openai._base_client - INFO - Retrying request to /chat/completions in 0.471350 seconds
[02:00:28.254] 2025-08-20 02:00:28,253 - openai._base_client - INFO - Retrying request to /chat/completions in 0.392316 seconds
[02:00:28.258] 2025-08-20 02:00:28,258 - openai._base_client - INFO - Retrying request to /chat/completions in 0.460228 seconds
[02:00:28.260] 2025-08-20 02:00:28,260 - openai._base_client - INFO - Retrying request to /chat/completions in 0.427795 seconds
[02:00:28.271] 2025-08-20 02:00:28,270 - openai._base_client - INFO - Retrying request to /chat/completions in 0.455715 seconds
[02:00:28.279] 2025-08-20 02:00:28,279 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394143 seconds
[02:00:28.286] 2025-08-20 02:00:28,286 - openai._base_client - INFO - Retrying request to /chat/completions in 0.404471 seconds
[02:00:28.290] 2025-08-20 02:00:28,290 - openai._base_client - INFO - Retrying request to /chat/completions in 0.430291 seconds
[02:00:28.290] 2025-08-20 02:00:28,290 - openai._base_client - INFO - Retrying request to /chat/completions in 0.478891 seconds
[02:00:28.303] 2025-08-20 02:00:28,303 - openai._base_client - INFO - Retrying request to /chat/completions in 0.477409 seconds
[02:00:28.303] 2025-08-20 02:00:28,303 - openai._base_client - INFO - Retrying request to /chat/completions in 0.483250 seconds
[02:00:28.304] 2025-08-20 02:00:28,304 - openai._base_client - INFO - Retrying request to /chat/completions in 0.468348 seconds
[02:00:28.304] 2025-08-20 02:00:28,304 - openai._base_client - INFO - Retrying request to /chat/completions in 0.475787 seconds
[02:00:28.307] 2025-08-20 02:00:28,307 - openai._base_client - INFO - Retrying request to /chat/completions in 0.485896 seconds
[02:00:28.308] 2025-08-20 02:00:28,307 - openai._base_client - INFO - Retrying request to /chat/completions in 0.404220 seconds
[02:00:28.308] 2025-08-20 02:00:28,308 - openai._base_client - INFO - Retrying request to /chat/completions in 0.453348 seconds
[02:00:28.344] 2025-08-20 02:00:28,344 - openai._base_client - INFO - Retrying request to /chat/completions in 0.384123 seconds
[02:00:51.091] 2025-08-20 02:00:51,091 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:51.094]   [SEARCH] Query: file_operations_reader
[02:00:51.094] 
[02:00:51.094] [TURN 2/10]
[02:00:51.094] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:01:12.369] 2025-08-20 02:01:12,368 - openai._base_client - INFO - Retrying request to /chat/completions in 0.427390 seconds
[02:01:20.165] 2025-08-20 02:01:20,165 - openai._base_client - INFO - Retrying request to /chat/completions in 0.430965 seconds
[02:02:26.620] 2025-08-20 02:02:26,618 - openai._base_client - INFO - Retrying request to /chat/completions in 0.407606 seconds
[02:02:28.863] 2025-08-20 02:02:28,863 - openai._base_client - INFO - Retrying request to /chat/completions in 0.977748 seconds
[02:02:28.873] 2025-08-20 02:02:28,873 - openai._base_client - INFO - Retrying request to /chat/completions in 0.881473 seconds
[02:02:28.878] 2025-08-20 02:02:28,878 - openai._base_client - INFO - Retrying request to /chat/completions in 0.780312 seconds
[02:02:28.886] 2025-08-20 02:02:28,885 - openai._base_client - INFO - Retrying request to /chat/completions in 0.927827 seconds
[02:02:28.889] 2025-08-20 02:02:28,889 - openai._base_client - INFO - Retrying request to /chat/completions in 0.840331 seconds
[02:02:28.892] 2025-08-20 02:02:28,892 - openai._base_client - INFO - Retrying request to /chat/completions in 0.859229 seconds
[02:02:28.901] 2025-08-20 02:02:28,901 - openai._base_client - INFO - Retrying request to /chat/completions in 0.940742 seconds
[02:02:28.904] 2025-08-20 02:02:28,904 - openai._base_client - INFO - Retrying request to /chat/completions in 0.990051 seconds
[02:02:28.917] 2025-08-20 02:02:28,916 - openai._base_client - INFO - Retrying request to /chat/completions in 0.806846 seconds
[02:02:28.918] 2025-08-20 02:02:28,918 - openai._base_client - INFO - Retrying request to /chat/completions in 0.955808 seconds
[02:02:28.930] 2025-08-20 02:02:28,930 - openai._base_client - INFO - Retrying request to /chat/completions in 0.904558 seconds
[02:02:28.950] 2025-08-20 02:02:28,949 - openai._base_client - INFO - Retrying request to /chat/completions in 0.861545 seconds
[02:02:28.960] 2025-08-20 02:02:28,960 - openai._base_client - INFO - Retrying request to /chat/completions in 0.990571 seconds
[02:02:28.971] 2025-08-20 02:02:28,970 - openai._base_client - INFO - Retrying request to /chat/completions in 0.785562 seconds
[02:02:28.971] 2025-08-20 02:02:28,971 - openai._base_client - INFO - Retrying request to /chat/completions in 0.970119 seconds
[02:02:28.972] 2025-08-20 02:02:28,972 - openai._base_client - INFO - Retrying request to /chat/completions in 0.830478 seconds
[02:02:28.979] 2025-08-20 02:02:28,978 - openai._base_client - INFO - Retrying request to /chat/completions in 0.957424 seconds
[02:02:28.984] 2025-08-20 02:02:28,984 - openai._base_client - INFO - Retrying request to /chat/completions in 0.987277 seconds
[02:02:28.986] 2025-08-20 02:02:28,986 - openai._base_client - INFO - Retrying request to /chat/completions in 0.751402 seconds
[02:02:29.006] 2025-08-20 02:02:29,006 - openai._base_client - INFO - Retrying request to /chat/completions in 0.934894 seconds
[02:02:29.026] 2025-08-20 02:02:29,026 - openai._base_client - INFO - Retrying request to /chat/completions in 0.871655 seconds
[02:02:29.039] 2025-08-20 02:02:29,039 - openai._base_client - INFO - Retrying request to /chat/completions in 0.859966 seconds
[02:02:29.040] 2025-08-20 02:02:29,039 - openai._base_client - INFO - Retrying request to /chat/completions in 0.852003 seconds
[02:02:29.046] 2025-08-20 02:02:29,046 - openai._base_client - INFO - Retrying request to /chat/completions in 0.960890 seconds
[02:02:29.046] 2025-08-20 02:02:29,046 - openai._base_client - INFO - Retrying request to /chat/completions in 0.932673 seconds
[02:02:29.057] 2025-08-20 02:02:29,057 - openai._base_client - INFO - Retrying request to /chat/completions in 0.896311 seconds
[02:02:51.173] 2025-08-20 02:02:51,172 - openai._base_client - INFO - Retrying request to /chat/completions in 0.470620 seconds
[02:03:13.151] 2025-08-20 02:03:13,150 - openai._base_client - INFO - Retrying request to /chat/completions in 0.772197 seconds
[02:03:18.681] 2025-08-20 02:03:18,680 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:03:18.684]   [SEARCH] Query: network api fetch
[02:03:18.686] 
[02:03:18.686] [TURN 2/10]
[02:03:18.687] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:03:20.938] 2025-08-20 02:03:20,938 - openai._base_client - INFO - Retrying request to /chat/completions in 0.820464 seconds
[02:03:35.665] 2025-08-20 02:03:35,664 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:03:35.668]   [SEARCH] Query: data parser
[02:03:35.670] 
[02:03:35.670] [TURN 2/10]
[02:03:35.671] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:03:41.151] 2025-08-20 02:03:41,151 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:03:41.152]   [SEARCH] Query: data validation
[02:03:41.153] 
[02:03:41.153] [TURN 2/10]
[02:03:41.154] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:04:01.116] 2025-08-20 02:04:01,115 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:01.119]   [SEARCH] Query: api fetch
[02:04:01.121] 
[02:04:01.121] [TURN 2/10]
[02:04:01.133] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:04:09.327] 2025-08-20 02:04:09,327 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:09.343]   [PARSE] Fuzzy matched 'network_fetcher
[02:04:09.344] {
[02:04:09.344]   "source": "https://api.example.com/data",
[02:04:09.344]   "timeout": 30,
[02:04:09.349]   "retry_count": 3
[02:04:09.349] }' to 'network_fetcher'
[02:04:09.349]   [EXECUTING] network_fetcher
[02:04:09.355]     Result: SUCCESS
[02:04:09.355] 
[02:04:09.355] [TURN 3/10]
[02:04:09.356] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:04:27.365] 2025-08-20 02:04:27,364 - openai._base_client - INFO - Retrying request to /chat/completions in 0.899159 seconds
[02:04:30.046] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.046] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.046]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.069] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.069] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.069]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.072] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:30.072] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:30.073] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4245
[02:04:30.073] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:30.073]   - use_ai_classification=True
[02:04:30.073]   - ai_classifier=True
[02:04:30.073]   - txt_content_len=4245
[02:04:30.073]   - task_model=deepseek-r1-0528
[02:04:30.090] [LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.090] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.090]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.091] 
[02:04:30.091] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.091]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.097] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.097] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.097]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.153] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.153] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.154]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.160] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.160] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.160]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.167] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.168] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.168]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.195] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.195] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.195]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.230] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.231] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.232]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.232] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.232] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.232]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.240] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.240] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.240]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.256] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.256] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.256]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.257] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.257] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.257]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.258] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.258] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.258]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.273] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.273] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.273] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.273]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.273] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.273]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.305] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.305] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.306] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.306] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.306]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.306]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.340] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.340] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.340]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.342] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.342] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.342]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.351] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:04:30.351] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:04:30.351]   [API_FAILURE] API failed (timeout or max retries)
[02:04:30.685] 2025-08-20 02:04:30,685 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:30.691] 2025-08-20 02:04:30,691 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:30.691] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:30.697] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:30.697] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:30.697] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4179
[02:04:30.697] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:30.697]   - use_ai_classification=True
[02:04:30.697]   - ai_classifier=True
[02:04:30.697]   - txt_content_len=4179
[02:04:30.697]   - task_model=deepseek-r1-0528
[02:04:30.842] 2025-08-20 02:04:30,842 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:30.843] 2025-08-20 02:04:30,843 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:30.843] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:30.847] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:30.847] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:30.847] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4097
[02:04:30.847] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:30.848]   - use_ai_classification=True
[02:04:30.848]   - ai_classifier=True
[02:04:30.848]   - txt_content_len=4097
[02:04:30.848]   - task_model=deepseek-r1-0528
[02:04:30.966] 2025-08-20 02:04:30,966 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:30.966] 2025-08-20 02:04:30,966 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:30.967] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:30.968] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:30.968] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:30.968] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4685
[02:04:30.968] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:30.968]   - use_ai_classification=True
[02:04:30.969]   - ai_classifier=True
[02:04:30.969]   - txt_content_len=4685
[02:04:30.969]   - task_model=deepseek-r1-0528
[02:04:31.133] 2025-08-20 02:04:31,132 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:31.134] 2025-08-20 02:04:31,134 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:31.134] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:31.138] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.138] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:31.138] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4201
[02:04:31.138] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.138]   - use_ai_classification=True
[02:04:31.139]   - ai_classifier=True
[02:04:31.139]   - txt_content_len=4201
[02:04:31.139]   - task_model=deepseek-r1-0528
[02:04:31.267] 2025-08-20 02:04:31,267 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:31.267] 2025-08-20 02:04:31,267 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:31.267] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:31.272] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.272] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:31.272] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4232
[02:04:31.272] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.272]   - use_ai_classification=True
[02:04:31.272]   - ai_classifier=True
[02:04:31.272]   - txt_content_len=4232
[02:04:31.272]   - task_model=deepseek-r1-0528
[02:04:31.397] 2025-08-20 02:04:31,397 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:31.398] 2025-08-20 02:04:31,398 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:31.398] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:31.400] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.400] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:31.400] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4442
[02:04:31.400] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.400]   - use_ai_classification=True
[02:04:31.400]   - ai_classifier=True
[02:04:31.400]   - txt_content_len=4442
[02:04:31.400]   - task_model=deepseek-r1-0528
[02:04:31.646] 2025-08-20 02:04:31,645 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:31.646] 2025-08-20 02:04:31,646 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:31.646] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:31.651] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.651] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:31.651] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4416
[02:04:31.651] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.651]   - use_ai_classification=True
[02:04:31.652]   - ai_classifier=True
[02:04:31.652]   - txt_content_len=4416
[02:04:31.652]   - task_model=deepseek-r1-0528
[02:04:31.785] 2025-08-20 02:04:31,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:31.785] 2025-08-20 02:04:31,785 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:31.785] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:31.788] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.788] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:31.788] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4647
[02:04:31.788] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.788]   - use_ai_classification=True
[02:04:31.788]   - ai_classifier=True
[02:04:31.788]   - txt_content_len=4647
[02:04:31.788]   - task_model=deepseek-r1-0528
[02:04:31.930] 2025-08-20 02:04:31,930 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:31.930] 2025-08-20 02:04:31,930 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:31.930] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:31.932] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.932] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:31.933] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4083
[02:04:31.933] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.933]   - use_ai_classification=True
[02:04:31.933]   - ai_classifier=True
[02:04:31.933]   - txt_content_len=4083
[02:04:31.933]   - task_model=deepseek-r1-0528
[02:04:32.059] 2025-08-20 02:04:32,059 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.059] 2025-08-20 02:04:32,059 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.060] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.063] Progress: 10/30 (Success: 0)
[02:04:32.063] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.063] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.063] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4144
[02:04:32.063] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.063]   - use_ai_classification=True
[02:04:32.063]   - ai_classifier=True
[02:04:32.063]   - txt_content_len=4144
[02:04:32.063]   - task_model=deepseek-r1-0528
[02:04:32.202] 2025-08-20 02:04:32,202 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.203] 2025-08-20 02:04:32,202 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.203] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.206] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.206] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.206] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4557
[02:04:32.206] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.206]   - use_ai_classification=True
[02:04:32.206]   - ai_classifier=True
[02:04:32.206]   - txt_content_len=4557
[02:04:32.206]   - task_model=deepseek-r1-0528
[02:04:32.329] 2025-08-20 02:04:32,329 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.329] 2025-08-20 02:04:32,329 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.329] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.331] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.331] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.331] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4426
[02:04:32.331] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.331]   - use_ai_classification=True
[02:04:32.331]   - ai_classifier=True
[02:04:32.331]   - txt_content_len=4426
[02:04:32.331]   - task_model=deepseek-r1-0528
[02:04:32.453] 2025-08-20 02:04:32,453 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.456] 2025-08-20 02:04:32,456 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.456] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.459] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.459] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.459] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4713
[02:04:32.459] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.459]   - use_ai_classification=True
[02:04:32.459]   - ai_classifier=True
[02:04:32.459]   - txt_content_len=4713
[02:04:32.459]   - task_model=deepseek-r1-0528
[02:04:32.604] 2025-08-20 02:04:32,603 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.608] 2025-08-20 02:04:32,607 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.608] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.612] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.612] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.612] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4834
[02:04:32.612] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.612]   - use_ai_classification=True
[02:04:32.612]   - ai_classifier=True
[02:04:32.612]   - txt_content_len=4834
[02:04:32.612]   - task_model=deepseek-r1-0528
[02:04:32.749] 2025-08-20 02:04:32,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.750] 2025-08-20 02:04:32,750 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.750] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.764] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.764] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.764] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4834
[02:04:32.764] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.764]   - use_ai_classification=True
[02:04:32.764]   - ai_classifier=True
[02:04:32.764]   - txt_content_len=4834
[02:04:32.764]   - task_model=deepseek-r1-0528
[02:04:32.962] 2025-08-20 02:04:32,961 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:32.963] 2025-08-20 02:04:32,962 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:32.963] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:32.968] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:32.968] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:32.968] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4454
[02:04:32.968] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:32.968]   - use_ai_classification=True
[02:04:32.968]   - ai_classifier=True
[02:04:32.968]   - txt_content_len=4454
[02:04:32.968]   - task_model=deepseek-r1-0528
[02:04:33.118] 2025-08-20 02:04:33,118 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:33.118] 2025-08-20 02:04:33,118 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:33.118] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:33.124] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:33.124] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:33.124] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4732
[02:04:33.124] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:33.124]   - use_ai_classification=True
[02:04:33.124]   - ai_classifier=True
[02:04:33.124]   - txt_content_len=4732
[02:04:33.124]   - task_model=deepseek-r1-0528
[02:04:33.271] 2025-08-20 02:04:33,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:33.273] 2025-08-20 02:04:33,272 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:33.273] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:33.274] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:33.274] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:33.274] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4554
[02:04:33.274] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:33.274]   - use_ai_classification=True
[02:04:33.274]   - ai_classifier=True
[02:04:33.274]   - txt_content_len=4554
[02:04:33.274]   - task_model=deepseek-r1-0528
[02:04:33.397] 2025-08-20 02:04:33,397 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:33.398] 2025-08-20 02:04:33,398 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:33.398] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:33.402] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:33.402] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:33.402] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4703
[02:04:33.402] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:33.402]   - use_ai_classification=True
[02:04:33.402]   - ai_classifier=True
[02:04:33.402]   - txt_content_len=4703
[02:04:33.402]   - task_model=deepseek-r1-0528
[02:04:33.547] 2025-08-20 02:04:33,547 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:33.547] 2025-08-20 02:04:33,547 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:33.547] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:33.550] Progress: 20/30 (Success: 0)
[02:04:33.550] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:33.550] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:33.550] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4758
[02:04:33.550] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:33.550]   - use_ai_classification=True
[02:04:33.550]   - ai_classifier=True
[02:04:33.550]   - txt_content_len=4758
[02:04:33.550]   - task_model=deepseek-r1-0528
[02:04:33.690] 2025-08-20 02:04:33,690 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:33.690] 2025-08-20 02:04:33,690 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:33.690] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:33.692] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:33.692] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:04:33.692] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4222
[02:04:33.692] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:33.692]   - use_ai_classification=True
[02:04:33.692]   - ai_classifier=True
[02:04:33.692]   - txt_content_len=4222
[02:04:33.692]   - task_model=deepseek-r1-0528
[02:04:33.814] 2025-08-20 02:04:33,814 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:33.815] 2025-08-20 02:04:33,814 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:33.815] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:04:51.891] 2025-08-20 02:04:51,891 - openai._base_client - INFO - Retrying request to /chat/completions in 0.760730 seconds
[02:05:14.349] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:14.349] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:14.349]   [API_FAILURE] API failed (timeout or max retries)
[02:05:14.353] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:14.353] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:14.354] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 8695
[02:05:14.354] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:14.354]   - use_ai_classification=True
[02:05:14.354]   - ai_classifier=True
[02:05:14.354]   - txt_content_len=8695
[02:05:14.354]   - task_model=deepseek-r1-0528
[02:05:14.354] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:05:18.696] 2025-08-20 02:05:18,695 - openai._base_client - INFO - Retrying request to /chat/completions in 0.486855 seconds
[02:05:22.262] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:22.263] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:22.263]   [API_FAILURE] API failed (timeout or max retries)
[02:05:22.267] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.267] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.268] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 8984
[02:05:22.268] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.268]   - use_ai_classification=True
[02:05:22.268]   - ai_classifier=True
[02:05:22.268]   - txt_content_len=8984
[02:05:22.268]   - task_model=deepseek-r1-0528
[02:05:22.268] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:05:35.683] 2025-08-20 02:05:35,682 - openai._base_client - INFO - Retrying request to /chat/completions in 0.491358 seconds
[02:05:41.161] 2025-08-20 02:05:41,161 - openai._base_client - INFO - Retrying request to /chat/completions in 0.393510 seconds
[02:06:05.783] 2025-08-20 02:06:05,783 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:06:05.787]   [PARSE] Fuzzy matched '{"name": "file_operations_reader", "parameters": {"source": "data/input.json"}}' to 'file_operations_reader'
[02:06:05.787]   [EXECUTING] file_operations_reader
[02:06:05.789]     Result: SUCCESS
[02:06:05.789] 
[02:06:05.789] [TURN 3/10]
[02:06:05.790] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:06:09.364] 2025-08-20 02:06:09,364 - openai._base_client - INFO - Retrying request to /chat/completions in 0.443152 seconds
[02:06:18.442] 2025-08-20 02:06:18,442 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:06:18.444]   [SEARCH] Query: data validation
[02:06:18.446] 
[02:06:18.446] [TURN 4/10]
[02:06:18.447] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[02:06:28.645] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:06:28.646] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:06:28.646]   [API_FAILURE] API failed (timeout or max retries)
[02:06:28.649] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:06:28.649] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:06:28.649] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 8886
[02:06:28.649] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:06:28.649]   - use_ai_classification=True
[02:06:28.649]   - ai_classifier=True
[02:06:28.649]   - txt_content_len=8886
[02:06:28.649]   - task_model=deepseek-r1-0528
[02:06:28.649] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:07:19.467] 2025-08-20 02:07:19,466 - openai._base_client - INFO - Retrying request to /chat/completions in 0.769972 seconds
[02:07:36.463] 2025-08-20 02:07:36,462 - openai._base_client - INFO - Retrying request to /chat/completions in 0.837838 seconds
[02:07:41.800] 2025-08-20 02:07:41,800 - openai._base_client - INFO - Retrying request to /chat/completions in 0.820197 seconds
[02:08:05.799] 2025-08-20 02:08:05,798 - openai._base_client - INFO - Retrying request to /chat/completions in 0.421913 seconds
[02:08:18.455] 2025-08-20 02:08:18,455 - openai._base_client - INFO - Retrying request to /chat/completions in 0.491280 seconds
[02:08:27.280] 2025-08-20 02:08:27,280 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:27.280] 2025-08-20 02:08:27,280 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:27.281] 2025-08-20 02:08:27,281 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:27.283] 2025-08-20 02:08:27,283 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:27.283] 2025-08-20 02:08:27,283 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:20.662] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:09:20.662] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:09:20.662]   [API_FAILURE] API failed (timeout or max retries)
[02:09:20.666] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:09:20.666] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:09:20.666] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 895
[02:09:20.666] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:09:20.666]   - use_ai_classification=True
[02:09:20.667]   - ai_classifier=True
[02:09:20.667]   - txt_content_len=895
[02:09:20.667]   - task_model=deepseek-r1-0528
[02:09:20.667] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:09:37.619] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:09:37.619] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:09:37.619]   [API_FAILURE] API failed (timeout or max retries)
[02:09:37.622] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:09:37.622] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:09:37.622] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 887
[02:09:37.622] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:09:37.623]   - use_ai_classification=True
[02:09:37.623]   - ai_classifier=True
[02:09:37.623]   - txt_content_len=887
[02:09:37.623]   - task_model=deepseek-r1-0528
[02:09:37.623] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:09:42.927] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:09:42.927] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:09:42.927]   [API_FAILURE] API failed (timeout or max retries)
[02:09:42.929] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:09:42.929] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:09:42.929] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 887
[02:09:42.929] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:09:42.929]   - use_ai_classification=True
[02:09:42.929]   - ai_classifier=True
[02:09:42.929]   - txt_content_len=887
[02:09:42.929]   - task_model=deepseek-r1-0528
[02:09:42.929] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
