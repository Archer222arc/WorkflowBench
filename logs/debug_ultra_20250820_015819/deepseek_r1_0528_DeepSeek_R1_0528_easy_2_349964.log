===== ÂàÜÁâá DeepSeek-R1-0528_easy_2 =====
Êó∂Èó¥: 2025-08-20T01:59:09.965706
Ê®°Âûã: deepseek-r1-0528
ÂÆû‰æã: DeepSeek-R1-0528-3
ÂëΩ‰ª§: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528-3 --prompt-types optimal --difficulty easy --task-types all --num-instances 8 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
ÁéØÂ¢ÉÂèòÈáè:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[01:59:11.933] 2025-08-20 01:59:11,933 - faiss.loader - INFO - Loading faiss.
[01:59:11.947] 2025-08-20 01:59:11,946 - faiss.loader - INFO - Successfully loaded faiss.
[01:59:12.915] [INFO] ‰ΩøÁî®ParquetÂ≠òÂÇ®Ê†ºÂºè
[01:59:13.290] [INFO] ‰ΩøÁî®ParquetÂ≠òÂÇ®Ê†ºÂºè
[01:59:13.292] [INFO] ‰ΩøÁî®PARQUETÂ≠òÂÇ®Ê†ºÂºè
[01:59:13.293] 
[01:59:13.293] ============================================================
[01:59:13.293] Êô∫ËÉΩÊâπÊµãËØï: deepseek-r1-0528 (idealab)
[01:59:13.293] Prompt types: ['optimal']
[01:59:13.293] ÈöæÂ∫¶: easy
[01:59:13.293] ÁõÆÊ†á: ÊØèÁßçÈÖçÁΩÆ 8 ‰∏™ÂÆû‰æã
[01:59:13.293] ============================================================
[01:59:13.293] ‚óã simple_task         :   0/  8 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 8 ‰∏™)
[01:59:13.293] ‚óã basic_task          :   0/  8 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 8 ‰∏™)
[01:59:13.293] ‚óã data_pipeline       :   0/  8 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 8 ‰∏™)
[01:59:13.293] ‚óã api_integration     :   0/  8 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 8 ‰∏™)
[01:59:13.293] ‚óã multi_stage_pipeline:   0/  8 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 8 ‰∏™)
[01:59:13.293] 
[01:59:13.293] ‚è≥ ÈúÄË¶ÅËøêË°å 40 ‰∏™Êñ∞ÊµãËØï
[01:59:13.293] 
[01:59:13.293] ‚ñ∂ ÂáÜÂ§á simple_task (8 ‰∏™ÂÆû‰æã)...
[01:59:13.293] 
[01:59:13.293] ‚ñ∂ ÂáÜÂ§á basic_task (8 ‰∏™ÂÆû‰æã)...
[01:59:13.293] 
[01:59:13.293] ‚ñ∂ ÂáÜÂ§á data_pipeline (8 ‰∏™ÂÆû‰æã)...
[01:59:13.293] 
[01:59:13.293] ‚ñ∂ ÂáÜÂ§á api_integration (8 ‰∏™ÂÆû‰æã)...
[01:59:13.293] 
[01:59:13.293] ‚ñ∂ ÂáÜÂ§á multi_stage_pipeline (8 ‰∏™ÂÆû‰æã)...
[01:59:13.293] 
[01:59:13.293] ‚ñ∂ ÂºÄÂßãÊâßË°å 40 ‰∏™ÊµãËØï...
[01:59:13.294] üì¶ ÊâπÈáèÊèê‰∫§Ê®°ÂºèÔºöÊØè20‰∏™ÊµãËØï‰øùÂ≠ò‰∏ÄÊ¨°
[01:59:13.294] üöÄ Ê£ÄÊµãÂà∞Azure APIÔºå‰ΩøÁî®Ë∂ÖÈ´òÂπ∂Âèë: workers=100, qps=200.0
[01:59:13.295] 2025-08-20 01:59:13,295 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for gpt-5-nano
[01:59:13.351] 2025-08-20 01:59:13,351 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[01:59:13.351] [AI_DEBUG] AIÂàÜÁ±ªÂô®ÂàùÂßãÂåñÊàêÂäü: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x17b648620>
[01:59:13.351] 2025-08-20 01:59:13,351 - batch_test_runner - INFO - Âü∫‰∫éTXTÊñá‰ª∂ÁöÑAIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî® (‰ΩøÁî®gpt-5-nano)
[01:59:13.351] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[01:59:13.352] 2025-08-20 01:59:13,352 - batch_test_runner - INFO - ============================================================
[01:59:13.352] 2025-08-20 01:59:13,352 - batch_test_runner - INFO - Batch test runner initialized
[01:59:13.352] 2025-08-20 01:59:13,352 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[01:59:13.352] 2025-08-20 01:59:13,352 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_015913.log
[01:59:13.352] 2025-08-20 01:59:13,352 - batch_test_runner - INFO - ============================================================
[01:59:13.352] 2025-08-20 01:59:13,352 - batch_test_runner - INFO - Running 40 tests with 100 workers, QPS limit: 200.0
[01:59:13.353] 2025-08-20 01:59:13,353 - batch_test_runner - INFO - Initializing test components...
[01:59:13.717] 2025-08-20 01:59:13,717 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[01:59:13.717] 2025-08-20 01:59:13,717 - batch_test_runner - INFO - ‚ö° [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[01:59:13.718] 2025-08-20 01:59:13,717 - batch_test_runner - INFO - ‚ö° This saves ~350MB memory while keeping all functionality intact
[01:59:13.718] [DEBUG] Creating new ToolCapabilityManager instance
[01:59:13.718] [OperationEmbeddingIndex] Initializing with unified API client manager
[01:59:13.718] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[01:59:13.718] 2025-08-20 01:59:13,718 - api_client_manager - INFO - Loaded configuration from config/config.json
[01:59:13.725] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[01:59:13.725] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[01:59:13.725] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[01:59:14.682] 2025-08-20 01:59:14,681 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[01:59:14.684] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[01:59:14.732] [INFO] Loaded 4150 embeddings from persistent cache
[01:59:14.732] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[01:59:14.733] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[01:59:14.733] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[01:59:14.733] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[01:59:14.740] [INFO] Successfully loaded FAISS index with dimension 3072
[01:59:14.741] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[01:59:14.741] [INFO] Loaded 15 operations with dimension 3072
[01:59:14.741] [INFO] Successfully loaded cached index
[01:59:14.741] [INFO] Operation semantic index initialized
[01:59:14.741] [INFO] Using device: cpu
[01:59:14.741] [INFO] Initialized tool success tracking attributes
[01:59:14.741] [INFO] Initializing embedding manager for enhanced tool selection
[01:59:14.741] [MCPEmbeddingManager] Creating new singleton instance
[01:59:14.741] [MCPEmbeddingManager] Initializing with unified API client manager
[01:59:14.752] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[01:59:14.752] [MCPEmbeddingManager] Client initialized successfully
[01:59:14.752] 2025-08-20 01:59:14,752 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:59:14.871] 2025-08-20 01:59:14,871 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:59:15.224] 2025-08-20 01:59:15,224 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[01:59:15.225] 2025-08-20 01:59:15,224 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[01:59:15.247] 2025-08-20 01:59:15,247 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:59:15.350] 2025-08-20 01:59:15,350 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:59:15.614] 2025-08-20 01:59:15,614 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[01:59:15.614] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[01:59:15.614] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[01:59:15.614] 2025-08-20 01:59:15,614 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:15.634] 2025-08-20 01:59:15,634 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:15.634] 2025-08-20 01:59:15,634 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:15.634] 2025-08-20 01:59:15,634 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:15.637] [SUCCESS] Loaded 30 tool embeddings
[01:59:15.637] 2025-08-20 01:59:15,637 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[01:59:15.637] [SUCCESS] Embedding manager initialized with 30 tools
[01:59:15.637] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[01:59:15.637] [INFO] Loading full MCP protocol registry...
[01:59:15.638] 2025-08-20 01:59:15,638 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:15.638] [INFO] Loaded full tool registry with 30 tools
[01:59:15.638] 2025-08-20 01:59:15,638 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:59:15.638] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:59:15.639] [INFO] Embedding manager ready with 30 tools
[01:59:15.639] [WARNING] Embedding manager exists but has no embeddings
[01:59:15.639] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[01:59:15.639] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[01:59:15.640] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[01:59:15.640] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:59:15.640] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[01:59:15.640] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[01:59:15.640] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:59:15.640] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:59:15.640] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:59:15.640] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:59:15.640] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[01:59:15.640] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:59:15.640] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:59:15.640] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[01:59:15.640] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[01:59:15.640] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[01:59:15.640] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:59:15.640] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:59:15.640] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:59:15.640] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[01:59:15.640] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[01:59:15.640] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[01:59:15.640] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[01:59:15.640] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[01:59:15.640] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[01:59:15.640] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[01:59:15.640] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[01:59:15.640] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[01:59:15.640] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[01:59:15.640] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[01:59:15.640] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[01:59:15.640] 2025-08-20 01:59:15,640 - mdp_workflow_generator - INFO - Loaded 30 tools
[01:59:15.640] [INFO] Setting default state_dim based on loaded tools
[01:59:15.640] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[01:59:15.640] 2025-08-20 01:59:15,640 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[01:59:15.640] [INFO] Setting default action_dim based on loaded tools
[01:59:15.640] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[01:59:15.640] 2025-08-20 01:59:15,640 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[01:59:15.640] [INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping neural network model loading
[01:59:15.640] [INFO] ‚ö° Memory optimization: Saving ~350MB by not loading model
[01:59:15.640] [INFO] ‚ö° Will use pre-generated workflows or random policy
[01:59:15.640] 2025-08-20 01:59:15,640 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[01:59:15.640] [INFO] Initializing TaskManager...
[01:59:17.525] 2025-08-20 01:59:17,525 - unified_training_manager - INFO - Using device: cpu
[01:59:17.662] 2025-08-20 01:59:17,661 - unified_training_manager - INFO - Task filtering results:
[01:59:17.662] 2025-08-20 01:59:17,661 - unified_training_manager - INFO -   Total: 5040 -> 5040
[01:59:17.662] 2025-08-20 01:59:17,661 - unified_training_manager - INFO -   simple_task: 320 -> 320
[01:59:17.662] 2025-08-20 01:59:17,661 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[01:59:17.662] 2025-08-20 01:59:17,661 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[01:59:17.662] 2025-08-20 01:59:17,661 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[01:59:17.662] 2025-08-20 01:59:17,662 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[01:59:17.662] 2025-08-20 01:59:17,662 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[01:59:17.664] 2025-08-20 01:59:17,664 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[01:59:17.665] [TaskManager] Difficulty level 'easy': 1096 tasks
[01:59:17.665] [TaskManager] Difficulty level 'very_easy': 856 tasks
[01:59:17.665] [TaskManager] Difficulty level 'medium': 1136 tasks
[01:59:17.665] [TaskManager] Difficulty level 'hard': 1096 tasks
[01:59:17.665] [TaskManager] Difficulty level 'very_hard': 856 tasks
[01:59:17.669] [INFO] TaskManager initialized with 5040 tasks
[01:59:17.669] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:59:17.669] [INFO] Initializing ToolCallVerifier...
[01:59:17.670] [INFO] ToolCallVerifier initialized with 30 tools
[01:59:17.670] [INFO] Output tools identified: 1
[01:59:17.670] [INFO] Component initialization status:
[01:59:17.670]   - embedding_manager: initialized
[01:59:17.670]   - task_manager: initialized
[01:59:17.670]   - output_verifier: initialized
[01:59:17.670]   - tool_capability_manager: initialized
[01:59:17.670]   - tool_success_rates: initialized with 0 entries
[01:59:17.670] [INFO] MDPWorkflowGenerator initialization complete
[01:59:17.670] 2025-08-20 01:59:17,670 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[01:59:17.670] 2025-08-20 01:59:17,670 - batch_test_runner - INFO - ‚úÖ MDPWorkflowGenerator initialized successfully:
[01:59:17.670] 2025-08-20 01:59:17,670 - batch_test_runner - INFO -   - task_manager: ‚úì
[01:59:17.670] 2025-08-20 01:59:17,670 - batch_test_runner - INFO -   - output_verifier: ‚úì
[01:59:17.670] 2025-08-20 01:59:17,670 - batch_test_runner - INFO -   - embedding_manager: ‚úì
[01:59:17.670] 2025-08-20 01:59:17,670 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[01:59:17.670] 2025-08-20 01:59:17,670 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[01:59:17.670] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:17.670] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:17.670] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:59:17.670] [FlawedWorkflowGenerator] RAG support: disabled
[01:59:17.672] DEBUG: Checking generator attributes
[01:59:17.672]   - has tool_capabilities: True
[01:59:17.672]   - has tool_capability_manager: True
[01:59:17.672]   - has task_manager: True
[01:59:17.672] [INFO] Loaded 30 tools from generator
[01:59:17.672] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[01:59:17.672] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:17.672] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:17.672] [INFO] Initializing LLM client using APIClientManager
[01:59:17.688] [INFO] Using Azure OpenAI client
[01:59:17.688] [DEBUG] Checking if generator has tool_capability_manager attribute
[01:59:17.688] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[01:59:17.688] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:17.688] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:17.688] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:59:17.688] [FlawedWorkflowGenerator] RAG support: enabled
[01:59:17.688] [INFO] FlawedWorkflowGenerator initialized successfully
[01:59:17.688] [INFO] Initializing StableScorer for Phase 2 scoring
[01:59:17.688] <tool_capability_manager.ToolCapabilityManager object at 0x311956270>
[01:59:17.688] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:17.688] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:17.689] [INFO] Loaded tool success history for 0 tools
[01:59:17.689] [INFO] StableScorer initialized with semantic capability
[01:59:17.689] [INFO] StableScorer initialized successfully
[01:59:17.689] [INFO] Loading task instances...
[01:59:17.689] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[01:59:17.696] [INFO] Loaded 630 task instances
[01:59:17.696] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:59:17.696] 2025-08-20 01:59:17,696 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[01:59:17.696] 2025-08-20 01:59:17,696 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[01:59:18.132] 2025-08-20 01:59:18,132 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[01:59:18.132] 2025-08-20 01:59:18,132 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[01:59:18.151] 2025-08-20 01:59:18,150 - batch_test_runner - INFO - Initialization complete
[01:59:18.201] 2025-08-20 01:59:18,201 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[01:59:18.201] 2025-08-20 01:59:18,201 - batch_test_runner - INFO - Starting batch test with 40 tasks, 100 workers
[01:59:18.201] 2025-08-20 01:59:18,201 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[01:59:18.203] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.205] 2025-08-20 01:59:18,204 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for DeepSeek-R1-0528-3
[01:59:18.206] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.206] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.207] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.211] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.211] 
[01:59:18.216] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.217] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.218] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.218] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.220] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.224] 
[01:59:18.224] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.224] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.224] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.224] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.224] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.224] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.224] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.225] 
[01:59:18.225] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.226] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.228] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.228] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.228] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.228] 2025-08-20 01:59:18,228 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.228] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.228] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.228] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.228] 2025-08-20 01:59:18,228 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.230] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.230] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.230] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.230] 2025-08-20 01:59:18,229 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.231] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.232] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.232] 
[01:59:18.232] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.232] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.233] 2025-08-20 01:59:18,232 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.233] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.233] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.262] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.263] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.263] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.263] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.264] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.264] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.264] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.267] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.267] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.267] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.267] 2025-08-20 01:59:18,267 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.267] 2025-08-20 01:59:18,267 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.270] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.270] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.270] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.271] 2025-08-20 01:59:18,271 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.272] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.272] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.273] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.273] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.273] 
[01:59:18.274] 2025-08-20 01:59:18,274 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.274] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.274] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.275] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.275] 
[01:59:18.278] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.288] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.288] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.289] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.289] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.296] 2025-08-20 01:59:18,295 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.307] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.307] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.308] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.316] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.316] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.317] 
[01:59:18.317] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.317] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.317] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.317] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.317] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.317] 2025-08-20 01:59:18,317 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.322] 2025-08-20 01:59:18,322 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.325] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.326] 
[01:59:18.326] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.326] 
[01:59:18.327] 2025-08-20 01:59:18,327 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.327] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.327] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.341] 2025-08-20 01:59:18,341 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.351] 2025-08-20 01:59:18,351 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.353] 2025-08-20 01:59:18,353 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.360] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.360] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.378] 2025-08-20 01:59:18,378 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.394] [INFO] Tool embedding index loaded successfully[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.394] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.394] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.394] 
[01:59:18.398] 2025-08-20 01:59:18,398 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.410] 2025-08-20 01:59:18,398 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.410] 2025-08-20 01:59:18,410 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.410] 2025-08-20 01:59:18,410 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:59:18.413] [INFO] Tool embedding index loaded successfully
[01:59:18.430] 2025-08-20 01:59:18,402 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.457] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.457] 2025-08-20 01:59:18,431 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.458] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.461] 2025-08-20 01:59:18,440 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.464] [INFO] Tool embedding index loaded successfully[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.464] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.464] 2025-08-20 01:59:18,402 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.470] 
[01:59:18.471] [INFO] Operation semantic index initialized[INFO] Operation semantic index initialized
[01:59:18.476] 
[01:59:18.477] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.478] 2025-08-20 01:59:18,456 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.481] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.482] 2025-08-20 01:59:18,457 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.485] 2025-08-20 01:59:18,464 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.485] 2025-08-20 01:59:18,476 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.492] 2025-08-20 01:59:18,477 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.499] [INFO] Operation semantic index initialized
[01:59:18.510] 2025-08-20 01:59:18,478 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.525] 2025-08-20 01:59:18,482 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.527] [INFO] Tool embedding index loaded successfully
[01:59:18.529] 2025-08-20 01:59:18,485 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.529] 2025-08-20 01:59:18,529 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.533] [INFO] Tool embedding index loaded successfully2025-08-20 01:59:18,510 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.536] [INFO] Tool embedding index loaded successfully
[01:59:18.539] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.539] 2025-08-20 01:59:18,523 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.539] 2025-08-20 01:59:18,523 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.539] 
[01:59:18.540] 2025-08-20 01:59:18,485 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.561] 2025-08-20 01:59:18,536 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.563] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json[INFO] Operation semantic index initialized
[01:59:18.563] 
[01:59:18.569] 2025-08-20 01:59:18,539 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.569] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.570] [INFO] Operation semantic index initialized
[01:59:18.570] 2025-08-20 01:59:18,539 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.570] 2025-08-20 01:59:18,570 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.573] [INFO] Tool embedding index loaded successfully
[01:59:18.573] [INFO] Operation semantic index initialized
[01:59:18.585] 2025-08-20 01:59:18,561 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.586] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.587] 2025-08-20 01:59:18,562 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.587] 
[01:59:18.587] [TURN 1/10]
[01:59:18.588] 2025-08-20 01:59:18,569 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.590] [INFO] Tool embedding index loaded successfully
[01:59:18.591] 2025-08-20 01:59:18,573 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.591] 2025-08-20 01:59:18,591 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.591] [INFO] Operation semantic index initialized
[01:59:18.591] 2025-08-20 01:59:18,585 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.594] [INFO] Tool embedding index loaded successfully
[01:59:18.596] 2025-08-20 01:59:18,587 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.597] 2025-08-20 01:59:18,587 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.597] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.601] 2025-08-20 01:59:18,591 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.604] [INFO] Tool embedding index loaded successfully[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.604] 2025-08-20 01:59:18,546 - mcp_embedding_manager - INFO - Index loaded successfully: 12 tools
[01:59:18.607] [INFO] Tool embedding index loaded successfully
[01:59:18.607] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.607] 2025-08-20 01:59:18,596 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.608] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.608] [INFO] Operation semantic index initialized
[01:59:18.608] 2025-08-20 01:59:18,597 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.611] [INFO] Tool embedding index loaded successfully
[01:59:18.611] 
[01:59:18.613] 2025-08-20 01:59:18,607 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.615] [INFO] Tool embedding index loaded successfully
[01:59:18.616] [INFO] Operation semantic index initialized
[01:59:18.618] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.624] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.624] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.625] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.625] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.625] [INFO] Operation semantic index initialized
[01:59:18.635] 2025-08-20 01:59:18,635 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.635] 2025-08-20 01:59:18,635 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.635] 2025-08-20 01:59:18,635 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.638] [INFO] Tool embedding index loaded successfully[INFO] Operation semantic index initialized
[01:59:18.638] [INFO] Operation semantic index initialized
[01:59:18.638] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.645] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.649] 
[01:59:18.650] [INFO] Operation semantic index initialized2025-08-20 01:59:18,650 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.650] 2025-08-20 01:59:18,650 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.650] 2025-08-20 01:59:18,650 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.653] [INFO] Tool embedding index loaded successfully
[01:59:18.653] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.653] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.653] 
[01:59:18.653] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.654] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.654] [INFO] Operation semantic index initialized
[01:59:18.654] [TURN 1/10]
[01:59:18.654] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.654] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.654] 
[01:59:18.655] 2025-08-20 01:59:18,655 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.655] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.655] [INFO] Operation semantic index initialized
[01:59:18.655] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.657] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.657] 
[01:59:18.657] [TURN 1/10]
[01:59:18.657] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.659] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.661] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.662] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.663] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.663] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.664] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.664] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.665] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.665] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.665] 
[01:59:18.665] [TURN 1/10]
[01:59:18.665] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.665] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.665] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.665] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.666] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.666] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.666] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.666] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.666] 2025-08-20 01:59:18,666 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.667] 2025-08-20 01:59:18,667 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.672] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.672] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.673] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.674] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.674] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.674] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.674] 
[01:59:18.675] [TURN 1/10]
[01:59:18.675] 
[01:59:18.676] 
[01:59:18.677] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.677] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.678] 
[01:59:18.678] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.680] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.681] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.681] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.681] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.681] 
[01:59:18.687] [MCPEmbeddingManager] Current cache size: 17 embeddings
[01:59:18.687] 2025-08-20 01:59:18,687 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.687] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.687] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.687] 2025-08-20 01:59:18,687 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.688] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.688] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.688] [MCPEmbeddingManager] Current cache size: 17 embeddings
[01:59:18.688] 2025-08-20 01:59:18,688 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.693] 
[01:59:18.693] [TURN 1/10]
[01:59:18.693] 2025-08-20 01:59:18,692 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.694] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.695] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.695] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.695] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.695] 2025-08-20 01:59:18,694 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.696] 
[01:59:18.696] [TURN 1/10]
[01:59:18.696] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.700] 
[01:59:18.700] [TURN 1/10]
[01:59:18.701] 2025-08-20 01:59:18,695 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.707] 2025-08-20 01:59:18,695 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.707] 2025-08-20 01:59:18,707 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.710] [INFO] Tool embedding index loaded successfully
[01:59:18.710] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.725] 
[01:59:18.725] [TURN 1/10]
[01:59:18.731] 2025-08-20 01:59:18,731 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.732] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.734] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.739] 2025-08-20 01:59:18,739 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.739] 2025-08-20 01:59:18,739 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.743] [INFO] Tool embedding index loaded successfully
[01:59:18.745] [InteractiveExecutor] API model name: DeepSeek-R1-0528-32025-08-20 01:59:18,745 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.745] 2025-08-20 01:59:18,745 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.745] 2025-08-20 01:59:18,745 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.747] [INFO] Tool embedding index loaded successfully
[01:59:18.748] 
[01:59:18.748] [TURN 1/10]
[01:59:18.749] [INFO] Operation semantic index initialized
[01:59:18.750] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.750] 
[01:59:18.750] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.752] 
[01:59:18.754] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.755] 
[01:59:18.755] [TURN 1/10]
[01:59:18.755] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.755] 2025-08-20 01:59:18,755 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.763] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.763] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.763] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.764] [INFO] Operation semantic index initialized
[01:59:18.765] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.768] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.782] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3[INFO] Operation semantic index initialized
[01:59:18.782] 
[01:59:18.782] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.782] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.782] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.782] 2025-08-20 01:59:18,782 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.782] 2025-08-20 01:59:18,782 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.782] 2025-08-20 01:59:18,782 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.785] [INFO] Tool embedding index loaded successfully
[01:59:18.785] [TURN 1/10]
[01:59:18.786] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:59:18,786 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.787] 
[01:59:18.787] 
[01:59:18.787] [TURN 1/10]
[01:59:18.788] 
[01:59:18.788] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.789] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.794] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.794] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.813] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.814] 
[01:59:18.814] [TURN 1/10]
[01:59:18.816] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.817] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.817] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.817] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.817] 2025-08-20 01:59:18,817 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.817] 2025-08-20 01:59:18,817 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.817] 2025-08-20 01:59:18,817 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.820] [INFO] Tool embedding index loaded successfully
[01:59:18.820] [INFO] Operation semantic index initialized
[01:59:18.821] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.822] 2025-08-20 01:59:18,822 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.823] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.826] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.826] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.826] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.826] 2025-08-20 01:59:18,826 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.831] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.833] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.833] 
[01:59:18.833] [TURN 1/10]
[01:59:18.834] 
[01:59:18.835] [TURN 1/10]
[01:59:18.835] [TURN 1/10]
[01:59:18.835] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.835] 
[01:59:18.836] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.849] 
[01:59:18.849] [TURN 1/10]
[01:59:18.851] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] No LLM client provided, initializing from api_client_manager[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.852] [INFO] Operation semantic index initialized
[01:59:18.873] 
[01:59:18.873] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.874] 
[01:59:18.874] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.878] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.878] 2025-08-20 01:59:18,878 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.878] 2025-08-20 01:59:18,878 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.878] 2025-08-20 01:59:18,878 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.881] [INFO] Tool embedding index loaded successfully
[01:59:18.881] 2025-08-20 01:59:18,881 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.882] 2025-08-20 01:59:18,881 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.882] 2025-08-20 01:59:18,881 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.884] [INFO] Tool embedding index loaded successfully
[01:59:18.885] 2025-08-20 01:59:18,885 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.885] 2025-08-20 01:59:18,885 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.885] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.886] 2025-08-20 01:59:18,886 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.887] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.887] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.889] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.892] [INFO] Tool embedding index loaded successfully
[01:59:18.893] [INFO] Operation semantic index initialized
[01:59:18.899] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.899] [INFO] Operation semantic index initialized
[01:59:18.900] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.900] 
[01:59:18.900] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.900] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.900] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.900] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.901] 2025-08-20 01:59:18,901 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.902] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.902] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.902] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.902] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.902] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.908] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.915] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)[InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-20 01:59:18,902 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.915] 
[01:59:18.915] 
[01:59:18.915] 2025-08-20 01:59:18,915 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.915] 2025-08-20 01:59:18,915 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.915] 2025-08-20 01:59:18,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.918] [INFO] Tool embedding index loaded successfully
[01:59:18.919] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.919] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.919] 2025-08-20 01:59:18,919 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.919] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.920] [InteractiveExecutor] Using prompt type: optimal for API key selection[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.920] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.920] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.920] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.920] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.921] 
[01:59:18.922] 2025-08-20 01:59:18,922 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.923] 
[01:59:18.926] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.926] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.926] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.927] [INFO] Operation semantic index initialized
[01:59:18.928] 2025-08-20 01:59:18,928 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.928] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.929] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.929] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.930] 
[01:59:18.930] [TURN 1/10]
[01:59:18.932] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.933] 2025-08-20 01:59:18,933 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.935] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.936] [InteractiveExecutor] Using prompt type: optimal for API key selection[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.950] [INFO] Operation semantic index initialized
[01:59:18.952] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:18.953] 
[01:59:18.953] [TURN 1/10]
[01:59:18.966] 2025-08-20 01:59:18,965 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.966] 2025-08-20 01:59:18,965 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.966] 2025-08-20 01:59:18,965 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.970] [INFO] Tool embedding index loaded successfully
[01:59:18.970] 
[01:59:18.970] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:18.972] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.979] 
[01:59:18.979] [TURN 1/10]
[01:59:18.980] 
[01:59:18.980] [TURN 1/10]
[01:59:18.991] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:18.992] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:18.993] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:18.993] 2025-08-20 01:59:18,993 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:18.994] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:18.994] 
[01:59:18.994] [TURN 1/10]
[01:59:18.994] 2025-08-20 01:59:18,994 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:18.995] [InteractiveExecutor] API model name: DeepSeek-R1-0528-32025-08-20 01:59:18,995 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:18.995] 
[01:59:18.995] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:18.998] [INFO] Tool embedding index loaded successfully[MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.999] 2025-08-20 01:59:18,995 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:18.999] 
[01:59:18.999] [INFO] Operation semantic index initialized
[01:59:18.999] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:18.999] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.000] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.000] 
[01:59:19.000] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:19.001] 
[01:59:19.005] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.005] 2025-08-20 01:59:19,005 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:19.005] 
[01:59:19.006] [TURN 1/10]
[01:59:19.013] [INFO] Operation semantic index initialized
[01:59:19.014] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:19.019] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:19.019] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:19.019] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:19.019] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:19.028] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:19.028] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:19.033] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.044] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:19.044] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:59:19.044] 
[01:59:19.044] [TURN 1/10]
[01:59:19.046] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.046] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:19.046] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:19.046] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:19.049] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:19.049] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:19.049] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:19.049] 2025-08-20 01:59:19,049 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:19.050] 2025-08-20 01:59:19,049 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.050] 2025-08-20 01:59:19,049 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.050] 2025-08-20 01:59:19,049 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.053] [INFO] Tool embedding index loaded successfully
[01:59:19.053] [TURN 1/10]
[01:59:19.053] 2025-08-20 01:59:19,053 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:19.065] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:19.065] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:19.065] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:19.072] 2025-08-20 01:59:19,072 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.072] 2025-08-20 01:59:19,072 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.072] 2025-08-20 01:59:19,072 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:59:19.075] [INFO] Tool embedding index loaded successfully
[01:59:19.075] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:19.076] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:19.080] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.081] 
[01:59:19.081] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:59:19.083] 2025-08-20 01:59:19,083 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.083] 2025-08-20 01:59:19,083 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.083] 2025-08-20 01:59:19,083 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.086] [INFO] Tool embedding index loaded successfully
[01:59:19.092] [MCPEmbeddingManager] Current cache size: 30 embeddings[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.092] [INFO] Operation semantic index initialized
[01:59:19.093] 
[01:59:19.093] 2025-08-20 01:59:19,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:19.094] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.095] 
[01:59:19.095] [TURN 1/10]
[01:59:19.096] [INFO] Operation semantic index initialized
[01:59:19.096] 
[01:59:19.096] [TURN 1/10]
[01:59:19.097] 2025-08-20 01:59:19,097 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:19.098] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.141] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.142] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:59:19.142] [InteractiveExecutor] Using prompt type: optimal for API key selection[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.144] [INFO] Operation semantic index initialized
[01:59:19.144] 
[01:59:19.146] 
[01:59:19.162] [TURN 1/10]2025-08-20 01:59:19,162 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.162] 2025-08-20 01:59:19,162 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.162] 2025-08-20 01:59:19,162 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:59:19.165] [INFO] Tool embedding index loaded successfully
[01:59:19.165] 2025-08-20 01:59:19,165 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.165] 2025-08-20 01:59:19,165 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.165] 2025-08-20 01:59:19,165 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:59:19.168] [INFO] Tool embedding index loaded successfully
[01:59:19.168] 
[01:59:19.169] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.175] [INFO] Operation semantic index initialized
[01:59:19.177] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:59:19.177] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13180059872)
[01:59:19.177] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:59:19.177] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:59:19,177 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.177] 2025-08-20 01:59:19,177 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.177] 2025-08-20 01:59:19,177 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.180] [INFO] Tool embedding index loaded successfully
[01:59:19.186] 
[01:59:19.190] 
[01:59:19.190] [TURN 1/10]
[01:59:19.191] 2025-08-20 01:59:19,191 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.191] 2025-08-20 01:59:19,191 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.191] 2025-08-20 01:59:19,191 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.194] [INFO] Tool embedding index loaded successfully
[01:59:19.194] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.198] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.200] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.200] [INFO] Operation semantic index initialized
[01:59:19.201] [INFO] Operation semantic index initialized
[01:59:19.201] 2025-08-20 01:59:19,201 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:59:19.202] 
[01:59:19.202] [TURN 1/10]
[01:59:19.202] 2025-08-20 01:59:19,202 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.202] 2025-08-20 01:59:19,202 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.202] 2025-08-20 01:59:19,202 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.205] [INFO] Tool embedding index loaded successfully
[01:59:19.205] 
[01:59:19.205] [TURN 1/10]
[01:59:19.206] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.206] [INFO] Operation semantic index initialized
[01:59:19.207] 
[01:59:19.207] [TURN 1/10]
[01:59:19.208] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.210] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.211] [INFO] Operation semantic index initialized
[01:59:19.213] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.218] 
[01:59:19.218] [TURN 1/10]
[01:59:19.218] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.233] 2025-08-20 01:59:19,232 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.233] 2025-08-20 01:59:19,233 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.233] 2025-08-20 01:59:19,233 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.235] [INFO] Tool embedding index loaded successfully
[01:59:19.236] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.242] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.253] [INFO] Operation semantic index initialized2025-08-20 01:59:19,253 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.253] 2025-08-20 01:59:19,253 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.253] 2025-08-20 01:59:19,253 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.255] [INFO] Tool embedding index loaded successfully
[01:59:19.257] 
[01:59:19.257] 
[01:59:19.257] [TURN 1/10]
[01:59:19.267] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.274] 2025-08-20 01:59:19,273 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.274] 2025-08-20 01:59:19,274 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.274] 2025-08-20 01:59:19,274 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:59:19.276] [INFO] Tool embedding index loaded successfully
[01:59:19.284] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.286] [INFO] Operation semantic index initialized
[01:59:19.286] 
[01:59:19.286] [TURN 1/10]
[01:59:19.286] 2025-08-20 01:59:19,286 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.286] 2025-08-20 01:59:19,286 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.286] 2025-08-20 01:59:19,286 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.289] [INFO] Tool embedding index loaded successfully
[01:59:19.292] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.293] [INFO] Operation semantic index initialized
[01:59:19.294] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.294] 
[01:59:19.294] [TURN 1/10]
[01:59:19.295] [INFO] Operation semantic index initialized
[01:59:19.300] 
[01:59:19.311] [TURN 1/10]
[01:59:19.314] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.315] 2025-08-20 01:59:19,315 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.315] 2025-08-20 01:59:19,315 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.315] 2025-08-20 01:59:19,315 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.318] [INFO] Tool embedding index loaded successfully
[01:59:19.318] 2025-08-20 01:59:19,318 - mcp_embedding_manager - INFO - FAISS index loaded
[01:59:19.318] 2025-08-20 01:59:19,318 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:59:19.318] 2025-08-20 01:59:19,318 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:59:19.321] [INFO] Tool embedding index loaded successfully
[01:59:19.321] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.322] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.322] [INFO] Operation semantic index initialized
[01:59:19.323] 
[01:59:19.323] [TURN 1/10]
[01:59:19.323] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.325] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:59:19.325] [INFO] Operation semantic index initialized
[01:59:19.325] 
[01:59:19.325] [TURN 1/10]
[01:59:19.325] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:59:19.326] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:00:13.504] 2025-08-20 02:00:13,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:13.525]   [SEARCH] Query: file reader
[02:00:13.529] 
[02:00:13.529] [TURN 2/10]
[02:00:13.532] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:00:27.074] 2025-08-20 02:00:27,073 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:27.077]   [SEARCH] Query: file_operations_reader
[02:00:27.078] 
[02:00:27.078] [TURN 2/10]
[02:00:27.089] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:00:38.913] 2025-08-20 02:00:38,912 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:38.914]   [SEARCH] Query: file_operations_reader
[02:00:38.914] 
[02:00:38.914] [TURN 2/10]
[02:00:38.915] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:00:50.459] 2025-08-20 02:00:50,458 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:50.461]   [SEARCH] Query: data parser
[02:00:50.462] 
[02:00:50.462] [TURN 2/10]
[02:00:50.463] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:01:07.577] 2025-08-20 02:01:07,577 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:01:07.579]   [PARSE] Found tool call: file_operations_reader
[02:01:07.580]   [EXECUTING] file_operations_reader
[02:01:07.581]     Result: SUCCESS
[02:01:07.581] 
[02:01:07.581] [TURN 3/10]
[02:01:07.582] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:01:19.023] 2025-08-20 02:01:19,022 - openai._base_client - INFO - Retrying request to /chat/completions in 0.389672 seconds
[02:01:19.024] 2025-08-20 02:01:19,023 - openai._base_client - INFO - Retrying request to /chat/completions in 0.389756 seconds
[02:01:19.029] 2025-08-20 02:01:19,029 - openai._base_client - INFO - Retrying request to /chat/completions in 0.480752 seconds
[02:01:19.030] 2025-08-20 02:01:19,030 - openai._base_client - INFO - Retrying request to /chat/completions in 0.465528 seconds
[02:01:19.031] 2025-08-20 02:01:19,030 - openai._base_client - INFO - Retrying request to /chat/completions in 0.425506 seconds
[02:01:19.031] 2025-08-20 02:01:19,031 - openai._base_client - INFO - Retrying request to /chat/completions in 0.375253 seconds
[02:01:19.033] 2025-08-20 02:01:19,033 - openai._base_client - INFO - Retrying request to /chat/completions in 0.478937 seconds
[02:01:19.077] 2025-08-20 02:01:19,076 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394108 seconds
[02:01:19.091] 2025-08-20 02:01:19,091 - openai._base_client - INFO - Retrying request to /chat/completions in 0.375986 seconds
[02:01:19.093] 2025-08-20 02:01:19,093 - openai._base_client - INFO - Retrying request to /chat/completions in 0.472275 seconds
[02:01:19.121] 2025-08-20 02:01:19,121 - openai._base_client - INFO - Retrying request to /chat/completions in 0.458485 seconds
[02:01:19.179] 2025-08-20 02:01:19,177 - openai._base_client - INFO - Retrying request to /chat/completions in 0.484796 seconds
[02:01:19.179] 2025-08-20 02:01:19,179 - openai._base_client - INFO - Retrying request to /chat/completions in 0.483085 seconds
[02:01:19.193] 2025-08-20 02:01:19,193 - openai._base_client - INFO - Retrying request to /chat/completions in 0.378937 seconds
[02:01:19.203] 2025-08-20 02:01:19,203 - openai._base_client - INFO - Retrying request to /chat/completions in 0.405412 seconds
[02:01:19.204] 2025-08-20 02:01:19,204 - openai._base_client - INFO - Retrying request to /chat/completions in 0.408615 seconds
[02:01:19.240] 2025-08-20 02:01:19,239 - openai._base_client - INFO - Retrying request to /chat/completions in 0.442903 seconds
[02:01:19.287] 2025-08-20 02:01:19,287 - openai._base_client - INFO - Retrying request to /chat/completions in 0.437229 seconds
[02:01:19.288] 2025-08-20 02:01:19,287 - openai._base_client - INFO - Retrying request to /chat/completions in 0.496154 seconds
[02:01:19.288] 2025-08-20 02:01:19,288 - openai._base_client - INFO - Retrying request to /chat/completions in 0.391545 seconds
[02:01:19.340] 2025-08-20 02:01:19,339 - openai._base_client - INFO - Retrying request to /chat/completions in 0.421520 seconds
[02:01:19.342] 2025-08-20 02:01:19,342 - openai._base_client - INFO - Retrying request to /chat/completions in 0.378464 seconds
[02:01:19.359] 2025-08-20 02:01:19,358 - openai._base_client - INFO - Retrying request to /chat/completions in 0.422407 seconds
[02:01:19.379] 2025-08-20 02:01:19,379 - openai._base_client - INFO - Retrying request to /chat/completions in 0.417903 seconds
[02:01:19.426] 2025-08-20 02:01:19,426 - openai._base_client - INFO - Retrying request to /chat/completions in 0.495626 seconds
[02:01:19.440] 2025-08-20 02:01:19,439 - openai._base_client - INFO - Retrying request to /chat/completions in 0.484484 seconds
[02:01:19.464] 2025-08-20 02:01:19,463 - openai._base_client - INFO - Retrying request to /chat/completions in 0.404511 seconds
[02:01:19.464] 2025-08-20 02:01:19,464 - openai._base_client - INFO - Retrying request to /chat/completions in 0.443362 seconds
[02:01:19.490] 2025-08-20 02:01:19,490 - openai._base_client - INFO - Retrying request to /chat/completions in 0.476955 seconds
[02:01:19.492] 2025-08-20 02:01:19,492 - openai._base_client - INFO - Retrying request to /chat/completions in 0.388942 seconds
[02:01:19.501] 2025-08-20 02:01:19,501 - openai._base_client - INFO - Retrying request to /chat/completions in 0.400832 seconds
[02:01:19.536] 2025-08-20 02:01:19,535 - openai._base_client - INFO - Retrying request to /chat/completions in 0.429150 seconds
[02:01:19.565] 2025-08-20 02:01:19,565 - openai._base_client - INFO - Retrying request to /chat/completions in 0.457360 seconds
[02:01:19.577] 2025-08-20 02:01:19,577 - openai._base_client - INFO - Retrying request to /chat/completions in 0.484098 seconds
[02:01:19.577] 2025-08-20 02:01:19,577 - openai._base_client - INFO - Retrying request to /chat/completions in 0.445439 seconds
[02:01:19.582] 2025-08-20 02:01:19,582 - openai._base_client - INFO - Retrying request to /chat/completions in 0.445528 seconds
[02:01:51.453] 2025-08-20 02:01:51,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:01:51.455]   [SEARCH] Query: file_operations_reader
[02:01:51.456] 
[02:01:51.456] [TURN 2/10]
[02:01:51.457] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:01:58.568] 2025-08-20 02:01:58,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:01:58.578]   [SEARCH] Query: file_operations_reader
[02:01:58.580] 
[02:01:58.580] [TURN 2/10]
[02:01:58.581] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:02.866] 2025-08-20 02:02:02,866 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:02.867]   [SEARCH] Query: file reader
[02:02:02.867] 
[02:02:02.867] [TURN 2/10]
[02:02:02.869] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:08.513] 2025-08-20 02:02:08,513 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:08.515]   [SEARCH] Query: network_fetcher
[02:02:08.516] 
[02:02:08.516] [TURN 2/10]
[02:02:08.517] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:13.539] 2025-08-20 02:02:13,539 - openai._base_client - INFO - Retrying request to /chat/completions in 0.468424 seconds
[02:02:15.005] 2025-08-20 02:02:15,003 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:15.022]   [SEARCH] Query: file_operations_reader
[02:02:15.023] 
[02:02:15.023] [TURN 2/10]
[02:02:15.028] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:31.044] 2025-08-20 02:02:31,043 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:31.049]   [INFO] Tool info request: file_operations_reader
[02:02:31.050] 
[02:02:31.050] [TURN 2/10]
[02:02:31.051] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:38.993] 2025-08-20 02:02:38,992 - openai._base_client - INFO - Retrying request to /chat/completions in 0.498479 seconds
[02:02:39.019] 2025-08-20 02:02:39,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:39.022]   [SEARCH] Query: api data fetcher
[02:02:39.024] 
[02:02:39.024] [TURN 2/10]
[02:02:39.025] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:50.542] 2025-08-20 02:02:50,541 - openai._base_client - INFO - Retrying request to /chat/completions in 0.401599 seconds
[02:02:52.540] 2025-08-20 02:02:52,539 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:52.544]   [PARSE] Fuzzy matched 'file_operations_reader
[02:02:52.544] {
[02:02:52.544]   "source": "data/input.json",
[02:02:52.544]   "options": {}
[02:02:52.544] }' to 'file_operations_reader'
[02:02:52.544]   [EXECUTING] file_operations_reader
[02:02:52.546]     Result: SUCCESS
[02:02:52.546] 
[02:02:52.546] [TURN 3/10]
[02:02:52.547] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:02:58.738] 2025-08-20 02:02:58,737 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:58.740]   [SEARCH] Query: data_processing_parser
[02:02:58.742] 
[02:02:58.742] [TURN 4/10]
[02:02:58.743] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:03:07.626] 2025-08-20 02:03:07,625 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:03:07.631]   [PARSE] Found tool call: file_operations_reader
[02:03:07.631]   [EXECUTING] file_operations_reader
[02:03:07.632]     Result: SUCCESS
[02:03:07.632] 
[02:03:07.632] [TURN 3/10]
[02:03:07.642] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:03:15.226] 2025-08-20 02:03:15,222 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:03:15.245]   [SEARCH] Query: file reader
[02:03:15.246] 
[02:03:15.246] [TURN 2/10]
[02:03:15.247] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:03:16.653] 2025-08-20 02:03:16,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:03:16.653]   [SEARCH] Query: data validation
[02:03:16.656] 
[02:03:16.656] [TURN 2/10]
[02:03:16.656] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:03:19.733] 2025-08-20 02:03:19,731 - openai._base_client - INFO - Retrying request to /chat/completions in 0.810198 seconds
[02:03:19.740] 2025-08-20 02:03:19,739 - openai._base_client - INFO - Retrying request to /chat/completions in 0.952333 seconds
[02:03:19.740] 2025-08-20 02:03:19,740 - openai._base_client - INFO - Retrying request to /chat/completions in 0.790797 seconds
[02:03:19.809] 2025-08-20 02:03:19,809 - openai._base_client - INFO - Retrying request to /chat/completions in 0.941009 seconds
[02:03:19.820] 2025-08-20 02:03:19,820 - openai._base_client - INFO - Retrying request to /chat/completions in 0.766134 seconds
[02:03:19.832] 2025-08-20 02:03:19,832 - openai._base_client - INFO - Retrying request to /chat/completions in 0.960178 seconds
[02:03:19.838] 2025-08-20 02:03:19,837 - openai._base_client - INFO - Retrying request to /chat/completions in 0.970920 seconds
[02:03:19.838] 2025-08-20 02:03:19,837 - openai._base_client - INFO - Retrying request to /chat/completions in 0.830334 seconds
[02:03:19.882] 2025-08-20 02:03:19,882 - openai._base_client - INFO - Retrying request to /chat/completions in 0.919306 seconds
[02:03:19.899] 2025-08-20 02:03:19,899 - openai._base_client - INFO - Retrying request to /chat/completions in 0.892473 seconds
[02:03:19.940] 2025-08-20 02:03:19,940 - openai._base_client - INFO - Retrying request to /chat/completions in 0.959276 seconds
[02:03:19.983] 2025-08-20 02:03:19,983 - openai._base_client - INFO - Retrying request to /chat/completions in 0.972392 seconds
[02:03:20.018] 2025-08-20 02:03:20,001 - openai._base_client - INFO - Retrying request to /chat/completions in 0.839547 seconds
[02:03:20.022] 2025-08-20 02:03:20,019 - openai._base_client - INFO - Retrying request to /chat/completions in 0.976574 seconds
[02:03:20.039] 2025-08-20 02:03:20,039 - openai._base_client - INFO - Retrying request to /chat/completions in 0.846743 seconds
[02:03:20.103] 2025-08-20 02:03:20,102 - openai._base_client - INFO - Retrying request to /chat/completions in 0.891589 seconds
[02:03:20.120] 2025-08-20 02:03:20,120 - openai._base_client - INFO - Retrying request to /chat/completions in 0.761976 seconds
[02:03:20.182] 2025-08-20 02:03:20,181 - openai._base_client - INFO - Retrying request to /chat/completions in 0.842080 seconds
[02:03:20.199] 2025-08-20 02:03:20,198 - openai._base_client - INFO - Retrying request to /chat/completions in 0.757629 seconds
[02:03:20.213] 2025-08-20 02:03:20,212 - openai._base_client - INFO - Retrying request to /chat/completions in 0.847617 seconds
[02:03:20.226] 2025-08-20 02:03:20,225 - openai._base_client - INFO - Retrying request to /chat/completions in 0.980584 seconds
[02:03:20.237] 2025-08-20 02:03:20,236 - openai._base_client - INFO - Retrying request to /chat/completions in 0.952658 seconds
[02:03:20.279] 2025-08-20 02:03:20,279 - openai._base_client - INFO - Retrying request to /chat/completions in 0.969170 seconds
[02:03:20.283] 2025-08-20 02:03:20,283 - openai._base_client - INFO - Retrying request to /chat/completions in 0.961412 seconds
[02:03:20.340] 2025-08-20 02:03:20,340 - openai._base_client - INFO - Retrying request to /chat/completions in 0.752350 seconds
[02:03:20.353] 2025-08-20 02:03:20,353 - openai._base_client - INFO - Retrying request to /chat/completions in 0.940228 seconds
[02:03:20.403] 2025-08-20 02:03:20,401 - openai._base_client - INFO - Retrying request to /chat/completions in 0.991671 seconds
[02:03:51.537] 2025-08-20 02:03:51,536 - openai._base_client - INFO - Retrying request to /chat/completions in 0.416243 seconds
[02:03:58.660] 2025-08-20 02:03:58,660 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394794 seconds
[02:04:02.951] 2025-08-20 02:04:02,947 - openai._base_client - INFO - Retrying request to /chat/completions in 0.387103 seconds
[02:04:08.600] 2025-08-20 02:04:08,599 - openai._base_client - INFO - Retrying request to /chat/completions in 0.454879 seconds
[02:04:15.129] 2025-08-20 02:04:15,128 - openai._base_client - INFO - Retrying request to /chat/completions in 0.388631 seconds
[02:04:28.867] 2025-08-20 02:04:28,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:28.888]   [SEARCH] Query: api data fetcher
[02:04:28.889] 
[02:04:28.889] [TURN 2/10]
[02:04:28.890] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:04:31.136] 2025-08-20 02:04:31,136 - openai._base_client - INFO - Retrying request to /chat/completions in 0.385954 seconds
[02:04:32.153] 2025-08-20 02:04:32,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:32.156]   [PARSE] Found tool call: data_processing_parser
[02:04:32.156]   [EXECUTING] data_processing_parser
[02:04:32.159]     Result: SUCCESS
[02:04:32.159] 
[02:04:32.159] [TURN 3/10]
[02:04:32.160] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:04:39.040] 2025-08-20 02:04:39,040 - openai._base_client - INFO - Retrying request to /chat/completions in 0.478208 seconds
[02:04:52.557] 2025-08-20 02:04:52,556 - openai._base_client - INFO - Retrying request to /chat/completions in 0.414575 seconds
[02:04:58.759] 2025-08-20 02:04:58,758 - openai._base_client - INFO - Retrying request to /chat/completions in 0.456693 seconds
[02:05:07.656] 2025-08-20 02:05:07,655 - openai._base_client - INFO - Retrying request to /chat/completions in 0.401299 seconds
[02:05:15.262] 2025-08-20 02:05:15,260 - openai._base_client - INFO - Retrying request to /chat/completions in 0.399218 seconds
[02:05:16.661] 2025-08-20 02:05:16,661 - openai._base_client - INFO - Retrying request to /chat/completions in 0.433379 seconds
[02:05:20.967] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:20.967] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:20.967]   [API_FAILURE] API failed (timeout or max retries)
[02:05:20.974] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:20.974] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:20.974] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4410
[02:05:20.974] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:20.974]   - use_ai_classification=True
[02:05:20.974]   - ai_classifier=True
[02:05:20.974]   - txt_content_len=4410
[02:05:20.974]   - task_model=deepseek-r1-0528
[02:05:20.989] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:20.989] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:20.989]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.001] [LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.001] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.002]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.002] 
[02:05:21.002] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.002]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.007] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.007] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.007]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.029] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.029] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.029]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.084] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.084] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.084]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.085] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.085] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.085]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.085] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.085] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.085]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.088] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.088] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.088]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.120] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.120] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.120]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.156] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.156] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.156]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.168] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.168] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.168]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.201] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.201] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.201]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.206] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.206] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.206]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.248] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.249] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.249]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.252] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.252] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.252]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.284] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.284] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.284]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.354] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.354] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.354]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.355] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.355] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.355]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.412] 2025-08-20 02:05:21,411 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:21.415] 2025-08-20 02:05:21,415 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:21.415] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:21.417] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:21.417] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:21.417] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4420
[02:05:21.417] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:21.417]   - use_ai_classification=True
[02:05:21.417]   - ai_classifier=True
[02:05:21.417]   - txt_content_len=4420
[02:05:21.417]   - task_model=deepseek-r1-0528
[02:05:21.464] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.464] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.464]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.466] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.466] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.466]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.529] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.529] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.529]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.544] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.544] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.544]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.552] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.552] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.552]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.637] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:21.638] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:21.638]   [API_FAILURE] API failed (timeout or max retries)
[02:05:21.680] 2025-08-20 02:05:21,679 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:21.680] 2025-08-20 02:05:21,680 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:21.681] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:21.683] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:21.683] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:21.683] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4604
[02:05:21.683] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:21.683]   - use_ai_classification=True
[02:05:21.683]   - ai_classifier=True
[02:05:21.683]   - txt_content_len=4604
[02:05:21.683]   - task_model=deepseek-r1-0528
[02:05:21.821] 2025-08-20 02:05:21,821 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:21.822] 2025-08-20 02:05:21,822 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:21.822] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:21.825] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:21.825] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:21.825] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4223
[02:05:21.826] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:21.826]   - use_ai_classification=True
[02:05:21.826]   - ai_classifier=True
[02:05:21.826]   - txt_content_len=4223
[02:05:21.826]   - task_model=deepseek-r1-0528
[02:05:22.048] 2025-08-20 02:05:22,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.048] 2025-08-20 02:05:22,048 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.049] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.050] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.050] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.050] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4434
[02:05:22.050] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.050]   - use_ai_classification=True
[02:05:22.050]   - ai_classifier=True
[02:05:22.050]   - txt_content_len=4434
[02:05:22.050]   - task_model=deepseek-r1-0528
[02:05:22.190] 2025-08-20 02:05:22,190 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.191] 2025-08-20 02:05:22,191 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.191] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.195] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.195] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.195] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4223
[02:05:22.195] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.195]   - use_ai_classification=True
[02:05:22.195]   - ai_classifier=True
[02:05:22.195]   - txt_content_len=4223
[02:05:22.195]   - task_model=deepseek-r1-0528
[02:05:22.334] 2025-08-20 02:05:22,334 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.334] 2025-08-20 02:05:22,334 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.334] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.339] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.339] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.339] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4201
[02:05:22.339] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.339]   - use_ai_classification=True
[02:05:22.339]   - ai_classifier=True
[02:05:22.339]   - txt_content_len=4201
[02:05:22.339]   - task_model=deepseek-r1-0528
[02:05:22.462] 2025-08-20 02:05:22,462 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.463] 2025-08-20 02:05:22,463 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.463] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.466] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.466] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.466] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4223
[02:05:22.467] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.467]   - use_ai_classification=True
[02:05:22.467]   - ai_classifier=True
[02:05:22.467]   - txt_content_len=4223
[02:05:22.467]   - task_model=deepseek-r1-0528
[02:05:22.600] 2025-08-20 02:05:22,600 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.601] 2025-08-20 02:05:22,601 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.602] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.604] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.604] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.604] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4222
[02:05:22.604] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.604]   - use_ai_classification=True
[02:05:22.604]   - ai_classifier=True
[02:05:22.604]   - txt_content_len=4222
[02:05:22.604]   - task_model=deepseek-r1-0528
[02:05:22.740] 2025-08-20 02:05:22,739 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.740] 2025-08-20 02:05:22,740 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.740] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.743] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.743] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.743] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4263
[02:05:22.743] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.743]   - use_ai_classification=True
[02:05:22.743]   - ai_classifier=True
[02:05:22.743]   - txt_content_len=4263
[02:05:22.743]   - task_model=deepseek-r1-0528
[02:05:22.879] 2025-08-20 02:05:22,879 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:22.880] 2025-08-20 02:05:22,879 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:22.880] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:22.882] Progress: 10/40 (Success: 0)
[02:05:22.882] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.882] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:22.882] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4154
[02:05:22.882] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.882]   - use_ai_classification=True
[02:05:22.882]   - ai_classifier=True
[02:05:22.882]   - txt_content_len=4154
[02:05:22.882]   - task_model=deepseek-r1-0528
[02:05:23.040] 2025-08-20 02:05:23,040 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.040] 2025-08-20 02:05:23,040 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.040] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.041] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.041] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.042] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4755
[02:05:23.042] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.042]   - use_ai_classification=True
[02:05:23.042]   - ai_classifier=True
[02:05:23.042]   - txt_content_len=4755
[02:05:23.042]   - task_model=deepseek-r1-0528
[02:05:23.168] 2025-08-20 02:05:23,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.169] 2025-08-20 02:05:23,168 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.169] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.170] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.170] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.171] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4420
[02:05:23.171] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.171]   - use_ai_classification=True
[02:05:23.171]   - ai_classifier=True
[02:05:23.171]   - txt_content_len=4420
[02:05:23.171]   - task_model=deepseek-r1-0528
[02:05:23.306] 2025-08-20 02:05:23,306 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.306] 2025-08-20 02:05:23,306 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.307] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.308] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.308] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.308] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4718
[02:05:23.308] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.308]   - use_ai_classification=True
[02:05:23.308]   - ai_classifier=True
[02:05:23.308]   - txt_content_len=4718
[02:05:23.308]   - task_model=deepseek-r1-0528
[02:05:23.448] 2025-08-20 02:05:23,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.449] 2025-08-20 02:05:23,449 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.449] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.452] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.452] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.452] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4660
[02:05:23.452] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.452]   - use_ai_classification=True
[02:05:23.453]   - ai_classifier=True
[02:05:23.453]   - txt_content_len=4660
[02:05:23.453]   - task_model=deepseek-r1-0528
[02:05:23.576] 2025-08-20 02:05:23,576 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.577] 2025-08-20 02:05:23,577 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.577] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.579] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.579] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.579] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4154
[02:05:23.579] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.579]   - use_ai_classification=True
[02:05:23.579]   - ai_classifier=True
[02:05:23.579]   - txt_content_len=4154
[02:05:23.579]   - task_model=deepseek-r1-0528
[02:05:23.735] 2025-08-20 02:05:23,735 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.736] 2025-08-20 02:05:23,736 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.736] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.741] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.741] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.741] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4778
[02:05:23.741] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.741]   - use_ai_classification=True
[02:05:23.741]   - ai_classifier=True
[02:05:23.741]   - txt_content_len=4778
[02:05:23.741]   - task_model=deepseek-r1-0528
[02:05:23.897] 2025-08-20 02:05:23,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:23.897] 2025-08-20 02:05:23,897 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:23.898] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:23.900] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:23.900] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:23.900] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4582
[02:05:23.900] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:23.900]   - use_ai_classification=True
[02:05:23.900]   - ai_classifier=True
[02:05:23.900]   - txt_content_len=4582
[02:05:23.900]   - task_model=deepseek-r1-0528
[02:05:24.038] 2025-08-20 02:05:24,038 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.038] 2025-08-20 02:05:24,038 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.038] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.043] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.044] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.044] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4083
[02:05:24.044] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.044]   - use_ai_classification=True
[02:05:24.044]   - ai_classifier=True
[02:05:24.044]   - txt_content_len=4083
[02:05:24.044]   - task_model=deepseek-r1-0528
[02:05:24.179] 2025-08-20 02:05:24,179 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.180] 2025-08-20 02:05:24,179 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.180] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.181] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.181] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.181] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4643
[02:05:24.181] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.181]   - use_ai_classification=True
[02:05:24.181]   - ai_classifier=True
[02:05:24.181]   - txt_content_len=4643
[02:05:24.181]   - task_model=deepseek-r1-0528
[02:05:24.304] 2025-08-20 02:05:24,304 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.304] 2025-08-20 02:05:24,304 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.305] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.307] Progress: 20/40 (Success: 0)
[02:05:24.307] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.307] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.307] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4461
[02:05:24.307] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.307]   - use_ai_classification=True
[02:05:24.307]   - ai_classifier=True
[02:05:24.307]   - txt_content_len=4461
[02:05:24.307]   - task_model=deepseek-r1-0528
[02:05:24.313] 2025-08-20 02:05:24,313 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:05:24.315]   [PARSE] Found tool call: network_fetcher
[02:05:24.315]   [EXECUTING] network_fetcher
[02:05:24.315]     Result: SUCCESS
[02:05:24.315] 
[02:05:24.315] [TURN 3/10]
[02:05:24.316] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:05:24.430] 2025-08-20 02:05:24,430 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.431] 2025-08-20 02:05:24,431 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.431] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.434] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.434] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.434] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4541
[02:05:24.434] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.434]   - use_ai_classification=True
[02:05:24.434]   - ai_classifier=True
[02:05:24.434]   - txt_content_len=4541
[02:05:24.434]   - task_model=deepseek-r1-0528
[02:05:24.558] 2025-08-20 02:05:24,558 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.559] 2025-08-20 02:05:24,558 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.559] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.561] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.561] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.561] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4211
[02:05:24.561] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.561]   - use_ai_classification=True
[02:05:24.561]   - ai_classifier=True
[02:05:24.561]   - txt_content_len=4211
[02:05:24.561]   - task_model=deepseek-r1-0528
[02:05:24.686] 2025-08-20 02:05:24,686 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.687] 2025-08-20 02:05:24,687 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.687] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.690] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.690] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.690] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4201
[02:05:24.690] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.690]   - use_ai_classification=True
[02:05:24.690]   - ai_classifier=True
[02:05:24.690]   - txt_content_len=4201
[02:05:24.690]   - task_model=deepseek-r1-0528
[02:05:24.823] 2025-08-20 02:05:24,823 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.824] 2025-08-20 02:05:24,824 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.824] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.827] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.827] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.828] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4677
[02:05:24.828] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.828]   - use_ai_classification=True
[02:05:24.828]   - ai_classifier=True
[02:05:24.828]   - txt_content_len=4677
[02:05:24.828]   - task_model=deepseek-r1-0528
[02:05:24.954] 2025-08-20 02:05:24,954 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:24.955] 2025-08-20 02:05:24,955 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:24.956] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:24.958] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:24.958] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:05:24.958] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4584
[02:05:24.958] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:24.958]   - use_ai_classification=True
[02:05:24.959]   - ai_classifier=True
[02:05:24.959]   - txt_content_len=4584
[02:05:24.959]   - task_model=deepseek-r1-0528
[02:05:25.293] 2025-08-20 02:05:25,293 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:25.294] 2025-08-20 02:05:25,294 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:25.294] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
[02:05:42.533] 2025-08-20 02:05:42,532 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:05:42.536]   [PARSE] Found tool call: data_processing_parser
[02:05:42.536]   [EXECUTING] data_processing_parser
[02:05:42.537]     Result: FAILED - TIMEOUT: Operation timed out (after 60 seconds)
[02:05:42.537] 
[02:05:42.537] [TURN 5/10]
[02:05:42.538] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:05:52.530] 2025-08-20 02:05:52,529 - openai._base_client - INFO - Retrying request to /chat/completions in 0.870594 seconds
[02:05:59.312] 2025-08-20 02:05:59,312 - openai._base_client - INFO - Retrying request to /chat/completions in 0.849423 seconds
[02:06:03.728] 2025-08-20 02:06:03,728 - openai._base_client - INFO - Retrying request to /chat/completions in 0.809240 seconds
[02:06:09.381] 2025-08-20 02:06:09,381 - openai._base_client - INFO - Retrying request to /chat/completions in 0.909203 seconds
[02:06:10.845] 2025-08-20 02:06:10,845 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:06:10.846]   [PARSE] Found tool call: file_operations_reader
[02:06:10.846]   [EXECUTING] file_operations_reader
[02:06:10.847]     Result: SUCCESS
[02:06:10.847] 
[02:06:10.847] [TURN 3/10]
[02:06:10.847] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:06:15.769] 2025-08-20 02:06:15,768 - openai._base_client - INFO - Retrying request to /chat/completions in 0.908259 seconds
[02:06:25.475] 2025-08-20 02:06:25,474 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:06:25.477]   [PARSE] Found tool call: file_operations_reader
[02:06:25.477]   [EXECUTING] file_operations_reader
[02:06:25.478]     Result: SUCCESS
[02:06:25.478] 
[02:06:25.478] [TURN 3/10]
[02:06:25.480] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:06:28.901] 2025-08-20 02:06:28,901 - openai._base_client - INFO - Retrying request to /chat/completions in 0.489436 seconds
[02:06:31.818] 2025-08-20 02:06:31,818 - openai._base_client - INFO - Retrying request to /chat/completions in 0.864783 seconds
[02:06:32.167] 2025-08-20 02:06:32,167 - openai._base_client - INFO - Retrying request to /chat/completions in 0.420766 seconds
[02:06:48.828] 2025-08-20 02:06:48,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:06:48.834]   [SEARCH] Query: data structure validation
[02:06:48.836] 
[02:06:48.836] [TURN 4/10]
[02:06:48.838] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:06:53.259] 2025-08-20 02:06:53,259 - openai._base_client - INFO - Retrying request to /chat/completions in 0.848373 seconds
[02:07:08.318] 2025-08-20 02:07:08,315 - openai._base_client - INFO - Retrying request to /chat/completions in 0.949761 seconds
[02:07:15.985] 2025-08-20 02:07:15,983 - openai._base_client - INFO - Retrying request to /chat/completions in 0.941229 seconds
[02:07:17.348] 2025-08-20 02:07:17,348 - openai._base_client - INFO - Retrying request to /chat/completions in 0.872454 seconds
[02:07:27.242] 2025-08-20 02:07:27,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:07:27.243]   [PARSE] Found tool call: file_operations_reader
[02:07:27.243]   [EXECUTING] file_operations_reader
[02:07:27.244]     Result: SUCCESS
[02:07:27.244] 
[02:07:27.244] [TURN 3/10]
[02:07:27.244] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:07:42.393] 2025-08-20 02:07:42,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:07:42.395]   [INFO] Tool info request: data_processing_parser
[02:07:42.395] 
[02:07:42.395] [TURN 4/10]
[02:07:42.396] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:07:42.546] 2025-08-20 02:07:42,545 - openai._base_client - INFO - Retrying request to /chat/completions in 0.479045 seconds
[02:07:53.656] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:07:53.656] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:07:53.656]   [API_FAILURE] API failed (timeout or max retries)
[02:07:53.663] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:07:53.663] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:07:53.663] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 8662
[02:07:53.663] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:07:53.663]   - use_ai_classification=True
[02:07:53.663]   - ai_classifier=True
[02:07:53.663]   - txt_content_len=8662
[02:07:53.663]   - task_model=deepseek-r1-0528
[02:07:53.663] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:08:04.803] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:08:04.804] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:08:04.804]   [API_FAILURE] API failed (timeout or max retries)
[02:08:04.806] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:08:04.806] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:08:04.806] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 8941
[02:08:04.806] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:08:04.806]   - use_ai_classification=True
[02:08:04.806]   - ai_classifier=True
[02:08:04.806]   - txt_content_len=8941
[02:08:04.806]   - task_model=deepseek-r1-0528
[02:08:04.806] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:08:10.538] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:08:10.538] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:08:10.538]   [API_FAILURE] API failed (timeout or max retries)
[02:08:10.539] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:08:10.539] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:08:10.539] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 9104
[02:08:10.539] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:08:10.539]   - use_ai_classification=True
[02:08:10.539]   - ai_classifier=True
[02:08:10.539]   - txt_content_len=9104
[02:08:10.539]   - task_model=deepseek-r1-0528
[02:08:10.539] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:08:25.492] 2025-08-20 02:08:25,491 - openai._base_client - INFO - Retrying request to /chat/completions in 0.384888 seconds
[02:08:29.671] 2025-08-20 02:08:29,671 - openai._base_client - INFO - Retrying request to /chat/completions in 0.998608 seconds
[02:08:33.090] 2025-08-20 02:08:33,089 - openai._base_client - INFO - Retrying request to /chat/completions in 0.976211 seconds
[02:08:33.090] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:08:33.090] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:08:33.090]   [API_FAILURE] API failed (timeout or max retries)
[02:08:33.094] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:08:33.094] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:08:33.094] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 5689
[02:08:33.094] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:08:33.094]   - use_ai_classification=True
[02:08:33.094]   - ai_classifier=True
[02:08:33.094]   - txt_content_len=5689
[02:08:33.094]   - task_model=deepseek-r1-0528
[02:08:33.094] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:08:33.095] Progress: 30/40 (Success: 0)
[02:08:37.688] 2025-08-20 02:08:37,688 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:08:37.690]   [SEARCH] Query: data_processing_parser
[02:08:37.691] 
[02:08:37.691] [TURN 4/10]
[02:08:37.691] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:08:39.517] 2025-08-20 02:08:39,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:08:39.517]   [SEARCH] Query: data_processing_parser
[02:08:39.518] 
[02:08:39.518] [TURN 4/10]
[02:08:39.518] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:08:48.845] 2025-08-20 02:08:48,845 - openai._base_client - INFO - Retrying request to /chat/completions in 0.499591 seconds
[02:09:04.724] 2025-08-20 02:09:04,723 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:09:04.727]   [PARSE] Found tool call: data_processing_parser
[02:09:04.727]   [EXECUTING] data_processing_parser
[02:09:04.728]     Result: SUCCESS
[02:09:04.728] 
[02:09:04.728] [TURN 5/10]
[02:09:04.729] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[02:09:09.669] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:09:09.669] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:09:09.669]   [API_FAILURE] API failed (timeout or max retries)
[02:09:09.673] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:09:18.288] 2025-08-20 02:09:18,287 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.289] 2025-08-20 02:09:18,288 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.290] 2025-08-20 02:09:18,289 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.391] 2025-08-20 02:09:18,390 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.392] 2025-08-20 02:09:18,391 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.395] 2025-08-20 02:09:18,395 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.402] 2025-08-20 02:09:18,402 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.523] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:09:18.523] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:09:18.523]   [API_FAILURE] API failed (timeout or max retries)
[02:09:18.525] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:09:18.525] [AI_DEBUG] ÊµãËØïÂ§±Ë¥•ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[02:09:18.525] [AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 887
[02:09:18.525] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:09:18.525]   - use_ai_classification=True
[02:09:18.525]   - ai_classifier=True
[02:09:18.525]   - txt_content_len=887
[02:09:18.525]   - task_model=deepseek-r1-0528
[02:09:18.525] [AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.95
[02:09:18.672] 2025-08-20 02:09:18,672 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:18.680] 2025-08-20 02:09:18,680 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:27.250] 2025-08-20 02:09:27,250 - openai._base_client - INFO - Retrying request to /chat/completions in 0.491288 seconds
[02:09:43.283] 2025-08-20 02:09:43,282 - openai._base_client - INFO - Retrying request to /chat/completions in 0.956817 seconds
