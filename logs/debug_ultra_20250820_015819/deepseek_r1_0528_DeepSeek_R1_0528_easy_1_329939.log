===== 分片 DeepSeek-R1-0528_easy_1 =====
时间: 2025-08-20T01:58:49.948057
模型: deepseek-r1-0528
实例: DeepSeek-R1-0528-2
命令: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528-2 --prompt-types optimal --difficulty easy --task-types all --num-instances 6 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[01:58:51.797] 2025-08-20 01:58:51,797 - faiss.loader - INFO - Loading faiss.
[01:58:51.812] 2025-08-20 01:58:51,811 - faiss.loader - INFO - Successfully loaded faiss.
[01:58:52.728] [INFO] 使用Parquet存储格式
[01:58:53.118] [INFO] 使用Parquet存储格式
[01:58:53.120] [INFO] 使用PARQUET存储格式
[01:58:53.120] 
[01:58:53.120] ============================================================
[01:58:53.120] 智能批测试: deepseek-r1-0528 (idealab)
[01:58:53.120] Prompt types: ['optimal']
[01:58:53.120] 难度: easy
[01:58:53.120] 目标: 每种配置 6 个实例
[01:58:53.120] ============================================================
[01:58:53.120] ○ simple_task         :   0/  6 已完成 (需要补充 6 个)
[01:58:53.120] ○ basic_task          :   0/  6 已完成 (需要补充 6 个)
[01:58:53.120] ○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
[01:58:53.121] ○ api_integration     :   0/  6 已完成 (需要补充 6 个)
[01:58:53.121] ○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)
[01:58:53.121] 
[01:58:53.121] ⏳ 需要运行 30 个新测试
[01:58:53.121] 
[01:58:53.121] ▶ 准备 simple_task (6 个实例)...
[01:58:53.121] 
[01:58:53.121] ▶ 准备 basic_task (6 个实例)...
[01:58:53.121] 
[01:58:53.121] ▶ 准备 data_pipeline (6 个实例)...
[01:58:53.121] 
[01:58:53.121] ▶ 准备 api_integration (6 个实例)...
[01:58:53.121] 
[01:58:53.121] ▶ 准备 multi_stage_pipeline (6 个实例)...
[01:58:53.121] 
[01:58:53.121] ▶ 开始执行 30 个测试...
[01:58:53.121] 📦 批量提交模式：每20个测试保存一次
[01:58:53.121] 🚀 检测到Azure API，使用超高并发: workers=100, qps=200.0
[01:58:53.122] 2025-08-20 01:58:53,122 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[01:58:53.183] 2025-08-20 01:58:53,182 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[01:58:53.183] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x170d8b7a0>
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[01:58:53.183] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - ============================================================
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - Batch test runner initialized
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_015853.log
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - ============================================================
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - Running 30 tests with 100 workers, QPS limit: 200.0
[01:58:53.183] 2025-08-20 01:58:53,183 - batch_test_runner - INFO - Initializing test components...
[01:58:53.500] 2025-08-20 01:58:53,500 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[01:58:53.500] 2025-08-20 01:58:53,500 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[01:58:53.500] 2025-08-20 01:58:53,500 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[01:58:53.501] [DEBUG] Creating new ToolCapabilityManager instance
[01:58:53.501] [OperationEmbeddingIndex] Initializing with unified API client manager
[01:58:53.501] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[01:58:53.501] 2025-08-20 01:58:53,501 - api_client_manager - INFO - Loaded configuration from config/config.json
[01:58:53.507] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[01:58:53.507] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[01:58:53.508] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[01:58:54.427] 2025-08-20 01:58:54,426 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[01:58:54.428] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[01:58:54.476] [INFO] Loaded 4150 embeddings from persistent cache
[01:58:54.476] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[01:58:54.476] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[01:58:54.477] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[01:58:54.477] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[01:58:54.481] [INFO] Successfully loaded FAISS index with dimension 3072
[01:58:54.481] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[01:58:54.481] [INFO] Loaded 15 operations with dimension 3072
[01:58:54.481] [INFO] Successfully loaded cached index
[01:58:54.481] [INFO] Operation semantic index initialized
[01:58:54.481] [INFO] Using device: cpu
[01:58:54.481] [INFO] Initialized tool success tracking attributes
[01:58:54.481] [INFO] Initializing embedding manager for enhanced tool selection
[01:58:54.481] [MCPEmbeddingManager] Creating new singleton instance
[01:58:54.481] [MCPEmbeddingManager] Initializing with unified API client manager
[01:58:54.488] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[01:58:54.488] [MCPEmbeddingManager] Client initialized successfully
[01:58:54.488] 2025-08-20 01:58:54,488 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:58:54.636] 2025-08-20 01:58:54,636 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:58:54.910] 2025-08-20 01:58:54,910 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[01:58:54.910] 2025-08-20 01:58:54,910 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[01:58:54.933] 2025-08-20 01:58:54,933 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:58:55.021] 2025-08-20 01:58:55,021 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:58:55.259] 2025-08-20 01:58:55,259 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[01:58:55.260] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[01:58:55.260] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[01:58:55.260] 2025-08-20 01:58:55,260 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:55.289] 2025-08-20 01:58:55,289 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:55.289] 2025-08-20 01:58:55,289 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:55.289] 2025-08-20 01:58:55,289 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:55.291] [SUCCESS] Loaded 30 tool embeddings
[01:58:55.291] 2025-08-20 01:58:55,291 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[01:58:55.291] [SUCCESS] Embedding manager initialized with 30 tools
[01:58:55.291] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[01:58:55.291] [INFO] Loading full MCP protocol registry...
[01:58:55.292] 2025-08-20 01:58:55,292 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:55.292] [INFO] Loaded full tool registry with 30 tools
[01:58:55.292] 2025-08-20 01:58:55,292 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:58:55.292] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:58:55.293] [INFO] Embedding manager ready with 30 tools
[01:58:55.293] [WARNING] Embedding manager exists but has no embeddings
[01:58:55.293] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[01:58:55.293] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:55.294] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:55.294] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:55.294] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[01:58:55.294] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[01:58:55.294] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:55.294] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:55.294] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:55.294] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:55.294] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:55.294] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:55.294] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:58:55.294] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:55.294] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:55.294] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[01:58:55.294] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:55.294] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:55.294] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:58:55.294] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:55.294] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:55.294] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:55.294] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[01:58:55.294] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[01:58:55.294] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[01:58:55.294] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[01:58:55.294] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[01:58:55.294] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[01:58:55.294] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[01:58:55.294] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[01:58:55.294] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[01:58:55.294] 2025-08-20 01:58:55,294 - mdp_workflow_generator - INFO - Loaded 30 tools
[01:58:55.294] [INFO] Setting default state_dim based on loaded tools
[01:58:55.294] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[01:58:55.294] 2025-08-20 01:58:55,294 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[01:58:55.294] [INFO] Setting default action_dim based on loaded tools
[01:58:55.294] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[01:58:55.294] 2025-08-20 01:58:55,294 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[01:58:55.294] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[01:58:55.294] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[01:58:55.294] [INFO] ⚡ Will use pre-generated workflows or random policy
[01:58:55.294] 2025-08-20 01:58:55,294 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[01:58:55.294] [INFO] Initializing TaskManager...
[01:58:56.788] 2025-08-20 01:58:56,787 - unified_training_manager - INFO - Using device: cpu
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO - Task filtering results:
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO -   Total: 5040 -> 5040
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO -   simple_task: 320 -> 320
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[01:58:56.898] 2025-08-20 01:58:56,898 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[01:58:56.901] 2025-08-20 01:58:56,901 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[01:58:56.901] [TaskManager] Difficulty level 'easy': 1096 tasks
[01:58:56.901] [TaskManager] Difficulty level 'very_easy': 856 tasks
[01:58:56.901] [TaskManager] Difficulty level 'medium': 1136 tasks
[01:58:56.901] [TaskManager] Difficulty level 'hard': 1096 tasks
[01:58:56.901] [TaskManager] Difficulty level 'very_hard': 856 tasks
[01:58:56.903] [INFO] TaskManager initialized with 5040 tasks
[01:58:56.903] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:58:56.903] [INFO] Initializing ToolCallVerifier...
[01:58:56.904] [INFO] ToolCallVerifier initialized with 30 tools
[01:58:56.904] [INFO] Output tools identified: 1
[01:58:56.904] [INFO] Component initialization status:
[01:58:56.904]   - embedding_manager: initialized
[01:58:56.904]   - task_manager: initialized
[01:58:56.904]   - output_verifier: initialized
[01:58:56.904]   - tool_capability_manager: initialized
[01:58:56.904]   - tool_success_rates: initialized with 0 entries
[01:58:56.904] [INFO] MDPWorkflowGenerator initialization complete
[01:58:56.904] 2025-08-20 01:58:56,904 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[01:58:56.904] 2025-08-20 01:58:56,904 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[01:58:56.904] 2025-08-20 01:58:56,904 - batch_test_runner - INFO -   - task_manager: ✓
[01:58:56.904] 2025-08-20 01:58:56,904 - batch_test_runner - INFO -   - output_verifier: ✓
[01:58:56.904] 2025-08-20 01:58:56,904 - batch_test_runner - INFO -   - embedding_manager: ✓
[01:58:56.904] 2025-08-20 01:58:56,904 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[01:58:56.904] 2025-08-20 01:58:56,904 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[01:58:56.904] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:56.904] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:56.904] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:58:56.904] [FlawedWorkflowGenerator] RAG support: disabled
[01:58:56.905] DEBUG: Checking generator attributes
[01:58:56.905]   - has tool_capabilities: True
[01:58:56.905]   - has tool_capability_manager: True
[01:58:56.905]   - has task_manager: True
[01:58:56.905] [INFO] Loaded 30 tools from generator
[01:58:56.905] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[01:58:56.905] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:56.905] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:56.905] [INFO] Initializing LLM client using APIClientManager
[01:58:56.911] [INFO] Using Azure OpenAI client
[01:58:56.911] [DEBUG] Checking if generator has tool_capability_manager attribute
[01:58:56.911] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[01:58:56.911] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:56.911] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:56.911] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:58:56.911] [FlawedWorkflowGenerator] RAG support: enabled
[01:58:56.911] [INFO] FlawedWorkflowGenerator initialized successfully
[01:58:56.911] [INFO] Initializing StableScorer for Phase 2 scoring
[01:58:56.911] <tool_capability_manager.ToolCapabilityManager object at 0x311096120>
[01:58:56.911] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:56.911] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:56.911] [INFO] Loaded tool success history for 0 tools
[01:58:56.912] [INFO] StableScorer initialized with semantic capability
[01:58:56.912] [INFO] StableScorer initialized successfully
[01:58:56.912] [INFO] Loading task instances...
[01:58:56.912] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[01:58:56.918] [INFO] Loaded 630 task instances
[01:58:56.918] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:58:56.918] 2025-08-20 01:58:56,918 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[01:58:56.918] 2025-08-20 01:58:56,918 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[01:58:57.238] 2025-08-20 01:58:57,238 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[01:58:57.239] 2025-08-20 01:58:57,238 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[01:58:57.254] 2025-08-20 01:58:57,254 - batch_test_runner - INFO - Initialization complete
[01:58:57.298] 2025-08-20 01:58:57,298 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[01:58:57.298] 2025-08-20 01:58:57,298 - batch_test_runner - INFO - Starting batch test with 30 tasks, 100 workers
[01:58:57.298] 2025-08-20 01:58:57,298 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[01:58:57.301] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.301] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.301] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.302] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.302] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.303] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.303] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.303] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.303] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.304] 2025-08-20 01:58:57,304 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for DeepSeek-R1-0528-2
[01:58:57.322] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.323] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.323] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.323] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.323] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.323] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.324] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.324] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.324] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.324] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.324] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.324] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.325] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.325] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.326] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.326] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:58:57.327] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.327] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.327] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.327] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.327] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.327] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.330] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.330] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.330] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.330] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.335] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.335] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.335] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.336] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.336] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.336] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.336] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.336] 
[01:58:57.336] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.336] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.336] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.337] 2025-08-20 01:58:57,337 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.337] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.337] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.337] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.337] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.338] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.338] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.338] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.338] 2025-08-20 01:58:57,338 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.339] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.339] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.342] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.342] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.342] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.342] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.342] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.342] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.342] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.342] 2025-08-20 01:58:57,342 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.343] 
[01:58:57.344] 2025-08-20 01:58:57,344 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.345] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.345] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.346] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.346] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.347] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.347] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.348] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.348] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.348] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.350] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.350] 
[01:58:57.350] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.350] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.350] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.350] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.350] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.352] 2025-08-20 01:58:57,352 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.354] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.354] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.354] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.354] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.354] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.354] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.354] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.354] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.354] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.355] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.355] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.355] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.355] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.355] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.355] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.356] 2025-08-20 01:58:57,354 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.356] 2025-08-20 01:58:57,354 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.356] 
[01:58:57.356] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.356] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.356] 
[01:58:57.356] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.356] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.357] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.357] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.357] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.357] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.359] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.359] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.359] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.360] [InteractiveExecutor] API model name: DeepSeek-R1-0528-22025-08-20 01:58:57,355 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.360] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.361] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.361] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.361] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.361] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.361] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.362] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.362] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.362] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.362] 2025-08-20 01:58:57,360 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.362] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.362] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.362] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.362] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.362] 
[01:58:57.363] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2[MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)2025-08-20 01:58:57,361 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.363] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.363] 
[01:58:57.364] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.364] 
[01:58:57.364] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.364] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.364] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.364] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.364] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.364] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.364] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.364] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.366] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.366] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.366] 2025-08-20 01:58:57,362 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.366] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.367] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.367] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.367] 2025-08-20 01:58:57,362 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.367] 2025-08-20 01:58:57,363 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.367] 
[01:58:57.368] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.368] 2025-08-20 01:58:57,363 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.368] 2025-08-20 01:58:57,363 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.373] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.373] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.374] 2025-08-20 01:58:57,364 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.374] 2025-08-20 01:58:57,364 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.374] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.374] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.374] 
[01:58:57.376] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.376] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.382] 2025-08-20 01:58:57,367 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.386] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:58:57.386] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:58:57.390] 2025-08-20 01:58:57,367 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.391] 2025-08-20 01:58:57,368 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.391] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.391] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.391] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.395] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.395] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.395] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.396] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.396] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.396] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.396] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.396] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.397] 2025-08-20 01:58:57,368 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.398] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.398] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.399] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.400] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2[MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.401] 
[01:58:57.401] 2025-08-20 01:58:57,394 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.410] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.410] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:58:57.410] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.410] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.412] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13182862592)
[01:58:57.412] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.412] 2025-08-20 01:58:57,399 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.412] 2025-08-20 01:58:57,399 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.412] 2025-08-20 01:58:57,399 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.414] 
[01:58:57.414] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:58:57.473] 2025-08-20 01:58:57,401 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.473] 2025-08-20 01:58:57,403 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.500] 2025-08-20 01:58:57,403 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.506] 2025-08-20 01:58:57,412 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.508] 2025-08-20 01:58:57,415 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.508] 2025-08-20 01:58:57,440 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.508] 2025-08-20 01:58:57,491 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.508] 2025-08-20 01:58:57,495 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:58:57.508] 2025-08-20 01:58:57,505 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.508] 2025-08-20 01:58:57,506 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.511] [INFO] Tool embedding index loaded successfully
[01:58:57.513] 2025-08-20 01:58:57,508 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.513] 2025-08-20 01:58:57,513 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.543] [INFO] Tool embedding index loaded successfully[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.547] [INFO] Operation semantic index initialized
[01:58:57.557] 2025-08-20 01:58:57,508 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.558] 
[01:58:57.558] 
[01:58:57.558] [TURN 1/10]
[01:58:57.579] 2025-08-20 01:58:57,542 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.586] 2025-08-20 01:58:57,557 - mcp_embedding_manager - INFO - Index loaded successfully: 11 tools
[01:58:57.588] [INFO] Tool embedding index loaded successfully
[01:58:57.602] 2025-08-20 01:58:57,579 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.602] 2025-08-20 01:58:57,602 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.604] [INFO] Tool embedding index loaded successfully
[01:58:57.605] 2025-08-20 01:58:57,605 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.605] 2025-08-20 01:58:57,605 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.605] 2025-08-20 01:58:57,605 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.607] [INFO] Tool embedding index loaded successfully
[01:58:57.615] 2025-08-20 01:58:57,615 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.615] 2025-08-20 01:58:57,615 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.615] 2025-08-20 01:58:57,615 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.673] [INFO] Tool embedding index loaded successfully2025-08-20 01:58:57,673 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.673] 2025-08-20 01:58:57,673 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.673] 2025-08-20 01:58:57,673 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:58:57.675] [INFO] Tool embedding index loaded successfully
[01:58:57.678] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.715] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.716] 
[01:58:57.717] 2025-08-20 01:58:57,717 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.717] 2025-08-20 01:58:57,717 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.717] 2025-08-20 01:58:57,717 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.744] [INFO] Tool embedding index loaded successfully
[01:58:57.747] 2025-08-20 01:58:57,747 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.747] 2025-08-20 01:58:57,747 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.747] 2025-08-20 01:58:57,747 - mcp_embedding_manager - INFO - Index loaded successfully: 29 tools
[01:58:57.750] [INFO] Tool embedding index loaded successfully
[01:58:57.751] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.753] 2025-08-20 01:58:57,752 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.753] 2025-08-20 01:58:57,753 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.753] 2025-08-20 01:58:57,753 - mcp_embedding_manager - INFO - Index loaded successfully: 29 tools
[01:58:57.755] [INFO] Tool embedding index loaded successfully
[01:58:57.762] [INFO] Operation semantic index initialized2025-08-20 01:58:57,762 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.762] 2025-08-20 01:58:57,762 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.762] 2025-08-20 01:58:57,762 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.764] [INFO] Tool embedding index loaded successfully
[01:58:57.764] 
[01:58:57.766] 2025-08-20 01:58:57,766 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.766] [INFO] Operation semantic index initialized
[01:58:57.768] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.797] 2025-08-20 01:58:57,776 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.798] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:57.809] [INFO] Operation semantic index initialized
[01:58:57.809] [TURN 1/10]
[01:58:57.813] 
[01:58:57.820] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.823] [INFO] Operation semantic index initialized[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.826] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.839] [INFO] Operation semantic index initialized[INFO] Operation semantic index initialized
[01:58:57.839] 
[01:58:57.839] [TURN 1/10]
[01:58:57.839] 
[01:58:57.843] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.848] [INFO] Operation semantic index initialized
[01:58:57.848] 2025-08-20 01:58:57,785 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.860] 
[01:58:57.879] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.890] 2025-08-20 01:58:57,785 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.891] 
[01:58:57.891] [TURN 1/10]
[01:58:57.898] [INFO] Operation semantic index initialized[INFO] Operation semantic index initialized
[01:58:57.904] 2025-08-20 01:58:57,797 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.911] 
[01:58:57.921] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-20 01:58:57,825 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.921] 
[01:58:57.928] 2025-08-20 01:58:57,839 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.933] 
[01:58:57.933] [TURN 1/10]
[01:58:57.933] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:57.935] 
[01:58:57.947] 2025-08-20 01:58:57,848 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.956] 2025-08-20 01:58:57,885 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.959] 
[01:58:57.959] [TURN 1/10]2025-08-20 01:58:57,890 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.962] [INFO] Tool embedding index loaded successfully
[01:58:57.962] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:57.963] 2025-08-20 01:58:57,890 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.963] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:57.964] [INFO] Operation semantic index initialized
[01:58:57.970] 2025-08-20 01:58:57,897 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.976] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.983] 
[01:58:57.983] [TURN 1/10]
[01:58:57.983] 
[01:58:57.989] 2025-08-20 01:58:57,904 - mcp_embedding_manager - INFO - Index loaded successfully: 20 tools
[01:58:57.992] [INFO] Tool embedding index loaded successfully
[01:58:57.992] [INFO] Operation semantic index initialized
[01:58:57.992] 2025-08-20 01:58:57,914 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.992] 2025-08-20 01:58:57,992 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.992] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-22025-08-20 01:58:57,920 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.992] 
[01:58:57.992] [TURN 1/10]
[01:58:57.992] 
[01:58:57.994] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.994] 2025-08-20 01:58:57,921 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.994] 
[01:58:57.994] [TURN 1/10]
[01:58:57.994] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:57.995] 2025-08-20 01:58:57,922 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:57.995] 2025-08-20 01:58:57,995 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.995] 2025-08-20 01:58:57,995 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:57.997] [INFO] Tool embedding index loaded successfully
[01:58:57.997] 
[01:58:57.998] [TURN 1/10]
[01:58:57.998] [INFO] Operation semantic index initialized
[01:58:57.998] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:57.999] 
[01:58:57.999] [TURN 1/10]
[01:58:57.999] 2025-08-20 01:58:57,935 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:57.999] 
[01:58:57.999] [TURN 1/10]
[01:58:57.999] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:57.999] 
[01:58:57.999] [TURN 1/10]
[01:58:57.999] 2025-08-20 01:58:57,952 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.000] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.000] [INFO] Operation semantic index initialized
[01:58:58.001] 
[01:58:58.001] [TURN 1/10]
[01:58:58.001] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.001] 2025-08-20 01:58:57,956 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.001] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.002] 2025-08-20 01:58:57,956 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.002] 2025-08-20 01:58:57,959 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.002] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.002] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.003] 2025-08-20 01:58:57,963 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.003] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.004] 2025-08-20 01:58:57,963 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.004] 2025-08-20 01:58:57,970 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.004] 2025-08-20 01:58:58,004 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.007] [INFO] Tool embedding index loaded successfully
[01:58:58.007] 2025-08-20 01:58:57,992 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.007] 2025-08-20 01:58:57,992 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.010] [INFO] Tool embedding index loaded successfully
[01:58:58.010] 2025-08-20 01:58:57,992 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.010] 2025-08-20 01:58:58,010 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.013] [INFO] Tool embedding index loaded successfully
[01:58:58.013] 2025-08-20 01:58:57,920 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.013] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.013] 2025-08-20 01:58:57,928 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.014] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.014] [INFO] Operation semantic index initialized
[01:58:58.014] 2025-08-20 01:58:57,947 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:58:58.016] [INFO] Tool embedding index loaded successfully
[01:58:58.017] 
[01:58:58.017] [TURN 1/10]
[01:58:58.017] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.017] 2025-08-20 01:58:57,999 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.020] [INFO] Tool embedding index loaded successfully
[01:58:58.020] [INFO] Operation semantic index initialized
[01:58:58.020] 2025-08-20 01:58:58,000 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.020] 2025-08-20 01:58:58,020 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.023] [INFO] Tool embedding index loaded successfully
[01:58:58.023] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.024] 2025-08-20 01:58:58,002 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.024] [INFO] Operation semantic index initialized
[01:58:58.024] 
[01:58:58.024] [TURN 1/10]
[01:58:58.024] 2025-08-20 01:58:58,002 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.025] 2025-08-20 01:58:58,003 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.028] [INFO] Tool embedding index loaded successfully
[01:58:58.028] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.028] 
[01:58:58.028] [TURN 1/10]
[01:58:58.028] [INFO] Operation semantic index initialized
[01:58:58.028] 
[01:58:58.028] [TURN 1/10]
[01:58:58.028] 2025-08-20 01:58:58,004 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.029] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.029] 2025-08-20 01:58:57,974 - mcp_embedding_manager - INFO - FAISS index loaded
[01:58:58.029] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.031] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.031] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.032] [INFO] Operation semantic index initialized2025-08-20 01:58:58,007 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.032] 2025-08-20 01:58:58,032 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.034] [INFO] Tool embedding index loaded successfully
[01:58:58.034] [INFO] Operation semantic index initialized
[01:58:58.034] 
[01:58:58.034] [TURN 1/10]
[01:58:58.034] [INFO] Operation semantic index initialized
[01:58:58.034] 
[01:58:58.035] [TURN 1/10]
[01:58:58.035] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.036] 
[01:58:58.036] 2025-08-20 01:58:58,013 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.036] 2025-08-20 01:58:58,036 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.038] [INFO] Tool embedding index loaded successfully
[01:58:58.038] 
[01:58:58.038] [TURN 1/10]
[01:58:58.039] 2025-08-20 01:58:58,001 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.042] [INFO] Tool embedding index loaded successfully
[01:58:58.042] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-22025-08-20 01:58:58,024 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.045] [INFO] Tool embedding index loaded successfully
[01:58:58.045] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.048] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.048] [INFO] Operation semantic index initialized
[01:58:58.052] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.052] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.052] [TURN 1/10]
[01:58:58.052] 
[01:58:58.053] 
[01:58:58.053] 2025-08-20 01:58:58,024 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.056] [INFO] Tool embedding index loaded successfully[INFO] Operation semantic index initialized
[01:58:58.056] 
[01:58:58.056] [TURN 1/10]
[01:58:58.056] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-20 01:58:58,028 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.056] 
[01:58:58.056] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.057] 
[01:58:58.058] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.061] [INFO] Tool embedding index loaded successfully
[01:58:58.061] 2025-08-20 01:58:58,031 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.061] [INFO] Operation semantic index initialized[INFO] Operation semantic index initialized
[01:58:58.061] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.062] 2025-08-20 01:58:58,013 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:58:58.062] 
[01:58:58.062] [TURN 1/10]
[01:58:58.062] 
[01:58:58.062] 2025-08-20 01:58:57,994 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.065] [INFO] Tool embedding index loaded successfully
[01:58:58.065] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.066] 2025-08-20 01:58:58,061 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.069] [INFO] Tool embedding index loaded successfully
[01:58:58.069] 
[01:58:58.069] [TURN 1/10]
[01:58:58.069] 2025-08-20 01:58:58,062 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:58:58.072] [INFO] Tool embedding index loaded successfully
[01:58:58.072] [INFO] Operation semantic index initialized
[01:58:58.072] 
[01:58:58.072] [TURN 1/10]
[01:58:58.073] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.073] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.074] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.075] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.076] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.076] [INFO] Operation semantic index initialized
[01:58:58.076] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.076] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.077] 
[01:58:58.077] [TURN 1/10]
[01:58:58.078] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:58:58.078] [INFO] Operation semantic index initialized
[01:58:58.078] 
[01:58:58.078] [TURN 1/10]
[01:58:58.078] [INFO] Operation semantic index initialized
[01:58:58.078] [INFO] Operation semantic index initialized
[01:58:58.078] 
[01:58:58.078] [TURN 1/10]
[01:58:58.079] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.079] [TURN 1/10]
[01:58:58.079] 
[01:58:58.079] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.080] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:58:58.081] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:59:10.354] 2025-08-20 01:59:10,353 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:10.363]   [SEARCH] Query: file_operations_reader
[01:59:10.368] 
[01:59:10.368] [TURN 2/10]
[01:59:10.370] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:59:11.406] 2025-08-20 01:59:11,406 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:11.406]   [SEARCH] Query: data parser
[01:59:11.406]   [SEARCH] Query: data parser
[01:59:11.407] 
[01:59:11.407] [TURN 2/10]
[01:59:11.407] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:59:38.615] 2025-08-20 01:59:38,613 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:38.619]   [INFO] Tool info request: file_operations_reader
[01:59:38.619] 
[01:59:38.619] [TURN 2/10]
[01:59:38.620] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:59:45.398] 2025-08-20 01:59:45,398 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:45.400]   [PARSE] Fuzzy matched 'file_operations_reader
[01:59:45.400] {
[01:59:45.400]   "source": "data/input.json"
[01:59:45.400] }' to 'file_operations_reader'
[01:59:45.400]   [EXECUTING] file_operations_reader
[01:59:45.401]     Result: SUCCESS
[01:59:45.401] 
[01:59:45.401] [TURN 3/10]
[01:59:45.402] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:59:54.864] 2025-08-20 01:59:54,863 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:54.869]   [SEARCH] Query: network api fetch
[01:59:54.871] 
[01:59:54.871] [TURN 2/10]
[01:59:54.872] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:59:55.282] 2025-08-20 01:59:55,282 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:59:55.284]   [SEARCH] Query: data validation
[01:59:55.285] 
[01:59:55.285] [TURN 2/10]
[01:59:55.285] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:00:09.669] 2025-08-20 02:00:09,668 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:09.673]   [PARSE] Found tool call: network_fetcher
[02:00:09.673]   [EXECUTING] network_fetcher
[02:00:09.674]     Result: FAILED - INVALID_RESPONSE: Invalid response from server
[02:00:09.674] 
[02:00:09.674] [TURN 3/10]
[02:00:09.675] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:00:33.895] 2025-08-20 02:00:33,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:33.899]   [SEARCH] Query: file reader
[02:00:33.901] 
[02:00:33.901] [TURN 2/10]
[02:00:33.902] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:00:37.691] 2025-08-20 02:00:37,691 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:37.695]   [SEARCH] Query: network_fetcher
[02:00:37.695] 
[02:00:37.695] [TURN 2/10]
[02:00:37.696] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:00:41.210] 2025-08-20 02:00:41,210 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:00:41.211]   [PARSE] Unknown tool: file_reader
[02:00:41.212] 
[02:00:41.212] [TURN 4/10]
[02:00:41.213] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:00:58.622] 2025-08-20 02:00:58,622 - openai._base_client - INFO - Retrying request to /chat/completions in 0.469047 seconds
[02:00:58.623] 2025-08-20 02:00:58,623 - openai._base_client - INFO - Retrying request to /chat/completions in 0.474600 seconds
[02:00:58.623] 2025-08-20 02:00:58,623 - openai._base_client - INFO - Retrying request to /chat/completions in 0.391320 seconds
[02:00:58.624] 2025-08-20 02:00:58,624 - openai._base_client - INFO - Retrying request to /chat/completions in 0.410529 seconds
[02:00:58.624] 2025-08-20 02:00:58,624 - openai._base_client - INFO - Retrying request to /chat/completions in 0.413444 seconds
[02:00:58.628] 2025-08-20 02:00:58,628 - openai._base_client - INFO - Retrying request to /chat/completions in 0.467551 seconds
[02:00:58.630] 2025-08-20 02:00:58,630 - openai._base_client - INFO - Retrying request to /chat/completions in 0.422087 seconds
[02:00:58.631] 2025-08-20 02:00:58,631 - openai._base_client - INFO - Retrying request to /chat/completions in 0.465038 seconds
[02:00:58.631] 2025-08-20 02:00:58,631 - openai._base_client - INFO - Retrying request to /chat/completions in 0.497323 seconds
[02:00:58.631] 2025-08-20 02:00:58,631 - openai._base_client - INFO - Retrying request to /chat/completions in 0.399927 seconds
[02:00:58.632] 2025-08-20 02:00:58,632 - openai._base_client - INFO - Retrying request to /chat/completions in 0.491012 seconds
[02:00:58.632] 2025-08-20 02:00:58,632 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394294 seconds
[02:00:58.634] 2025-08-20 02:00:58,634 - openai._base_client - INFO - Retrying request to /chat/completions in 0.377808 seconds
[02:00:58.634] 2025-08-20 02:00:58,634 - openai._base_client - INFO - Retrying request to /chat/completions in 0.407844 seconds
[02:00:58.635] 2025-08-20 02:00:58,635 - openai._base_client - INFO - Retrying request to /chat/completions in 0.428806 seconds
[02:00:58.635] 2025-08-20 02:00:58,635 - openai._base_client - INFO - Retrying request to /chat/completions in 0.413067 seconds
[02:00:58.636] 2025-08-20 02:00:58,635 - openai._base_client - INFO - Retrying request to /chat/completions in 0.479771 seconds
[02:00:58.645] 2025-08-20 02:00:58,645 - openai._base_client - INFO - Retrying request to /chat/completions in 0.397718 seconds
[02:00:58.645] 2025-08-20 02:00:58,645 - openai._base_client - INFO - Retrying request to /chat/completions in 0.462399 seconds
[02:00:58.646] 2025-08-20 02:00:58,646 - openai._base_client - INFO - Retrying request to /chat/completions in 0.379344 seconds
[02:00:58.646] 2025-08-20 02:00:58,646 - openai._base_client - INFO - Retrying request to /chat/completions in 0.434482 seconds
[02:00:58.648] 2025-08-20 02:00:58,648 - openai._base_client - INFO - Retrying request to /chat/completions in 0.458567 seconds
[02:00:58.649] 2025-08-20 02:00:58,649 - openai._base_client - INFO - Retrying request to /chat/completions in 0.497281 seconds
[02:01:10.379] 2025-08-20 02:01:10,379 - openai._base_client - INFO - Retrying request to /chat/completions in 0.405205 seconds
[02:01:11.409] 2025-08-20 02:01:11,409 - openai._base_client - INFO - Retrying request to /chat/completions in 0.477126 seconds
[02:01:24.902] 2025-08-20 02:01:24,900 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:01:24.940]   [PARSE] Found tool call: network_fetcher
[02:01:24.940]   [EXECUTING] network_fetcher
[02:01:24.942]     Result: SUCCESS
[02:01:24.943] 
[02:01:24.943] [TURN 5/10]
[02:01:24.945] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:01:45.411] 2025-08-20 02:01:45,410 - openai._base_client - INFO - Retrying request to /chat/completions in 0.484032 seconds
[02:01:48.799] 2025-08-20 02:01:48,799 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:01:48.803]   [SEARCH] Query: data reader
[02:01:48.804] 
[02:01:48.804] [TURN 2/10]
[02:01:48.805] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:01:55.290] 2025-08-20 02:01:55,289 - openai._base_client - INFO - Retrying request to /chat/completions in 0.477525 seconds
[02:02:09.889] 2025-08-20 02:02:09,883 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:09.903]   [SEARCH] Query: network_fetcher
[02:02:09.904] 
[02:02:09.904] [TURN 2/10]
[02:02:09.905] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:02:16.349] 2025-08-20 02:02:16,348 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:16.353]   [SEARCH] Query: network_fetcher
[02:02:16.353] 
[02:02:16.353] [TURN 2/10]
[02:02:16.354] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:02:33.984] 2025-08-20 02:02:33,984 - openai._base_client - INFO - Retrying request to /chat/completions in 0.421471 seconds
[02:02:37.772] 2025-08-20 02:02:37,772 - openai._base_client - INFO - Retrying request to /chat/completions in 0.470583 seconds
[02:02:38.367] 2025-08-20 02:02:38,367 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:38.375]   [SEARCH] Query: data processing parser
[02:02:38.386] 
[02:02:38.386] [TURN 2/10]
[02:02:38.390] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:02:50.169] 2025-08-20 02:02:50,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:02:50.173]   [PARSE] Fuzzy matched 'file_operations_reader
[02:02:50.173] {
[02:02:50.173]   "source": "data/input.json"
[02:02:50.173] }' to 'file_operations_reader'
[02:02:50.173]   [EXECUTING] file_operations_reader
[02:02:50.175]     Result: FAILED - TIMEOUT: Operation timed out (after 53 seconds)
[02:02:50.175] 
[02:02:50.175] [TURN 3/10]
[02:02:50.176] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:02:59.393] 2025-08-20 02:02:59,392 - openai._base_client - INFO - Retrying request to /chat/completions in 0.947786 seconds
[02:02:59.397] 2025-08-20 02:02:59,397 - openai._base_client - INFO - Retrying request to /chat/completions in 0.956692 seconds
[02:02:59.397] 2025-08-20 02:02:59,397 - openai._base_client - INFO - Retrying request to /chat/completions in 0.783839 seconds
[02:02:59.403] 2025-08-20 02:02:59,403 - openai._base_client - INFO - Retrying request to /chat/completions in 0.821694 seconds
[02:02:59.404] 2025-08-20 02:02:59,404 - openai._base_client - INFO - Retrying request to /chat/completions in 0.778027 seconds
[02:02:59.404] 2025-08-20 02:02:59,404 - openai._base_client - INFO - Retrying request to /chat/completions in 0.778624 seconds
[02:02:59.405] 2025-08-20 02:02:59,405 - openai._base_client - INFO - Retrying request to /chat/completions in 0.807082 seconds
[02:02:59.405] 2025-08-20 02:02:59,405 - openai._base_client - INFO - Retrying request to /chat/completions in 0.763945 seconds
[02:02:59.414] 2025-08-20 02:02:59,414 - openai._base_client - INFO - Retrying request to /chat/completions in 0.976102 seconds
[02:02:59.417] 2025-08-20 02:02:59,416 - openai._base_client - INFO - Retrying request to /chat/completions in 0.994676 seconds
[02:02:59.417] 2025-08-20 02:02:59,417 - openai._base_client - INFO - Retrying request to /chat/completions in 0.842463 seconds
[02:02:59.417] 2025-08-20 02:02:59,417 - openai._base_client - INFO - Retrying request to /chat/completions in 0.968653 seconds
[02:02:59.419] 2025-08-20 02:02:59,419 - openai._base_client - INFO - Retrying request to /chat/completions in 0.764667 seconds
[02:02:59.424] 2025-08-20 02:02:59,424 - openai._base_client - INFO - Retrying request to /chat/completions in 0.812156 seconds
[02:02:59.436] 2025-08-20 02:02:59,436 - openai._base_client - INFO - Retrying request to /chat/completions in 0.926378 seconds
[02:02:59.437] 2025-08-20 02:02:59,437 - openai._base_client - INFO - Retrying request to /chat/completions in 0.793386 seconds
[02:02:59.444] 2025-08-20 02:02:59,443 - openai._base_client - INFO - Retrying request to /chat/completions in 0.934556 seconds
[02:02:59.448] 2025-08-20 02:02:59,447 - openai._base_client - INFO - Retrying request to /chat/completions in 0.858880 seconds
[02:02:59.462] 2025-08-20 02:02:59,461 - openai._base_client - INFO - Retrying request to /chat/completions in 0.775195 seconds
[02:03:12.217] 2025-08-20 02:03:12,216 - openai._base_client - INFO - Retrying request to /chat/completions in 0.776468 seconds
[02:03:25.028] 2025-08-20 02:03:25,027 - openai._base_client - INFO - Retrying request to /chat/completions in 0.384348 seconds
[02:03:46.296] 2025-08-20 02:03:46,295 - openai._base_client - INFO - Retrying request to /chat/completions in 0.784581 seconds
[02:03:48.884] 2025-08-20 02:03:48,884 - openai._base_client - INFO - Retrying request to /chat/completions in 0.423805 seconds
[02:03:56.332] 2025-08-20 02:03:56,331 - openai._base_client - INFO - Retrying request to /chat/completions in 0.956838 seconds
[02:04:09.991] 2025-08-20 02:04:09,990 - openai._base_client - INFO - Retrying request to /chat/completions in 0.498096 seconds
[02:04:16.098] 2025-08-20 02:04:16,098 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:16.103]   [SEARCH] Query: data parser
[02:04:16.107] 
[02:04:16.107] [TURN 2/10]
[02:04:16.109] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:04:16.436] 2025-08-20 02:04:16,436 - openai._base_client - INFO - Retrying request to /chat/completions in 0.388468 seconds
[02:04:24.098] 2025-08-20 02:04:24,097 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:24.103]   [SEARCH] Query: file_operations_reader
[02:04:24.104] 
[02:04:24.104] [TURN 2/10]
[02:04:24.105] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:04:27.593] 2025-08-20 02:04:27,587 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:27.597]   [SEARCH] Query: file reader
[02:04:27.597] 
[02:04:27.597] [TURN 2/10]
[02:04:27.599] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:04:33.837] 2025-08-20 02:04:33,836 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:33.842]   [PARSE] Found tool call: file_operations_reader
[02:04:33.842]   [EXECUTING] file_operations_reader
[02:04:33.845]     Result: FAILED - PERMISSION_DENIED: Insufficient permissions (required permission: execute)
[02:04:33.845] 
[02:04:33.845] [TURN 3/10]
[02:04:33.847] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:04:34.757] 2025-08-20 02:04:34,756 - openai._base_client - INFO - Retrying request to /chat/completions in 0.914796 seconds
[02:04:38.368] 2025-08-20 02:04:38,368 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:04:38.369]   [PARSE] Found tool call: file_operations_reader
[02:04:38.369]   [EXECUTING] file_operations_reader
[02:04:38.369]     Result: FAILED - OPERATION_FAILED: Operation could not be completed
[02:04:38.369] 
[02:04:38.369] [TURN 3/10]
[02:04:38.371] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:04:38.404] 2025-08-20 02:04:38,403 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394449 seconds
[02:04:38.522] 2025-08-20 02:04:38,522 - openai._base_client - INFO - Retrying request to /chat/completions in 0.849883 seconds
[02:04:50.186] 2025-08-20 02:04:50,185 - openai._base_client - INFO - Retrying request to /chat/completions in 0.404605 seconds
[02:05:00.482] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.482] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.482]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.490] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:00.490] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:00.490] [AI_DEBUG] 生成的txt_content长度: 4791
[02:05:00.490] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:00.490]   - use_ai_classification=True
[02:05:00.490]   - ai_classifier=True
[02:05:00.490]   - txt_content_len=4791
[02:05:00.490]   - task_model=deepseek-r1-0528
[02:05:00.503] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.503] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.503]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.512] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.512] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.512]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.521] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.522] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.522]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.523] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.524] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.525]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.533] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.533] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.533]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.534] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.534] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.535]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.536] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.536] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.536]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.585] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.585] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.585]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.618] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.618] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.618]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.643] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.643] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.643]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.674] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.674] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.674]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.676] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.676] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.676]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.677] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.677] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.677]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.677] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.677] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.678]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.679] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:00.679] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:00.679]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.861] 2025-08-20 02:05:00,861 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:00.862] 2025-08-20 02:05:00,862 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:00.862] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:00.864] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:00.864] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:00.864] [AI_DEBUG] 生成的txt_content长度: 4179
[02:05:00.864] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:00.864]   - use_ai_classification=True
[02:05:00.864]   - ai_classifier=True
[02:05:00.864]   - txt_content_len=4179
[02:05:00.864]   - task_model=deepseek-r1-0528
[02:05:01.021] 2025-08-20 02:05:01,021 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.021] 2025-08-20 02:05:01,021 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.021] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.023] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.023] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.023] [AI_DEBUG] 生成的txt_content长度: 4160
[02:05:01.023] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.023]   - use_ai_classification=True
[02:05:01.023]   - ai_classifier=True
[02:05:01.023]   - txt_content_len=4160
[02:05:01.023]   - task_model=deepseek-r1-0528
[02:05:01.146] 2025-08-20 02:05:01,146 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.148] 2025-08-20 02:05:01,146 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.148] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.150] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.150] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.150] [AI_DEBUG] 生成的txt_content长度: 4469
[02:05:01.150] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.150]   - use_ai_classification=True
[02:05:01.150]   - ai_classifier=True
[02:05:01.150]   - txt_content_len=4469
[02:05:01.150]   - task_model=deepseek-r1-0528
[02:05:01.285] 2025-08-20 02:05:01,285 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.286] 2025-08-20 02:05:01,286 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.286] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.289] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.289] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.289] [AI_DEBUG] 生成的txt_content长度: 4627
[02:05:01.289] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.289]   - use_ai_classification=True
[02:05:01.289]   - ai_classifier=True
[02:05:01.289]   - txt_content_len=4627
[02:05:01.289]   - task_model=deepseek-r1-0528
[02:05:01.412] 2025-08-20 02:05:01,412 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.414] 2025-08-20 02:05:01,414 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.414] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.417] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.418] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.418] [AI_DEBUG] 生成的txt_content长度: 4430
[02:05:01.418] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.418]   - use_ai_classification=True
[02:05:01.418]   - ai_classifier=True
[02:05:01.418]   - txt_content_len=4430
[02:05:01.418]   - task_model=deepseek-r1-0528
[02:05:01.538] 2025-08-20 02:05:01,538 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.539] 2025-08-20 02:05:01,539 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.539] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.542] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.542] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.542] [AI_DEBUG] 生成的txt_content长度: 4154
[02:05:01.542] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.542]   - use_ai_classification=True
[02:05:01.542]   - ai_classifier=True
[02:05:01.542]   - txt_content_len=4154
[02:05:01.542]   - task_model=deepseek-r1-0528
[02:05:01.680] 2025-08-20 02:05:01,680 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.681] 2025-08-20 02:05:01,681 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.681] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.683] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.683] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.683] [AI_DEBUG] 生成的txt_content长度: 4511
[02:05:01.683] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.683]   - use_ai_classification=True
[02:05:01.683]   - ai_classifier=True
[02:05:01.683]   - txt_content_len=4511
[02:05:01.683]   - task_model=deepseek-r1-0528
[02:05:01.800] 2025-08-20 02:05:01,800 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.800] 2025-08-20 02:05:01,800 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.800] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.802] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.802] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.802] [AI_DEBUG] 生成的txt_content长度: 4719
[02:05:01.802] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.802]   - use_ai_classification=True
[02:05:01.802]   - ai_classifier=True
[02:05:01.802]   - txt_content_len=4719
[02:05:01.802]   - task_model=deepseek-r1-0528
[02:05:01.925] 2025-08-20 02:05:01,925 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:01.926] 2025-08-20 02:05:01,926 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:01.926] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:01.929] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:01.929] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:01.929] [AI_DEBUG] 生成的txt_content长度: 4253
[02:05:01.929] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:01.929]   - use_ai_classification=True
[02:05:01.929]   - ai_classifier=True
[02:05:01.929]   - txt_content_len=4253
[02:05:01.929]   - task_model=deepseek-r1-0528
[02:05:02.103] 2025-08-20 02:05:02,103 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.104] 2025-08-20 02:05:02,104 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.104] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:02.105] Progress: 10/30 (Success: 0)
[02:05:02.105] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:02.105] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:02.105] [AI_DEBUG] 生成的txt_content长度: 4438
[02:05:02.105] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:02.105]   - use_ai_classification=True
[02:05:02.105]   - ai_classifier=True
[02:05:02.105]   - txt_content_len=4438
[02:05:02.105]   - task_model=deepseek-r1-0528
[02:05:02.242] 2025-08-20 02:05:02,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.242] 2025-08-20 02:05:02,242 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.242] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:02.244] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:02.244] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:02.244] [AI_DEBUG] 生成的txt_content长度: 4511
[02:05:02.244] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:02.244]   - use_ai_classification=True
[02:05:02.244]   - ai_classifier=True
[02:05:02.244]   - txt_content_len=4511
[02:05:02.244]   - task_model=deepseek-r1-0528
[02:05:02.362] 2025-08-20 02:05:02,362 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.362] 2025-08-20 02:05:02,362 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.363] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:02.364] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:02.364] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:02.364] [AI_DEBUG] 生成的txt_content长度: 4636
[02:05:02.364] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:02.364]   - use_ai_classification=True
[02:05:02.364]   - ai_classifier=True
[02:05:02.364]   - txt_content_len=4636
[02:05:02.364]   - task_model=deepseek-r1-0528
[02:05:02.480] 2025-08-20 02:05:02,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.481] 2025-08-20 02:05:02,481 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.481] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:02.483] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:02.483] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:02.483] [AI_DEBUG] 生成的txt_content长度: 4454
[02:05:02.483] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:02.483]   - use_ai_classification=True
[02:05:02.483]   - ai_classifier=True
[02:05:02.483]   - txt_content_len=4454
[02:05:02.483]   - task_model=deepseek-r1-0528
[02:05:02.617] 2025-08-20 02:05:02,615 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.617] 2025-08-20 02:05:02,617 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.617] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:02.620] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:02.620] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:02.620] [AI_DEBUG] 生成的txt_content长度: 4446
[02:05:02.620] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:02.620]   - use_ai_classification=True
[02:05:02.620]   - ai_classifier=True
[02:05:02.620]   - txt_content_len=4446
[02:05:02.620]   - task_model=deepseek-r1-0528
[02:05:02.752] 2025-08-20 02:05:02,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.753] 2025-08-20 02:05:02,753 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.754] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:02.761] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:02.761] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:02.761] [AI_DEBUG] 生成的txt_content长度: 4647
[02:05:02.761] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:02.761]   - use_ai_classification=True
[02:05:02.761]   - ai_classifier=True
[02:05:02.761]   - txt_content_len=4647
[02:05:02.761]   - task_model=deepseek-r1-0528
[02:05:02.882] 2025-08-20 02:05:02,881 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:02.882] 2025-08-20 02:05:02,882 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:02.883] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:13.243] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:13.244] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:13.244]   [API_FAILURE] API failed (timeout or max retries)
[02:05:13.247] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:13.247] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:13.248] [AI_DEBUG] 生成的txt_content长度: 11646
[02:05:13.248] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:13.248]   - use_ai_classification=True
[02:05:13.248]   - ai_classifier=True
[02:05:13.248]   - txt_content_len=11646
[02:05:13.248]   - task_model=deepseek-r1-0528
[02:05:13.248] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:14.015] 2025-08-20 02:05:14,015 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[02:05:14.026]   [PARSE] Found tool call: network_fetcher
[02:05:14.026]   [EXECUTING] network_fetcher
[02:05:14.027]     Result: SUCCESS
[02:05:14.027] 
[02:05:14.027] [TURN 3/10]
[02:05:14.034] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[02:05:25.737] 2025-08-20 02:05:25,736 - openai._base_client - INFO - Retrying request to /chat/completions in 0.974025 seconds
[02:05:47.333] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:47.335] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:47.335]   [API_FAILURE] API failed (timeout or max retries)
[02:05:47.337] [DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[02:05:47.338] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:49.612] 2025-08-20 02:05:49,612 - openai._base_client - INFO - Retrying request to /chat/completions in 0.847985 seconds
[02:05:57.547] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:05:57.548] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:05:57.548]   [API_FAILURE] API failed (timeout or max retries)
[02:05:57.553] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:57.553] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:57.554] [AI_DEBUG] 生成的txt_content长度: 8653
[02:05:57.554] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:57.554]   - use_ai_classification=True
[02:05:57.554]   - ai_classifier=True
[02:05:57.554]   - txt_content_len=8653
[02:05:57.554]   - task_model=deepseek-r1-0528
[02:05:57.554] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:06:16.116] 2025-08-20 02:06:16,116 - openai._base_client - INFO - Retrying request to /chat/completions in 0.468885 seconds
[02:06:17.090] 2025-08-20 02:06:17,089 - openai._base_client - INFO - Retrying request to /chat/completions in 0.781131 seconds
[02:06:33.865] 2025-08-20 02:06:33,864 - openai._base_client - INFO - Retrying request to /chat/completions in 0.418424 seconds
[02:06:35.918] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:06:35.919] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:06:35.919]   [API_FAILURE] API failed (timeout or max retries)
[02:06:35.923] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:06:35.924] [AI_DEBUG] 测试失败，准备调用AI分类
[02:06:35.924] [AI_DEBUG] 生成的txt_content长度: 9159
[02:06:35.924] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:06:35.924]   - use_ai_classification=True
[02:06:35.924]   - ai_classifier=True
[02:06:35.924]   - txt_content_len=9159
[02:06:35.924]   - task_model=deepseek-r1-0528
[02:06:35.924] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:06:35.927] Progress: 20/30 (Success: 1)
[02:06:38.378] 2025-08-20 02:06:38,377 - openai._base_client - INFO - Retrying request to /chat/completions in 0.415919 seconds
[02:06:39.047] 2025-08-20 02:06:39,046 - openai._base_client - INFO - Retrying request to /chat/completions in 0.826308 seconds
[02:06:39.646] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:06:39.646] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:06:39.646]   [API_FAILURE] API failed (timeout or max retries)
[02:06:39.649] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:06:39.649] [AI_DEBUG] 测试失败，准备调用AI分类
[02:06:39.649] [AI_DEBUG] 生成的txt_content长度: 9232
[02:06:39.649] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:06:39.649]   - use_ai_classification=True
[02:06:39.649]   - ai_classifier=True
[02:06:39.649]   - txt_content_len=9232
[02:06:39.649]   - task_model=deepseek-r1-0528
[02:06:39.649] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:06:50.863] 2025-08-20 02:06:50,863 - openai._base_client - INFO - Retrying request to /chat/completions in 0.814715 seconds
[02:07:14.042] 2025-08-20 02:07:14,042 - openai._base_client - INFO - Retrying request to /chat/completions in 0.398980 seconds
[02:07:26.980] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:07:26.981] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:07:26.981]   [API_FAILURE] API failed (timeout or max retries)
[02:07:26.984] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:07:50.768] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:07:50.769] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:07:50.769]   [API_FAILURE] API failed (timeout or max retries)
[02:07:50.770] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:07:50.770] [AI_DEBUG] 测试失败，准备调用AI分类
[02:07:50.771] [AI_DEBUG] 生成的txt_content长度: 8680
[02:07:50.771] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:07:50.771]   - use_ai_classification=True
[02:07:50.771]   - ai_classifier=True
[02:07:50.771]   - txt_content_len=8680
[02:07:50.771]   - task_model=deepseek-r1-0528
[02:07:50.771] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:08:16.970] 2025-08-20 02:08:16,970 - openai._base_client - INFO - Retrying request to /chat/completions in 0.954444 seconds
[02:08:18.132] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:08:18.132] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:08:18.132]   [API_FAILURE] API failed (timeout or max retries)
[02:08:18.135] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:08:18.135] [AI_DEBUG] 测试失败，准备调用AI分类
[02:08:18.135] [AI_DEBUG] 生成的txt_content长度: 9042
[02:08:18.135] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:08:18.135]   - use_ai_classification=True
[02:08:18.135]   - ai_classifier=True
[02:08:18.135]   - txt_content_len=9042
[02:08:18.135]   - task_model=deepseek-r1-0528
[02:08:18.135] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:08:34.538] 2025-08-20 02:08:34,538 - openai._base_client - INFO - Retrying request to /chat/completions in 0.871002 seconds
[02:08:39.088] 2025-08-20 02:08:39,088 - openai._base_client - INFO - Retrying request to /chat/completions in 0.908113 seconds
[02:08:40.241] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:08:40.241] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:08:40.241]   [API_FAILURE] API failed (timeout or max retries)
[02:08:40.244] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:08:40.245] [AI_DEBUG] 测试失败，准备调用AI分类
[02:08:40.245] [AI_DEBUG] 生成的txt_content长度: 8206
[02:08:40.245] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:08:40.245]   - use_ai_classification=True
[02:08:40.245]   - ai_classifier=True
[02:08:40.245]   - txt_content_len=8206
[02:08:40.245]   - task_model=deepseek-r1-0528
[02:08:40.245] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:08:51.971] [LLM_ERROR] Attempt 1/5: Request timed out.
[02:08:51.979] [TIMEOUT] API call timed out after 120 seconds, not retrying
[02:08:51.979]   [API_FAILURE] API failed (timeout or max retries)
[02:08:51.992] [DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[02:08:51.993] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:08:57.387] 2025-08-20 02:08:57,386 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:57.402] 2025-08-20 02:08:57,402 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:57.402] 2025-08-20 02:08:57,402 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:08:57.405] 2025-08-20 02:08:57,405 - batch_test_runner - ERROR - Test timeout after 600 seconds (10 minutes)
[02:09:14.707] 2025-08-20 02:09:14,706 - openai._base_client - INFO - Retrying request to /chat/completions in 0.785583 seconds
