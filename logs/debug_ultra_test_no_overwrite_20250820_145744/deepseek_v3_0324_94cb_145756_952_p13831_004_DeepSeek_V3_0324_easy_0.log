===== 分片 DeepSeek-V3-0324_easy_0 =====
时间: 2025-08-20T14:57:56.960726
模型: deepseek-v3-0324
实例: DeepSeek-V3-0324
命令: python -u smart_batch_runner.py --model deepseek-v3-0324 --deployment DeepSeek-V3-0324 --prompt-types baseline --difficulty easy --task-types simple_task --num-instances 1 --max-workers 2 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --adaptive
环境变量:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[14:57:58.494] 2025-08-20 14:57:58,494 - faiss.loader - INFO - Loading faiss.
[14:57:58.507] 2025-08-20 14:57:58,507 - faiss.loader - INFO - Successfully loaded faiss.
[14:57:59.021] [INFO] 使用JSON存储格式
[14:57:59.021] [INFO] 使用JSON存储格式
[14:57:59.347] [INFO] 使用JSON存储格式
[14:57:59.348] [INFO] 使用JSON存储格式
[14:57:59.349] 
[14:57:59.349] ============================================================
[14:57:59.349] 智能批测试: deepseek-v3-0324 (idealab)
[14:57:59.349] Prompt types: ['baseline']
[14:57:59.349] 难度: easy
[14:57:59.349] 目标: 每种配置 1 个实例
[14:57:59.349] ============================================================
[14:57:59.349] ○ simple_task         :   0/  1 已完成 (需要补充 1 个)
[14:57:59.349] 
[14:57:59.349] ⏳ 需要运行 1 个新测试
[14:57:59.349] 
[14:57:59.349] ▶ 准备 simple_task (1 个实例)...
[14:57:59.349] 
[14:57:59.349] ▶ 开始执行 1 个测试...
[14:57:59.349] 📦 批量提交模式：每20个测试保存一次
[14:57:59.349] 🚀 检测到Azure API，使用超高并发: workers=100, qps=200.0
[14:57:59.350] 2025-08-20 14:57:59,350 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[14:57:59.455] 2025-08-20 14:57:59,455 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:57:59.456] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x16ca6ae70>
[14:57:59.456] 2025-08-20 14:57:59,455 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[14:57:59.456] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - ============================================================
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - Batch test runner initialized
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=True
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_145759.log
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - ============================================================
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - Running 1 tests with adaptive rate limiting
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - Initial settings: workers=100, QPS=200.0
[14:57:59.456] 2025-08-20 14:57:59,456 - batch_test_runner - INFO - Initializing test components...
[14:57:59.739] 2025-08-20 14:57:59,739 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[14:57:59.739] 2025-08-20 14:57:59,739 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[14:57:59.739] 2025-08-20 14:57:59,739 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[14:57:59.739] [DEBUG] Creating new ToolCapabilityManager instance
[14:57:59.739] [OperationEmbeddingIndex] Initializing with unified API client manager
[14:57:59.739] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[14:57:59.741] 2025-08-20 14:57:59,741 - api_client_manager - INFO - Loaded configuration from config/config.json
[14:57:59.748] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[14:57:59.748] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[14:57:59.748] [OperationEmbeddingIndex] Detecting actual embedding dimension...
