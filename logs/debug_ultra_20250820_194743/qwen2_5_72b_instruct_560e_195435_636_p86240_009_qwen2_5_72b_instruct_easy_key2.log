===== 分片 qwen2.5-72b-instruct_easy_key2 =====
时间: 2025-08-20T19:54:35.637604
模型: qwen2.5-72b-instruct
实例: qwen-key2
命令: python -u smart_batch_runner.py --model qwen2.5-72b-instruct --deployment qwen-key2 --prompt-types optimal --difficulty easy --task-types all --num-instances 1 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[19:54:37.263] 2025-08-20 19:54:37,263 - faiss.loader - INFO - Loading faiss.
[19:54:37.278] 2025-08-20 19:54:37,278 - faiss.loader - INFO - Successfully loaded faiss.
[19:54:38.099] [INFO] 使用Parquet存储格式
[19:54:38.461] [INFO] 使用Parquet存储格式
[19:54:38.464] [INFO] 使用PARQUET存储格式
[19:54:38.464] 
[19:54:38.464] ============================================================
[19:54:38.464] 智能批测试: qwen2.5-72b-instruct (idealab)
[19:54:38.464] Prompt types: ['optimal']
[19:54:38.464] 难度: easy
[19:54:38.464] 目标: 每种配置 1 个实例
[19:54:38.464] ============================================================
[19:54:38.493] ○ simple_task         :   0/  1 已完成 (需要补充 1 个)
[19:54:38.498] ○ basic_task          :   0/  1 已完成 (需要补充 1 个)
[19:54:38.503] ○ data_pipeline       :   0/  1 已完成 (需要补充 1 个)
[19:54:38.509] ○ api_integration     :   0/  1 已完成 (需要补充 1 个)
[19:54:38.513] ○ multi_stage_pipeline:   0/  1 已完成 (需要补充 1 个)
[19:54:38.513] 
[19:54:38.513] ⏳ 需要运行 5 个新测试
[19:54:38.513] 
[19:54:38.513] ▶ 准备 simple_task (1 个实例)...
[19:54:38.513] 
[19:54:38.513] ▶ 准备 basic_task (1 个实例)...
[19:54:38.513] 
[19:54:38.513] ▶ 准备 data_pipeline (1 个实例)...
[19:54:38.513] 
[19:54:38.513] ▶ 准备 api_integration (1 个实例)...
[19:54:38.513] 
[19:54:38.513] ▶ 准备 multi_stage_pipeline (1 个实例)...
[19:54:38.513] 
[19:54:38.513] ▶ 开始执行 5 个测试...
[19:54:38.513] 📦 批量提交模式：每20个测试保存一次
[19:54:38.513] ⚠️  检测到idealab API，调整并发: workers=3, qps=5.0
[19:54:38.515] 2025-08-20 19:54:38,515 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[19:54:38.572] 2025-08-20 19:54:38,572 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[19:54:38.572] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x16a286390>
[19:54:38.572] 2025-08-20 19:54:38,572 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[19:54:38.572] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[19:54:38.573] 2025-08-20 19:54:38,573 - batch_test_runner - INFO - ============================================================
[19:54:38.573] 2025-08-20 19:54:38,573 - batch_test_runner - INFO - Batch test runner initialized
[19:54:38.573] 2025-08-20 19:54:38,573 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[19:54:38.574] 2025-08-20 19:54:38,574 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_195438.log
[19:54:38.574] 2025-08-20 19:54:38,574 - batch_test_runner - INFO - ============================================================
[19:54:38.574] 2025-08-20 19:54:38,574 - batch_test_runner - INFO - Running 5 tests with 3 workers, QPS limit: 5.0
[19:54:38.574] 2025-08-20 19:54:38,574 - batch_test_runner - INFO - Initializing test components...
[19:54:38.905] 2025-08-20 19:54:38,905 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[19:54:38.905] 2025-08-20 19:54:38,905 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[19:54:38.905] 2025-08-20 19:54:38,905 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[19:54:38.905] [DEBUG] Creating new ToolCapabilityManager instance
[19:54:38.905] [OperationEmbeddingIndex] Initializing with unified API client manager
[19:54:38.905] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[19:54:38.906] 2025-08-20 19:54:38,906 - api_client_manager - INFO - Loaded configuration from config/config.json
[19:54:38.912] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[19:54:38.912] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[19:54:38.912] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[19:54:39.789] 2025-08-20 19:54:39,788 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[19:54:39.792] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[19:54:39.855] [INFO] Loaded 4150 embeddings from persistent cache
[19:54:39.855] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[19:54:39.856] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[19:54:39.856] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[19:54:39.856] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[19:54:39.860] [INFO] Successfully loaded FAISS index with dimension 3072
[19:54:39.860] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[19:54:39.860] [INFO] Loaded 15 operations with dimension 3072
[19:54:39.860] [INFO] Successfully loaded cached index
[19:54:39.860] [INFO] Operation semantic index initialized
[19:54:39.860] [INFO] Using device: cpu
[19:54:39.861] [INFO] Initialized tool success tracking attributes
[19:54:39.861] [INFO] Initializing embedding manager for enhanced tool selection
[19:54:39.861] [MCPEmbeddingManager] Creating new singleton instance
[19:54:39.861] [MCPEmbeddingManager] Initializing with unified API client manager
[19:54:39.869] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[19:54:39.869] [MCPEmbeddingManager] Client initialized successfully
[19:54:39.869] 2025-08-20 19:54:39,869 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[19:54:39.999] 2025-08-20 19:54:39,999 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[19:54:40.241] 2025-08-20 19:54:40,241 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[19:54:40.241] 2025-08-20 19:54:40,241 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[19:54:40.264] 2025-08-20 19:54:40,264 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[19:54:40.324] 2025-08-20 19:54:40,324 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[19:54:40.653] 2025-08-20 19:54:40,653 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[19:54:40.653] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[19:54:40.653] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[19:54:40.653] 2025-08-20 19:54:40,653 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[19:54:40.982] 2025-08-20 19:54:40,982 - mcp_embedding_manager - INFO - FAISS index loaded
[19:54:40.983] 2025-08-20 19:54:40,982 - mcp_embedding_manager - INFO - Updated dimension to 3072
[19:54:40.983] 2025-08-20 19:54:40,982 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[19:54:40.985] [SUCCESS] Loaded 30 tool embeddings
[19:54:40.985] 2025-08-20 19:54:40,985 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[19:54:40.985] [SUCCESS] Embedding manager initialized with 30 tools
[19:54:40.985] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[19:54:40.985] [INFO] Loading full MCP protocol registry...
[19:54:40.985] 2025-08-20 19:54:40,985 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[19:54:40.985] [INFO] Loaded full tool registry with 30 tools
[19:54:40.985] 2025-08-20 19:54:40,985 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[19:54:40.985] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[19:54:40.986] [INFO] Embedding manager ready with 30 tools
[19:54:40.986] [WARNING] Embedding manager exists but has no embeddings
[19:54:40.986] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[19:54:40.986] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[19:54:40.986] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[19:54:40.986] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[19:54:40.986] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[19:54:40.986] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[19:54:40.986] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[19:54:40.986] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[19:54:40.986] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[19:54:40.986] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[19:54:40.986] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[19:54:40.986] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[19:54:40.986] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[19:54:40.986] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[19:54:40.986] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[19:54:40.986] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[19:54:40.986] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[19:54:40.986] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[19:54:40.986] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[19:54:40.986] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[19:54:40.986] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[19:54:40.986] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[19:54:40.986] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[19:54:40.986] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[19:54:40.986] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[19:54:40.986] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[19:54:40.986] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[19:54:40.986] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[19:54:40.986] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[19:54:40.986] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[19:54:40.986] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[19:54:40.986] 2025-08-20 19:54:40,986 - mdp_workflow_generator - INFO - Loaded 30 tools
[19:54:40.986] [INFO] Setting default state_dim based on loaded tools
[19:54:40.986] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[19:54:40.986] 2025-08-20 19:54:40,986 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[19:54:40.986] [INFO] Setting default action_dim based on loaded tools
[19:54:40.986] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[19:54:40.986] 2025-08-20 19:54:40,986 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[19:54:40.986] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[19:54:40.986] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[19:54:40.986] [INFO] ⚡ Will use pre-generated workflows or random policy
[19:54:40.986] 2025-08-20 19:54:40,986 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[19:54:40.986] [INFO] Initializing TaskManager...
[19:54:41.921] 2025-08-20 19:54:41,921 - unified_training_manager - INFO - Using device: cpu
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO - Task filtering results:
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO -   Total: 5040 -> 5040
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO -   simple_task: 320 -> 320
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[19:54:42.023] 2025-08-20 19:54:42,023 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[19:54:42.025] 2025-08-20 19:54:42,025 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[19:54:42.025] [TaskManager] Difficulty level 'easy': 1096 tasks
[19:54:42.025] [TaskManager] Difficulty level 'very_easy': 856 tasks
[19:54:42.025] [TaskManager] Difficulty level 'medium': 1136 tasks
[19:54:42.025] [TaskManager] Difficulty level 'hard': 1096 tasks
[19:54:42.025] [TaskManager] Difficulty level 'very_hard': 856 tasks
[19:54:42.027] [INFO] TaskManager initialized with 5040 tasks
[19:54:42.027] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[19:54:42.027] [INFO] Initializing ToolCallVerifier...
[19:54:42.028] [INFO] ToolCallVerifier initialized with 30 tools
[19:54:42.028] [INFO] Output tools identified: 1
[19:54:42.028] [INFO] Component initialization status:
[19:54:42.028]   - embedding_manager: initialized
[19:54:42.028]   - task_manager: initialized
[19:54:42.028]   - output_verifier: initialized
[19:54:42.028]   - tool_capability_manager: initialized
[19:54:42.028]   - tool_success_rates: initialized with 0 entries
[19:54:42.028] [INFO] MDPWorkflowGenerator initialization complete
[19:54:42.028] 2025-08-20 19:54:42,028 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[19:54:42.028] 2025-08-20 19:54:42,028 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[19:54:42.028] 2025-08-20 19:54:42,028 - batch_test_runner - INFO -   - task_manager: ✓
[19:54:42.028] 2025-08-20 19:54:42,028 - batch_test_runner - INFO -   - output_verifier: ✓
[19:54:42.028] 2025-08-20 19:54:42,028 - batch_test_runner - INFO -   - embedding_manager: ✓
[19:54:42.028] 2025-08-20 19:54:42,028 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[19:54:42.028] 2025-08-20 19:54:42,028 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[19:54:42.028] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.028] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.028] [FlawedWorkflowGenerator] Initialized with 30 tools
[19:54:42.028] [FlawedWorkflowGenerator] RAG support: disabled
[19:54:42.029] DEBUG: Checking generator attributes
[19:54:42.029]   - has tool_capabilities: True
[19:54:42.029]   - has tool_capability_manager: True
[19:54:42.029]   - has task_manager: True
[19:54:42.029] [INFO] Loaded 30 tools from generator
[19:54:42.029] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[19:54:42.029] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.029] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.029] [INFO] Initializing LLM client using APIClientManager
[19:54:42.035] [INFO] Using Azure OpenAI client
[19:54:42.035] [DEBUG] Checking if generator has tool_capability_manager attribute
[19:54:42.035] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[19:54:42.035] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.035] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.035] [FlawedWorkflowGenerator] Initialized with 30 tools
[19:54:42.035] [FlawedWorkflowGenerator] RAG support: enabled
[19:54:42.035] [INFO] FlawedWorkflowGenerator initialized successfully
[19:54:42.035] [INFO] Initializing StableScorer for Phase 2 scoring
[19:54:42.035] <tool_capability_manager.ToolCapabilityManager object at 0x16a2c6a80>
[19:54:42.035] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.035] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.035] [INFO] Loaded tool success history for 0 tools
[19:54:42.035] [INFO] StableScorer initialized with semantic capability
[19:54:42.035] [INFO] StableScorer initialized successfully
[19:54:42.035] [INFO] Loading task instances...
[19:54:42.035] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[19:54:42.041] [INFO] Loaded 630 task instances
[19:54:42.041] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[19:54:42.041] 2025-08-20 19:54:42,041 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[19:54:42.041] 2025-08-20 19:54:42,041 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[19:54:42.338] 2025-08-20 19:54:42,338 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[19:54:42.338] 2025-08-20 19:54:42,338 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[19:54:42.354] 2025-08-20 19:54:42,353 - batch_test_runner - INFO - Initialization complete
[19:54:42.377] 2025-08-20 19:54:42,377 - batch_test_runner - INFO - Starting batch test with 5 tasks, 3 workers
[19:54:42.377] 2025-08-20 19:54:42,377 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[19:54:42.378] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[19:54:42.380] 2025-08-20 19:54:42,380 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
[19:54:42.387] 2025-08-20 19:54:42,387 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[19:54:42.387] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[19:54:42.387] [InteractiveExecutor] Using prompt type: optimal for API key selection
[19:54:42.388] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[19:54:42.388] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.388] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.388] 2025-08-20 19:54:42,388 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[19:54:42.692] 2025-08-20 19:54:42,692 - mcp_embedding_manager - INFO - FAISS index loaded
[19:54:42.694] 2025-08-20 19:54:42,692 - mcp_embedding_manager - INFO - Updated dimension to 3072
[19:54:42.694] 2025-08-20 19:54:42,692 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[19:54:42.695] [INFO] Tool embedding index loaded successfully
[19:54:42.695] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[19:54:42.699] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[19:54:42.700] [INFO] Operation semantic index initialized
[19:54:42.701] 
[19:54:42.701] [TURN 1/10]
[19:54:42.702] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:42.716] 2025-08-20 19:54:42,716 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[19:54:42.717] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[19:54:42.717] [InteractiveExecutor] Using prompt type: optimal for API key selection
[19:54:42.717] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[19:54:42.717] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.717] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.717] 2025-08-20 19:54:42,717 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[19:54:42.747] 2025-08-20 19:54:42,747 - mcp_embedding_manager - INFO - FAISS index loaded
[19:54:42.747] 2025-08-20 19:54:42,747 - mcp_embedding_manager - INFO - Updated dimension to 3072
[19:54:42.747] 2025-08-20 19:54:42,747 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[19:54:42.749] [INFO] Tool embedding index loaded successfully
[19:54:42.751] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[19:54:42.751] [INFO] Operation semantic index initialized
[19:54:42.751] 
[19:54:42.751] [TURN 1/10]
[19:54:42.752] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:42.869] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[19:54:42.876] 2025-08-20 19:54:42,876 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[19:54:42.876] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[19:54:42.876] [InteractiveExecutor] Using prompt type: optimal for API key selection
[19:54:42.876] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[19:54:42.876] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:42.876] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:42.876] 2025-08-20 19:54:42,876 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[19:54:42.894] 2025-08-20 19:54:42,894 - mcp_embedding_manager - INFO - FAISS index loaded
[19:54:42.894] 2025-08-20 19:54:42,894 - mcp_embedding_manager - INFO - Updated dimension to 3072
[19:54:42.894] 2025-08-20 19:54:42,894 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[19:54:42.897] [INFO] Tool embedding index loaded successfully
[19:54:42.897] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[19:54:42.897] [INFO] Operation semantic index initialized
[19:54:42.898] 
[19:54:42.898] [TURN 1/10]
[19:54:42.898] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:43.681] 2025-08-20 19:54:43,681 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:43.682] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"33b9211c-79da-9514-b438-c50362f89160"}, traceId: 213e06a117557448834418634e88e8'}
[19:54:43.682] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[19:54:44.059] 2025-08-20 19:54:44,058 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:44.060]   [SEARCH] Query: file reader
[19:54:44.061] 
[19:54:44.061] [TURN 2/10]
[19:54:44.079] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:44.212] 2025-08-20 19:54:44,212 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:44.217]   [SEARCH] Query: data validation parser
[19:54:44.217] 
[19:54:44.217] [TURN 2/10]
[19:54:44.217] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:44.456] 2025-08-20 19:54:44,456 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:44.457] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fdaf3b9f-c869-9642-ac38-5b17838776f6"}, traceId: 213e066c17557448841885202e7ada'}
[19:54:44.457] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[19:54:44.629] 2025-08-20 19:54:44,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:44.629] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3dfdc646-7d03-9b93-b78c-48fad170db7a"}, traceId: 213e04ea17557448843345813e3380'}
[19:54:44.629] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[19:54:44.746] 2025-08-20 19:54:44,745 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:44.747] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"881e77ad-249d-9c13-80c2-0914d28b0205"}, traceId: 213e06a117557448844458643e88e8'}
[19:54:44.747] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[19:54:45.688] 2025-08-20 19:54:45,688 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:45.691] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ba6b2d8-a2d1-9150-b2c7-379e17874c42"}, traceId: 213e04ea17557448854145815e3380'}
[19:54:45.691] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[19:54:46.098] 2025-08-20 19:54:46,098 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:46.098] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7fd7f52-7cb6-9ee2-b3dc-3bad75a3780a"}, traceId: 213e066c17557448858595216e7ada'}
[19:54:46.098] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[19:54:47.193] 2025-08-20 19:54:47,193 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:47.198] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e9b2c34-f4e7-97fb-a662-4aef91b9d2ca"}, traceId: 213e06a117557448869198680e88e8'}
[19:54:47.198] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[19:54:47.870] 2025-08-20 19:54:47,870 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:47.871] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dfad64e8-9969-9dd5-9d16-141b5efd91ef"}, traceId: 213e04ea17557448876345819e3380'}
[19:54:47.871] [RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[19:54:48.135] 2025-08-20 19:54:48,135 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:48.136]   [EARLY_EXIT] No actions taken, continuing...
[19:54:48.136] 
[19:54:48.136] [TURN 3/10]
[19:54:48.142] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:48.501] 2025-08-20 19:54:48,501 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:48.502] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"442ad814-82ae-9407-84ec-675f1d94c131"}, traceId: 213e066c17557448882525231e7ada'}
[19:54:48.502] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[19:54:50.121] 2025-08-20 19:54:50,121 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:50.122] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"feb5bfd6-3600-9a91-975c-a8c3d9b0f1c5"}, traceId: 213e06a117557448898838714e88e8'}
[19:54:50.122] [RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[19:54:50.646] 2025-08-20 19:54:50,645 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:50.648] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5df2494e-eb5e-9d73-9d23-cdc31b7356c6"}, traceId: 213e04ea17557448903665828e3380'}
[19:54:50.648] [RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[19:54:50.880] 2025-08-20 19:54:50,879 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:50.881]   [EARLY_EXIT] No actions taken, continuing...
[19:54:50.881] 
[19:54:50.881] [TURN 4/10]
[19:54:50.882] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:52.030] 2025-08-20 19:54:52,028 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:52.033]   [EARLY_EXIT] No actions taken, continuing...
[19:54:52.033] 
[19:54:52.033] [TURN 5/10]
[19:54:52.034] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:52.968] 2025-08-20 19:54:52,966 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:52.969]   [EARLY_EXIT] No actions taken, continuing...
[19:54:52.969] 
[19:54:52.969] [TURN 6/10]
[19:54:52.970] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:53.610] 2025-08-20 19:54:53,608 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:53.611]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[19:54:53.612] 
[19:54:53.612] [TURN 7/10]
[19:54:53.613] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:54.008] 2025-08-20 19:54:54,007 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:54.009] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a1fc06e-45df-9b1f-8092-be6bacc37405"}, traceId: 213e066c17557448937235261e7ada'}
[19:54:54.009] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[19:54:54.953] 2025-08-20 19:54:54,953 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:54.954]   [SEARCH] Query: file reader json
[19:54:54.955] 
[19:54:54.955] [TURN 2/10]
[19:54:54.955] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:55.134] 2025-08-20 19:54:55,134 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:55.135] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3685cae3-793a-9ecb-9f11-d8f3ce476be5"}, traceId: 213e066c17557448948305267e7ada'}
[19:54:55.135] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[19:54:55.874] 2025-08-20 19:54:55,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:55.875]   [EARLY_EXIT] No actions taken, continuing...
[19:54:55.875] 
[19:54:55.875] [TURN 3/10]
[19:54:55.875] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:55.961] 2025-08-20 19:54:55,961 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:55.965] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3bb8c39f-0971-9af7-b91a-66434378df35"}, traceId: 213e04ea17557448957315846e3380'}
[19:54:55.965] [ERROR] Max retries reached after 5 attempts
[19:54:55.965] [API_FAILURE] All retries exhausted
[19:54:55.965]   [API_FAILURE] API failed (timeout or max retries)
[19:54:55.967] [DEBUG] Got result for task: has_result=True, save_logs=True
[19:54:55.967] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[19:54:55.967] [AI_DEBUG] 生成的txt_content长度: 8539
[19:54:55.967] [AI_DEBUG] _ai_classify_with_txt_content called:
[19:54:55.968]   - use_ai_classification=True
[19:54:55.968] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[19:54:55.968]   - ai_classifier=True
[19:54:55.968]   - txt_content_len=8539
[19:54:55.968]   - task_model=qwen2.5-72b-instruct
[19:54:55.968] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[19:54:55.980] 2025-08-20 19:54:55,980 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[19:54:55.980] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[19:54:55.980] [InteractiveExecutor] Using prompt type: optimal for API key selection
[19:54:55.981] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[19:54:55.981] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:54:55.981] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:54:55.981] 2025-08-20 19:54:55,981 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[19:54:56.006] 2025-08-20 19:54:56,006 - mcp_embedding_manager - INFO - FAISS index loaded
[19:54:56.006] 2025-08-20 19:54:56,006 - mcp_embedding_manager - INFO - Updated dimension to 3072
[19:54:56.006] 2025-08-20 19:54:56,006 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[19:54:56.009] [INFO] Tool embedding index loaded successfully
[19:54:56.010] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[19:54:56.010] [INFO] Operation semantic index initialized
[19:54:56.010] 
[19:54:56.010] [TURN 1/10]
[19:54:56.010] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:56.804] 2025-08-20 19:54:56,804 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:54:56.805]   [EARLY_EXIT] No actions taken, continuing...
[19:54:56.805] 
[19:54:56.805] [TURN 4/10]
[19:54:56.805] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:54:56.843] 2025-08-20 19:54:56,843 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:56.843] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9e77ea67-1511-9004-9bca-f1bd99e1d25a"}, traceId: 213e066c17557448965607156e7b3d'}
[19:54:56.843] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[19:54:57.200] 2025-08-20 19:54:57,200 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:57.200] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b2711723-baea-9a0b-a698-c13d742f640e"}, traceId: 213e06a117557448969238797e88e8'}
[19:54:57.200] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[19:54:57.777] 2025-08-20 19:54:57,777 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:57.778] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"363ccb62-0d3e-92e0-aa0b-1ed035550cd7"}, traceId: 213e066c17557448974995273e7ada'}
[19:54:57.778] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[19:54:58.085] 2025-08-20 19:54:58,083 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:58.085] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63e81ce7-78e8-9c6b-bdcd-4a6bd9b5f65c"}, traceId: 213e066c17557448978017169e7b3d'}
[19:54:58.085] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[19:54:58.531] 2025-08-20 19:54:58,531 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:58.532] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.AllocationQuota","message":"Allocated quota exceeded, please increase your quota limit.","request_id":"6cc9da86-09f8-9012-8e8d-74449a36fecd"}, traceId: 213e06a117557448982998840e88e8'}
[19:54:58.532] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[19:54:59.631] 2025-08-20 19:54:59,630 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:54:59.632] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.AllocationQuota","message":"Allocated quota exceeded, please increase your quota limit.","request_id":"9eb0bbf7-1baf-9c98-b873-7b71599325c5"}, traceId: 213e066c17557448992397186e7b3d'}
[19:54:59.632] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[19:55:00.436] 2025-08-20 19:55:00,436 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:00.436] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a13a76a-1673-95f2-976a-a76981249632"}, traceId: 213e066c17557449001495297e7ada'}
[19:55:00.436] [RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[19:55:01.060] 2025-08-20 19:55:01,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:01.060]   [EARLY_EXIT] No actions taken, continuing...
[19:55:01.060] 
[19:55:01.060] [TURN 5/10]
[19:55:01.061] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:01.996] 2025-08-20 19:55:01,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:01.998]   [EARLY_EXIT] No actions taken, continuing...
[19:55:01.998] 
[19:55:01.998] [TURN 6/10]
[19:55:01.999] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:02.060] 2025-08-20 19:55:02,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:02.062] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d8a8620b-3b05-92c1-87ec-34c869dd012a"}, traceId: 213e066c17557449018027217e7b3d'}
[19:55:02.063] [RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[19:55:02.492] 2025-08-20 19:55:02,492 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[19:55:02.497] [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[19:55:03.171] 2025-08-20 19:55:03,171 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:03.172]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[19:55:03.172] 
[19:55:03.172] [TURN 7/10]
[19:55:03.174] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:03.578] 2025-08-20 19:55:03,578 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:03.579] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc3840eb-1091-9af6-9e21-32c1f68467f2"}, traceId: 213e06a117557449032948994e88e8'}
[19:55:03.579] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[19:55:03.976] 2025-08-20 19:55:03,976 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:03.976] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24fb68a6-d5b4-9e68-8a64-4129992f4312"}, traceId: 213e066c17557449036905316e7ada'}
[19:55:03.976] [ERROR] Max retries reached after 5 attempts
[19:55:03.976] [API_FAILURE] All retries exhausted
[19:55:03.976]   [API_FAILURE] API failed (timeout or max retries)
[19:55:03.976] [ASSISTED] Task received 1 format helps, final result: failure
[19:55:03.977] [DEBUG] Got result for task: has_result=True, save_logs=True
[19:55:03.977] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[19:55:03.977] [AI_DEBUG] 生成的txt_content长度: 10260
[19:55:03.977] [AI_DEBUG] _ai_classify_with_txt_content called:
[19:55:03.977]   - use_ai_classification=True
[19:55:03.977]   - ai_classifier=True
[19:55:03.977]   - txt_content_len=10260
[19:55:03.977]   - task_model=qwen2.5-72b-instruct
[19:55:03.977] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[19:55:03.978] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[19:55:03.985] 2025-08-20 19:55:03,985 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[19:55:03.985] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[19:55:03.985] [InteractiveExecutor] Using prompt type: optimal for API key selection
[19:55:03.985] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[19:55:03.985] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13197497968)
[19:55:03.985] [MCPEmbeddingManager] Current cache size: 30 embeddings
[19:55:03.985] 2025-08-20 19:55:03,985 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[19:55:04.005] 2025-08-20 19:55:04,005 - mcp_embedding_manager - INFO - FAISS index loaded
[19:55:04.005] 2025-08-20 19:55:04,005 - mcp_embedding_manager - INFO - Updated dimension to 3072
[19:55:04.005] 2025-08-20 19:55:04,005 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[19:55:04.007] [INFO] Tool embedding index loaded successfully
[19:55:04.008] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[19:55:04.008] [INFO] Operation semantic index initialized
[19:55:04.008] 
[19:55:04.008] [TURN 1/10]
[19:55:04.008] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:04.848] 2025-08-20 19:55:04,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:04.848] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c983b183-e433-9ca8-85d2-2fe1f9a5b993"}, traceId: 213e007017557449045682675eead5'}
[19:55:04.849] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[19:55:06.031] 2025-08-20 19:55:06,031 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:06.031]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[19:55:06.031] 
[19:55:06.031] [TURN 8/10]
[19:55:06.032] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:06.611] 2025-08-20 19:55:06,611 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:06.611] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b707c0ec-7574-95e0-bfc5-53e86dbd67f2"}, traceId: 213e066c17557449063847228e7b3d'}
[19:55:06.611] [ERROR] Max retries reached after 5 attempts
[19:55:06.611] [API_FAILURE] All retries exhausted
[19:55:06.611]   [API_FAILURE] API failed (timeout or max retries)
[19:55:06.651] 2025-08-20 19:55:06,651 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:06.651] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a9364fd-37c7-99dd-a239-deb288adb407"}, traceId: 213e007017557449063652706eead5'}
[19:55:06.651] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[19:55:06.900] 2025-08-20 19:55:06,900 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:06.901]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[19:55:06.902] 
[19:55:06.902] [TURN 9/10]
[19:55:06.904] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:08.034] 2025-08-20 19:55:08,034 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:08.035]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[19:55:08.035] 
[19:55:08.035] [TURN 10/10]
[19:55:08.037] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:08.385] 2025-08-20 19:55:08,385 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:08.388] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7344eb67-e0ec-9c82-8b90-5373031c9437"}, traceId: 213e06a117557449081591092e88e8'}
[19:55:08.388] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[19:55:08.941] 2025-08-20 19:55:08,940 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:08.942] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a35c3f9d-e5e3-9377-8af9-a9c09b9d9597"}, traceId: 213e007017557449086732726eead5'}
[19:55:08.942] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[19:55:10.185] 2025-08-20 19:55:10,185 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:10.185] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"57c31533-1192-9d15-9e61-6ba524615461"}, traceId: 213e06a117557449098881100e88e8'}
[19:55:10.185] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[19:55:12.444] 2025-08-20 19:55:12,443 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:12.444] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b0440ea-b888-9552-bfa6-d05121acb902"}, traceId: 213e06a117557449121611107e88e8'}
[19:55:12.444] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[19:55:12.891] 2025-08-20 19:55:12,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:12.891]   [SEARCH] Query: file reader
[19:55:12.892] 
[19:55:12.892] [TURN 2/10]
[19:55:12.892] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[19:55:13.289] 2025-08-20 19:55:13,288 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:13.290] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.AllocationQuota","message":"Allocated quota exceeded, please increase your quota limit.","request_id":"62b16eed-d21f-939a-8d38-78e1f3ebde27"}, traceId: 213e007017557449130102788eead5'}
[19:55:13.290] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[19:55:14.696] 2025-08-20 19:55:14,694 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:14.697] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.AllocationQuota","message":"Allocated quota exceeded, please increase your quota limit.","request_id":"a5abec9b-ed93-9f66-ba85-2aec7ba05acb"}, traceId: 213e007017557449144332808eead5'}
[19:55:14.697] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[19:55:14.847] 2025-08-20 19:55:14,846 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[19:55:14.848] [AI_DEBUG] AI分类结果: category=max_turns_errors, confidence=0.72
[19:55:14.853] [DEBUG] Got result for task: has_result=True, save_logs=True
[19:55:14.853] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[19:55:14.853] [AI_DEBUG] 生成的txt_content长度: 4161
[19:55:14.853] [AI_DEBUG] _ai_classify_with_txt_content called:
[19:55:14.853]   - use_ai_classification=True
[19:55:14.853]   - ai_classifier=True
[19:55:14.854]   - txt_content_len=4161
[19:55:14.854]   - task_model=qwen2.5-72b-instruct
[19:55:14.854] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[19:55:15.053] 2025-08-20 19:55:15,053 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:15.054] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d7f43a2-328b-93f4-b404-180fcfa23073"}, traceId: 213e06a117557449147531115e88e8'}
[19:55:15.054] [RETRY] 400 error detected, waiting 5.1s before retry (not counting as turn)...
[19:55:16.257] 2025-08-20 19:55:16,257 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:16.257] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.AllocationQuota","message":"Allocated quota exceeded, please increase your quota limit.","request_id":"081df8dd-7698-9df8-9c74-ed94d1234962"}, traceId: 213e007017557449159762830eead5'}
[19:55:16.257] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[19:55:17.886] 2025-08-20 19:55:17,886 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:17.888] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"be90b421-e2fe-949b-b335-fede784c9643"}, traceId: 213e007017557449176612848eead5'}
[19:55:17.888] [RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[19:55:21.722] 2025-08-20 19:55:21,722 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[19:55:21.723]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[19:55:21.723] [ASSISTED] Task received 5 format helps, final result: failure
[19:55:23.707] 2025-08-20 19:55:23,706 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[19:55:23.708] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"84a21a0f-780f-952b-9d18-44915e5ee3a7"}, traceId: 213e081017557449234616447e0a46'}
[19:55:23.708] [ERROR] Max retries reached after 5 attempts
[19:55:23.708] [API_FAILURE] All retries exhausted
[19:55:23.708]   [API_FAILURE] API failed (timeout or max retries)
[19:55:26.407] 2025-08-20 19:55:26,406 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[19:55:26.409] [AI_DEBUG] AI分类结果: category=other_errors, confidence=0.78
[19:55:26.412] [DEBUG] Got result for task: has_result=True, save_logs=True
[19:55:26.412] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[19:55:26.412] [AI_DEBUG] 生成的txt_content长度: 15261
[19:55:26.412] [AI_DEBUG] _ai_classify_with_txt_content called:
[19:55:26.412]   - use_ai_classification=True
[19:55:26.412]   - ai_classifier=True
[19:55:26.412]   - txt_content_len=15261
[19:55:26.412]   - task_model=qwen2.5-72b-instruct
[19:55:26.412] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[19:55:33.758] 2025-08-20 19:55:33,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[19:55:33.760] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[19:55:33.763] [DEBUG] Got result for task: has_result=True, save_logs=True
[19:55:33.763] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[19:55:33.764] [AI_DEBUG] 生成的txt_content长度: 9013
[19:55:33.764] [AI_DEBUG] _ai_classify_with_txt_content called:
[19:55:33.764]   - use_ai_classification=True
[19:55:33.764]   - ai_classifier=True
[19:55:33.764]   - txt_content_len=9013
[19:55:33.764]   - task_model=qwen2.5-72b-instruct
[19:55:33.764] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[19:55:44.880] 2025-08-20 19:55:44,879 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[19:55:44.882] [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[19:55:44.885] 
[19:55:44.885] [INFO] Batch writing 5 records to database (qwen2.5-72b-instruct:5)
[19:55:44.885] 2025-08-20 19:55:44,885 - batch_test_runner - INFO - Batch writing 5 records to database (qwen2.5-72b-instruct:5)
[19:55:44.886] [INFO] Successfully wrote 5/5 records (qwen2.5-72b-instruct:5)
[19:55:44.886] 2025-08-20 19:55:44,886 - batch_test_runner - INFO - Successfully wrote 5/5 records (qwen2.5-72b-instruct:5)
[19:55:44.888] [INFO] 数据已同步到Parquet存储
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO - Database saved successfully
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO - ============================================================
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO - Batch test completed at 2025-08-20T19:55:44.888580
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO - Summary:
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO -   - Total tests: 5
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO -   - Successful: 0
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO -   - Failed: 5
[19:55:44.888] 2025-08-20 19:55:44,888 - batch_test_runner - INFO -   - Success rate: 0.0%
[19:55:44.889] 2025-08-20 19:55:44,889 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250820_195438.log
[19:55:44.889] 2025-08-20 19:55:44,889 - batch_test_runner - INFO - ============================================================
[19:55:44.889] 
[19:55:44.889] ✅ 批测试完成
[19:55:44.889]    成功: 0/5
[19:55:44.889]    失败: 5/5
[19:55:44.889] 
[19:55:44.889] 📤 最终保存5个测试结果...
[19:55:44.891] [DEBUG] 创建新的manager实例: key=True_
[19:55:44.891] ✅ 已保存 5 个测试结果到数据库
[19:55:45.000] [INFO] 已将 5 个汇总写入Parquet
[19:55:45.038] [INFO] 刷新manager缓存: key=True_

==================================================
分片 qwen2.5-72b-instruct_easy_key2 完成
退出码: 0
总行数: 589
运行时间: 70.7秒
时间: 2025-08-20T19:55:46.387116
