=== ÊµãËØïÂºÄÂßãÊó∂Èó¥: 2025Âπ¥ 8Êúà31Êó• ÊòüÊúüÊó• 18Êó∂11ÂàÜ29Áßí EDT ===
=== ÊâßË°åÂëΩ‰ª§: python3 ./ultra_parallel_runner.py --model Llama-3.3-70B-Instruct --prompt-types cot --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 50 ===
INFO:__main__:ÂàùÂßãÂåñÂÆû‰æãÊ±†: 17‰∏™ÂÆû‰æã (2‰∏™Azure + 6‰∏™IdealLab)
INFO:__main__:üìú ‰ΩøÁî®‰º†ÁªüÊï∞ÊçÆÂ∫ìÂÜôÂÖ•Ê®°Âºè
INFO:__main__:ËµÑÊ∫êÊ±†Áä∂ÊÄÅ: 17‰∏™ÂÆû‰æã, ÂÆπÈáè1306
INFO:__main__:
üî• ÂêØÂä®Ë∂ÖÈ´òÂπ∂Ë°åÊµãËØï
INFO:__main__:   Ê®°Âûã: Llama-3.3-70B-Instruct
INFO:__main__:   PromptÁ±ªÂûã: cot
INFO:__main__:   ÈöæÂ∫¶: easy
INFO:__main__:   ÂÆû‰æãÊï∞: 20
INFO:__main__:   ÈÄüÁéáÊ®°Âºè: fixed
INFO:__main__:LlamaÊ®°Âûã Llama-3.3-70B-Instruct ÊöÇÊó∂‰ΩøÁî®ÂçïÈÉ®ÁΩ≤Á≠ñÁï•ÔºàÈÅøÂÖçÂ§öÈÉ®ÁΩ≤Âπ∂ÂèëÈóÆÈ¢òÔºâ
INFO:__main__:ÂàõÂª∫‰ªªÂä°ÂàÜÁâá: 1‰∏™ÂÆû‰æãÂπ∂Ë°å
INFO:__main__:üìä ÂàõÂª∫‰∫Ü 1 ‰∏™Âπ∂Ë°åÂàÜÁâá
INFO:__main__:  AzureÂºÄÊ∫êÊ®°ÂûãËá™ÂÆö‰πâ: 1‰∏™prompt √ó 50 = 50 workers
INFO:__main__:üöÄ ÂêØÂä®ÂàÜÁâá Llama-3.3-70B-Instruct_easy_0: Llama-3.3-70B-Instruct
INFO:__main__:   ÂÆû‰æãÊï∞: 20, Ê®°Âûã: Llama-3.3-70B-Instruct
INFO:__main__:   ËÆæÁΩÆSTORAGE_FORMAT=jsonÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆUSE_PARTIAL_LOADING=trueÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆTASK_LOAD_COUNT=20ÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆSKIP_MODEL_LOADING=trueÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆUSE_RESULT_COLLECTOR=trueÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆKMP_DUPLICATE_LIB_OK=TRUEÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆPYTHONMALLOC=mallocÁªôÂ≠êËøõÁ®ã
INFO:__main__:üöÄ Á¨¨‰∏Ä‰∏™ÂàÜÁâá Llama-3.3-70B-Instruct_easy_0 Á´ãÂç≥ÂêØÂä®
INFO:__main__:‚è≥ Âπ∂ÂèëÁ≠âÂæÖ 1 ‰∏™ÂàÜÁâáÂÆåÊàê...
2025-08-31 18:11:30,131 - faiss.loader - INFO - Loading faiss.
2025-08-31 18:11:30,155 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 18:11:30,904 - smart_result_collector - INFO - Ëá™Âä®‰øùÂ≠òÁ∫øÁ®ãÂ∑≤ÂêØÂä®
2025-08-31 18:11:30,904 - smart_result_collector - INFO - SmartResultCollectorÂàùÂßãÂåñÂÆåÊàê
2025-08-31 18:11:30,904 - smart_result_collector - INFO -   - ‰∏¥Êó∂ÁõÆÂΩï: temp_results
2025-08-31 18:11:30,904 - smart_result_collector - INFO -   - ÂÜÖÂ≠òÈòàÂÄº: 20
2025-08-31 18:11:30,904 - smart_result_collector - INFO -   - Êó∂Èó¥ÈòàÂÄº: 300Áßí
2025-08-31 18:11:30,904 - smart_result_collector - INFO -   - Ëá™Âä®‰øùÂ≠ò: 60Áßí
2025-08-31 18:11:30,904 - smart_result_collector - INFO -   - Ëá™ÈÄÇÂ∫îÈòàÂÄº: True
2025-08-31 18:11:30,904 - result_collector_adapter - INFO - ‚úÖ ‰ΩøÁî®SmartResultCollector
2025-08-31 18:11:30,904 - result_collector_adapter - INFO - AdaptiveResultCollectorÂàùÂßãÂåñÂÆåÊàêÔºå‰ΩøÁî®: smart
2025-08-31 18:11:30,906 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for gpt-5-nano
2025-08-31 18:11:30,956 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 18:11:30,956 - batch_test_runner - INFO - Âü∫‰∫éTXTÊñá‰ª∂ÁöÑAIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî® (‰ΩøÁî®gpt-5-nano)
2025-08-31 18:11:30,956 - batch_test_runner - INFO - ============================================================
2025-08-31 18:11:30,956 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 18:11:30,956 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 18:11:30,956 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_181130.log
2025-08-31 18:11:30,956 - batch_test_runner - INFO - ============================================================
2025-08-31 18:11:30,956 - batch_test_runner - INFO - Running 100 tests with 50 workers, QPS limit: None
2025-08-31 18:11:30,956 - batch_test_runner - INFO - Initializing test components...
2025-08-31 18:11:31,296 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 18:11:31,297 - batch_test_runner - INFO - ‚ö° [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 18:11:31,297 - batch_test_runner - INFO - ‚ö° This saves ~350MB memory while keeping all functionality intact
2025-08-31 18:11:31,297 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 18:11:31,772 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:31,814 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 18:11:31,928 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 18:11:32,215 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 18:11:32,215 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 18:11:32,290 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 18:11:32,356 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 18:11:32,647 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 18:11:32,647 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:32,897 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:32,897 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:32,897 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:32,906 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 18:11:32,909 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 18:11:32,909 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 18:11:32,915 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 18:11:32,915 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 18:11:32,915 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 18:11:32,915 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 18:11:35,027 - unified_training_manager - INFO - Using device: cpu
2025-08-31 18:11:35,672 - unified_training_manager - INFO - Task filtering results:
2025-08-31 18:11:35,672 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 18:11:35,672 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 18:11:35,672 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 18:11:35,672 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 18:11:35,672 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 18:11:35,672 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 18:11:35,672 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 18:11:35,676 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 18:11:35,680 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 18:11:35,681 - batch_test_runner - INFO - ‚úÖ MDPWorkflowGenerator initialized successfully:
2025-08-31 18:11:35,681 - batch_test_runner - INFO -   - task_manager: ‚úì
2025-08-31 18:11:35,681 - batch_test_runner - INFO -   - output_verifier: ‚úì
2025-08-31 18:11:35,681 - batch_test_runner - INFO -   - embedding_manager: ‚úì
2025-08-31 18:11:35,681 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 18:11:35,682 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 18:11:35,702 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 18:11:35,704 - result_collector - INFO - ResultCollectorÂàùÂßãÂåñÔºå‰∏¥Êó∂ÁõÆÂΩï: temp_results
2025-08-31 18:11:35,704 - result_merger - INFO - ResultMergerÂàùÂßãÂåñÂÆåÊàê
2025-08-31 18:11:35,704 - merger_lock - INFO - Ëé∑ÂæóÂêàÂπ∂Âô®ÈîÅ (PID: 51259)
2025-08-31 18:11:35,704 - result_merger - INFO - üöÄ ÂêØÂä®ResultMergerÔºåÂêàÂπ∂Èó¥Èöî: 10Áßí
2025-08-31 18:11:35,705 - result_merger - INFO - ResultMergerÂºÄÂßãËøêË°åÔºåÊô∫ËÉΩÂÅúÊ≠¢ÈòàÂÄº: 3ËΩÆ
2025-08-31 18:11:35,705 - result_merger - INFO - ‚úÖ ResultMergerÂêéÂè∞Á∫øÁ®ãÂ∑≤ÂêØÂä®ÔºåÊîØÊåÅÊô∫ËÉΩÂÅúÊ≠¢Êú∫Âà∂
2025-08-31 18:11:35,719 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 18:11:35,719 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 18:11:36,110 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 18:11:36,110 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 18:11:36,165 - batch_test_runner - INFO - Initialization complete
2025-08-31 18:11:36,236 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
2025-08-31 18:11:36,236 - batch_test_runner - INFO - Starting batch test with 100 tasks, 50 workers
2025-08-31 18:11:36,237 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 18:11:36,240 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for Llama-3.3-70B-Instruct
2025-08-31 18:11:36,240 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,240 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,241 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,243 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,243 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,243 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,244 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,244 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,244 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,246 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,246 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,246 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,246 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,246 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,246 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,248 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,249 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,251 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,253 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,253 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,254 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,254 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,254 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,254 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,257 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,257 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,259 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,260 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,263 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,263 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,310 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,310 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,310 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,343 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,353 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,354 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,354 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,355 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,382 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,382 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,382 - mcp_embedding_manager - INFO - Index loaded successfully: 24 tools
2025-08-31 18:11:36,391 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,404 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,404 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,404 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,413 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,413 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,414 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,425 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,428 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,428 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,428 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,439 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,453 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,463 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,463 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,463 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,463 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,464 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,465 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,475 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,475 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,476 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,477 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,478 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,479 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,483 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,486 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,508 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,509 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,512 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,512 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,517 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,523 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,524 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,526 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,527 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,549 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,549 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,549 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,562 - batch_test_runner - INFO - Batch timeout set to 6000s (100.0 minutes) for 100 tasks
2025-08-31 18:11:36,564 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè

============================================================
Êô∫ËÉΩÊâπÊµãËØï: Llama-3.3-70B-Instruct (user_azure)
Prompt types: ['cot']
ÈöæÂ∫¶: easy
ÁõÆÊ†á: ÊØèÁßçÈÖçÁΩÆ 20 ‰∏™ÂÆû‰æã
============================================================
‚óã simple_task         :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã basic_task          :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã data_pipeline       :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã api_integration     :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã multi_stage_pipeline:   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)

‚è≥ ÈúÄË¶ÅËøêË°å 100 ‰∏™Êñ∞ÊµãËØï

‚ñ∂ ÂáÜÂ§á simple_task (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á basic_task (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á data_pipeline (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á api_integration (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á multi_stage_pipeline (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂºÄÂßãÊâßË°å 100 ‰∏™ÊµãËØï...
üìä Ëá™ÈÄÇÂ∫îcheckpoint_interval: 20
üì¶ ÊâπÈáèÊèê‰∫§Ê®°ÂºèÔºöÊØè20‰∏™ÊµãËØï‰øùÂ≠ò‰∏ÄÊ¨°
üöÄ Ê£ÄÊµãÂà∞Azure APIÔºå‰ΩøÁî®Ë∂ÖÈ´òÂπ∂Âèë: workers=50, qps=None
üß† ÂêØÁî®SmartResultCollectorÊ®°ÂºèÔºåÊô∫ËÉΩÊï∞ÊçÆÁÆ°ÁêÜ
[AI_DEBUG] AIÂàÜÁ±ªÂô®ÂàùÂßãÂåñÊàêÂäü: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x107923370>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ‚ö° SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ‚ö° Memory optimization: Saving ~350MB by not loading model
[INFO] ‚ö° Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî®
[INFO] Ê£ÄÊµãÂà∞Âπ∂ÂèëÁéØÂ¢ÉÔºå‰ΩøÁî®ÂÆâÂÖ®Â≠òÂÇ®Ê®°ÂºèÔºàResultCollectorÔºâ2025-08-31 18:11:36,587 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,587 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,587 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
2025-08-31 18:11:36,596 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,596 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,596 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,605 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,606 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,606 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,618 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,626 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,651 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,651 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,671 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,671 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,671 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,685 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,685 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,685 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,685 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,699 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,699 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,701 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,702 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,713 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,715 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,715 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,715 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,728 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,728 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,728 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,740 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,742 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,747 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,760 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,761 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,761 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,780 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,780 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,781 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,787 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,787 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,787 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,790 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,793 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,796 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,807 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,808 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,808 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,818 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,824 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,825 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,825 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,839 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,860 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,864 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,864 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,864 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,875 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,875 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,875 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,886 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,891 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,892 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,896 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,896 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,896 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,897 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,897 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,898 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,902 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,903 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,903 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,903 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,909 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,910 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,910 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,910 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,911 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,914 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,914 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,920 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,929 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:36,938 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,943 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,943 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,944 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,944 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,945 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,945 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,947 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:36,948 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:36,954 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,956 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:36,971 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,971 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:36,972 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:36,988 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,988 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct

[INFO] ÂêéÂè∞ÂêàÂπ∂ËøõÁ®ãÂ∑≤ÂêØÂä®ÔºàÊØè10ÁßíÂêàÂπ∂‰∏ÄÊ¨°Ôºâ
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x11b792120>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 21 embeddings
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 18:11:36,996 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:36,998 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:36,999 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:36,999 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,001 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,005 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,008 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,008 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,023 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,029 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,030 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,033 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,039 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,042 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,045 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,048 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,050 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,056 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,056 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,058 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,060 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,062 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,076 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,093 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,095 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,095 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,105 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,105 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,116 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,121 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,121 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,121 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,122 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,126 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,127 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,128 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,139 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,141 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,145 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,146 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,147 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,149 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,149 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,151 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,151 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,156 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,158 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,161 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,164 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,165 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,165 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,210 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,166 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,177 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,185 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,189 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,189 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,189 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,189 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,193 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,193 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,194 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,206 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,210 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,210 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,166 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,213 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,215 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,215 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,225 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,226 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,227 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,229 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,230 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,230 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,231 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,231 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,231 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,241 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,245 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,248 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,248 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,250 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,251 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,254 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,260 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,278 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,301 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:37,301 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,304 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,308 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,309 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,310 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 24 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 21 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection2025-08-31 18:11:37,312 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,312 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,314 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,318 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,319 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,322 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,330 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,334 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,345 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,354 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,357 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,357 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,358 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,456 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,358 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,362 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,363 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,366 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,372 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,372 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,390 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,391 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,393 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,399 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,412 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,414 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,434 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,442 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,442 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,454 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,455 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,455 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,456 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,456 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,456 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,358 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:37,456 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,458 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,461 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,463 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,467 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,470 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,471 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,473 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,475 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,475 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,484 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,484 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,487 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,493 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,574 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,508 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,508 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,509 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,511 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,530 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,530 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:37,541 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,552 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,553 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,554 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,555 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,555 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,558 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,559 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,583 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,506 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:37,585 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,586 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,589 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,602 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:37,605 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,606 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,619 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,623 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,640 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,653 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,670 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,671 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,672 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,688 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,688 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:37,693 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,716 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,719 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,723 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct2025-08-31 18:11:37,732 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,732 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,746 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,764 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,769 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,832 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,832 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,852 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,853 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,853 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:37,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:37,972 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:37,997 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:37,997 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,008 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,012 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,012 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,022 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,022 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,022 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,041 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,041 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,041 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,053 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,053 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,053 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,089 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,089 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,089 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,097 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,106 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,110 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,112 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,112 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,115 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,131 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,149 - mcp_embedding_manager - INFO - Index loaded successfully: 19 tools
2025-08-31 18:11:38,163 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,164 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,186 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,186 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,191 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,198 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:38,215 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,215 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,198 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,199 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,199 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:38,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,244 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,245 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:38,264 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,286 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,322 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,635 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,644 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,762 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,817 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,853 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,859 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-31 18:11:38,870 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:38,965 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,112 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,112 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,131 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,161 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,167 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,182 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,191 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,303 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,312 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,705 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,816 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,903 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,962 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:39,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,160 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,160 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,258 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,310 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,340 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,403 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,417 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,489 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,584 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,591 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,685 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,807 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,847 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,933 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,953 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,992 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:40,995 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,001 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,057 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,073 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,083 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,095 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected2025-08-31 18:11:41,298 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,429 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,456 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,505 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,553 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,627 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,827 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:41,842 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,136 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,141 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,256 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,257 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,257 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,264 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,482 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,495 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,505 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,546 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,552 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,582 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,625 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,659 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,795 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,817 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:42,835 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,044 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,059 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,062 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,062 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,134 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,306 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,306 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,307 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,355 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,368 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,380 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,441 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,521 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,533 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,536 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,547 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"


[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data structure validation

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data structure validation

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 5/10]
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data structure validation

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 18:11:43,578 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,609 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,684 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,888 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,893 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:43,893 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:43,893 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:43,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,906 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:43,907 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:43,912 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,932 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:43,932 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:43,932 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:43,945 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,977 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,982 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:43,995 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,010 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,042 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,061 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,066 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,071 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,073 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,093 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,115 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,121 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,171 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,354 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,354 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,354 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,362 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,377 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,396 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,398 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:44,398 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:44,398 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:44,405 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:44,405 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:44,428 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:44,428 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:44,428 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:44,439 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,457 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,736 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,751 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,878 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,879 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,879 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,879 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:44,987 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data parsing tool

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
  [SEARCH] Query: json file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data reader

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation schema checker

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
  [SEARCH] Query: file reader writer
    Result: SUCCESS

[TURN 5/10]

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data parsing json

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data structure validation

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: CSV format)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser
  [SEARCH] Query: data validation parser

[TURN 2/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 7/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS2025-08-31 18:11:45,057 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,128 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,159 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,246 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,250 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,301 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,308 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,430 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,499 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,730 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,925 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,926 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,927 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,927 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,948 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:45,951 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,012 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,015 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,072 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,092 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,093 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,115 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,118 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,302 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,302 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,449 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,458 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,461 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,461 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,461 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,463 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,468 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,469 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:46,491 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:46,491 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:46,491 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:46,527 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,570 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,577 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,579 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,618 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:46,618 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:46,618 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:46,618 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,618 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,618 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"


[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - FILE_NOT_FOUND: Specified file not found (path: /data/file_operations_reader_385.dat)

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 9 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 27326
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=27326
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
  [SEARCH] Query: json file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: file_operations_reader

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: data_processing_validator

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 10 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: json file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer2025-08-31 18:11:46,621 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:46,621 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:46,622 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,622 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,622 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,624 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,629 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,654 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:46,654 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:46,654 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,655 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,655 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,655 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,661 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,778 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:46,778 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:46,778 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:46,778 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:46,779 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,779 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,779 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:46,785 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:46,792 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,801 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,850 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:46,850 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:46,850 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,850 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,850 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,850 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:46,857 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:46,863 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,865 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,865 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,865 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,872 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,872 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:46,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:46,895 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:46,895 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,895 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,895 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,895 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,895 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:46,895 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:46,895 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:46,909 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,975 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:46,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,977 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:46,977 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,977 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:46,978 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,980 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,980 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,980 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,987 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:46,987 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:46,987 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,990 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,994 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:46,994 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,016 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,016 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,016 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,025 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,026 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,028 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,028 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,028 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: data_processing_validator

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: data_processing_validator

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
  [SEARCH] Query: schema generator
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]

[TURN 8/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 9/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data file reader

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 18:11:47,032 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,032 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,032 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,034 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,034 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,034 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,035 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,035 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,035 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,042 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,044 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,071 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,071 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,071 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,072 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,072 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,072 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,074 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,075 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,075 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,075 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,075 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,075 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,080 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,082 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,085 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,085 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,086 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,086 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,086 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,086 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,090 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,090 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,091 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,091 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,091 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,092 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,098 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,119 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,120 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,120 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,120 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,120 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,120 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,124 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,124 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,125 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,125 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,125 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,129 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,132 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,154 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,154 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,154 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,154 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,154 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,154 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,155 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,155 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,155 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,155 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,155 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,156 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,162 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,164 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,167 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,167 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,167 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,168 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,168 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,168 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,173 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,201 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,201 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,202 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,202 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,205 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,205 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,205 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,206 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: JSON format)
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
    Result: FAILED - TIMEOUT: Operation timed out (after 38 seconds)

[TURN 6/10]
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]

[TURN 1/10]
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 18:11:47,206 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,206 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,206 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,207 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,207 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,207 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,207 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,207 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,207 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,208 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,208 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,213 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,214 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,216 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,219 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,219 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,220 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,220 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,220 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,220 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,226 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,228 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,230 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,244 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,244 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,244 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,244 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,244 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,244 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,248 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,248 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,248 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,249 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,249 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,249 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,250 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,250 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,250 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,254 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,256 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,256 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,258 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,258 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,258 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,264 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,264 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,268 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,268 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,268 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,268 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,268 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,269 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,271 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,273 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,274 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,274 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,274 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,274 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,274 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,274 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,274 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,274 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,275 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,275 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,276 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,277 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,277 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,277 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,278 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,278 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,278 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,280 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,280 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,280 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,280 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,283 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,286 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,288 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,291 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,292 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,297 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 18:11:47,297 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,297 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,300 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,301 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,301 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,308 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,319 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,319 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,319 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,337 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,337 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,337 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,337 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,337 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,337 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,338 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,338 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,338 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,338 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,338 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,338 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,343 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,344 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,344 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,345 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,345 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,346 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,346 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,346 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,346 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,346 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,347 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,350 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,351 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,351 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,351 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,357 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,359 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,362 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,377 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,378 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,378 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,378 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,378 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,378 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,378 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,379 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,401 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,402 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,402 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,403 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,403 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,403 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,403 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,403 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,403 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,406 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,406 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,407 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,407 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,407 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,407 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,408 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,409 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,409 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,409 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,409 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,410 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,410 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,412 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,411 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,413 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,414 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,415 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,415 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,415 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,415 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3

[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: failure
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}2025-08-31 18:11:47,417 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,417 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,417 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,418 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,419 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,419 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,420 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,420 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,420 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,421 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,423 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,427 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,429 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,431 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,432 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,500 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,500 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,501 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,502 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,502 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,503 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,503 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,503 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,505 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,505 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,505 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,506 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,507 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,507 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,508 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,508 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,508 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,515 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,517 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,519 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,521 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,535 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,535 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,535 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,536 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,536 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,536 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,539 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,539 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,539 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,539 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,539 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,539 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,541 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,541 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,541 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,541 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,542 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,542 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,542 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,546 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,549 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,550 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,551 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,551 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,551 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,551 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,552 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,552 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,553 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,553 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,553 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,553 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,553 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,553 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,554 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,554 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,554 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,554 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,554 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,555 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,555 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,555 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,555 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,555 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,555 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,562 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,562 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,564 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [SEARCH] Query: json file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-32025-08-31 18:11:47,565 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,565 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,566 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,566 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,567 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,567 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,567 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,568 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,568 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,568 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,570 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,570 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,570 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,570 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,571 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,571 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,571 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,572 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,572 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,572 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,573 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,573 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,574 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,574 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,574 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,580 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,582 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,582 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,584 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,587 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,611 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,611 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,612 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,621 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,621 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,622 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,622 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,622 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,623 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,623 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,623 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,623 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,624 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,625 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,625 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,625 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,625 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,625 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,625 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,625 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,626 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,627 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,627 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,627 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,629 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,629 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,629 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,630 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,630 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,630 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,631 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,633 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,635 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,635 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,636 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,636 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,637 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,637 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,637 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,637 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,639 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,640 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,640 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,641 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,642 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,642 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,642 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,644 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

  [SEARCH] Query: json file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [INFO] Tool info request: data_processing_parser

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}2025-08-31 18:11:47,644 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,644 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,645 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,645 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,645 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,646 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,648 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,648 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,648 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,649 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,649 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,650 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,650 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,650 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,652 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,653 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,653 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,653 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,653 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,653 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,653 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,657 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,657 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,658 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,660 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,661 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,661 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,663 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,664 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,664 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,664 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,665 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,668 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,671 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,671 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,671 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,672 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,679 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,680 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,680 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,681 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,682 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,682 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,682 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,686 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,686 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,686 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,696 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,697 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,697 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,697 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,698 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,698 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,698 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,698 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,699 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,699 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,699 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,699 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,709 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,710 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,710 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,711 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,711 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,711 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,712 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}2025-08-31 18:11:47,713 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,713 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,713 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,713 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,714 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,714 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,715 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,716 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,716 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,716 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,716 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,716 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,716 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,717 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,717 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,718 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,718 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,723 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,725 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,725 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,727 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,727 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,731 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,731 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,731 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,739 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,741 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,746 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,747 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,747 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,759 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,759 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,759 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,761 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,761 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,761 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,761 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,761 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,762 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,762 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,762 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,762 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,762 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,762 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,763 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,773 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,774 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,777 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,775 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,777 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,774 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,775 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,780 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,782 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,783 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,783 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,784 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,786 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,790 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,791 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,791 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,793 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,794 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,794 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,795 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,796 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,797 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,797 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2

[TURN 1/10]
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
2025-08-31 18:11:47,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,798 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,798 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,798 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,800 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,803 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,804 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:47,804 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,805 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,805 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,814 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,831 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,831 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,831 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,832 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,833 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,834 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,835 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,835 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,835 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,835 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,839 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,836 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,838 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,838 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,838 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,838 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,838 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,839 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,839 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,835 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,848 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,848 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,849 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,849 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,849 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,850 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,851 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,851 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,851 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,851 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,853 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,855 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,854 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,856 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,857 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,858 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,858 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,858 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,859 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,859 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,860 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,860 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,860 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,861 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:47,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,866 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,870 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,872 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,872 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,873 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,873 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,873 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,874 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,874 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,875 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,876 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,883 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,883 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,891 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:47,896 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,897 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,901 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:47,901 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,902 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,902 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,902 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:47,902 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,905 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,909 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,919 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,920 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,920 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,921 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,922 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,922 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,922 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,922 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,922 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-32025-08-31 18:11:47,923 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,932 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:47,932 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,932 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:47,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:47,932 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,942 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:47,945 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:47,942 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,945 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,955 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,942 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,955 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,956 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:47,957 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,957 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,958 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,958 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,959 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,960 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,960 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,960 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,963 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,966 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,968 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,969 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,969 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:47,972 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:47,972 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:47,972 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,978 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:47,979 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,001 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,001 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,001 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,023 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,023 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,024 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,024 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,024 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,025 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,025 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,027 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,028 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,028 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,028 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,029 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,029 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,029 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,032 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,035 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,038 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,059 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,059 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,059 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,060 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,060 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,060 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,065 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,065 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,065 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,066 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,066 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,066 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,067 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,067 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,067 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,070 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,070 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,070 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,071 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,071 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,071 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,071 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,075 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,075 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,077 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,077 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,077 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,077 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct

[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
  [INFO] Tool info request: data_processing_parser

[TURN 8/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully2025-08-31 18:11:48,078 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,078 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,078 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,078 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,079 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,085 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,089 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,089 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,089 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,089 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,090 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,090 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,092 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,092 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,094 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,096 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,096 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,097 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,097 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,097 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,097 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,100 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,100 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,100 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,104 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,106 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,107 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,114 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,114 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,118 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,118 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,118 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,118 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,118 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,119 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,119 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,119 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,122 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,122 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,122 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,122 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,133 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,134 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,134 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,133 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,134 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,135 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,135 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,135 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,135 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,136 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,139 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,139 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,139 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,139 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,140 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,140 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,140 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,140 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,141 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,141 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,141 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,142 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,142 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,141 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,141 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,141 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,141 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
  [INFO] Tool info request: data_processing_validator

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)2025-08-31 18:11:48,142 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,142 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,141 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,141 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,142 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,143 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,143 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,143 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,144 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,144 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,144 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,144 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,145 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,145 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,149 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,145 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,145 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,146 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,145 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,151 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,153 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,154 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,154 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,154 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,158 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,159 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,159 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,161 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,162 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,162 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,162 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,162 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,163 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,163 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,164 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,164 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,164 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,165 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,172 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,175 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,175 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,176 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,180 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,195 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,181 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,181 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,182 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,183 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,194 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,180 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,201 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,209 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,209 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,214 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,214 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,215 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,216 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,219 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,219 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,221 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,221 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,221 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,222 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,224 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,225 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,225 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,225 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,226 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,230 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,241 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,242 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,242 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,242 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,243 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,250 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct

[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
  [SEARCH] Query: data parser

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: full_success
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 18:11:48,251 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,251 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,252 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,253 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,261 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,261 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,261 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,264 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,265 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,253 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,266 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,267 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,270 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,270 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,271 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,272 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,271 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,272 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,272 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,272 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,272 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,271 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,272 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,285 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,285 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,285 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,286 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,286 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,286 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,287 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,287 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,288 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,288 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,289 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,292 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,294 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,294 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,294 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,294 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,295 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,295 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,295 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,295 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,296 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,296 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,297 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,297 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,298 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,298 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,298 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,298 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,298 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,298 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,299 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,299 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,300 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,300 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,301 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,302 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,303 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,303 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,304 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,305 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,306 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,307 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,308 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,309 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,322 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,312 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,313 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,316 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,317 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,318 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,319 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,322 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,322 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,323 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [SEARCH] Query: file reader

[TURN 6/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
  [INFO] Tool info request: file_operations_reader

[TURN 7/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-32025-08-31 18:11:48,311 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,325 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,326 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,326 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,327 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,332 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,332 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,336 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,336 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,337 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,345 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,361 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,347 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,348 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,348 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,349 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,349 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,360 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,360 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,361 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,361 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,361 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,346 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,363 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,363 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,373 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,373 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,373 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,378 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,378 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,380 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,381 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,384 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,385 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,387 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,390 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,390 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,390 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,392 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,392 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,393 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,393 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,395 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,395 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,397 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,398 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,398 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,399 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,399 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,400 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,411 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,412 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,413 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,425 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,425 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,444 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,429 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,439 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,440 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,442 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,443 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,446 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,446 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,446 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,443 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,446 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,446 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,446 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,447 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,444 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,445 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,444 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,447 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,448 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,448 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,448 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,448 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,448 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,448 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,459 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,460 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,460 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,460 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,460 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct

[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
    Result: SUCCESS

[TURN 3/10]2025-08-31 18:11:48,460 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,460 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,460 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,460 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,461 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,462 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,464 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,467 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,467 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,468 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,468 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,468 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,474 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,470 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,471 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,474 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,475 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,475 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,469 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,477 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,477 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,477 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,483 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,488 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,490 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,491 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,494 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,496 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,496 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,496 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,508 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,508 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,508 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,519 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,520 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,552 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,552 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,553 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,553 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,553 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,564 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,564 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,565 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,565 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,566 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,566 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,566 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,567 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,567 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,568 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,569 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,569 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,569 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,569 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,569 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,569 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,570 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,570 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,570 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,571 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,572 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,572 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,572 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,572 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,573 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,573 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,573 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,576 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,582 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,583 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,585 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,586 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,596 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:48,602 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,603 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,603 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,603 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,603 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,603 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,610 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,613 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,613 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,614 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,614 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,614 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,621 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,624 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,625 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,625 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,625 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,625 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,625 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,630 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
  [INFO] Tool info request: file_operations_reader

[TURN 4/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct2025-08-31 18:11:48,637 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,637 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,638 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,638 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,638 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,643 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,649 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,649 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,650 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,650 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,650 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,650 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,650 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,650 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,650 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,651 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,651 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,651 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,653 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,654 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,654 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,654 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,655 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,655 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,655 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,655 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,656 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,656 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,656 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,656 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,657 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,659 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,661 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,661 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,661 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,662 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,662 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,662 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,662 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,662 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,663 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,663 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,663 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,663 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,666 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,666 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,666 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,671 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,668 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,671 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,669 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,670 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,672 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,670 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 18:11:48,672 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,671 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,667 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,671 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,668 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,672 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,672 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,671 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,672 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,671 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,673 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,673 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,673 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,673 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,673 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,674 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,674 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,674 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,678 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,675 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,680 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,680 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,680 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,676 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,681 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:48,676 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,686 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,686 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,679 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,689 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,689 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,687 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,689 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,690 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,675 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,688 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,691 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,687 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,692 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,693 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,693 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,693 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,694 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,694 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,697 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,698 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,699 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,700 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,700 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,700 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,700 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,701 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,701 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,701 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,701 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,701 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,703 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,703 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,703 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,705 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,705 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,705 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,705 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,705 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,707 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,712 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,714 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,715 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,717 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,717 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,717 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,718 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,719 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,720 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,720 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,722 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,723 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,723 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,724 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,724 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,724 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,732 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,734 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,743 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,745 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,746 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,746 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,748 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,750 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error2025-08-31 18:11:48,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,752 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,752 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,752 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,762 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,762 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,762 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,762 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,762 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,763 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,763 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,763 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,763 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,763 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,763 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,764 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,764 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,764 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,765 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,765 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,765 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,770 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,772 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,775 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,777 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,780 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,780 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,780 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,783 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,784 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,784 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,784 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,784 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,784 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,785 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,785 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,787 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,788 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,788 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,788 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,789 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,789 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,791 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,792 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,798 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,798 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,798 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,799 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,799 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,799 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,800 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,801 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,801 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,807 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,816 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,819 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,819 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:48,819 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,820 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,821 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:48,822 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,822 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:48,822 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,822 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,822 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,823 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,823 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,823 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,823 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,823 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct2025-08-31 18:11:48,823 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,824 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,824 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,824 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,824 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,825 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,825 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,826 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,828 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,829 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,829 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,829 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,829 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,830 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,830 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,830 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,832 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,834 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,844 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,844 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,844 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,848 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,849 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,851 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,851 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,852 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,854 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,854 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,855 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,864 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,865 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,865 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,866 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,866 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,867 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,868 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,868 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,869 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,870 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,871 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,871 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,886 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,886 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,872 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,873 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,873 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,873 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,873 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,873 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,890 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,874 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,885 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,885 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,885 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,886 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:48,871 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,871 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,887 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,887 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,887 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,888 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,890 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,890 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,875 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,892 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,892 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,892 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:48,892 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:48,893 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,893 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,893 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,899 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,899 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,893 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,899 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,894 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,899 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,895 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,901 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,901 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,896 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,904 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,894 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,894 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,894 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error

[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 18:11:48,895 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,904 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,896 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,908 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,908 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,899 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,909 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,896 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:48,910 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,911 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,911 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,911 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,911 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,911 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,912 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,912 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,913 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,925 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,925 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,929 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,930 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,931 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,932 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,932 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,932 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,932 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,933 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,935 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,935 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,940 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,940 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,940 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,943 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,940 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,940 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,941 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,941 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,943 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,943 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,943 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,940 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,944 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,944 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,944 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,944 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,944 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,944 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,946 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,946 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,948 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,946 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,946 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,947 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,949 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,948 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,949 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,946 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,950 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,955 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,956 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,958 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,960 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,962 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,963 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,963 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,963 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,965 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,967 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,967 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,971 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,973 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:48,977 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,977 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,978 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,978 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,978 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,979 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,979 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,979 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,980 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:48,982 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:48,982 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,990 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,990 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,992 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:48,992 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:48,992 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:48,996 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,003 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,048 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,048 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,048 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,056 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,056 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,056 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,084 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,085 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,086 - mcp_embedding_manager - INFO - FAISS index loaded

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 18:11:49,086 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,087 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,087 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,089 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,088 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,089 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,102 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,098 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,103 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,105 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,106 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,106 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,088 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,106 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,107 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,107 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,107 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,107 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,107 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,108 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,119 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,120 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,120 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,121 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,121 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,124 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,124 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,121 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,124 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,135 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,121 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,136 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:49,136 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,137 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,140 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,137 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,140 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,140 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,137 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,140 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,140 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,140 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,141 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,141 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,141 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,141 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,141 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,141 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,142 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,142 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,142 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,149 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,150 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,150 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,150 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,151 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,151 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,152 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,154 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,156 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,156 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,156 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,156 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,157 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,157 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,157 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,158 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,158 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,158 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,158 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,159 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,159 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,159 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,160 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,160 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,160 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[INFO] Tool embedding index loaded successfully
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 18:11:49,160 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,161 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,161 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,161 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,162 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,162 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,162 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,162 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,162 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,163 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,163 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,163 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,163 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,165 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,167 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,168 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,169 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,169 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,171 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,171 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,174 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,175 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,175 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,175 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,176 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,177 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,180 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,181 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,181 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,181 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,183 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,183 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,184 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,184 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,184 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,184 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,185 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,188 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,189 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,190 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,193 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,193 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,193 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,195 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,196 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,199 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,199 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,210 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,210 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,210 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,211 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,211 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,211 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,211 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,212 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,212 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,212 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,214 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,214 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,215 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,215 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,215 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,216 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,216 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,216 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,217 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,217 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,217 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,218 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,218 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,218 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,218 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,218 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,218 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,218 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,219 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,219 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2

[TURN 1/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error2025-08-31 18:11:49,221 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,221 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,222 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,223 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,222 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,224 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,224 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,224 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,226 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,226 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,226 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,230 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,231 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,232 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,233 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,233 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,234 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,235 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,235 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,235 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,236 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,236 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,236 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,237 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,237 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,237 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,237 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,237 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,244 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,244 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,244 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,251 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,257 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,258 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,259 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,261 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,264 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,264 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,265 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,265 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,270 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,267 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,268 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,270 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,286 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,295 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,296 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,297 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,299 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,301 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,301 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,307 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,308 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,313 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,313 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,313 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-32025-08-31 18:11:49,313 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,314 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,314 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,315 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,316 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,316 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,316 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,316 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,317 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,317 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,318 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,319 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,319 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,320 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,320 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,320 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,321 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,335 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,331 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:49,331 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,332 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,332 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,332 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,333 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,333 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,333 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,334 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,334 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,334 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,335 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,335 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,321 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,336 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,338 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,339 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,343 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,343 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,343 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,343 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,343 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,344 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,345 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,345 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,346 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,366 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,366 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,358 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,362 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,362 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,362 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,363 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,366 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,366 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,366 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,357 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,360 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,379 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,379 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,380 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,380 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,380 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,380 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,381 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,381 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,382 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,383 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,384 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,386 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,386 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,387 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,388 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,388 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,405 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,405 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,405 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,394 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,399 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,412 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct

[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2

[TURN 1/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 18:11:49,399 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,400 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,400 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,401 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,401 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,402 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,394 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,399 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,398 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,410 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,411 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,411 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,412 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,399 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,413 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,413 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,414 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,414 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,414 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,414 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,415 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,415 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,416 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,416 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,418 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,419 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,423 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,423 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,433 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,434 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,434 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,435 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,436 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,442 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,445 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,449 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,450 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,458 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,462 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,462 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,463 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,465 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,465 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,468 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,469 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,472 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,480 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,481 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,484 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,488 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,499 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,499 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,499 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,501 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,511 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,511 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,512 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,512 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,519 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,523 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,523 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,525 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,526 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,526 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,527 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,527 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,528 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,529 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,529 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,529 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,530 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,539 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,530 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,531 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,531 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,532 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,532 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,533 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,534 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,534 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,536 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,537 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,538 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,538 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,538 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,539 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,560 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,560 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,560 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,530 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,560 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,560 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,560 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,560 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,561 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,562 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,563 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,563 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,563 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,564 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,576 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct2025-08-31 18:11:49,576 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,578 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,579 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,581 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,583 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,605 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,600 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,600 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,600 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,600 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,600 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,600 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,601 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,601 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,601 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,601 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,601 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,604 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,604 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,604 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,616 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,599 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,616 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,627 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,627 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,620 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,621 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,622 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,631 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,622 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,622 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,621 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,628 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,628 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,620 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,630 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,622 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,631 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,631 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,631 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,632 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,633 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,634 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,636 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,638 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,638 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,639 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,641 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,642 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,646 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,646 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,649 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,650 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,653 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,655 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,655 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,656 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,656 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,657 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,657 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,658 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,658 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,658 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,671 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,672 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,680 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,681 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,688 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,690 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,691 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,698 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,714 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,715 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,715 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,722 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,725 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]2025-08-31 18:11:49,726 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,726 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,726 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,726 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,727 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,727 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,727 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,727 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,728 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,730 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,730 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,731 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,731 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,731 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,732 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,733 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,733 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,734 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,737 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,740 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,741 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,742 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,742 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,743 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,743 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,744 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,745 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,746 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,747 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,748 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,748 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,749 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,759 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,761 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,761 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,761 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,762 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,762 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,762 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,788 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,789 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,790 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,791 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,797 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error

[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 18:11:49,813 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,814 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,815 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,816 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,817 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,817 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,820 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,820 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,821 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,822 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,822 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,822 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,837 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,823 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,824 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,831 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,831 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,835 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,835 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,835 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,836 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,836 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,836 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,836 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,836 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,836 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,836 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,837 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,837 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,847 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,847 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,848 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,823 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,853 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,848 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,848 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,848 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,851 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,851 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,851 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,851 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,851 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,852 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,852 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,852 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,852 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,853 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,853 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,853 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,853 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,853 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,848 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,853 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,854 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,854 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,854 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,854 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,854 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,854 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,854 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,870 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,872 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,873 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,875 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,876 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,855 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,877 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,856 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,855 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,879 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,879 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,877 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,880 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,880 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,855 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,882 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,882 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,891 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,882 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,878 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,856 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,884 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,884 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,884 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,890 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,866 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,892 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,892 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,893 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,893 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,894 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,895 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,895 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,903 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,903 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,904 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,905 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,907 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,911 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,912 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,914 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,919 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,924 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:49,929 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...

[TURN 1/10]
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 18:11:49,931 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,931 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,933 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,935 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,935 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,936 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,938 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,941 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,941 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,941 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,943 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,944 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,946 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:49,946 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,949 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,952 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,963 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,963 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,963 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,968 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,968 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:49,979 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,979 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:49,979 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:49,979 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:49,980 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:49,980 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:49,980 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:49,987 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:49,991 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:49,991 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:49,996 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:49,996 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:49,996 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,006 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,006 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,013 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,013 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,014 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,014 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,014 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,019 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,021 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,023 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,023 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,023 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,023 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,023 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,023 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,023 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,032 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,033 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,033 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,033 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,033 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,033 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,033 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,033 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,034 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,034 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,034 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,035 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,035 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,035 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,035 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,035 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,039 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,039 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,040 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,040 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,041 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,041 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,043 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,043 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,043 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,044 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,047 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,047 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,048 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,048 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,048 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,049 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,050 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,053 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,057 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,063 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 18:11:50,123 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,124 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,124 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,125 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,125 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,125 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,125 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,125 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,125 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,126 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,126 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,126 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,126 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,127 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,127 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,127 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,127 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,127 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,128 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,128 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,128 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,128 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,129 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,129 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,129 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,129 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,129 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,129 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,129 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,130 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,130 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,130 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,131 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,131 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,134 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:50,141 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,145 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,146 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,147 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,147 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,149 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,150 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:50,153 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,153 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,153 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,160 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,161 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,161 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,163 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,164 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,165 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,165 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,166 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:50,178 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,179 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,184 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,184 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,186 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,186 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,186 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,196 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,197 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error

[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 18:11:50,197 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,197 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,197 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,197 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,198 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,202 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,202 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,202 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,209 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,209 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,209 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,210 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,213 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,226 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,227 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,227 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,227 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,237 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,237 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,238 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,238 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,238 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,239 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,240 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,240 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,240 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:50,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,241 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,241 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,243 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,243 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,244 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,244 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,244 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,244 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,244 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,245 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,246 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,246 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,246 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,246 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,247 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,247 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,247 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,248 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,249 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,249 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,249 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,250 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,250 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,250 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,251 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,253 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,253 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error2025-08-31 18:11:50,255 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,255 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,255 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,256 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,256 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,257 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,257 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,257 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,260 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,261 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,262 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,262 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,262 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,263 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,263 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,263 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,263 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,264 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,264 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,264 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,277 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,265 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,265 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,267 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,267 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,277 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,277 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,277 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,277 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,264 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,278 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,279 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,286 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,286 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,280 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,281 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,284 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,285 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,281 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,292 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,291 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,291 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,291 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,298 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,299 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,291 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,280 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,301 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,290 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,299 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,299 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,299 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,292 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,300 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,301 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,298 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,313 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,321 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,321 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,324 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,323 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,324 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,324 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,322 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,325 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,325 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,326 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,326 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,328 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,328 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,329 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,329 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,329 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,330 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,330 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,330 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,331 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,332 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,332 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,332 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,336 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,336 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:50,339 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,341 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,342 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,344 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:50,348 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,356 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,356 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,356 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,358 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,360 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,360 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,361 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,361 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,361 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,367 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2

[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}2025-08-31 18:11:50,370 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,372 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 18:11:50,378 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,379 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,379 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,380 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,380 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,381 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,381 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,392 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,393 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,394 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,394 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,394 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,395 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,405 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,406 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,406 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,407 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,408 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,408 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,409 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,409 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,409 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,410 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,411 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,411 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,411 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,424 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,424 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,425 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,425 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,425 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,426 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,435 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,436 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,436 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,436 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,451 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,451 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,459 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,459 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,463 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,463 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,463 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,464 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,464 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: cot for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5236316224)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 18:11:50,465 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,465 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 18:11:50,465 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,468 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,471 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,468 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,468 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,470 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,470 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,470 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,470 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,470 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,470 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,471 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,471 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 18:11:50,471 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,468 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,471 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,471 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,471 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,471 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,473 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 18:11:50,473 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,473 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,473 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,473 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,484 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,485 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,486 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,486 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,486 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,487 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,489 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,488 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,488 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,488 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,488 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,489 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,489 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,489 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,490 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,491 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,491 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,491 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,496 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,497 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,498 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,498 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,498 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,498 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,498 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,499 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,501 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,502 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,504 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,505 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,505 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,505 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,505 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,505 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,505 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,507 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,512 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,645 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,645 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,645 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,645 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,646 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,647 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,647 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,647 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,648 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,648 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,648 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,648 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,648 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,648 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,648 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,648 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,649 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,649 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,649 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,649 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,649 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,650 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,650 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,650 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,656 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,657 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,658 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,659 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,682 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,682 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,682 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,682 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,682 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,682 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,683 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure

[TURN 1/10]
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}2025-08-31 18:11:50,683 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,683 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,683 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,683 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,683 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,683 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,684 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,686 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,686 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,686 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,687 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,688 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,688 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,688 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,689 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,689 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,690 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,690 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,690 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,691 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,695 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,695 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,694 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,698 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,693 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,700 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,700 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,694 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,706 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,706 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,700 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,702 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,701 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,707 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,712 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,691 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,709 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,713 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,710 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,713 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,711 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,712 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,714 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,712 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,714 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,714 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,707 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,715 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,716 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,716 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,717 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,717 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,718 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,718 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,717 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,720 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,720 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,717 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,720 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,717 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,723 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,723 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,725 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,729 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,737 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,737 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,737 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,738 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,739 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,741 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,742 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,744 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,744 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,744 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,751 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,769 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,769 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,769 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,770 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,770 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,770 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}2025-08-31 18:11:50,772 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,772 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,772 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,772 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,772 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,775 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,775 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,775 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,775 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,775 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,777 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,777 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,777 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,778 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,778 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,778 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,781 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,784 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,785 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,821 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,821 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,821 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,821 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,822 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,822 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,822 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,822 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,822 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,822 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,822 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,822 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,823 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,823 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,823 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,823 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,823 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,823 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,829 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,830 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,831 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,832 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,833 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,833 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,833 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,839 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,842 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,842 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,842 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,843 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,843 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,843 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,844 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,844 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,845 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,846 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,846 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,846 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,846 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,847 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,847 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,847 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,847 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,847 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,849 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,853 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,855 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,856 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,857 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,857 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,857 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,857 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,857 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,859 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}2025-08-31 18:11:50,860 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,860 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,860 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,860 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,860 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,863 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,864 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,864 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,865 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,865 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,865 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,867 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,868 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,868 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,868 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,868 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,868 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,868 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,871 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,874 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,887 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,887 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,887 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,888 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,888 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,888 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,888 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,888 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,888 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,889 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,889 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,889 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,892 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,893 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,893 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,893 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,893 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,893 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,895 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,896 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,896 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,896 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,897 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,897 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,897 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,897 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,900 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,903 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,904 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,904 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,904 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,904 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,904 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,905 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,911 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,942 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,942 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:50,942 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,942 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,942 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,942 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,948 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,948 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,949 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,949 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,949 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,949 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,950 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,955 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,958 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:50,958 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,958 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,958 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,958 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,960 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,960 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:50,960 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,960 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,960 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,960 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,962 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,962 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct2025-08-31 18:11:50,962 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,962 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,962 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,962 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,965 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:50,967 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,969 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,971 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,971 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,971 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,972 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,972 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,973 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,973 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,973 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,973 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,973 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,973 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,976 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,976 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,976 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,976 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,977 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,980 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,980 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,982 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:50,982 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:50,982 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:50,982 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:50,982 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:50,982 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,984 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:50,989 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,006 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,006 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,006 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,007 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,007 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,007 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,009 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,010 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,010 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,010 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,011 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,011 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,011 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,011 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,011 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,011 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,011 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,011 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,011 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,012 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,012 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,013 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,013 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,013 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,014 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,017 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,017 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,017 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,017 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,017 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,017 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,020 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,022 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,023 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,026 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,052 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,052 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,052 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,052 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,052 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,052 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,058 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,058 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,058 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct

[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error2025-08-31 18:11:51,059 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,059 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,059 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,060 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,065 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,169 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,169 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,169 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,169 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,169 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,170 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:51,170 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,171 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,171 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,172 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,172 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,172 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,178 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,180 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,206 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,206 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,206 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,206 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,206 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,206 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,209 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,210 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:51,210 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:51,210 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,210 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,210 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,210 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,211 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,211 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,212 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,212 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,212 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,213 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,216 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,219 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,221 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,222 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,222 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,222 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,222 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,222 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,228 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,248 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:51,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,248 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,248 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,254 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,254 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,254 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,254 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,254 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,254 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,255 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,256 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,256 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,256 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,256 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,256 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,261 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,262 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,324 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,324 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,324 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:51,324 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,324 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,325 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,325 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,329 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,329 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,329 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,329 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,329 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,329 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,331 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,335 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct2025-08-31 18:11:51,389 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,390 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,390 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,390 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,390 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,390 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,396 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,439 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,440 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,440 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,440 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,440 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,440 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,446 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,518 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,519 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,519 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,519 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,519 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,520 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:51,520 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:51,520 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,520 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,520 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,520 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,520 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,520 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,521 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,521 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,521 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,521 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,521 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,521 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,528 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,528 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,529 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,577 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,577 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:51,577 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,578 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,578 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,578 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,583 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,694 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,695 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,695 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:51,695 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,695 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,695 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,695 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,700 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,760 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,760 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:51,760 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,761 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,761 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,761 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,766 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,778 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,778 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:51,778 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,779 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,779 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,779 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,784 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,795 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,795 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:51,796 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,796 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,796 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,796 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,802 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:51,869 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,870 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error

[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [SEARCH] Query: json file reader
  [SEARCH] Query: json data reader
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct2025-08-31 18:11:51,870 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:51,870 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,870 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,870 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,870 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,876 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,930 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:51,931 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:51,931 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:51,931 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:51,931 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:51,931 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:51,936 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,008 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,008 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:52,008 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,009 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,009 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,009 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,014 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,130 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:52,130 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,130 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,130 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,130 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,136 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,408 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,408 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:52,408 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:52,408 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:52,408 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,409 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,409 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,414 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,508 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,508 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:52,509 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,509 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,509 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,509 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,515 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,524 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,524 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:52,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,524 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,524 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,530 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,644 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,644 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:52,644 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,645 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,645 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,645 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,651 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,741 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,741 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:52,741 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,741 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,741 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,741 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,747 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,782 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:52,782 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,783 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,783 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,783 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,790 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:52,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,855 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:52,855 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:52,855 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:52,855 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,855 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,861 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error2025-08-31 18:11:52,905 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:52,905 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:52,905 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,905 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,905 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,911 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:52,983 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:52,983 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:52,983 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:52,983 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:52,983 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:52,983 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:52,991 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:53,021 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,021 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:53,021 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:53,021 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:53,021 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,021 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,021 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,027 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,125 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:53,125 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:53,126 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,126 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,131 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,310 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,310 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:53,310 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:53,311 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,311 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,311 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,316 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,378 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,379 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:53,379 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,379 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,379 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,379 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,384 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,431 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,432 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:53,432 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:53,432 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:53,432 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,432 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,432 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:53,438 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:53,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,449 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:11:53,449 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,449 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,449 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,449 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:53,455 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:53,481 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,482 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:53,482 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,482 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,482 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,482 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,488 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:11:53,595 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:53,595 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:53,595 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:11:53,595 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:53,595 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:53,595 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:53,595 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:53,601 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:53,917 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:11:54,007 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:54,008 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error

[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct2025-08-31 18:11:54,008 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,008 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:54,008 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:54,008 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:54,014 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:54,495 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:54,495 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:11:54,495 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,496 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:54,496 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:54,496 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:54,503 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:11:54,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:54,622 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:54,622 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,622 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:54,622 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:54,622 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,627 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,692 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:54,693 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:54,693 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,693 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:54,693 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:54,693 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:54,699 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:55,155 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:11:55,156 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:11:55,156 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:55,156 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:11:55,156 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:11:55,156 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:11:55,162 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:11:55,836 - result_merger - INFO - üõë ËøûÁª≠3ËΩÆÊó†Êñ∞Êñá‰ª∂ÔºåËá™Âä®ÂÅúÊ≠¢ÂêàÂπ∂Âô®Èò≤Ê≠¢hang‰Ωè
2025-08-31 18:11:55,836 - result_merger - INFO - üèÅ ResultMergerÂêàÂπ∂Âæ™ÁéØÂ∑≤ÁªìÊùü
2025-08-31 18:12:03,240 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:10,297 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:20,132 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:20,133 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:12:20,133 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:12:20,133 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:20,134 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:20,134 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:20,134 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:20,141 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:20,297 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:20,297 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:12:20,297 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:20,297 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:20,297 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:20,298 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:20,305 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:20,412 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:20,412 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:12:20,412 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:20,412 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:20,413 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:20,413 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:20,419 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:12:20,615 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:20,615 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:12:20,615 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:12:20,615 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:20,616 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:20,616 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:20,616 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:20,622 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:20,731 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:20,742 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:12:20,742 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:20,742 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:20,742 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:20,742 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:20,749 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 44 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 20540
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20540
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 43 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error2025-08-31 18:12:20,753 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:22,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:22,125 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:12:22,125 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:22,125 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:22,125 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:22,125 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:22,132 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:27,184 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:27,184 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:12:27,185 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,185 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:27,185 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:27,185 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:27,191 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:27,383 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:27,384 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:12:27,384 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,384 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:27,384 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:27,384 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,390 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,496 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:27,496 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 18:12:27,496 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 18:12:27,497 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:27,497 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:27,497 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:27,497 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:27,503 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 18:12:27,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:27,617 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 18:12:27,617 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,618 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:27,618 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:27,618 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:27,624 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 18:12:27,731 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 18:12:27,732 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 18:12:27,732 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,732 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 18:12:27,732 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 18:12:27,732 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 18:12:27,737 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 18:12:28,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:37,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:45,779 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:49,377 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:50,008 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:50,958 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:51,991 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:53,314 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:53,626 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:54,141 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:54,328 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:54,869 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:54,994 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 42 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 26901
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=26901
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 27258
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=27258
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 17 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 17 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 16 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure2025-08-31 18:12:55,663 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:55,668 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:56,422 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:56,600 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:56,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:58,335 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:58,575 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:59,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:59,509 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:59,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:12:59,856 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:00,256 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:00,408 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:00,923 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:00,941 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:01,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:01,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:02,701 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:02,727 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:03,418 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:04,080 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:04,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:05,162 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:05,684 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:08,107 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:08,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:09,827 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:11,218 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:12,731 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:14,143 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:14,247 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:16,109 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:17,817 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:18,840 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:19,571 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:20,305 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:20,830 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:21,189 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:21,877 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:22,554 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 27932
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=27932
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 15 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 15 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 10 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 10 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 9 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 29758
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=29758
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 18981
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18981
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 21545
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21545
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: network api fetch
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 18872
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18872
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: network_fetcher
  [EXECUTING] network_fetcher
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected2025-08-31 18:13:23,199 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:23,747 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:27,163 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:28,221 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:29,025 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:30,319 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:31,142 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:34,097 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:41,276 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:53,391 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:53,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:53,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:54,907 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:55,486 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:56,865 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:57,527 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:13:58,826 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:00,265 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:01,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:01,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:03,295 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:05,815 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:13,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:22,594 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:29,291 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:29,293 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469292550.json
2025-08-31 18:14:29,305 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469293486.json
2025-08-31 18:14:29,306 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469306127.json
2025-08-31 18:14:29,306 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469306559.json
2025-08-31 18:14:29,307 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469306984.json
2025-08-31 18:14:29,307 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469307405.json
2025-08-31 18:14:29,308 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469307767.json
2025-08-31 18:14:29,308 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469308160.json
2025-08-31 18:14:29,308 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469308576.json
2025-08-31 18:14:29,309 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469308918.json
2025-08-31 18:14:29,309 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469309247.json
2025-08-31 18:14:29,310 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469309658.json
2025-08-31 18:14:29,310 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469310298.json
2025-08-31 18:14:29,311 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469310619.json
2025-08-31 18:14:29,311 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469311277.json
2025-08-31 18:14:29,311 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469311647.json
2025-08-31 18:14:29,312 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469311936.json
2025-08-31 18:14:29,312 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469312195.json
2025-08-31 18:14:29,312 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469312394.json
2025-08-31 18:14:29,312 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678469312654.json
2025-08-31 18:14:35,009 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"


[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: file_operations_reader

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data filter

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 25610
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25610
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 6 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - OPERATION_FAILED: Operation could not be completed
[ASSISTED] Task received 6 format helps, final result: failure
  [SEARCH] Query: json file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: data_processing_parser

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    Result: SUCCESS

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data filter
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG RAG] data_processing_filter semantically matched with data_processing_transformer (score: 0.716)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_transformer (score: 0.617)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
Progress: 10/100 (Success: 4)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 23377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23377
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [SEARCH] Query: json data reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS
[ASSISTED] Task received 6 format helps, final result: full_success2025-08-31 18:14:42,623 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:14:54,271 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:15:03,603 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:15:11,639 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:15:19,387 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:15:28,249 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:15:56,201 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:16:08,365 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:16:16,027 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:16:30,919 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:16:30,924 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590922660.json
2025-08-31 18:16:30,925 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590924832.json
2025-08-31 18:16:30,927 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590925807.json
2025-08-31 18:16:30,939 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590933490.json
2025-08-31 18:16:30,940 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590939942.json
2025-08-31 18:16:30,941 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590940834.json
2025-08-31 18:16:30,941 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590941614.json
2025-08-31 18:16:30,942 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590942132.json
2025-08-31 18:16:30,943 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590942633.json
2025-08-31 18:16:30,944 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590943940.json
2025-08-31 18:16:30,945 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678590944503.json
2025-08-31 18:16:38,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:16:46,631 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:16:58,471 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:17:10,687 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:17:18,015 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:17:25,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4337
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4337
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: FAILED - TIMEOUT: Operation timed out (after 29 seconds)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data filter

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    [PENALTY] Recent failures: 1, success rate reduced
    Result: FAILED - TIMEOUT: Operation timed out (after 52 seconds)

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 18456
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18456
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 25093
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25093
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 5963
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5963
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: file_operations_reader

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - TIMEOUT: Operation timed out (after 34 seconds)

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 23126
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23126
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
  [SEARCH] Query: file reader

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_scanner
  [EXECUTING] file_operations_scanner
    Result: SUCCESS
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG RAG] file_operations_reader semantically matched with file_operations_scanner (score: 0.751)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4377
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 14445
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14445
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[LLM_ERROR] Attempt 1/5: Request timed out.
[TIMEOUT] API call timed out after 150 seconds, not retrying
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.6
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 15574
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15574
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò20‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=20, Êó∂Èó¥=0.0s, Âº∫Âà∂=False
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 20/20 ‰∏™ÁªìÊûú
Progress: 20/100 (Success: 8)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 24436
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24436
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª2025-08-31 18:17:38,522 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:17:52,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:06,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:15,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:23,613 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:30,686 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:37,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:37,412 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717411465.json
2025-08-31 18:18:37,413 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717412425.json
2025-08-31 18:18:37,413 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717413367.json
2025-08-31 18:18:37,414 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717414013.json
2025-08-31 18:18:37,414 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717414440.json
2025-08-31 18:18:37,415 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717414795.json
2025-08-31 18:18:37,415 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717415089.json
2025-08-31 18:18:37,415 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717415364.json
2025-08-31 18:18:37,416 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717415659.json
2025-08-31 18:18:37,416 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717416095.json
2025-08-31 18:18:37,417 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717416896.json
2025-08-31 18:18:37,417 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717417439.json
2025-08-31 18:18:37,418 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678717417884.json
2025-08-31 18:18:45,363 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:50,644 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:18:57,423 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:19:04,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:19:11,578 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:19:24,217 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:19:32,298 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:19:40,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:19:47,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4377
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 12843
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12843
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 23352
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23352
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4377
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 18032
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18032
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 17706
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17706
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 24434
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24434
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 24975
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24975
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 20997
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20997
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.8
Progress: 30/100 (Success: 13)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 21323
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21323
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.6
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò11‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=11, Êó∂Èó¥=121.6s, Âº∫Âà∂=False
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 11/11 ‰∏™ÁªìÊûú
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4182
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4182
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 25930
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25930
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 9053
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=9053
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 22942
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22942
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4196
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4196
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 18197
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18197
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4156
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True2025-08-31 18:19:54,128 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:00,456 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:08,973 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:16,349 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:22,269 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:28,650 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:36,371 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:42,284 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:42,285 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842285379.json
2025-08-31 18:20:42,286 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842286108.json
2025-08-31 18:20:42,286 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842286532.json
2025-08-31 18:20:42,287 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842286916.json
2025-08-31 18:20:42,287 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842287318.json
2025-08-31 18:20:42,288 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842287636.json
2025-08-31 18:20:42,288 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842288080.json
2025-08-31 18:20:42,290 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842288447.json
2025-08-31 18:20:42,290 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842290080.json
2025-08-31 18:20:42,290 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842290295.json
2025-08-31 18:20:42,291 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842290963.json
2025-08-31 18:20:42,291 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842291220.json
2025-08-31 18:20:42,291 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842291451.json
2025-08-31 18:20:42,291 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842291664.json
2025-08-31 18:20:42,292 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842291869.json
2025-08-31 18:20:42,292 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842292069.json
2025-08-31 18:20:42,292 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678842292407.json
2025-08-31 18:20:49,293 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:20:57,001 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:05,446 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:11,937 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:18,756 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:27,999 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:34,513 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:43,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:21:49,120 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

  - ai_classifier=True
  - txt_content_len=4156
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 20224
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20224
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19058
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19058
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.72
Progress: 40/100 (Success: 18)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4174
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4174
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4174
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4174
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4187
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4187
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 26042
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=26042
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.78
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò13‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=13, Êó∂Èó¥=126.5s, Âº∫Âà∂=False
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 13/13 ‰∏™ÁªìÊûú
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4182
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4182
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4180
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4180
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4336
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4336
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4168
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4168
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 16714
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16714
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4156
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4156
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.75
Progress: 50/100 (Success: 19)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19721
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19721
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4166
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4166
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4255
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4255
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4196
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4196
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ2025-08-31 18:21:56,496 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:02,862 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:11,536 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:19,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:25,921 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:35,533 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:44,324 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:44,326 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964325753.json
2025-08-31 18:22:44,327 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964326550.json
2025-08-31 18:22:44,327 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964327211.json
2025-08-31 18:22:44,328 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964327820.json
2025-08-31 18:22:44,328 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964328189.json
2025-08-31 18:22:44,328 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964328489.json
2025-08-31 18:22:44,329 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964328822.json
2025-08-31 18:22:44,329 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964329064.json
2025-08-31 18:22:44,330 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964329843.json
2025-08-31 18:22:44,330 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964330202.json
2025-08-31 18:22:44,331 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964330627.json
2025-08-31 18:22:44,331 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964331256.json
2025-08-31 18:22:44,331 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964331596.json
2025-08-31 18:22:44,332 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964332049.json
2025-08-31 18:22:44,332 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964332366.json
2025-08-31 18:22:44,332 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756678964332620.json
2025-08-31 18:22:51,842 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:22:57,440 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:07,096 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:16,470 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:22,779 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:30,672 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:39,158 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:47,887 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:23:57,092 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 23079
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23079
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4239
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4239
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.77
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4267
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4267
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4167
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4167
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4196
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4196
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4289
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4289
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.78
Progress: 60/100 (Success: 21)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4245
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4245
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò17‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=17, Êó∂Èó¥=124.9s, Âº∫Âà∂=False
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 17/17 ‰∏™ÁªìÊûú
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 8315
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=8315
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4249
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4249
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4221
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4221
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4251
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4251
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4209
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4209
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19859
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19859
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4248
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4248
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4209
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4209
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4246
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4246
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
Progress: 70/100 (Success: 22)
[DEBUG] Got result for task: has_result=True, save_logs=False2025-08-31 18:24:10,524 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:24:20,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:24:27,536 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:24:37,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:24:43,986 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:24:51,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:24:51,015 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091014432.json
2025-08-31 18:24:51,016 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091015674.json
2025-08-31 18:24:51,016 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091016348.json
2025-08-31 18:24:51,017 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091016945.json
2025-08-31 18:24:51,017 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091017338.json
2025-08-31 18:24:51,018 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091017935.json
2025-08-31 18:24:51,018 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091018318.json
2025-08-31 18:24:51,018 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091018605.json
2025-08-31 18:24:51,019 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091018924.json
2025-08-31 18:24:51,019 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091019269.json
2025-08-31 18:24:51,020 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091019604.json
2025-08-31 18:24:51,020 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091020243.json
2025-08-31 18:24:51,022 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091020503.json
2025-08-31 18:24:51,022 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091022437.json
2025-08-31 18:24:51,022 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679091022660.json
2025-08-31 18:25:01,914 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:25:13,583 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:25:22,591 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:25:27,771 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:25:36,826 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:25:48,544 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:04,767 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:04,771 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164769214.json
2025-08-31 18:26:04,772 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164771407.json
2025-08-31 18:26:04,774 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164772616.json
2025-08-31 18:26:04,776 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164775280.json
2025-08-31 18:26:04,777 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164776865.json
2025-08-31 18:26:04,778 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164777641.json
2025-08-31 18:26:04,779 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164778525.json
2025-08-31 18:26:04,779 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 1 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164779269.json
2025-08-31 18:26:04,780 - batch_test_runner - INFO - Batch writing 100 records to database (Llama-3.3-70B-Instruct:100)
2025-08-31 18:26:04,795 - result_collector - INFO - üì§ Â∑≤Êèê‰∫§ Llama-3.3-70B-Instruct ÁöÑ 100 ‰∏™ÁªìÊûúÂà∞Êî∂ÈõÜÂô®: Llama-3.3-70B-Instruct_51259_1756679164780749.json
2025-08-31 18:26:04,795 - batch_test_runner - INFO - Successfully wrote 100/100 records (Llama-3.3-70B-Instruct:100)
2025-08-31 18:26:04,881 - batch_test_runner - INFO - Database saved successfully
2025-08-31 18:26:04,881 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 18:26:04,882 - batch_test_runner - INFO - ============================================================
2025-08-31 18:26:04,882 - batch_test_runner - INFO - Batch test completed at 2025-08-31T18:26:04.882071
2025-08-31 18:26:04,882 - batch_test_runner - INFO - Summary:
2025-08-31 18:26:04,882 - batch_test_runner - INFO -   - Total tests: 100
2025-08-31 18:26:04,882 - batch_test_runner - INFO -   - Successful: 35
2025-08-31 18:26:04,882 - batch_test_runner - INFO -   - Failed: 65
2025-08-31 18:26:04,882 - batch_test_runner - INFO -   - Success rate: 35.0%
2025-08-31 18:26:04,882 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_181130.log
2025-08-31 18:26:04,882 - batch_test_runner - INFO - ============================================================
2025-08-31 18:26:04,882 - batch_test_runner - INFO - üßπ Ê≠£Âú®Ê∏ÖÁêÜÂ≠òÂÇ®ÈÄÇÈÖçÂô®ËµÑÊ∫ê...
2025-08-31 18:26:04,882 - result_merger - INFO - ÂêàÂπ∂Á∫øÁ®ãÂ∑≤ÁªèÂÅúÊ≠¢ÔºåÊó†ÈúÄÈáçÂ§çÊìç‰Ωú
2025-08-31 18:26:04,883 - result_merger - INFO - ÂèëÁé∞101‰∏™Êñ∞ÁöÑÁªìÊûúÊñá‰ª∂
2025-08-31 18:26:04,930 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 18:26:04,930 - result_merger - INFO - [MERGER_PROTECTION] ‰ΩøÁî®managerÂÜÖÁΩÆÁöÑÂÆâÂÖ®ÂêàÂπ∂Êú∫Âà∂
2025-08-31 18:26:12,880 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:12,881 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected. The task shows 0% required tool coverage and no tools were executed, with an 'Unknown error' rather than a misstep in too
2025-08-31 18:26:17,878 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:17,879 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is reported as Unknown error; there is no observable evidence of a concrete agent-level decision mistake (tool choice,
2025-08-31 18:26:23,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:23,977 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Error appears to be a generic system/API failure (Unknown error) with no observed agent decisions (no tool usage, parameters, sequence, or dependencies to 

[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19101
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19101
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19994
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19994
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4237
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4237
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.76
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4255
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4255
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4445
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4445
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 27265
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=27265
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4267
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4267
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò16‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=16, Êó∂Èó¥=122.0s, Âº∫Âà∂=False
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 16/16 ‰∏™ÁªìÊûú
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 18270
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18270
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=dependency_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4174
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4174
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4245
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4245
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.62
Progress: 80/100 (Success: 26)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 25477
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25477
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4277
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4277
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4188
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4188
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.76
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4140
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4140
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 20088
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20088
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 25188
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25188
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 41732025-08-31 18:26:28,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:28,014 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any API integration tool, leaving the task without the required tool(s). This indicates a wrong or missing tool
2025-08-31 18:26:35,222 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:35,222 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent did not establish or respect required dependencies for the API integration workflow (no initialization/configuration/auth steps were perform
2025-08-31 18:26:43,350 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:43,351 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No actions were executed and no prerequisites (like authentication setup, data loading, or API readiness) were established before attempting the API i
2025-08-31 18:26:51,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:51,911 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool for an api_integration task, resulting in no execution steps. This omission constitutes a wrong tool c
2025-08-31 18:26:58,583 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:26:58,584 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The task had no defined requirements and no prerequisite steps to execute; the agent failed to establish or resolve dependencies (clarify task, determ
2025-08-31 18:27:03,827 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:03,827 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision error detected: there is no evidence of tool selection, parameter configuration, sequence ordering, or dependency handling being at
2025-08-31 18:27:08,547 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:08,548 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool appropriate for the api_integration task, resulting in zero progress. This indicates a tool-selection 
2025-08-31 18:27:13,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:13,933 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or any action taken for the data_pipeline task. The agent skipped initiating any data processing steps, effectively failing t
2025-08-31 18:27:20,039 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:20,039 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle required tool dependencies for the multi-stage pipeline; no data loading or preliminary stages were executed, so downstream ste
2025-08-31 18:27:26,286 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:26,287 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tools to process the task, resulting in only partial success. With no tools executed (and no explicit required 
2025-08-31 18:27:35,041 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:35,041 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized to handle the (unknown) task, resulting in 0% tool coverage and a complete failure. This indicates a wrong o
2025-08-31 18:27:40,362 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:40,362 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Partial success with quality issues, and no clear tool execution details, suggests the agent made an inappropriate tool choice for the task (or fa
2025-08-31 18:27:47,148 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:47,148 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent attempted to execute workflow steps in an order that is inconsistent with the task's simplicity (no tools were required). This likely le
2025-08-31 18:27:53,365 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:53,365 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute or define any stages of the multi_stage_pipeline, effectively failing to follow the required workflow sequence. No tools
2025-08-31 18:27:58,571 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:27:58,571 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision path to evaluate: no tools were required or executed, so there is no tool selection, parameter config, sequence, or dependency decision t
2025-08-31 18:28:03,218 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:03,220 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to progress the task; due to task ambiguity/unknown task, the decision to pick an appropriate tool was ski
2025-08-31 18:28:10,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:10,900 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Partial success with quality issues and no tools were selected or executed. There is no evidence of a defined sequence of steps (A‚ÜíB‚ÜíC) or logical
2025-08-31 18:28:17,373 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:17,374 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameter config, sequence order, or dependency handling). The task shows Unknown error wit
2025-08-31 18:28:22,695 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:22,695 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error identifiable given the task metadata: no tools were specified or executed, no parameter choices documented, and no depende
2025-08-31 18:28:29,732 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:29,733 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: the task required no tools and involved no sequencing or dependencies, so there were no tool selections, parameter config
2025-08-31 18:28:35,000 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:35,000 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not implement or initiate the required multi-stage workflow in the correct order; no steps/tools were executed, indicating a failure
2025-08-31 18:28:39,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:39,759 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No clear agent decision error can be identified from the data. The error is reported as Unknown error with no tool executions or results, providing no evid
2025-08-31 18:28:43,062 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:43,063 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No clear agent decision error can be identified from the provided log. The error message is generic ('Unknown error') and there are no tool selections, par
2025-08-31 18:28:52,033 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:52,034 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The run produced an 'Unknown error' before any tool was selected or executed; there is no evidence of a tool mis-selection or mis-sequence, but the pi
2025-08-31 18:28:56,318 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:28:56,319 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any tool required for the api_integration task; executed tools list is empty, indicating a wrong or missing 
2025-08-31 18:29:08,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:08,252 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were chosen or executed; the agent failed to select or initiate tool usage, resulting in a complete failure with zero tool activity. This
2025-08-31 18:29:11,676 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:11,676 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and/or invoke any of the required tools for the multi_stage_pipeline (no tools executed). This constitutes a wrong tool
2025-08-31 18:29:17,918 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:17,919 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to engage any appropriate tool (no tools were selected or executed) for a task that requires tool-based processing, leading to incomp
2025-08-31 18:29:22,428 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:22,429 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool executions were performed and there is an Unknown error; there is no evidence of an incorrect tool choice, parameter misconfiguration, sequence mis
2025-08-31 18:29:28,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:28,393 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameters, sequence, or dependencies). The error message is generic ('Unknown error') with
2025-08-31 18:29:36,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:36,017 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and there is no observable agent decision data to attribute a specific error to (tool selection, parameter configuration, sequence o
2025-08-31 18:29:39,507 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:39,507 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and engage the required API integration tool(s); no tools were used and no steps were performed, effectively indicating
2025-08-31 18:29:49,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:49,362 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions or steps were executed for a task labeled basic_task. The agent did not initiate or follow any execution sequence, effectively failing 
2025-08-31 18:29:57,576 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:29:57,576 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The execution trace indicates an 'Unknown' tool was requested/used (Unknown (Error: Unknown)), suggesting the agent selected a non-existent or ina
2025-08-31 18:30:03,188 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:03,189 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error. The error is reported as Unknown error with no tool executions listed, so we cannot attribute it to tool se
2025-08-31 18:30:07,796 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:07,796 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Tool execution details show an 'Unknown' tool with an error, indicating the agent selected an invalid/unsupported tool for the task and no valid t
2025-08-31 18:30:14,192 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:14,193 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The agent delivered a partial solution due to incomplete/incorrect task configuration (missing or mis-specified parameters/constraints), causing
2025-08-31 18:30:18,152 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:18,153 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any appropriate tools to start the multi_stage_pipeline task, resulting in zero executed steps and no progres
2025-08-31 18:30:23,732 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:23,733 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Partial success indicates the agent did not follow the required workflow sequence for the simple_task, resulting in an incomplete/quality-issue ou

[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4173
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4167
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4167
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19242
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19242
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 21835
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21835
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.85
Progress: 90/100 (Success: 28)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4249
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4249
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4378
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4378
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.73
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò15‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=15, Êó∂Èó¥=126.7s, Âº∫Âà∂=False
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 15/15 ‰∏™ÁªìÊûú
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 44123
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=44123
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 47399
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=47399
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 39001
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=39001
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 37613
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=37613
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_selection_errors, confidence=0.92
[DEBUG] Got result for task: has_result=True, save_logs=False
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 40611
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=40611
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 36812
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=36812
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 4143
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4143
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=timeout_errors, confidence=0.85
Progress: 100/100 (Success: 35)
üíæ Êô∫ËÉΩCheckpoint: ‰øùÂ≠ò8‰∏™ÁªìÊûú...
   Ëß¶ÂèëÂéüÂõ†: Êï∞Èáè=8, Êó∂Èó¥=73.8s, Âº∫Âà∂=True
‚úÖ CheckpointÂÆåÊàê: ÊàêÂäü‰øùÂ≠ò 8/8 ‰∏™ÁªìÊûú

[INFO] Batch writing 100 records to database (Llama-3.3-70B-Instruct:100)
[INFO] Successfully wrote 100/100 records (Llama-3.3-70B-Instruct:100)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_182604.json
[SAVE_ENHANCED] ÂºÄÂßãÂ¢ûÂº∫‰øùÂ≠òÔºåÊó∂Èó¥: 18:26:04
[SAVE_ENHANCED] ‰ΩøÁî®Êñá‰ª∂ÈîÅÊú∫Âà∂‰øùÂ≠ò
[SAVE_ENHANCED] Êñá‰ª∂ÈîÅ‰øùÂ≠òÊàêÂäü

üìä Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] Ê≠£Âú®ÂÅúÊ≠¢ResultMerger...
[INFO] ÊâßË°åÊúÄÁªàÂêàÂπ∂...
[INFO] Enhanced manager: AIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî®
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.65) - No agent decision error detected. The task shows 0
[V3_UPDATE] ÂàõÂª∫Êñ∞promptÁ±ªÂûãÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot
[V3_UPDATE] ÂàõÂª∫Êñ∞Â∑•ÂÖ∑ÊàêÂäüÁéáÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8
[V3_UPDATE] ÂàõÂª∫Êñ∞ÈöæÂ∫¶ÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8 -> easy
[V3_UPDATE] ÂàõÂª∫Êñ∞‰ªªÂä°Á±ªÂûãÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8 -> easy -> api_integration
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 1)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.60) - No tools were executed and the error is reported a
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 2)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.72) - Error appears to be a generic system/API failure (2025-08-31 18:30:30,174 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:30,175 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed for the task (no required tools). The failure is not due to an agent decision (tool choice, parameters, sequence, or dep
2025-08-31 18:30:38,228 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:38,229 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were required or executed. The failure appears to be that the agent did not take any action for the simple task, rat

[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: dependency_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: dependency_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.72) - The agent did not select or invoke any tool for an
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 7)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: dependency_errors (confidence: 0.85) - The task had no defined requirements and no prereq
[V3_UPDATE] ÂàõÂª∫Êñ∞‰ªªÂä°Á±ªÂûãÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 1)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No agent-level decision error detected: there is n
[V3_UPDATE] ÂàõÂª∫Êñ∞‰ªªÂä°Á±ªÂûãÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: dependency_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.62) - Agent did not select or invoke any tools to proces
[V3_UPDATE] ÂàõÂª∫Êñ∞‰ªªÂä°Á±ªÂûãÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8 -> easy -> simple_task
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 1)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - No tools were selected or initialized to handle th
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.60) - Partial success with quality issues, and no clear 
[V3_UPDATE] ÂàõÂª∫Êñ∞‰ªªÂä°Á±ªÂûãÁªìÊûÑ: Llama-3.3-70B-Instruct -> cot -> 0.8 -> easy -> basic_task
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - Agent did not select or invoke any tool to progres
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: sequence_order_errors (confidence: 0.62) - Partial success with quality issues and no tools w
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 3)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No evidence of a specific agent decision error (to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 6)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.60) - No clear agent decision error can be identified fr
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 9)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.85) - No clear agent decision error can be identified fr
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 3)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: dependency_errors (confidence: 0.42) - The run produced an 'Unknown error' before any too
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.55) - Agent failed to engage any appropriate tool (no to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 5)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.85) - No tool executions were performed and there is an 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 11)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.62) - No evidence of a specific agent decision error (to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: sequence_order_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.62) - The execution trace indicates an 'Unknown' tool wa
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 7)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No evidence of a concrete agent decision error. Th
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.85) - Tool execution details show an 'Unknown' tool with
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: parameter_config_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.85) - No tools were selected or executed for the task (n
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.62)
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 20)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 12)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 11)
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 27)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 30)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.13s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 27)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 28)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 31)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 32)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 22)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 26)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 30)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 20)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 28)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 29)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 34)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 39)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 39)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 40)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 41)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 43)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors2025-08-31 18:30:44,698 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:44,698 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error. The task shows an Unknown error with no tool execution data, tool selections, parameters, or sequence infor
2025-08-31 18:30:54,024 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:30:54,024 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or select any tools, effectively failing to initiate the required workflow for a simple task. This inaction co
2025-08-31 18:31:00,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:00,775 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No defined task requirements or tools were provided (Required Tools: 0), and the error message is 'Unknown error.' This leaves no basis to assess any speci
2025-08-31 18:31:05,693 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:05,694 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be identified because the task required no tools (0/0 coverage) and no tools were executed. The error reported is 'Unknown error', 
2025-08-31 18:31:12,831 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:12,832 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute the failure to a specific agent decision. No tools were chosen or executed and the error is labeled Unknown error, so
2025-08-31 18:31:22,446 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:22,447 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error (tool choice, parameters, sequence, or dependencies) fits this case because the task requires no tools and there was inact
2025-08-31 18:31:28,118 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:28,119 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to establish and execute the required api_integration workflow: no tools were selected or executed, effectively skipping the nece
2025-08-31 18:31:31,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:31,393 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any required data processing tool (e.g., data_loader/pdf_reader) for the data_pipeline task, resulting in 0% to
2025-08-31 18:31:39,322 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:39,324 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or define any appropriate tool to begin the data_pipeline task, resulting in no actions taken. This is a tool-selection d
2025-08-31 18:31:44,883 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:44,883 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or use any appropriate tools for the data_pipeline task, leading to partial success; this is a tool-selection decision error 
2025-08-31 18:31:49,027 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:49,028 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (no tool selected/used, no incorrect parameters, and no incorrect sequence). The error message is generic/unknown, su
2025-08-31 18:31:54,433 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:31:54,434 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task, effectively resulting in no tool being used. This is a tool-selection decision error
2025-08-31 18:32:01,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:01,662 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Partial success with detected quality issues suggests the agent did not configure essential pipeline parameters or validation settings correctly
2025-08-31 18:32:06,304 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:06,305 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any appropriate tool for the api_integration task; no API client/tool was used, indicating a wrong tool choice/dec
2025-08-31 18:32:11,732 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:11,733 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent invoked tools (and even used 'Unknown' tools) despite there being no required tools defined for the task, indicating an incorrect tool choic
2025-08-31 18:32:17,799 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:17,800 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not choose or invoke any tool appropriate for a data_pipeline task (no required tools were selected/executed). This indicates a tool
2025-08-31 18:32:24,314 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:24,315 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or planned due to an undefined task context; the agent did not choose any tool (i.e., failed tool selection). This prevente
2025-08-31 18:32:33,231 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:33,232 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No workflow steps were executed; the agent failed to follow the required execution sequence for simple_task (no A‚ÜíB‚ÜíC steps completed), resulting 
2025-08-31 18:32:37,711 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:37,711 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Agent provided wrong or insufficient parameters for the data_pipeline tools, leading to degraded output quality and only partial success. This i
2025-08-31 18:32:43,562 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:43,563 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required API integration tooling but no tool was invoked. The agent did not select or initialize the necessary tool(s) for the integratio
2025-08-31 18:32:51,701 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:51,701 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a concrete agent decision error: no tools were selected/executed (Required Tools Coverage = 0%), the task is Unknown, and the error
2025-08-31 18:32:58,014 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:32:58,015 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision could be identified. The task shows an unknown error with no tools executed, and there is no evidence of wrong tool choice, in
2025-08-31 18:33:03,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:03,641 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task. This indicates a failure at the tool-selection step (wrong or missing tool choice),
2025-08-31 18:33:10,457 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:10,458 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not initiate or select any tools to execute the multi-stage pipeline, effectively omitting required tooling. In a multi_stage_pipeli
2025-08-31 18:33:17,073 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:17,074 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent did not execute any tools and did not establish or follow a workflow sequence, effectively neglecting required tool dependencies. This indicates
2025-08-31 18:33:23,049 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:23,049 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No execution sequence was defined or implemented; the agent did not perform any data pipeline steps (no tools invoked), indicating a missing/incor
2025-08-31 18:33:30,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:30,212 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or use any of the required tools; required tools coverage is 0% and tool execution details are unknown. This indicates a 
2025-08-31 18:33:35,098 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:35,098 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected or executed due to an unknown system-level error; there is no evidence of a wrong tool choice, incorrect parameters, improper sequence
2025-08-31 18:33:40,866 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:40,866 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not follow the required workflow sequence, leading to partial execution and quality issues instead of achieving full coverage. Steps
2025-08-31 18:33:45,130 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:45,130 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initiated for the api_integration task, resulting in 0% coverage and a complete failure. This is a decision error where 
2025-08-31 18:33:55,262 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:33:55,262 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of an agent decision error (no incorrect tool selection, parameters, sequence, or dependencies). The failure is reported as an Unknown
2025-08-31 18:34:02,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:02,886 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The task context shows 'Task: Unknown task' with no required tools and no tools executed. This indicates the agent failed to establish or resolve the 
2025-08-31 18:34:07,444 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:07,445 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage data and no clear evidence of an incorrect agent decision. The error message is generic ('Unknown error'), so it's not possible to attribute 

[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 41)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 39)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 45)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 43)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 47)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 43)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 46)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 46)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 49)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 49)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 37)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 43)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 49)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 41)
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 51)2025-08-31 18:34:14,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:14,753 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any required tool for the api_integration task; no tools were invoked, leading to complete failure.",
  "conf
2025-08-31 18:34:22,161 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:22,161 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tools for the multi_stage_pipeline task, resulting in zero tool usage and no execution steps. In a mult
2025-08-31 18:34:28,349 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:28,349 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to apply the required data_pipeline sequence; no tools were invoked, indicating omission or incorrect execution of sequential steps (
2025-08-31 18:34:34,961 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:34,962 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Tool execution encountered unknown errors (Unknown/Unknown) during execution, causing partial success. There is no evidence of incorrect agent decisions in
2025-08-31 18:34:40,111 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:40,112 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown/system-level failure occurred with no observable agent decisions (no tool selections, parameters, or sequence chosen). This is not a detected agent
2025-08-31 18:34:45,656 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:45,656 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task reported no required tools (0/0 coverage), yet the agent proceeded with a tool-based approach or tool choice inconsistent with the task (
2025-08-31 18:34:52,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:52,169 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any of the required data processing tools for the data_pipeline task, resulting in 0% tool coverage and an incomple
2025-08-31 18:34:58,091 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:34:58,091 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initiate any of the required tools for the multi-stage pipeline, effectively skipping needed stages (no tools executed)
2025-08-31 18:35:03,509 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:03,510 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: the task required no tools, so there was no tool selection, parameterization, sequencing, or dependency issue to attribut
2025-08-31 18:35:09,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:09,135 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for an unknown task, indicating a failure to choose an appropriate tool or tool approach. This lack of a proper
2025-08-31 18:35:14,905 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:14,905 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision is evidenced: no tools were selected or executed (0% coverage). The error message 'Unknown error' with an unknown task implies
2025-08-31 18:35:21,629 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:21,630 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and execute the required tools (tool coverage 0%), resulting in no proper tool usage and preventing the pipeline from proce
2025-08-31 18:35:26,925 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:26,926 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a faulty agent decision (tool choice, parameters, sequence, or dependencies) since there were no required tools and the failure is described
2025-08-31 18:35:36,616 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:36,616 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool required for the API integration task, effectively stopping progress. This is a wrong tool decision/om
2025-08-31 18:35:42,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:42,934 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error. The report shows partial success with quality issues but provides no details on tool 
2025-08-31 18:35:51,951 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:51,952 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "System-level unknown error occurred before any tool execution; no evidence of the agent choosing wrong tool, misconfiguring parameters, incorrect sequence,
2025-08-31 18:35:58,599 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:35:58,599 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a specific agent decision error (tool selection, parameter configuration, sequence order, or dependency handling) due to the absenc
2025-08-31 18:36:02,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:02,425 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or initialized to perform the (unknown) simple task. The agent failed to pick an appropriate tool from the available toolset,
2025-08-31 18:36:08,795 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:08,796 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected/executed for a data_pipeline task, indicating the agent failed to choose or initialize the required tooling (tool choice er
2025-08-31 18:36:15,806 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:15,806 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision errors detected: no tools were selected or executed, no parameters were provided, and no sequencing or dependency decisions to e
2025-08-31 18:36:22,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:22,912 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools (0 required). The agent's lack of action or any attempt to engage a tool would constitute selecting an inappropriate to
2025-08-31 18:36:30,738 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:30,738 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No concrete tool was selected or applied to address the (unknown) task, indicating a faulty tool-choice/strategy decision by the agent. The absenc
2025-08-31 18:36:39,126 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:39,128 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or used for the data_pipeline task, indicating a failure in the initial tool-selection decision by the agent (likely due to l
2025-08-31 18:36:48,626 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:48,627 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "There is no evidence of any tool usage or explicit tool selection in the execution trace (Required Tools Coverage = 0%, Executed Tools = none). Wi
2025-08-31 18:36:55,650 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:36:55,651 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Partial success with quality issues indicates the agent used incorrect or suboptimal configuration/parameters for the output generation (e.g., i
2025-08-31 18:37:00,371 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:00,371 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed and no required data_pipeline tool (e.g., data_loader/pdf_reader) was selected. The agent failed to choose or apply the app
2025-08-31 18:37:07,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:07,517 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Partial success with quality issues suggests the agent did not follow the intended evaluation/answer construction sequence for the basic_task; the
2025-08-31 18:37:12,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:12,529 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select a valid/defined tool for the task, leading to an unknown/tool execution path and partial output quality. The 'Unknown' ex
2025-08-31 18:37:21,066 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:21,067 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed due to an unknown task specification; this indicates a tool-selection decision error (either selecting an inappro
2025-08-31 18:37:25,584 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:25,584 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error message is generic 'Unknown error', suggesting a tool/infra failure rather than a wrong agent decision. There is no ev
2025-08-31 18:37:29,756 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:29,756 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The partial success with quality issues suggests the agent misconfigured tool parameters or settings (e.g., incorrect file paths, schema/thresho
2025-08-31 18:37:34,506 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:34,507 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any of the required tools for the multi_stage_pipeline (0/0 coverage). No tools were executed, effectively 
2025-08-31 18:37:38,937 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:38,938 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or configured for the api_integration task; the agent failed to pick an appropriate API client/tool (e.g., HTTP client) to 
2025-08-31 18:37:44,163 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:44,163 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No required tool(s) for the api_integration task were selected or invoked; tool coverage is 0% (0/0), indicating a failure in tool selection/trigg
2025-08-31 18:37:49,396 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:49,397 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is insufficient information to attribute a specific agent decision error. No tools were executed (execution details are missing) and the error messag
2025-08-31 18:37:54,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:37:54,622 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected; the failure appears to be an unknown/system-level error (no tools were executed). This is not attributable to tool select
2025-08-31 18:38:03,256 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:03,257 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed (tool coverage 0%), so there is no concrete agent decision error (tool choice, parameter, sequence, or dependency). The 
2025-08-31 18:38:09,567 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:09,568 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized to perform the multi_stage_pipeline. The agent did not choose any required tools or define the initial step,
2025-08-31 18:38:20,837 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:20,837 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The pipeline was not executed in the required sequential order (or some stages were skipped). Without performing the expected A‚ÜíB‚ÜíC progression (e
2025-08-31 18:38:31,002 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:31,002 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task presented with unknown requirements and yielded a partial success with quality issues, yet no tools were applied or a valid tooling workf

[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 47)
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 51)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.65) - No evidence of a specific agent decision error. Th
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 51)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.55) - No defined task requirements or tools were provide
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 49)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.85) - No agent decision could be identified because the 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 53)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.72) - Insufficient information to attribute the failure 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 43)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.62) - The agent did not select or define any appropriate
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 45)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85) - Agent did not select or use any appropriate tools 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 46)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.62) - No evidence of a wrong agent decision (no tool sel
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 55)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: parameter_config_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.65) - Agent invoked tools (and even used 'Unknown' tools
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 53)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85) - The agent did not choose or invoke any tool approp
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 49)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85) - No tools were selected or planned due to an undefi
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 57)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: parameter_config_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There is no evidence of a concrete agent decision 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 53)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.65) - No actionable agent decision could be identified. 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 55)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.56) - No tools were selected or executed for the data_pi
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 51)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: dependency_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 51)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.85) - The agent did not select or use any of the require
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 52)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.85) - No tool was selected or executed due to an unknown
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 59)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.10s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.75) - There is no evidence of an agent decision error (n
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 61)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: dependency_errors (confidence: 0.72) - The task context shows 'Task: Unknown task' with n
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 55)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.85) - No tool usage data and no clear evidence of an inc2025-08-31 18:38:35,669 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:35,669 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent attempted to invoke an unknown/unsupported tool for a task that requires no tools; wrong tool decision led to partial success (tool executio
2025-08-31 18:38:42,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:42,154 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no tool selections, configurations, or sequence actions performed due to an unknown/system-level error. Because no agent decisions were executed
2025-08-31 18:38:48,974 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:48,974 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not establish or follow a proper execution sequence for the basic_task, resulting in partial success with quality issues. No tools w
2025-08-31 18:38:55,063 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:38:55,065 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Partial success with quality issues suggests incorrect or suboptimal parameter settings/configuration in the data_pipeline (e.g., validation thr
2025-08-31 18:39:02,255 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:02,256 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No data pipeline steps were executed and there was no progressive sequence (A‚ÜíB‚ÜíC). The agent failed to initiate/sequence the required data ingest
2025-08-31 18:39:07,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:07,785 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown runtime error occurred with no tools selected or executed. There is no evidence of a wrong tool choice, incorrect parameters, improper sequence, or
2025-08-31 18:39:14,861 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:14,862 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a tool selection, parameter, sequence, or dependency error by the agent. The execution record contains no tools used and the error 
2025-08-31 18:39:20,212 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:20,213 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies); the failure is an unknown/internal error with no tool execution
2025-08-31 18:39:25,683 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:25,684 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select and invoke any API client/tool necessary for an api_integration task; no tools were executed, indicating a wrong initial tool
2025-08-31 18:39:31,747 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:31,747 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked to execute the multi_stage_pipeline task, halting the workflow at the initial stage; this indicates a wrong tool
2025-08-31 18:39:37,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:37,734 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool appropriate for the task, resulting in no progress. This indicates a wrong decision about tool usage (
2025-08-31 18:39:44,834 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:44,835 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected or executed (Required Tools Coverage 0%), so there is no agent decision path to evaluate for tool_selection_errors, parameter_config_e
2025-08-31 18:39:51,812 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:51,813 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error can be identified: there were no tools executed (empty execution plan) and the error message is Unknown. This appears to b
2025-08-31 18:39:57,619 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:39:57,619 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error (tool choice, parameterization, sequence, or dependencies). The failure is reported as an unknown/system-lev
2025-08-31 18:40:08,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:08,844 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "There were no required tools for this simple task, so no tool sequencing was necessary. The partial success stems from not delivering a complete, 
2025-08-31 18:40:14,994 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:14,994 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error detected. There were no required tools or parameters to select or configure, and no execution steps were performed. The co
2025-08-31 18:40:21,083 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:21,084 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or actions executed for the data_pipeline task. This effectively shows a tool selection/decision error by failing to pick a
2025-08-31 18:40:28,106 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:28,107 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The task context is unknown and no tools were executed, so there is no evidence of a wrong tool choice, incorrect parameters, or improper sequence. The fai
2025-08-31 18:40:34,205 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:34,205 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent invoked tooling despite the task requiring zero tools (0% coverage). The task did not need any tools, yet tool execution was attempted, indi
2025-08-31 18:40:39,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:39,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute a PRIMARY AGENT decision error: no tools were selected/executed and the error is reported as Unknown. This appears to
2025-08-31 18:40:45,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:45,020 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision was made to perform the basic_task; there were 0 required tools (0/0). The task failed due to inaction rather than a tool select
2025-08-31 18:40:50,681 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:50,682 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No wrong agent decision detected: The task required no tools (0/0 coverage) and no tools were executed. Partial success appears to be due to quality issues
2025-08-31 18:40:54,981 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:40:54,981 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and initiate any of the necessary data-pipeline tools (e.g., data_loader, pdf_reader) or to define a workable sequence.
2025-08-31 18:41:00,232 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:00,233 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or used despite a task that requires tooling; the agent failed to pick the appropriate tool (or any tool), resulting in zer
2025-08-31 18:41:07,470 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:07,471 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to handle the data_pipeline task (no required tools identified or chosen), indicating a failure at the too
2025-08-31 18:41:13,075 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:13,075 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent-made decisions (tool selection, parameter config, sequence, or dependency handling) due to absence of tool execution data; error appea
2025-08-31 18:41:22,357 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:22,358 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent ignored logical workflow dependencies by not selecting or executing any tools, effectively breaking the required task sequence and producing
2025-08-31 18:41:29,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:29,169 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tools for the data_pipeline task, effectively choosing 'no tool' instead of the required tooling. This indicate
2025-08-31 18:41:34,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:34,013 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or configure any tools suitable for the API integration task; no tools were executed and no workflow plan was defined, indica
2025-08-31 18:41:39,794 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:39,794 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Tool execution failed due to an unknown/tool-level error during execution; there is no evidence of incorrect agent tool choice, parameter configuration, se
2025-08-31 18:41:44,804 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:44,805 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error indicates a system/tool failure outside agent decision; there is no evidence of incorrect tool selection, parameterization, sequencing, or de
2025-08-31 18:41:52,443 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:52,443 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error: the task required no tools (0/0), no parameters were configured, and no execution sequence occurred. The er
2025-08-31 18:41:57,741 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:41:57,741 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameter usage, sequence, or dependencies). The task indicates zero required tools and the
2025-08-31 18:42:01,994 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:01,995 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tools for the multi_stage_pipeline task, effectively skipping necessary stages (e.g., data_loader foll
2025-08-31 18:42:10,714 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:10,714 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps nor follow any execution sequence for the simple_task. There was no tool usage and no workflow executed, indic
2025-08-31 18:42:18,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:18,113 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or initialize any required tooling for the data_pipeline task; no tools were executed (required tools coverage 0%), ind
2025-08-31 18:42:25,683 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:25,684 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a misstep by the agent (no wrong tool chosen, incorrect parameters, wrong sequence, or missing dependencies). The error message is generic (
2025-08-31 18:42:32,499 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:32,499 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or an inappropriate tool was implicitly chosen for an api_integration task with unknown requirements, resulting in 0% tool us
2025-08-31 18:42:36,002 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:36,003 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or activate any required data_pipeline tools; no tools were executed, resulting in 0% coverage. This indicates a faulty i
2025-08-31 18:42:42,009 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:42,010 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any required tool(s) for the multi-stage pipeline, effectively omitting necessary steps. This omission constitu
2025-08-31 18:42:49,444 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:49,445 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any required API integration tool; no tools were used (0% coverage). This indicates a wrong/absent tool cho

[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 53)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.63)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: sequence_order_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.85) - Tool execution encountered unknown errors (Unknown
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 55)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - Unknown/system-level failure occurred with no obse
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 57)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.65) - The task reported no required tools (0/0 coverage)
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 57)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.85) - No tools were selected or executed for an unknown 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 55)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.72) - No actionable agent decision is evidenced: no tool
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 63)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - Agent failed to select and execute the required to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 59)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.75) - System-level unknown error occurred before any too
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 57)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.55) - There is no evidence of a specific agent decision 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 61)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.85) - No tool was selected or initialized to perform the
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 59)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.62) - No concrete tool was selected or applied to addres
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 57)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.65) - No tool was selected or used for the data_pipeline
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 59)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.45) - There is no evidence of any tool usage or explicit
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 58)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: parameter_config_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: sequence_order_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.72) - The agent did not select a valid/defined tool for 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 61)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - No tool was selected or executed due to an unknown
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 63)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.80) - No tools were executed and the error message is ge
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 65)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: parameter_config_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85) - No required tool(s) for the api_integration task w
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 67)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There is insufficient information to attribute a s
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 65)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision error detected; the failure appe
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 66)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.45) - The task presented with unknown requirements and y
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 61)2025-08-31 18:42:55,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:42:55,480 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Partial success with quality issues suggests the agent executed steps in a suboptimal or illogical order, failing to respect the implied workflow/
2025-08-31 18:43:00,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:00,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error can be identified from the available logs. The failure appears to stem from task ambiguity/unknown task and lack of action
2025-08-31 18:43:09,723 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:09,724 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No clear agent decision error detected: tool_selection_errors, parameter_config_errors, sequence_order_errors, and dependency_errors are not evidenced. The
2025-08-31 18:43:19,869 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:19,869 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "no_agent_error",
  "reason": "There were zero required tools (tool coverage 0/0). The partial success is due to output quality, not a mistake in tool choice, parameter configuration, 
2025-08-31 18:43:19,870 - focused_ai_classifier - WARNING - Unknown category from AI: no_agent_error, defaulting to OTHER
2025-08-31 18:43:24,985 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:24,986 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or explicit agent decision details were provided; with 0% tool coverage and only 'Partial success - quality issues detected' there is insuffi
2025-08-31 18:43:30,891 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:30,891 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Partial success with quality issues suggests the data_pipeline was executed with misconfigured or incorrect parameters (e.g., wrong file paths, 
2025-08-31 18:43:36,320 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:36,320 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameter configuration, sequence order, or dependencies). The error is a generic 'Unknown 
2025-08-31 18:43:41,057 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:41,057 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not identify or select any appropriate tool for the (unknown) data_pipeline task, effectively abstaining from action. This is a wron
2025-08-31 18:43:48,680 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:48,681 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to handle the api_integration task; there was no progress because of an attempted halt at the tool-sel
2025-08-31 18:43:54,648 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:43:54,649 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools (e.g., API client or HTTP requester) were selected or invoked for the api_integration task. The agent failed to pick the appropriate tool
2025-08-31 18:44:00,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:00,201 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were executed and no data flow occurred, indicating the agent failed to establish or respect necessary tool dependencies (e.g., load ‚Üí transf
2025-08-31 18:44:08,536 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:08,537 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools or steps were executed, indicating the workflow did not proceed along the expected sequence for the API integration task (A‚ÜíB‚ÜíC). The age
2025-08-31 18:44:16,568 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:16,570 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no tool selections or executions to judge (required tools coverage is 0%), and the error message is Unknown error. This indicates a system-level
2025-08-31 18:44:24,967 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:24,968 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error detected. The failure appears to be a tool/system issue (Unknown error) rather than a wrong tool choice, incorrect paramet
2025-08-31 18:44:31,521 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:31,522 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision: no tools were selected or executed, no parameters were configured, and no execution sequence was performed. The
2025-08-31 18:44:36,991 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:36,991 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the api_integration task, leading to complete failure. This is a tool selection error: the agent failed to c
2025-08-31 18:44:41,620 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:41,620 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the multi_stage_pipeline task; the agent failed to choose and invoke the required tools, leading to complet
2025-08-31 18:44:48,803 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:48,804 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tools for the multi_stage_pipeline; no tools were executed and no processing steps defined, effectively omi
2025-08-31 18:44:55,326 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:44:55,326 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or specify any appropriate tool for the unknown/basic task (no tools executed), leading to an incomplete outcome and only par
2025-08-31 18:45:03,576 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:03,577 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute a specific agent decision error. The log shows 'Partial success - quality issues detected' with Tool Execution Detail
2025-08-31 18:45:09,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:09,502 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence: no tools were selected or invoked, no parameters set, and no sequence decisions documented. The error is unknown and cannot be 
2025-08-31 18:45:16,369 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:16,369 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision error can be identified from the provided data. There were no tools used (required tools coverage 0%), and the partial success
2025-08-31 18:45:26,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:26,855 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or invoke any tool appropriate for a basic_task, resulting in no concrete execution steps and only partial (quality) output
2025-08-31 18:45:33,367 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:33,368 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not establish or execute the required multi-stage pipeline in the correct order, resulting in no tools being invoked. There is no ev
2025-08-31 18:45:43,526 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:43,527 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked; the agent did not choose any tool appropriate to address the unknown task, resulting in partial output quality.
2025-08-31 18:45:53,890 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:45:53,890 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools (required tool list is empty), yet the failure occurred with an Unknown error and no tools were executed. This suggests
2025-08-31 18:46:03,525 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:03,525 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actionable steps or tools were executed, effectively bypassing the intended workflow sequence for a simple task. The agent chose to take zero a
2025-08-31 18:46:09,545 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:09,547 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error is evidenced: there were zero required tools (coverage 0/0), and the partial success appears to be due to output quality r
2025-08-31 18:46:15,218 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:15,218 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked for a task that requires tooling; the agent failed to choose the appropriate tool (or any tool) to perform the sim
2025-08-31 18:46:24,389 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:24,391 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task achieved partial success due to missing or misapplied quality-control steps in the execution sequence; the workflow did not include the n
2025-08-31 18:46:34,239 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:34,239 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit evidence of a concrete agent decision error (no clear wrong tool choice, incorrect parameters, wrong sequence, or missing dependencies) is prov
2025-08-31 18:46:42,315 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:42,315 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task was unknown and no tools were chosen or invoked. The agent should have requested clarification or selected an appropriate tool to proceed
2025-08-31 18:46:51,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:46:51,912 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: no tools were required or used, and there is no evidence of wrong tool choice, incorrect parameters, incorrect sequencing
2025-08-31 18:47:01,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:47:01,209 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and there is no explicit error message. There is no evidence of a concrete agent decision (tool selection, parameter con
2025-08-31 18:47:07,415 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:47:07,416 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The partial success with detected quality issues suggests the agent used suboptimal or incorrect parameters during the pipeline execution, leadi
2025-08-31 18:47:13,206 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 18:47:13,207 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a concrete agent decision error (no tool was selected/executed, no parameters set, and no sequence established). The error message 
2025-08-31 18:47:13,207 - result_merger - INFO - Ê®°ÂûãLlama-3.3-70B-Instruct‰øùÂ≠ò200/200Êù°ËÆ∞ÂΩï
2025-08-31 18:47:13,209 - result_merger - INFO - ÂêàÂπ∂ÂÆåÊàêÔºåÂÖ±Â§ÑÁêÜ101‰∏™Êñá‰ª∂Ôºå‰øùÂ≠ò200Êù°ËÆ∞ÂΩï
2025-08-31 18:47:13,210 - batch_test_runner - INFO - ‚úÖ Â≠òÂÇ®ÈÄÇÈÖçÂô®ËµÑÊ∫êÊ∏ÖÁêÜÂÆåÊàê
2025-08-31 18:47:13,213 - batch_test_runner - INFO - üîö Â≠êËøõÁ®ãÊµãËØïÂÆåÊàêÔºå‰∏ªÂä®ÈÄÄÂá∫

[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85) - Agent attempted to invoke an unknown/unsupported t
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 63)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.85) - There were no tool selections, configurations, or 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 64)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: parameter_config_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.75) - Unknown runtime error occurred with no tools selec
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 69)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There is no evidence of a tool selection, paramete
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 69)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.65) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 61)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.85) - No tool was selected or executed (Required Tools C
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 63)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.60) - No concrete agent decision error can be identified
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 63)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.85) - No evidence of a concrete agent decision error (to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 67)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.40)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.85) - The task context is unknown and no tools were exec
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 65)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.72) - Agent invoked tooling despite the task requiring z
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 66)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.65) - Insufficient information to attribute a PRIMARY AG
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 69)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.85) - No tools were selected or used despite a task that
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 65)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.60) - Agent did not select or invoke any tool to handle 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 71)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.85) - No evidence of agent-made decisions (tool selectio
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 71)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.85) - Tool execution failed due to an unknown/tool-level
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 67)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - Unknown error indicates a system/tool failure outs
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 71)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.72) - No evidence of a concrete agent decision error: th
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 68)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.60) - The agent failed to select or initialize any requi
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 73)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No evidence of a misstep by the agent (no wrong to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 73)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.72) - No tool was selected or an inappropriate tool was 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 73)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.65) - Partial success with quality issues suggests the a
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 71)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.72) - No concrete agent decision error can be identified
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 69)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: other_errors (confidence: 0.70) - No clear agent decision error detected: tool_selec
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 75)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.20)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: parameter_config_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.72) - No evidence of a specific agent decision error (to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 75)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: tool_selection_errors (confidence: 0.85) - The agent did not identify or select any appropria
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 77)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.70) - The agent did not select or invoke any tool to han
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 76)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct data_pipeline: dependency_errors (confidence: 0.45)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct api_integration: other_errors (confidence: 0.62) - There were no tool selections or executions to jud
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> api_integration (total: 79)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.78) - No concrete agent decision error detected. The fai
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 75)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There is no evidence of any agent decision: no too
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 76)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.80)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.65) - Agent did not select or specify any appropriate to
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 71)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.62) - Insufficient information to attribute a specific a
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 72)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No agent decision evidence: no tools were selected
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> multi_stage_pipeline (total: 79)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.66)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.62) - No tools were selected or invoked; the agent did n
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 75)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.40) - The task required no tools (required tool list is 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 73)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.62) - No actionable steps or tools were executed, effect
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 74)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Time-based flush (30.1s since last flush)...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: tool_selection_errors (confidence: 0.76)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 77)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.85) - No explicit evidence of a concrete agent decision 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 77)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct basic_task: tool_selection_errors (confidence: 0.72) - The task was unknown and no tools were chosen or i
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> basic_task (total: 78)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] Llama-3.3-70B-Instruct basic_task: other_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct data_pipeline: parameter_config_errors (confidence: 0.65) - The partial success with detected quality issues s
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> data_pipeline (total: 79)
[AI-CLASSIFY-NEW] Llama-3.3-70B-Instruct simple_task: other_errors (confidence: 0.72) - There is no evidence of a concrete agent decision 
[V3_UPDATE] Êõ¥Êñ∞ÁªüËÆ°ÂÆåÊàê: Llama-3.3-70B-Instruct -> cot -> simple_task (total: 79)
[INFO] ÊúÄÁªàÂêàÂπ∂ÂÆåÊàê: 101 ‰∏™Êñá‰ª∂
2025-08-31 18:47:13,363 - smart_result_collector - INFO - SmartResultCollector Ê≠£Âú®ÂÖ≥Èó≠...
2025-08-31 18:47:13,363 - smart_result_collector - INFO - SmartResultCollector Â∑≤ÂÖ≥Èó≠
INFO:__main__:‚úÖ ÂàÜÁâá Llama-3.3-70B-Instruct_easy_0 ÂÆåÊàê
INFO:__main__:
üìä Âπ∂Ë°åÊµãËØïÂÆåÊàê
INFO:__main__:   ÊàêÂäü: 1/1 ‰∏™ÂàÜÁâá
INFO:__main__:   ÊÄªËÄóÊó∂: 2146.3Áßí
INFO:__main__:   ÁêÜËÆ∫Âä†ÈÄüÊØî: 1x
INFO:__main__:ÊúÄÁªàÂà©Áî®Áéá: 0.0%
=== ÊµãËØïÁªìÊùüÊó∂Èó¥: 2025Âπ¥ 8Êúà31Êó• ÊòüÊúüÊó• 18Êó∂47ÂàÜ16Áßí EDT ===
=== ÊµãËØïÁî®Êó∂: 2147Áßí ===
