===== åˆ†ç‰‡ qwen2.5-14b-instruct_very_easy_key0 =====
æ—¶é—´: 2025-08-27T16:06:54.596420
æ¨¡å‹: qwen2.5-14b-instruct
å®ä¾‹: qwen-key0
å‘½ä»¤: python -u smart_batch_runner.py --model qwen2.5-14b-instruct --deployment qwen-key0 --prompt-types optimal --difficulty very_easy --task-types all --num-instances 10 --max-workers 2 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
ç¯å¢ƒå˜é‡:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[16:06:57.948] 
[16:06:57.960] A module that was compiled using NumPy 1.x cannot be run in
[16:06:57.960] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[16:06:57.960] versions of NumPy, modules must be compiled with NumPy 2.0.
[16:06:57.960] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[16:06:57.960] 
[16:06:57.960] If you are a user of the module, the easiest solution will be to
[16:06:57.960] downgrade to 'numpy<2' or try to upgrade the affected module.
[16:06:57.960] We expect that some modules will need time to support NumPy 2.
[16:06:57.960] 
[16:06:57.960] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[16:06:57.960]     from batch_test_runner import BatchTestRunner, TestTask
[16:06:57.960]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[16:06:57.960]     from mdp_workflow_generator import MDPWorkflowGenerator
[16:06:57.960]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[16:06:57.960]     import torch
[16:06:57.960]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[16:06:57.960]     from .functional import *  # noqa: F403
[16:06:57.960]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[16:06:57.960]     import torch.nn.functional as F
[16:06:57.960]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[16:06:57.960]     from .modules import *  # noqa: F403
[16:06:57.960]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[16:06:57.960]     from .transformer import TransformerEncoder, TransformerDecoder, \
[16:06:57.960]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[16:06:57.960]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[16:06:57.961] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[16:06:57.962]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[16:06:59.381] 2025-08-27 16:06:59,379 - faiss.loader - INFO - Loading faiss.
[16:06:59.481] 2025-08-27 16:06:59,480 - faiss.loader - INFO - Successfully loaded faiss.
[16:07:01.220] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[16:07:01.222] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[16:07:02.170] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[16:07:02.171] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[16:07:02.174] 
[16:07:02.174] ============================================================
[16:07:02.174] æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-14b-instruct (idealab)
[16:07:02.174] Prompt types: ['optimal']
[16:07:02.174] éš¾åº¦: very_easy
[16:07:02.174] ç›®æ ‡: æ¯ç§é…ç½® 10 ä¸ªå®ä¾‹
[16:07:02.174] ============================================================
[16:07:02.177] â—‹ simple_task         :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[16:07:02.179] â—‹ basic_task          :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[16:07:02.182] â—‹ data_pipeline       :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[16:07:02.184] â—‹ api_integration     :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[16:07:02.186] â—‹ multi_stage_pipeline:   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[16:07:02.186] 
[16:07:02.186] â³ éœ€è¦è¿è¡Œ 50 ä¸ªæ–°æµ‹è¯•
[16:07:02.186] 
[16:07:02.186] â–¶ å‡†å¤‡ simple_task (10 ä¸ªå®ä¾‹)...
[16:07:02.186] 
[16:07:02.187] â–¶ å‡†å¤‡ basic_task (10 ä¸ªå®ä¾‹)...
[16:07:02.187] 
[16:07:02.187] â–¶ å‡†å¤‡ data_pipeline (10 ä¸ªå®ä¾‹)...
[16:07:02.187] 
[16:07:02.187] â–¶ å‡†å¤‡ api_integration (10 ä¸ªå®ä¾‹)...
[16:07:02.187] 
[16:07:02.187] â–¶ å‡†å¤‡ multi_stage_pipeline (10 ä¸ªå®ä¾‹)...
[16:07:02.187] 
[16:07:02.187] â–¶ å¼€å§‹æ‰§è¡Œ 50 ä¸ªæµ‹è¯•...
[16:07:02.187] ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
[16:07:02.187] ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
[16:07:02.187] âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
[16:07:02.188] 2025-08-27 16:07:02,188 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
[16:07:02.189] 2025-08-27 16:07:02,188 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
[16:07:02.189] 2025-08-27 16:07:02,188 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
[16:07:02.189] ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[16:07:02.192] 2025-08-27 16:07:02,192 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
[16:07:02.329] 2025-08-27 16:07:02,328 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[16:07:02.329] [AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7f8b23089570>
[16:07:02.329] 2025-08-27 16:07:02,328 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
[16:07:02.329] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[16:07:02.329] 2025-08-27 16:07:02,329 - batch_test_runner - INFO - ============================================================
[16:07:02.330] 2025-08-27 16:07:02,329 - batch_test_runner - INFO - Batch test runner initialized
[16:07:02.330] 2025-08-27 16:07:02,330 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[16:07:02.330] 2025-08-27 16:07:02,330 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_160702.log
[16:07:02.330] 2025-08-27 16:07:02,330 - batch_test_runner - INFO - ============================================================
[16:07:02.330] 2025-08-27 16:07:02,330 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[16:07:02.330] 2025-08-27 16:07:02,330 - batch_test_runner - INFO - Initializing test components...
[16:07:05.077] 2025-08-27 16:07:05,076 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[16:07:05.077] 2025-08-27 16:07:05,077 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[16:07:05.077] 2025-08-27 16:07:05,077 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
[16:07:05.079] [DEBUG] Creating new ToolCapabilityManager instance
[16:07:05.079] [OperationEmbeddingIndex] Initializing with unified API client manager
[16:07:05.079] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[16:07:05.080] 2025-08-27 16:07:05,080 - api_client_manager - INFO - Loaded configuration from config/config.json
[16:07:05.098] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[16:07:05.098] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[16:07:05.098] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[16:07:06.073] 2025-08-27 16:07:06,071 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[16:07:06.103] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[16:07:06.212] [INFO] Loaded 4150 embeddings from persistent cache
[16:07:06.213] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[16:07:06.213] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[16:07:06.226] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[16:07:06.226] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[16:07:06.234] [INFO] Successfully loaded FAISS index with dimension 3072
[16:07:06.234] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[16:07:06.235] [INFO] Loaded 15 operations with dimension 3072
[16:07:06.235] [INFO] Successfully loaded cached index
[16:07:06.241] [INFO] Operation semantic index initialized
[16:07:06.250] [INFO] Using device: cpu
[16:07:06.253] [INFO] Initialized tool success tracking attributes
[16:07:06.253] [INFO] Initializing embedding manager for enhanced tool selection
[16:07:06.253] [MCPEmbeddingManager] Creating new singleton instance
[16:07:06.253] [MCPEmbeddingManager] Initializing with unified API client manager
[16:07:06.301] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[16:07:06.301] [MCPEmbeddingManager] Client initialized successfully
[16:07:06.302] 2025-08-27 16:07:06,301 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[16:07:06.538] 2025-08-27 16:07:06,538 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[16:07:10.304] 2025-08-27 16:07:10,301 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[16:07:10.305] 2025-08-27 16:07:10,303 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[16:07:10.428] 2025-08-27 16:07:10,428 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[16:07:10.627] 2025-08-27 16:07:10,627 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[16:07:59.113] 2025-08-27 16:07:59,083 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[16:07:59.131] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[16:07:59.132] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[16:07:59.134] 2025-08-27 16:07:59,115 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[16:07:59.667] 2025-08-27 16:07:59,666 - mcp_embedding_manager - INFO - FAISS index loaded
[16:07:59.668] 2025-08-27 16:07:59,667 - mcp_embedding_manager - INFO - Updated dimension to 3072
[16:07:59.668] 2025-08-27 16:07:59,667 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[16:07:59.690] [SUCCESS] Loaded 30 tool embeddings
[16:07:59.691] 2025-08-27 16:07:59,691 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[16:07:59.691] [SUCCESS] Embedding manager initialized with 30 tools
[16:07:59.691] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[16:07:59.691] [INFO] Loading full MCP protocol registry...
[16:07:59.722] 2025-08-27 16:07:59,722 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[16:07:59.724] [INFO] Loaded full tool registry with 30 tools
[16:07:59.751] 2025-08-27 16:07:59,724 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[16:07:59.759] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[16:07:59.768] [INFO] Embedding manager ready with 30 tools
[16:07:59.768] [WARNING] Embedding manager exists but has no embeddings
[16:07:59.772] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[16:07:59.875] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[16:07:59.877] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[16:07:59.877] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[16:07:59.880] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[16:07:59.886] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[16:07:59.886] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[16:07:59.886] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[16:07:59.888] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[16:07:59.888] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[16:07:59.888] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[16:07:59.888] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[16:07:59.888] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[16:07:59.890] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[16:07:59.892] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[16:07:59.895] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[16:07:59.897] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[16:07:59.898] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[16:07:59.898] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[16:07:59.898] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[16:07:59.901] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[16:07:59.903] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[16:07:59.903] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[16:07:59.903] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[16:07:59.903] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[16:07:59.903] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[16:07:59.903] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[16:07:59.903] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[16:07:59.906] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[16:07:59.906] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[16:07:59.906] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[16:07:59.906] 2025-08-27 16:07:59,906 - mdp_workflow_generator - INFO - Loaded 30 tools
[16:07:59.906] [INFO] Setting default state_dim based on loaded tools
[16:07:59.906] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[16:07:59.906] 2025-08-27 16:07:59,906 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[16:07:59.906] [INFO] Setting default action_dim based on loaded tools
[16:07:59.906] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[16:07:59.906] 2025-08-27 16:07:59,906 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[16:07:59.906] [INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[16:07:59.906] [INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[16:07:59.906] [INFO] âš¡ Will use pre-generated workflows or random policy
[16:07:59.906] 2025-08-27 16:07:59,906 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[16:07:59.906] [INFO] Initializing TaskManager...
