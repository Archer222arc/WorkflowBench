[1;33m[WARNING][0m ⚠️ 未找到conda环境，使用系统Python
[0;34m[INFO][0m === 5.3 缺陷工作流测试脚本启动 ===
[0;34m[INFO][0m 时间戳: 20250829_004828
[0;34m[INFO][0m 日志文件: /Users/ruicheng/Documents/GitHub/WorkflowBench/logs/test_5_3_custom_20250829_004828.log
[0;34m[INFO][0m 检查环境和依赖文件...
[0;32m[SUCCESS][0m 所有必需文件检查完成
[0;34m[INFO][0m 获取用户选择...
[0;34m[INFO][0m 用户选择的缺陷类型: flawed_sequence_disorder
[0;34m[INFO][0m 选择开源模型进行测试
[0;34m[INFO][0m 开始执行 5.3 缺陷工作流测试
[0;34m[INFO][0m 缺陷类型数: 1
[0;34m[INFO][0m 测试模型数: 8
[0;34m[INFO][0m 总测试组合: 8
[0;34m[INFO][0m 模型配置: opensource
[0;34m[INFO][0m 并发配置: 50 workers, 10 processes
[0;34m[INFO][0m 存储配置: JSON + ResultCollector
[0;34m[INFO][0m 🚀 开始测试 - 缺陷类型: flawed_sequence_disorder
[0;34m[INFO][0m 进度: 1/8 - 测试模型: DeepSeek-V3-0324
[0;34m[INFO][0m 🚀 开始测试 - 模型: DeepSeek-V3-0324, 缺陷类型: flawed_sequence_disorder
[0;34m[INFO][0m 执行命令: USE_RESULT_COLLECTOR='true' STORAGE_FORMAT='json' KMP_DUPLICATE_LIB_OK=TRUE python3 ./ultra_parallel_runner.py --model DeepSeek-V3-0324 --prompt-types flawed_sequence_disorder --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 50
[0;32m[SUCCESS][0m ✅ 模型 DeepSeek-V3-0324 测试完成
[0;34m[INFO][0m 详细日志: /Users/ruicheng/Documents/GitHub/WorkflowBench/logs/ultra_parallel_DeepSeek_V3_0324_flawed_sequence_disorder_20250829_004828.log
[0;34m[INFO][0m 日志行数:      137
[0;34m[INFO][0m 等待 3 秒后测试下一个模型...
[0;34m[INFO][0m 进度: 2/8 - 测试模型: DeepSeek-R1-0528
[0;34m[INFO][0m 🚀 开始测试 - 模型: DeepSeek-R1-0528, 缺陷类型: flawed_sequence_disorder
[0;34m[INFO][0m 执行命令: USE_RESULT_COLLECTOR='true' STORAGE_FORMAT='json' KMP_DUPLICATE_LIB_OK=TRUE python3 ./ultra_parallel_runner.py --model DeepSeek-R1-0528 --prompt-types flawed_sequence_disorder --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 50
[0;32m[SUCCESS][0m ✅ 模型 DeepSeek-R1-0528 测试完成
[0;34m[INFO][0m 详细日志: /Users/ruicheng/Documents/GitHub/WorkflowBench/logs/ultra_parallel_DeepSeek_R1_0528_flawed_sequence_disorder_20250829_004828.log
[0;34m[INFO][0m 日志行数:       69
[0;34m[INFO][0m 等待 3 秒后测试下一个模型...
[0;34m[INFO][0m 进度: 3/8 - 测试模型: Llama-3.3-70B-Instruct
[0;34m[INFO][0m 🚀 开始测试 - 模型: Llama-3.3-70B-Instruct, 缺陷类型: flawed_sequence_disorder
[0;34m[INFO][0m 执行命令: USE_RESULT_COLLECTOR='true' STORAGE_FORMAT='json' KMP_DUPLICATE_LIB_OK=TRUE python3 ./ultra_parallel_runner.py --model Llama-3.3-70B-Instruct --prompt-types flawed_sequence_disorder --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 50
[0;32m[SUCCESS][0m ✅ 模型 Llama-3.3-70B-Instruct 测试完成
[0;34m[INFO][0m 详细日志: /Users/ruicheng/Documents/GitHub/WorkflowBench/logs/ultra_parallel_Llama_3_3_70B_Instruct_flawed_sequence_disorder_20250829_004828.log
[0;34m[INFO][0m 日志行数:       69
[0;34m[INFO][0m 等待 3 秒后测试下一个模型...
[0;34m[INFO][0m 进度: 4/8 - 测试模型: qwen2.5-72b-instruct
[0;34m[INFO][0m 🚀 开始测试 - 模型: qwen2.5-72b-instruct, 缺陷类型: flawed_sequence_disorder
[0;34m[INFO][0m 执行命令: USE_RESULT_COLLECTOR='true' STORAGE_FORMAT='json' KMP_DUPLICATE_LIB_OK=TRUE python3 ./ultra_parallel_runner.py --model qwen2.5-72b-instruct --prompt-types flawed_sequence_disorder --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 1
[0;31m[ERROR][0m ❌ 模型 qwen2.5-72b-instruct 测试失败 (退出码: 143)
[0;31m[ERROR][0m 检查日志: /Users/ruicheng/Documents/GitHub/WorkflowBench/logs/ultra_parallel_qwen2_5_72b_instruct_flawed_sequence_disorder_20250829_004828.log
[0;31m[ERROR][0m === 最后50行日志内容 ===
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=23890
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [SEARCH] Query: file reader
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50a0f7d5-df1f-989b-9e74-f79e370cab2a"}, traceId: 2150452b17564433231662008e778a'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"986d875e-2a27-9047-b8df-6ba4bb532b5a"}, traceId: 215044eb17564433269043619e7f91'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e2a7423-e52f-9191-9c3f-2752ed16def0"}, traceId: 2150452b17564433276732019e778a'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...2025-08-29 00:55:50,526 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:55:51,955 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:55:52,991 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:55:53,232 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:55:53,770 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:55:53,841 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   === 测试结束时间: 2025年 8月29日 星期五 00时55分54秒 EDT ===
[0;31m[ERROR][0m   === 退出码: 143 ===
[0;31m[ERROR][0m === 日志结束 ===
[0;31m[ERROR][0m === Python错误traceback ===
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"40eb97d6-7cd4-9c70-a8df-567ae99bf814"}, traceId: 2150459f17564429354002875e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9655c30-effc-99ee-bbf2-896615bb0fbe"}, traceId: 2150417917564429367995435eed45'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [SEARCH] Query: data processing parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dc6f565c-6afc-9d48-bd6a-417b766406b1"}, traceId: 2150459f17564429388142898e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0bba24f9-9b3a-995e-b66f-ef14757d3c79"}, traceId: 2150417917564429408475449eed45'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91597d91-46f6-96f2-958f-c81694610e21"}, traceId: 2150417917564429428475465eed45'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a52c516d-4a68-94b3-9373-e802328504a7"}, traceId: 2150417917564429448675475eed45'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0747d54f-4ec3-93eb-bbfb-909d3ff31911"}, traceId: 2150417917564429468845480eed45'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98f2cf42-0b1a-9781-b034-383c5fd20539"}, traceId: 2150459f17564429473862953e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"14e95af7-7302-918e-8dc9-086fca0a1a3a"}, traceId: 2150459f17564429488992959e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...2025-08-29 00:49:31,017 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:49:31,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:32,036 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:49:33,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:34,002 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:34,179 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:49:35,259 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:36,254 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:36,674 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:49:37,250 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:38,516 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:38,970 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:49:40,158 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:40,989 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:49:41,034 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:42,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:43,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:44,182 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:45,013 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:49:45,298 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"49329de8-8cb8-95dd-8bb1-5b3be62d5562"}, traceId: 2150415b17564429530672735ee3ef'}
[0;31m[ERROR][0m   [ERROR] Max retries reached after 5 attempts
[0;31m[ERROR][0m   [API_FAILURE] All retries exhausted
[0;31m[ERROR][0m     [API_FAILURE] API failed (timeout or max retries)
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 14323
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=14323
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea327505-988d-97ba-82f5-d6c5ffdac35a"}, traceId: 2150459f17564429544802977e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4238cdfe-3467-9345-8e23-aa40dd5d7740"}, traceId: 2150409517564429555085697eece3'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e678e059-bc40-90f7-972c-5825b5588369"}, traceId: 2150459f17564429565802984e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ee04bba-9d85-94a1-b103-8542de0e1d0c"}, traceId: 2150416717564429591955752eed70'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"74a6bff9-5b0d-9e3c-a60b-3038a2ba5985"}, traceId: 2150459f17564429594513005e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b7c5d28-1013-90c0-a069-c4d9dfb38d46"}, traceId: 215041d717564429621072740e346d'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efd0da15-e5e7-97c6-9fca-2d827250e8d9"}, traceId: 2150459f17564429624893020e7f75'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e9edaef-fe5c-9861-962c-0d043169e6d9"}, traceId: 215040ed17564429647281886ebe48'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b207be7b-03f4-936a-8748-86a27a561c6c"}, traceId: 2150459f17564429654953033e7f75'}
[0;31m[ERROR][0m   [ERROR] Max retries reached after 5 attempts
[0;31m[ERROR][0m   [API_FAILURE] All retries exhausted
[0;31m[ERROR][0m     [API_FAILURE] API failed (timeout or max retries)
[0;31m[ERROR][0m   [ASSISTED] Task received 4 format helps, final result: failure
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 21189
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=21189
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44fd7375-1918-987f-9848-bd5e79fbb51d"}, traceId: 213e03d917564429678478847e1dac'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.852025-08-29 00:49:50,590 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:49:50,813 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:52,653 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:53,269 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:54,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:49:54,135 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:55,047 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:55,113 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:49:56,076 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:49:56,157 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:49:57,301 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   2025-08-29 00:50:09,960 - mcp_embedding_manager - INFO - Updated dimension to 3072
[0;31m[ERROR][0m   2025-08-29 00:50:09,960 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[0;31m[ERROR][0m   2025-08-29 00:50:09,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:50:11,130 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08cb2b5b-7206-9baa-af11-8a6f635f3f11"}, traceId: 213e06b617564429707823925e818a'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f864686-45b2-92ec-be71-cd26b8680f43"}, traceId: 213e03d917564429717638858e1dac'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b781cf35-14a8-9ae2-8e81-26357a37df1f"}, traceId: 213e065c17564429734584089e83cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1953f686-9488-916d-81a0-b3fb6807ac43"}, traceId: 213e065017564429759516464e7e45'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc5419d1-2349-9543-9968-859d8531f8c1"}, traceId: 213e03d917564429786978887e1dac'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e05eb18d-22be-9436-87b3-8d655b203d94"}, traceId: 2150415b17564429807458080ee4d6'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06d85be5-5089-9116-979c-72e5ca27ad00"}, traceId: 2150417517564429847816816edffa'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[0;31m[ERROR][0m   [ASSISTED] Task received 5 format helps, final result: failure
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 25586
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=25586
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c708385a-bbc4-9200-87ec-4b74e89326e5"}, traceId: 213e065c17564429863362004e81e2'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b5195d90-3de1-9d67-9e60-dea78b0f6656"}, traceId: 213e065c17564429877642014e81e2'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[0;31m[ERROR][0m   [ASSISTED] Task received 5 format helps, final result: failure
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=25592
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f672e8f-fff1-9ebc-9334-5801aaaf29f8"}, traceId: 213e065c17564429902792027e81e2'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"615d8775-f818-9408-8ff9-e0f03ede3662"}, traceId: 213e065c17564429938132050e81e2'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7368983e-8b32-949c-a672-c278a2c33419"}, traceId: 215045b017564429958551902e8310'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"618e61c5-67a1-9b29-b3c8-91e53fd8c5f9"}, traceId: 215045b017564429976401907e8310'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e630e2d0-809c-9189-9b56-571f0d052dde"}, traceId: 2150413117564430003827581ee96f'}
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8ebc5fb-d007-9367-987f-1c519ad9a978"}, traceId: 213e065c17564430008652080e81e2'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f9785d23-0010-95ee-b0a2-83fd61a2bb91"}, traceId: 213e065c17564430029122091e81e2'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a2110181-19c4-9187-854c-5e85213ff80b"}, traceId: 2150435d17564430034491922e20a9'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[0;31m[ERROR][0m   [ASSISTED] Task received 5 format helps, final result: failure
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 25578
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=25578
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c5851af-1636-945c-a795-bd0ab1588d9d"}, traceId: 2150416317564430097033963e148d'}
[0;31m[ERROR][0m   [ERROR] Max retries reached after 5 attempts
[0;31m[ERROR][0m   [API_FAILURE] All retries exhausted
[0;31m[ERROR][0m     [API_FAILURE] API failed (timeout or max retries)
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4bb92569-4a25-95f4-a4ce-5d85bc932142"}, traceId: 213e062017564430108552505e8047'}2025-08-29 00:50:34,340 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:50:34,981 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:50:36,016 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:50:37,354 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:50:37,419 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[0;31m[ERROR][0m   2025-08-29 00:50:37,420 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[0;31m[ERROR][0m   2025-08-29 00:50:37,451 - mcp_embedding_manager - INFO - FAISS index loaded
[0;31m[ERROR][0m   2025-08-29 00:50:37,451 - mcp_embedding_manager - INFO - Updated dimension to 3072
[0;31m[ERROR][0m   2025-08-29 00:50:37,451 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[0;31m[ERROR][0m   2025-08-29 00:50:38,840 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:40,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:40,054 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:50:41,080 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:42,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:43,052 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:44,027 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:44,387 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:45,230 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:46,081 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:50:46,883 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:50:48,095 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"880cb145-ea4f-92df-84ab-02734328c7c3"}, traceId: 213e065917564430117243652e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 14656
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=14656
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b338ea4b-255b-942e-bfa1-5e111b93f435"}, traceId: 213e062017564430142582525e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed1cb7bc-990f-99a7-84f1-872f73ca621f"}, traceId: 213e065917564430147423666e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e969fb1b-2298-94cb-b64c-b57600c28945"}, traceId: 213e065917564430177713674e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0ebb3c8-b14e-9c28-8065-6580aaad9029"}, traceId: 213e065917564430188203676e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51020be4-8f1c-9518-b1ca-7a0a699ed2e8"}, traceId: 213e062017564430203372565e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"319086cc-b8d2-9661-8346-2fe340c52d0b"}, traceId: 213e065917564430208263683e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9f12068d-5477-9af5-ae67-81bd0e030d9b"}, traceId: 213e062017564430223542585e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"543c73d1-b0f0-9ea9-ba62-2543b7b2daad"}, traceId: 213e065917564430247963694e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7b9cc8a-49db-9cc0-a8cb-bcd4c4c4ee53"}, traceId: 213e062017564430278342615e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d0e52cf7-0781-98eb-8aef-628799421cce"}, traceId: 213e062017564430314122642e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2cf215d-d4d4-9232-8b7e-fb76c8e7fb23"}, traceId: 213e065917564430318823726e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1a93a464-98d0-9371-b914-af9a5df66f2c"}, traceId: 213e062017564430329102646e8047'}2025-08-29 00:50:56,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:50:57,776 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:50:57,994 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:50:58,013 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[0;31m[ERROR][0m   2025-08-29 00:50:58,013 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[0;31m[ERROR][0m   2025-08-29 00:50:58,040 - mcp_embedding_manager - INFO - FAISS index loaded
[0;31m[ERROR][0m   2025-08-29 00:50:58,040 - mcp_embedding_manager - INFO - Updated dimension to 3072
[0;31m[ERROR][0m   2025-08-29 00:50:58,040 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[0;31m[ERROR][0m   2025-08-29 00:50:59,986 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:00,316 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:00,790 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:02,269 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:02,780 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:51:02,799 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:03,300 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:05,960 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:06,008 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:07,008 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:07,775 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:09,376 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:10,027 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5346c20-2820-9fd2-b907-88e0535c39e0"}, traceId: 213e065917564430347283752e80d7'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b363dbb7-b5b3-9fa3-bd98-26baa9d56eb3"}, traceId: 213e062017564430357532663e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[0;31m[ERROR][0m   [ASSISTED] Task received 5 format helps, final result: failure
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 25570
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=25570
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4ad7295-4cff-92e4-8b7e-455cff4fd0ee"}, traceId: 213e062017564430397852718e8047'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 4/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 5/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [EARLY_EXIT] No actions taken, continuing...
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 6/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 7/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 8/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8bfd623f-e4ba-9eb5-91e2-65eb803f63fd"}, traceId: 2150434117564430458472315e1f07'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"792e3356-16d9-95a2-a648-7b2b83c0150b"}, traceId: 213e060a17564430478621857e8ab5'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[0;31m[ERROR][0m   [ASSISTED] Task received 5 format helps, final result: failure
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 25571
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=25571
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   [INFO] Operation semantic index initialized
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 1/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d01298e-6ce3-93d2-8d15-3a2995c6cc0f"}, traceId: 213e065517564430494855983e80cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f2fbae22-44dc-96a3-9da4-15806dad1b80"}, traceId: 213e065517564430508615985e80cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 9/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 10/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6732142-ccd7-9375-944a-88f3366c14fd"}, traceId: 215041e117564430524127286e343c'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bb164ea-5096-9a94-a854-0475a7795e4f"}, traceId: 213e065517564430528885993e80cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8feb9115-87de-9835-b572-a9033534b2ae"}, traceId: 213e006e17564430544334526e12b4'}2025-08-29 00:51:21,016 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:21,054 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[0;31m[ERROR][0m   2025-08-29 00:51:21,056 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[0;31m[ERROR][0m   2025-08-29 00:51:21,058 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[0;31m[ERROR][0m   2025-08-29 00:51:21,063 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[0;31m[ERROR][0m   2025-08-29 00:51:21,155 - mcp_embedding_manager - INFO - FAISS index loaded
[0;31m[ERROR][0m   2025-08-29 00:51:21,162 - mcp_embedding_manager - INFO - Updated dimension to 3072
[0;31m[ERROR][0m   2025-08-29 00:51:21,162 - mcp_embedding_manager - INFO - Index loaded successfully: 5 tools
[0;31m[ERROR][0m   2025-08-29 00:51:21,190 - mcp_embedding_manager - INFO - FAISS index loaded
[0;31m[ERROR][0m   2025-08-29 00:51:21,190 - mcp_embedding_manager - INFO - Updated dimension to 3072
[0;31m[ERROR][0m   2025-08-29 00:51:21,190 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[0;31m[ERROR][0m   2025-08-29 00:51:22,689 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:23,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:51:24,979 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:51:25,091 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:26,022 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   2025-08-29 00:51:26,975 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:51:28,029 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[0;31m[ERROR][0m   2025-08-29 00:51:28,337 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[0;31m[ERROR][0m   2025-08-29 00:51:28,557 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[0;31m[ERROR][0m   2025-08-29 00:51:29,056 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"17b69e77-51d9-9e72-ae57-684197af2dfa"}, traceId: 213e065517564430574776003e80cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[0;31m[ERROR][0m     [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[0;31m[ERROR][0m   [ASSISTED] Task received 5 format helps, final result: failure
[0;31m[ERROR][0m   [DEBUG] Got result for task: has_result=True, save_logs=False
[0;31m[ERROR][0m   [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[0;31m[ERROR][0m   [AI_DEBUG] 生成的txt_content长度: 23139
[0;31m[ERROR][0m   [AI_DEBUG] _ai_classify_with_txt_content called:
[0;31m[ERROR][0m     - use_ai_classification=True
[0;31m[ERROR][0m     - ai_classifier=True
[0;31m[ERROR][0m     - txt_content_len=23139
[0;31m[ERROR][0m     - task_model=qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[0;31m[ERROR][0m   [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[0;31m[ERROR][0m   [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [InteractiveExecutor] Using prompt type: flawed_sequence_disorder for API key selection
[0;31m[ERROR][0m   [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [MCPEmbeddingManager] Reusing existing singleton instance (id: 5845412976)
[0;31m[ERROR][0m   [MCPEmbeddingManager] Current cache size: 30 embeddings
[0;31m[ERROR][0m   [INFO] Tool embedding index loaded successfully
[0;31m[ERROR][0m   [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[0;31m[ERROR][0m   --
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m     [SEARCH] Query: data validation parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 2/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f3f03bf-df08-9618-862f-53ba3c411d03"}, traceId: 213e065517564430605076011e80cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m     [INFO] Tool info request: data_processing_parser
[0;31m[ERROR][0m   
[0;31m[ERROR][0m   [TURN 3/10]
[0;31m[ERROR][0m   [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[0;31m[ERROR][0m   [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"60528748-b356-989f-b839-77662aa0ba09"}, traceId: 213e065517564430625276020e80cf'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"744b6768-cb24-9d98-b135-fe165279686e"}, traceId: 213e065417564430630268811e7f7e'}
[0;31m[ERROR][0m   [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[0;31m[ERROR][0m   [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ddad59e-bd15-998d-a3f8-0e9eaf0b1782"}, traceId: 213e065517564430656926027e80cf'}
[1;33m[WARNING][0m 接收到中断信号，正在清理...
[0;34m[INFO][0m 清理完成
