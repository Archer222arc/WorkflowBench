===== åˆ†ç‰‡ qwen2.5-3b-instruct_very_easy_key0 =====
æ—¶é—´: 2025-08-27T13:11:00.185096
æ¨¡å‹: qwen2.5-3b-instruct
å®ä¾‹: qwen-key0
å‘½ä»¤: python -u smart_batch_runner.py --model qwen2.5-3b-instruct --deployment qwen-key0 --prompt-types optimal --difficulty very_easy --task-types all --num-instances 10 --max-workers 50 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
ç¯å¢ƒå˜é‡:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[13:11:01.169] 
[13:11:01.172] A module that was compiled using NumPy 1.x cannot be run in
[13:11:01.173] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[13:11:01.173] versions of NumPy, modules must be compiled with NumPy 2.0.
[13:11:01.173] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[13:11:01.173] 
[13:11:01.173] If you are a user of the module, the easiest solution will be to
[13:11:01.173] downgrade to 'numpy<2' or try to upgrade the affected module.
[13:11:01.173] We expect that some modules will need time to support NumPy 2.
[13:11:01.173] 
[13:11:01.173] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[13:11:01.173]     from batch_test_runner import BatchTestRunner, TestTask
[13:11:01.173]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[13:11:01.173]     from mdp_workflow_generator import MDPWorkflowGenerator
[13:11:01.173]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[13:11:01.173]     import torch
[13:11:01.173]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[13:11:01.173]     from .functional import *  # noqa: F403
[13:11:01.173]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[13:11:01.173]     import torch.nn.functional as F
[13:11:01.173]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[13:11:01.173]     from .modules import *  # noqa: F403
[13:11:01.173]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[13:11:01.173]     from .transformer import TransformerEncoder, TransformerDecoder, \
[13:11:01.173]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[13:11:01.173]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[13:11:01.174] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[13:11:01.177]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[13:11:03.645] 2025-08-27 13:11:03,630 - faiss.loader - INFO - Loading faiss.
[13:11:03.700] 2025-08-27 13:11:03,699 - faiss.loader - INFO - Successfully loaded faiss.
[13:11:06.921] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[13:11:06.931] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[13:11:12.270] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[13:11:12.283] [INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[13:11:12.294] 
[13:11:12.295] ============================================================
[13:11:12.295] æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-3b-instruct (idealab)
[13:11:12.295] Prompt types: ['optimal']
[13:11:12.295] éš¾åº¦: very_easy
[13:11:12.295] ç›®æ ‡: æ¯ç§é…ç½® 10 ä¸ªå®ä¾‹
[13:11:12.295] ============================================================
[13:11:12.307] â—‹ simple_task         :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[13:11:12.312] â—‹ basic_task          :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[13:11:12.318] â—‹ data_pipeline       :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[13:11:12.320] â—‹ api_integration     :   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[13:11:12.324] â—‹ multi_stage_pipeline:   0/ 10 å·²å®Œæˆ (éœ€è¦è¡¥å…… 10 ä¸ª)
[13:11:12.324] 
[13:11:12.324] â³ éœ€è¦è¿è¡Œ 50 ä¸ªæ–°æµ‹è¯•
[13:11:12.324] 
[13:11:12.324] â–¶ å‡†å¤‡ simple_task (10 ä¸ªå®ä¾‹)...
[13:11:12.324] 
[13:11:12.324] â–¶ å‡†å¤‡ basic_task (10 ä¸ªå®ä¾‹)...
[13:11:12.324] 
[13:11:12.324] â–¶ å‡†å¤‡ data_pipeline (10 ä¸ªå®ä¾‹)...
[13:11:12.324] 
[13:11:12.324] â–¶ å‡†å¤‡ api_integration (10 ä¸ªå®ä¾‹)...
[13:11:12.324] 
[13:11:12.324] â–¶ å‡†å¤‡ multi_stage_pipeline (10 ä¸ªå®ä¾‹)...
[13:11:12.324] 
[13:11:12.324] â–¶ å¼€å§‹æ‰§è¡Œ 50 ä¸ªæµ‹è¯•...
[13:11:12.324] ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
[13:11:12.324] ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
[13:11:12.324] âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
[13:11:12.328] 2025-08-27 13:11:12,328 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
[13:11:12.328] 2025-08-27 13:11:12,328 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
[13:11:12.329] 2025-08-27 13:11:12,328 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
[13:11:12.329] 2025-08-27 13:11:12,328 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
[13:11:12.329] 2025-08-27 13:11:12,328 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
[13:11:12.329] 2025-08-27 13:11:12,328 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
[13:11:12.329] 2025-08-27 13:11:12,329 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
[13:11:12.329] 2025-08-27 13:11:12,329 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
[13:11:12.329] 2025-08-27 13:11:12,329 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
[13:11:12.329] ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[13:11:12.339] 2025-08-27 13:11:12,339 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
[13:11:12.570] 2025-08-27 13:11:12,569 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[13:11:12.570] [AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7fd657d8fc20>
[13:11:12.570] 2025-08-27 13:11:12,570 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
[13:11:12.570] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[13:11:12.571] 2025-08-27 13:11:12,571 - batch_test_runner - INFO - ============================================================
[13:11:12.572] 2025-08-27 13:11:12,571 - batch_test_runner - INFO - Batch test runner initialized
[13:11:12.572] 2025-08-27 13:11:12,572 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[13:11:12.572] 2025-08-27 13:11:12,572 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_131112.log
[13:11:12.572] 2025-08-27 13:11:12,572 - batch_test_runner - INFO - ============================================================
[13:11:12.572] 2025-08-27 13:11:12,572 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[13:11:12.572] 2025-08-27 13:11:12,572 - batch_test_runner - INFO - Initializing test components...
[13:11:37.151] 2025-08-27 13:11:37,089 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[13:11:37.190] 2025-08-27 13:11:37,134 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[13:11:37.191] 2025-08-27 13:11:37,136 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
[13:11:37.196] [DEBUG] Creating new ToolCapabilityManager instance
[13:11:37.197] [OperationEmbeddingIndex] Initializing with unified API client manager
[13:11:37.212] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[13:11:37.223] 2025-08-27 13:11:37,214 - api_client_manager - INFO - Loaded configuration from config/config.json
[13:11:37.438] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[13:11:37.438] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[13:11:37.439] [OperationEmbeddingIndex] Detecting actual embedding dimension...
