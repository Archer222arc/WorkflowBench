===== 分片 DeepSeek-R1-0528_easy_2 =====
时间: 2025-08-20T01:07:40.441521
模型: deepseek-r1-0528
实例: DeepSeek-R1-0528-3
命令: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528-3 --prompt-types optimal --difficulty easy --task-types all --num-instances 8 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[01:07:42.250] 2025-08-20 01:07:42,250 - faiss.loader - INFO - Loading faiss.
[01:07:42.264] 2025-08-20 01:07:42,264 - faiss.loader - INFO - Successfully loaded faiss.
[01:07:43.423] [INFO] 使用Parquet存储格式
[01:07:43.825] [INFO] 使用Parquet存储格式
[01:07:43.829] [INFO] 使用PARQUET存储格式
[01:07:43.830] 
[01:07:43.830] ============================================================
[01:07:43.830] 智能批测试: deepseek-r1-0528 (idealab)
[01:07:43.830] Prompt types: ['optimal']
[01:07:43.830] 难度: easy
[01:07:43.830] 目标: 每种配置 8 个实例
[01:07:43.830] ============================================================
[01:07:43.830] ○ simple_task         :   0/  8 已完成 (需要补充 8 个)
[01:07:43.830] ○ basic_task          :   0/  8 已完成 (需要补充 8 个)
[01:07:43.830] ○ data_pipeline       :   0/  8 已完成 (需要补充 8 个)
[01:07:43.830] ○ api_integration     :   0/  8 已完成 (需要补充 8 个)
[01:07:43.830] ○ multi_stage_pipeline:   0/  8 已完成 (需要补充 8 个)
[01:07:43.830] 
[01:07:43.830] ⏳ 需要运行 40 个新测试
[01:07:43.830] 
[01:07:43.830] ▶ 准备 simple_task (8 个实例)...
[01:07:43.830] 
[01:07:43.830] ▶ 准备 basic_task (8 个实例)...
[01:07:43.830] 
[01:07:43.830] ▶ 准备 data_pipeline (8 个实例)...
[01:07:43.830] 
[01:07:43.830] ▶ 准备 api_integration (8 个实例)...
[01:07:43.830] 
[01:07:43.830] ▶ 准备 multi_stage_pipeline (8 个实例)...
[01:07:43.830] 
[01:07:43.830] ▶ 开始执行 40 个测试...
[01:07:43.830] 📦 批量提交模式：每20个测试保存一次
[01:07:43.830] 🚀 检测到Azure API，使用超高并发: workers=100, qps=200.0
[01:07:43.832] 2025-08-20 01:07:43,832 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[01:07:43.891] 2025-08-20 01:07:43,891 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[01:07:43.891] 2025-08-20 01:07:43,891 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[01:07:43.891] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - ============================================================
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - Batch test runner initialized
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_010743.log
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - ============================================================
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - Running 40 tests with 100 workers, QPS limit: 200.0
[01:07:43.892] 2025-08-20 01:07:43,892 - batch_test_runner - INFO - Initializing test components...
[01:07:44.244] 2025-08-20 01:07:44,244 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[01:07:44.244] 2025-08-20 01:07:44,244 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[01:07:44.244] 2025-08-20 01:07:44,244 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[01:07:44.244] [DEBUG] Creating new ToolCapabilityManager instance
[01:07:44.244] [OperationEmbeddingIndex] Initializing with unified API client manager
[01:07:44.244] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[01:07:44.244] 2025-08-20 01:07:44,244 - api_client_manager - INFO - Loaded configuration from config/config.json
[01:07:44.251] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[01:07:44.251] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[01:07:44.251] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[01:07:45.250] 2025-08-20 01:07:45,249 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[01:07:45.252] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[01:07:45.284] [INFO] Loaded 4150 embeddings from persistent cache
[01:07:45.284] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[01:07:45.285] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[01:07:45.285] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[01:07:45.285] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[01:07:45.290] [INFO] Successfully loaded FAISS index with dimension 3072
[01:07:45.290] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[01:07:45.290] [INFO] Loaded 15 operations with dimension 3072
[01:07:45.290] [INFO] Successfully loaded cached index
[01:07:45.290] [INFO] Operation semantic index initialized
[01:07:45.290] [INFO] Using device: cpu
[01:07:45.291] [INFO] Initialized tool success tracking attributes
[01:07:45.291] [INFO] Initializing embedding manager for enhanced tool selection
[01:07:45.291] [MCPEmbeddingManager] Creating new singleton instance
[01:07:45.291] [MCPEmbeddingManager] Initializing with unified API client manager
[01:07:45.300] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[01:07:45.300] [MCPEmbeddingManager] Client initialized successfully
[01:07:45.300] 2025-08-20 01:07:45,300 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:07:45.460] 2025-08-20 01:07:45,460 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:07:45.707] 2025-08-20 01:07:45,707 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[01:07:45.707] 2025-08-20 01:07:45,707 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[01:07:45.731] 2025-08-20 01:07:45,731 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:07:45.798] 2025-08-20 01:07:45,798 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:07:46.060] 2025-08-20 01:07:46,060 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[01:07:46.060] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[01:07:46.060] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[01:07:46.060] 2025-08-20 01:07:46,060 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:46.086] 2025-08-20 01:07:46,086 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:46.086] 2025-08-20 01:07:46,086 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:46.086] 2025-08-20 01:07:46,086 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:46.088] [SUCCESS] Loaded 30 tool embeddings
[01:07:46.088] 2025-08-20 01:07:46,088 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[01:07:46.088] [SUCCESS] Embedding manager initialized with 30 tools
[01:07:46.088] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[01:07:46.088] [INFO] Loading full MCP protocol registry...
[01:07:46.089] 2025-08-20 01:07:46,089 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:46.090] [INFO] Loaded full tool registry with 30 tools
[01:07:46.090] 2025-08-20 01:07:46,089 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:07:46.090] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:07:46.090] [INFO] Embedding manager ready with 30 tools
[01:07:46.090] [WARNING] Embedding manager exists but has no embeddings
[01:07:46.090] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[01:07:46.090] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:46.090] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:46.091] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:46.091] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[01:07:46.091] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[01:07:46.091] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:46.091] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:46.091] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:46.091] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:46.091] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:46.091] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:46.091] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:46.091] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:46.091] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:46.091] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:46.091] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:46.091] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:46.091] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:46.091] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:46.091] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:46.091] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:46.091] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:46.091] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[01:07:46.091] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[01:07:46.091] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[01:07:46.091] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[01:07:46.091] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[01:07:46.091] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[01:07:46.091] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[01:07:46.091] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[01:07:46.091] 2025-08-20 01:07:46,091 - mdp_workflow_generator - INFO - Loaded 30 tools
[01:07:46.091] [INFO] Setting default state_dim based on loaded tools
[01:07:46.091] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[01:07:46.091] 2025-08-20 01:07:46,091 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[01:07:46.091] [INFO] Setting default action_dim based on loaded tools
[01:07:46.091] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[01:07:46.091] 2025-08-20 01:07:46,091 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[01:07:46.091] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[01:07:46.091] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[01:07:46.091] [INFO] ⚡ Will use pre-generated workflows or random policy
[01:07:46.091] 2025-08-20 01:07:46,091 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[01:07:46.091] [INFO] Initializing TaskManager...
[01:07:47.900] 2025-08-20 01:07:47,900 - unified_training_manager - INFO - Using device: cpu
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO - Task filtering results:
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO -   Total: 5040 -> 5040
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO -   simple_task: 320 -> 320
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[01:07:48.046] 2025-08-20 01:07:48,046 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[01:07:48.048] 2025-08-20 01:07:48,048 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[01:07:48.048] [TaskManager] Difficulty level 'easy': 1096 tasks
[01:07:48.048] [TaskManager] Difficulty level 'very_easy': 856 tasks
[01:07:48.048] [TaskManager] Difficulty level 'medium': 1136 tasks
[01:07:48.048] [TaskManager] Difficulty level 'hard': 1096 tasks
[01:07:48.048] [TaskManager] Difficulty level 'very_hard': 856 tasks
[01:07:48.051] [INFO] TaskManager initialized with 5040 tasks
[01:07:48.051] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:07:48.051] [INFO] Initializing ToolCallVerifier...
[01:07:48.051] [INFO] ToolCallVerifier initialized with 30 tools
[01:07:48.052] [INFO] Output tools identified: 1
[01:07:48.052] [INFO] Component initialization status:
[01:07:48.052]   - embedding_manager: initialized
[01:07:48.052]   - task_manager: initialized
[01:07:48.052]   - output_verifier: initialized
[01:07:48.052]   - tool_capability_manager: initialized
[01:07:48.052]   - tool_success_rates: initialized with 0 entries
[01:07:48.052] [INFO] MDPWorkflowGenerator initialization complete
[01:07:48.052] 2025-08-20 01:07:48,051 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[01:07:48.052] 2025-08-20 01:07:48,052 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[01:07:48.052] 2025-08-20 01:07:48,052 - batch_test_runner - INFO -   - task_manager: ✓
[01:07:48.052] 2025-08-20 01:07:48,052 - batch_test_runner - INFO -   - output_verifier: ✓
[01:07:48.052] 2025-08-20 01:07:48,052 - batch_test_runner - INFO -   - embedding_manager: ✓
[01:07:48.052] 2025-08-20 01:07:48,052 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[01:07:48.052] 2025-08-20 01:07:48,052 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[01:07:48.052] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.052] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.052] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:07:48.052] [FlawedWorkflowGenerator] RAG support: disabled
[01:07:48.053] DEBUG: Checking generator attributes
[01:07:48.053]   - has tool_capabilities: True
[01:07:48.053]   - has tool_capability_manager: True
[01:07:48.053]   - has task_manager: True
[01:07:48.053] [INFO] Loaded 30 tools from generator
[01:07:48.053] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[01:07:48.053] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.053] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.053] [INFO] Initializing LLM client using APIClientManager
[01:07:48.063] [INFO] Using Azure OpenAI client
[01:07:48.063] [DEBUG] Checking if generator has tool_capability_manager attribute
[01:07:48.063] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[01:07:48.063] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.063] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.063] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:07:48.063] [FlawedWorkflowGenerator] RAG support: enabled
[01:07:48.063] [INFO] FlawedWorkflowGenerator initialized successfully
[01:07:48.063] [INFO] Initializing StableScorer for Phase 2 scoring
[01:07:48.063] <tool_capability_manager.ToolCapabilityManager object at 0x324d56270>
[01:07:48.063] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.063] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.063] [INFO] Loaded tool success history for 0 tools
[01:07:48.063] [INFO] StableScorer initialized with semantic capability
[01:07:48.063] [INFO] StableScorer initialized successfully
[01:07:48.063] [INFO] Loading task instances...
[01:07:48.063] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[01:07:48.070] [INFO] Loaded 630 task instances
[01:07:48.070] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:07:48.070] 2025-08-20 01:07:48,070 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[01:07:48.070] 2025-08-20 01:07:48,070 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[01:07:48.749] 2025-08-20 01:07:48,749 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[01:07:48.750] 2025-08-20 01:07:48,749 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[01:07:48.771] 2025-08-20 01:07:48,770 - batch_test_runner - INFO - Initialization complete
[01:07:48.832] 2025-08-20 01:07:48,832 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[01:07:48.832] 2025-08-20 01:07:48,832 - batch_test_runner - INFO - Starting batch test with 40 tasks, 100 workers
[01:07:48.832] 2025-08-20 01:07:48,832 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[01:07:48.847] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.893] 2025-08-20 01:07:48,893 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for DeepSeek-R1-0528-3
[01:07:48.893] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.897] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.898] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.899] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.900] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.901] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.902] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.904] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.904] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.910] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.910] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.910] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.911] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.911] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.911] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.913] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.913] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.913] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.913] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.913] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.913] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.913] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.913] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.913] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.913] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.913] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.913] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.914] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.914] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.914] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:48.914] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.914] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.915] 2025-08-20 01:07:48,914 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.915] 
[01:07:48.915] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.915] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.915] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.916] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:48.916] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.916] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.916] 2025-08-20 01:07:48,915 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.916] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.916] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.916] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:48.917] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:48.917] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.917] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.917] 
[01:07:48.917] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:48,917 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.918] 
[01:07:48.918] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.918] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.918] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.919] 
[01:07:48.919] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.919] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.919] 
[01:07:48.919] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.919] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.921] 2025-08-20 01:07:48,921 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.922] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.922] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.924] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:48.924] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.924] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.924] 2025-08-20 01:07:48,924 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.925] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.925] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.925] 2025-08-20 01:07:48,925 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.927] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:48.927] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.927] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.931] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.931] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.962] [InteractiveExecutor] API model name: DeepSeek-R1-0528-32025-08-20 01:07:48,935 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.990] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.991] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.993] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.993] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.995] 
[01:07:48.996] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.997] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:48.997] 2025-08-20 01:07:48,994 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:48.998] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.999] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.999] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.999] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:48.999] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:48.999] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:48.999] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:48.999] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.013] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.013] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.013] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.013] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.014] 
[01:07:49.016] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.016] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.016] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.016] 2025-08-20 01:07:49,016 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.017] 2025-08-20 01:07:49,017 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.021] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.021] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.022] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.022] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.025] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.025] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.025] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.026] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.026] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.026] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.067] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.067] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.067] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.067] 
[01:07:49.067] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.068] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.068] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:49,068 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.069] 2025-08-20 01:07:49,069 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.069] 2025-08-20 01:07:49,069 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.069] 
[01:07:49.069] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.070] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.070] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.070] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.071] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.071] 2025-08-20 01:07:49,071 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.072] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.072] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.072] 2025-08-20 01:07:49,072 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.076] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.076] 
[01:07:49.076] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.076] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.082] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] API model name: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.082] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.082] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.083] 2025-08-20 01:07:49,082 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.084] 
[01:07:49.084] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.084] 
[01:07:49.086] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.086] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.086] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.086] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.093] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.093] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.093] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.115] 2025-08-20 01:07:49,084 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.121] 2025-08-20 01:07:49,086 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.127] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:49,086 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.129] 2025-08-20 01:07:49,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.131] 
[01:07:49.132] [InteractiveExecutor] API model name: DeepSeek-R1-0528-32025-08-20 01:07:49,124 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.135] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.136] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.136] [InteractiveExecutor] Using prompt type: optimal for API key selection2025-08-20 01:07:49,129 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.136] 
[01:07:49.136] 
[01:07:49.137] 
[01:07:49.137] 2025-08-20 01:07:49,137 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.137] 2025-08-20 01:07:49,137 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.140] [INFO] Tool embedding index loaded successfully
[01:07:49.141] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.141] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.141] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.142] 2025-08-20 01:07:49,142 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.144] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.144] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.153] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.154] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.178] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.178] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.178] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.178] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.190] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.190] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.191] [MCPEmbeddingManager] Current cache size: 30 embeddings[MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.191] 2025-08-20 01:07:49,191 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.191] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.198] 
[01:07:49.198] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.198] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.199] 2025-08-20 01:07:49,199 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.200] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.203] 
[01:07:49.211] [INFO] Operation semantic index initialized
[01:07:49.212] 2025-08-20 01:07:49,212 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.226] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:49,226 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.226] 
[01:07:49.228] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.231] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.237] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.237] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.256] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.256] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.256] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.260] 2025-08-20 01:07:49,260 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.260] 2025-08-20 01:07:49,260 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.260] 2025-08-20 01:07:49,260 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.262] [INFO] Tool embedding index loaded successfully
[01:07:49.263] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.274] 
[01:07:49.275] 2025-08-20 01:07:49,275 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.298] 2025-08-20 01:07:49,298 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.303] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.310] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.310] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.317] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.318] 2025-08-20 01:07:49,318 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.318] 2025-08-20 01:07:49,318 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.321] [INFO] Tool embedding index loaded successfully
[01:07:49.325] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-20 01:07:49,325 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.325] 2025-08-20 01:07:49,325 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.325] 2025-08-20 01:07:49,325 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.328] [INFO] Tool embedding index loaded successfully
[01:07:49.328] 
[01:07:49.350] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.357] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.357] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.358] 2025-08-20 01:07:49,357 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.368] [INFO] Operation semantic index initialized[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.368] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.369] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.374] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.374] 
[01:07:49.381] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.381] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.391] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.407] [TURN 1/10]
[01:07:49.408] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.408] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.430] 
[01:07:49.431] 2025-08-20 01:07:49,430 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.431] 2025-08-20 01:07:49,431 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.437] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.437] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.437] 2025-08-20 01:07:49,437 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:07:49.440] [INFO] Tool embedding index loaded successfully
[01:07:49.446] [MCPEmbeddingManager] Current cache size: 20 embeddings
[01:07:49.446] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.453] 2025-08-20 01:07:49,453 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.457] [INFO] Operation semantic index initialized
[01:07:49.467] 2025-08-20 01:07:49,467 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.494] [INFO] Operation semantic index initialized2025-08-20 01:07:49,484 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.504] 
[01:07:49.505] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.532] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.536] 2025-08-20 01:07:49,484 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.541] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.541] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.547] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.547] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.548] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.548] [INFO] Operation semantic index initialized
[01:07:49.549] 
[01:07:49.549] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.549] [MCPEmbeddingManager] Current cache size: 17 embeddings
[01:07:49.563] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:49,489 - mcp_embedding_manager - INFO - Index loaded successfully: 19 tools
[01:07:49.566] [INFO] Tool embedding index loaded successfully
[01:07:49.566] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.566] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.570] 
[01:07:49.571] [InteractiveExecutor] Using prompt type: optimal for API key selection2025-08-20 01:07:49,494 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.571] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.572] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.572] 
[01:07:49.572] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.573] 
[01:07:49.581] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.581] 2025-08-20 01:07:49,494 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.581] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.581] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.588] 2025-08-20 01:07:49,504 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.588] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.588] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.588] [MCPEmbeddingManager] Current cache size: 20 embeddings
[01:07:49.588] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.588] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.588] [MCPEmbeddingManager] Current cache size: 20 embeddings2025-08-20 01:07:49,511 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.592] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.604] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.605] 
[01:07:49.605] 2025-08-20 01:07:49,520 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.613] 2025-08-20 01:07:49,532 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.614] [INFO] Operation semantic index initialized
[01:07:49.617] 2025-08-20 01:07:49,536 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.617] 
[01:07:49.642] [TURN 1/10]2025-08-20 01:07:49,540 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.642] 
[01:07:49.643] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.658] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.658] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.661] 2025-08-20 01:07:49,555 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.661] 2025-08-20 01:07:49,571 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.663] [INFO] Tool embedding index loaded successfully
[01:07:49.663] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.663] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.664] 2025-08-20 01:07:49,571 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.670] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.671] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.671] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.671] [MCPEmbeddingManager] Current cache size: 17 embeddings
[01:07:49.676] 2025-08-20 01:07:49,572 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.676] 
[01:07:49.676] [TURN 1/10]
[01:07:49.677] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.677] 2025-08-20 01:07:49,580 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.677] 2025-08-20 01:07:49,677 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.677] 2025-08-20 01:07:49,677 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.679] [INFO] Tool embedding index loaded successfully
[01:07:49.679] 
[01:07:49.679] [TURN 1/10]
[01:07:49.680] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.680] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.680] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.680] 2025-08-20 01:07:49,581 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.680] 2025-08-20 01:07:49,680 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.680] 2025-08-20 01:07:49,592 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.681] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.681] 2025-08-20 01:07:49,593 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.684] 2025-08-20 01:07:49,603 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.686] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:49.686] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.686] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:49,606 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.688] 2025-08-20 01:07:49,613 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.688] [INFO] Operation semantic index initialized
[01:07:49.688] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:07:49,613 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.697] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.698] 
[01:07:49.702] 
[01:07:49.702] [TURN 1/10]
[01:07:49.702] 2025-08-20 01:07:49,613 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.702] [INFO] Operation semantic index initialized
[01:07:49.704] 
[01:07:49.706] 2025-08-20 01:07:49,617 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.707] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.708] 2025-08-20 01:07:49,617 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.708] 2025-08-20 01:07:49,642 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.708] 
[01:07:49.708] [TURN 1/10]
[01:07:49.709] 2025-08-20 01:07:49,642 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.709] 2025-08-20 01:07:49,642 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.709] 
[01:07:49.709] [TURN 1/10]
[01:07:49.710] 
[01:07:49.710] [TURN 1/10]
[01:07:49.713] 2025-08-20 01:07:49,643 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.725] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[01:07:49.725] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.726] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.727] 2025-08-20 01:07:49,643 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.728] 2025-08-20 01:07:49,658 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.728] 2025-08-20 01:07:49,664 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.730] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.731] 2025-08-20 01:07:49,671 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.731] 2025-08-20 01:07:49,676 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.731] 2025-08-20 01:07:49,679 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.731] 2025-08-20 01:07:49,731 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.731] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.734] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.734] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.734] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:49.734] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-32025-08-20 01:07:49,588 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.740] 
[01:07:49.740] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:49.746] 2025-08-20 01:07:49,680 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.749] [INFO] Tool embedding index loaded successfully[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:07:49,581 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.749] 
[01:07:49.749] 
[01:07:49.751] 2025-08-20 01:07:49,680 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.751] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.751] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.752] 2025-08-20 01:07:49,684 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.752] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-20 01:07:49,588 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.753] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[01:07:49.753] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13504319168)
[01:07:49.753] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-20 01:07:49,686 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.753] 
[01:07:49.753] 
[01:07:49.756] [INFO] Tool embedding index loaded successfully
[01:07:49.757] 2025-08-20 01:07:49,688 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.760] [INFO] Tool embedding index loaded successfully[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-20 01:07:49,702 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.760] 
[01:07:49.760] 
[01:07:49.762] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.763] 2025-08-20 01:07:49,705 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.765] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.766] [INFO] Operation semantic index initialized
[01:07:49.766] 
[01:07:49.766] [TURN 1/10]
[01:07:49.766] 2025-08-20 01:07:49,707 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.769] [INFO] Operation semantic index initialized[INFO] Tool embedding index loaded successfully
[01:07:49.770] 
[01:07:49.770] [TURN 1/10]
[01:07:49.770] 
[01:07:49.770] [INFO] Operation semantic index initialized
[01:07:49.771] 2025-08-20 01:07:49,708 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.772] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:07:49,709 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.772] 
[01:07:49.774] 
[01:07:49.774] [TURN 1/10]
[01:07:49.774] 2025-08-20 01:07:49,713 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.776] [INFO] Tool embedding index loaded successfully2025-08-20 01:07:49,725 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.776] 
[01:07:49.778] 2025-08-20 01:07:49,727 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.779] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.781] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.785] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.801] [INFO] Operation semantic index initialized
[01:07:49.801] 
[01:07:49.801] [TURN 1/10]
[01:07:49.801] 2025-08-20 01:07:49,728 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.802] 2025-08-20 01:07:49,728 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.804] [INFO] Tool embedding index loaded successfully
[01:07:49.825] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.826] 2025-08-20 01:07:49,731 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.826] [INFO] Operation semantic index initialized
[01:07:49.827] 
[01:07:49.827] [TURN 1/10]
[01:07:49.827] 2025-08-20 01:07:49,731 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.830] [INFO] Tool embedding index loaded successfully
[01:07:49.839] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.840] 2025-08-20 01:07:49,679 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.841] 2025-08-20 01:07:49,733 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.843] [INFO] Tool embedding index loaded successfully
[01:07:49.862] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.869] [INFO] Operation semantic index initialized
[01:07:49.869] 2025-08-20 01:07:49,734 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.869] 2025-08-20 01:07:49,740 - mcp_embedding_manager - INFO - Index loaded successfully: 14 tools
[01:07:49.871] [INFO] Tool embedding index loaded successfully
[01:07:49.871] 
[01:07:49.875] [TURN 1/10]
[01:07:49.875] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.876] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.876] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.877] [INFO] Operation semantic index initialized
[01:07:49.877] 
[01:07:49.877] [TURN 1/10]
[01:07:49.887] 2025-08-20 01:07:49,749 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.889] [INFO] Tool embedding index loaded successfully
[01:07:49.890] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.892] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.892] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.892] 2025-08-20 01:07:49,750 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.892] [INFO] Operation semantic index initialized
[01:07:49.892] 
[01:07:49.892] [TURN 1/10]
[01:07:49.892] [INFO] Operation semantic index initialized
[01:07:49.893] 2025-08-20 01:07:49,752 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.895] [INFO] Tool embedding index loaded successfully
[01:07:49.896] 
[01:07:49.896] [TURN 1/10]2025-08-20 01:07:49,752 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.899] [INFO] Tool embedding index loaded successfully
[01:07:49.899] 2025-08-20 01:07:49,756 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.899] 
[01:07:49.900] 2025-08-20 01:07:49,756 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:49.901] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.902] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.902] 2025-08-20 01:07:49,763 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.906] [INFO] Tool embedding index loaded successfully[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.906] [INFO] Operation semantic index initialized
[01:07:49.906] 2025-08-20 01:07:49,765 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.906] 
[01:07:49.907] 
[01:07:49.907] [TURN 1/10]
[01:07:49.907] 2025-08-20 01:07:49,771 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.909] [INFO] Tool embedding index loaded successfully
[01:07:49.912] 2025-08-20 01:07:49,773 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.914] [INFO] Tool embedding index loaded successfully
[01:07:49.914] [INFO] Operation semantic index initialized
[01:07:49.915] 
[01:07:49.915] [TURN 1/10]
[01:07:49.916] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.917] 2025-08-20 01:07:49,777 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.919] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.920] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.930] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.930] 2025-08-20 01:07:49,778 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.932] [INFO] Tool embedding index loaded successfully
[01:07:49.932] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.937] [INFO] Operation semantic index initialized[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:07:49,801 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.940] [INFO] Tool embedding index loaded successfully
[01:07:49.940] 2025-08-20 01:07:49,804 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.941] 
[01:07:49.941] 
[01:07:49.941] [INFO] Operation semantic index initialized[INFO] Operation semantic index initialized
[01:07:49.942] 
[01:07:49.942] 
[01:07:49.942] [TURN 1/10]
[01:07:49.943] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.944] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.945] [INFO] Operation semantic index initialized[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.945] [INFO] Operation semantic index initialized
[01:07:49.945] 
[01:07:49.945] 
[01:07:49.945] [TURN 1/10]
[01:07:49.946] 2025-08-20 01:07:49,826 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.959] [INFO] Tool embedding index loaded successfully[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:07:49,826 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.960] 2025-08-20 01:07:49,956 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.960] 2025-08-20 01:07:49,956 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.982] [INFO] Tool embedding index loaded successfully
[01:07:49.982] 
[01:07:49.983] 2025-08-20 01:07:49,840 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.983] 
[01:07:49.983] [INFO] Operation semantic index initialized
[01:07:49.983] [TURN 1/10]
[01:07:49.984] 2025-08-20 01:07:49,892 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:49.984] 
[01:07:49.984] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:49.984] 2025-08-20 01:07:49,899 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:49.985] 
[01:07:49.985] [TURN 1/10]
[01:07:49.986] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:49.986] 2025-08-20 01:07:49,906 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.990] [INFO] Tool embedding index loaded successfully
[01:07:49.990] 
[01:07:49.990] [TURN 1/10]
[01:07:49.991] 2025-08-20 01:07:49,917 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:49.999] [INFO] Tool embedding index loaded successfully
[01:07:50.001] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.002] [INFO] Operation semantic index initialized
[01:07:50.002] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-32025-08-20 01:07:49,940 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.002] 
[01:07:50.003] 2025-08-20 01:07:49,941 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.019] 2025-08-20 01:07:49,891 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.019] 2025-08-20 01:07:50,019 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.023] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.024] 2025-08-20 01:07:49,984 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.027] [INFO] Tool embedding index loaded successfully
[01:07:50.028] 
[01:07:50.028] [TURN 1/10]
[01:07:50.028] 2025-08-20 01:07:49,984 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.028] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.029] [INFO] Operation semantic index initialized
[01:07:50.031] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.031] [TURN 1/10]
[01:07:50.031] 2025-08-20 01:07:49,845 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.032] 
[01:07:50.032] [TURN 1/10]
[01:07:50.033] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.033] 2025-08-20 01:07:50,002 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.033] 
[01:07:50.036] [INFO] Tool embedding index loaded successfully
[01:07:50.036] 2025-08-20 01:07:50,003 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.036] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.037] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.038] [INFO] Operation semantic index initialized
[01:07:50.038] 
[01:07:50.038] [TURN 1/10]
[01:07:50.038] [INFO] Operation semantic index initialized
[01:07:50.039] 
[01:07:50.039] [TURN 1/10]
[01:07:50.039] [INFO] Operation semantic index initialized
[01:07:50.039] 
[01:07:50.039] [TURN 1/10]
[01:07:50.039] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.040] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.041] 2025-08-20 01:07:50,019 - mcp_embedding_manager - INFO - Index loaded successfully: 16 tools
[01:07:50.043] [INFO] Tool embedding index loaded successfully2025-08-20 01:07:50,027 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.044] 
[01:07:50.044] 2025-08-20 01:07:49,983 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.044] 2025-08-20 01:07:50,044 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.048] [INFO] Tool embedding index loaded successfully
[01:07:50.048] 2025-08-20 01:07:50,032 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.049] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.049] 2025-08-20 01:07:50,037 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.052] [INFO] Tool embedding index loaded successfully
[01:07:50.052] [INFO] Operation semantic index initialized
[01:07:50.052] 
[01:07:50.052] [TURN 1/10]
[01:07:50.052] 2025-08-20 01:07:50,043 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.066] 2025-08-20 01:07:50,028 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.068] [INFO] Tool embedding index loaded successfully
[01:07:50.068] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.079] 2025-08-20 01:07:50,048 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.082] [INFO] Tool embedding index loaded successfully
[01:07:50.082] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.083] 2025-08-20 01:07:50,052 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.091] [INFO] Tool embedding index loaded successfully
[01:07:50.092] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.093] 2025-08-20 01:07:50,093 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.093] 2025-08-20 01:07:50,093 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.093] 2025-08-20 01:07:50,093 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.095] [INFO] Tool embedding index loaded successfully
[01:07:50.096] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.097] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.101] 2025-08-20 01:07:50,101 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.101] 
[01:07:50.101] [INFO] Operation semantic index initialized[INFO] Operation semantic index initialized
[01:07:50.102] 
[01:07:50.102] [TURN 1/10]
[01:07:50.102] 2025-08-20 01:07:50,101 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:50.102] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.102] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.103] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.103] [INFO] Operation semantic index initialized
[01:07:50.104] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.104] 
[01:07:50.105] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.105] 2025-08-20 01:07:50,101 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.105] 
[01:07:50.105] [TURN 1/10]
[01:07:50.105] 
[01:07:50.105] [TURN 1/10]
[01:07:50.105] 2025-08-20 01:07:50,102 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:50.105] [INFO] Operation semantic index initialized
[01:07:50.105] [INFO] Operation semantic index initialized
[01:07:50.105] [INFO] Operation semantic index initialized
[01:07:50.105] 2025-08-20 01:07:50,105 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.113] [INFO] Tool embedding index loaded successfully
[01:07:50.113] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.115] 2025-08-20 01:07:50,105 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:50.121] [INFO] Tool embedding index loaded successfully
[01:07:50.121] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.122] [INFO] Operation semantic index initialized
[01:07:50.122] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.124] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.124] 
[01:07:50.124] [TURN 1/10]
[01:07:50.124] 
[01:07:50.124] [TURN 1/10]
[01:07:50.124] [INFO] Operation semantic index initialized
[01:07:50.125] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:50.125] 
[01:07:50.125] [TURN 1/10]
[01:07:50.125] [INFO] Operation semantic index initialized
[01:07:50.125] 
[01:07:50.125] [TURN 1/10]
[01:07:50.125] 
[01:07:50.125] [TURN 1/10]
[01:07:50.125] 
[01:07:50.125] [TURN 1/10]
[01:07:50.126] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.127] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.128] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.129] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.129] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:07:50.132] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:09:16.728] 2025-08-20 01:09:16,727 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:09:16.737]   [SEARCH] Query: file_operations_reader
[01:09:16.738] 
[01:09:16.738] [TURN 2/10]
[01:09:16.747] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[01:09:49.925] 2025-08-20 01:09:49,924 - openai._base_client - INFO - Retrying request to /chat/completions in 0.408722 seconds
[01:09:50.447] 2025-08-20 01:09:50,445 - openai._base_client - INFO - Retrying request to /chat/completions in 0.497292 seconds
[01:09:50.447] 2025-08-20 01:09:50,447 - openai._base_client - INFO - Retrying request to /chat/completions in 0.440513 seconds
[01:09:50.447] 2025-08-20 01:09:50,447 - openai._base_client - INFO - Retrying request to /chat/completions in 0.413229 seconds
[01:09:50.449] 2025-08-20 01:09:50,448 - openai._base_client - INFO - Retrying request to /chat/completions in 0.468847 seconds
[01:09:50.449] 2025-08-20 01:09:50,448 - openai._base_client - INFO - Retrying request to /chat/completions in 0.475374 seconds
[01:09:50.449] 2025-08-20 01:09:50,449 - openai._base_client - INFO - Retrying request to /chat/completions in 0.449000 seconds
[01:09:50.449] 2025-08-20 01:09:50,449 - openai._base_client - INFO - Retrying request to /chat/completions in 0.483095 seconds
[01:09:50.449] 2025-08-20 01:09:50,449 - openai._base_client - INFO - Retrying request to /chat/completions in 0.454989 seconds
[01:09:50.450] 2025-08-20 01:09:50,449 - openai._base_client - INFO - Retrying request to /chat/completions in 0.425820 seconds
[01:09:50.450] 2025-08-20 01:09:50,450 - openai._base_client - INFO - Retrying request to /chat/completions in 0.378838 seconds
[01:09:50.450] 2025-08-20 01:09:50,450 - openai._base_client - INFO - Retrying request to /chat/completions in 0.418240 seconds
[01:09:50.450] 2025-08-20 01:09:50,450 - openai._base_client - INFO - Retrying request to /chat/completions in 0.411205 seconds
[01:09:50.452] 2025-08-20 01:09:50,450 - openai._base_client - INFO - Retrying request to /chat/completions in 0.400412 seconds
[01:09:50.452] 2025-08-20 01:09:50,450 - openai._base_client - INFO - Retrying request to /chat/completions in 0.455464 seconds
[01:09:50.452] 2025-08-20 01:09:50,451 - openai._base_client - INFO - Retrying request to /chat/completions in 0.414151 seconds
[01:09:50.452] 2025-08-20 01:09:50,451 - openai._base_client - INFO - Retrying request to /chat/completions in 0.462930 seconds
[01:09:50.452] 2025-08-20 01:09:50,451 - openai._base_client - INFO - Retrying request to /chat/completions in 0.434212 seconds
[01:09:50.452] 2025-08-20 01:09:50,451 - openai._base_client - INFO - Retrying request to /chat/completions in 0.410790 seconds
[01:09:50.452] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.483413 seconds
[01:09:50.453] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394390 seconds
[01:09:50.453] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.472461 seconds
[01:09:50.454] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.410295 seconds
[01:09:50.454] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.449523 seconds
[01:09:50.454] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.386922 seconds
[01:09:50.454] 2025-08-20 01:09:50,452 - openai._base_client - INFO - Retrying request to /chat/completions in 0.497744 seconds
[01:09:50.454] 2025-08-20 01:09:50,453 - openai._base_client - INFO - Retrying request to /chat/completions in 0.457776 seconds
[01:09:50.454] 2025-08-20 01:09:50,453 - openai._base_client - INFO - Retrying request to /chat/completions in 0.425293 seconds
[01:09:50.454] 2025-08-20 01:09:50,453 - openai._base_client - INFO - Retrying request to /chat/completions in 0.389185 seconds
[01:09:50.454] 2025-08-20 01:09:50,453 - openai._base_client - INFO - Retrying request to /chat/completions in 0.409154 seconds
[01:09:50.457] 2025-08-20 01:09:50,457 - openai._base_client - INFO - Retrying request to /chat/completions in 0.467545 seconds
[01:09:50.457] 2025-08-20 01:09:50,457 - openai._base_client - INFO - Retrying request to /chat/completions in 0.415564 seconds
[01:09:50.457] 2025-08-20 01:09:50,457 - openai._base_client - INFO - Retrying request to /chat/completions in 0.448519 seconds
[01:09:50.458] 2025-08-20 01:09:50,457 - openai._base_client - INFO - Retrying request to /chat/completions in 0.426370 seconds
[01:09:50.458] 2025-08-20 01:09:50,457 - openai._base_client - INFO - Retrying request to /chat/completions in 0.421164 seconds
[01:09:50.458] 2025-08-20 01:09:50,458 - openai._base_client - INFO - Retrying request to /chat/completions in 0.466764 seconds
[01:09:50.458] 2025-08-20 01:09:50,458 - openai._base_client - INFO - Retrying request to /chat/completions in 0.444411 seconds
[01:09:50.458] 2025-08-20 01:09:50,458 - openai._base_client - INFO - Retrying request to /chat/completions in 0.392458 seconds
[01:09:50.458] 2025-08-20 01:09:50,458 - openai._base_client - INFO - Retrying request to /chat/completions in 0.446013 seconds
[01:11:16.756] 2025-08-20 01:11:16,755 - openai._base_client - INFO - Retrying request to /chat/completions in 0.494524 seconds
[01:11:50.776] 2025-08-20 01:11:50,775 - openai._base_client - INFO - Retrying request to /chat/completions in 0.981602 seconds
[01:11:51.183] 2025-08-20 01:11:51,183 - openai._base_client - INFO - Retrying request to /chat/completions in 0.962798 seconds
[01:11:51.184] 2025-08-20 01:11:51,183 - openai._base_client - INFO - Retrying request to /chat/completions in 0.998646 seconds
[01:11:51.187] 2025-08-20 01:11:51,184 - openai._base_client - INFO - Retrying request to /chat/completions in 0.986887 seconds
[01:11:51.188] 2025-08-20 01:11:51,184 - openai._base_client - INFO - Retrying request to /chat/completions in 0.988560 seconds
[01:11:51.188] 2025-08-20 01:11:51,186 - openai._base_client - INFO - Retrying request to /chat/completions in 0.810123 seconds
[01:11:51.188] 2025-08-20 01:11:51,187 - openai._base_client - INFO - Retrying request to /chat/completions in 0.906636 seconds
[01:11:51.188] 2025-08-20 01:11:51,187 - openai._base_client - INFO - Retrying request to /chat/completions in 0.758174 seconds
[01:11:51.188] 2025-08-20 01:11:51,187 - openai._base_client - INFO - Retrying request to /chat/completions in 0.888750 seconds
[01:11:51.188] 2025-08-20 01:11:51,188 - openai._base_client - INFO - Retrying request to /chat/completions in 0.990013 seconds
[01:11:51.188] 2025-08-20 01:11:51,188 - openai._base_client - INFO - Retrying request to /chat/completions in 0.964904 seconds
[01:11:51.189] 2025-08-20 01:11:51,188 - openai._base_client - INFO - Retrying request to /chat/completions in 0.856042 seconds
[01:11:51.189] 2025-08-20 01:11:51,188 - openai._base_client - INFO - Retrying request to /chat/completions in 0.996868 seconds
[01:11:51.189] 2025-08-20 01:11:51,188 - openai._base_client - INFO - Retrying request to /chat/completions in 0.758121 seconds
[01:11:51.189] 2025-08-20 01:11:51,189 - openai._base_client - INFO - Retrying request to /chat/completions in 0.926623 seconds
[01:11:51.197] 2025-08-20 01:11:51,197 - openai._base_client - INFO - Retrying request to /chat/completions in 0.934149 seconds
[01:11:51.199] 2025-08-20 01:11:51,198 - openai._base_client - INFO - Retrying request to /chat/completions in 0.967311 seconds
[01:11:51.199] 2025-08-20 01:11:51,198 - openai._base_client - INFO - Retrying request to /chat/completions in 0.828424 seconds
[01:11:51.199] 2025-08-20 01:11:51,198 - openai._base_client - INFO - Retrying request to /chat/completions in 0.790855 seconds
[01:11:51.199] 2025-08-20 01:11:51,199 - openai._base_client - INFO - Retrying request to /chat/completions in 0.835793 seconds
[01:11:51.199] 2025-08-20 01:11:51,199 - openai._base_client - INFO - Retrying request to /chat/completions in 0.816360 seconds
[01:11:51.237] 2025-08-20 01:11:51,237 - openai._base_client - INFO - Retrying request to /chat/completions in 0.780059 seconds
[01:11:51.252] 2025-08-20 01:11:51,252 - openai._base_client - INFO - Retrying request to /chat/completions in 0.958094 seconds
[01:11:51.256] 2025-08-20 01:11:51,256 - openai._base_client - INFO - Retrying request to /chat/completions in 0.933331 seconds
[01:11:51.268] 2025-08-20 01:11:51,267 - openai._base_client - INFO - Retrying request to /chat/completions in 0.834640 seconds
[01:11:51.270] 2025-08-20 01:11:51,269 - openai._base_client - INFO - Retrying request to /chat/completions in 0.811669 seconds
[01:11:51.270] 2025-08-20 01:11:51,270 - openai._base_client - INFO - Retrying request to /chat/completions in 0.837904 seconds
[01:11:51.273] 2025-08-20 01:11:51,273 - openai._base_client - INFO - Retrying request to /chat/completions in 0.984675 seconds
[01:11:51.274] 2025-08-20 01:11:51,274 - openai._base_client - INFO - Retrying request to /chat/completions in 0.888085 seconds
[01:11:51.275] 2025-08-20 01:11:51,275 - openai._base_client - INFO - Retrying request to /chat/completions in 0.803084 seconds
[01:11:51.275] 2025-08-20 01:11:51,275 - openai._base_client - INFO - Retrying request to /chat/completions in 0.796888 seconds
[01:11:51.276] 2025-08-20 01:11:51,276 - openai._base_client - INFO - Retrying request to /chat/completions in 0.916999 seconds
[01:11:51.276] 2025-08-20 01:11:51,276 - openai._base_client - INFO - Retrying request to /chat/completions in 0.925481 seconds
[01:11:51.276] 2025-08-20 01:11:51,276 - openai._base_client - INFO - Retrying request to /chat/completions in 0.816715 seconds
[01:11:51.276] 2025-08-20 01:11:51,276 - openai._base_client - INFO - Retrying request to /chat/completions in 0.964718 seconds
[01:11:51.277] 2025-08-20 01:11:51,277 - openai._base_client - INFO - Retrying request to /chat/completions in 0.873617 seconds
[01:11:51.279] 2025-08-20 01:11:51,279 - openai._base_client - INFO - Retrying request to /chat/completions in 0.850812 seconds
[01:11:51.280] 2025-08-20 01:11:51,280 - openai._base_client - INFO - Retrying request to /chat/completions in 0.926844 seconds
[01:11:51.281] 2025-08-20 01:11:51,280 - openai._base_client - INFO - Retrying request to /chat/completions in 0.835156 seconds
[01:13:17.725] 2025-08-20 01:13:17,724 - openai._base_client - INFO - Retrying request to /chat/completions in 0.833394 seconds
[01:13:52.055] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.057] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.057]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.117] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:52.201] [LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.201] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.201]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.202] 
[01:13:52.202] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.202]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.237] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.237] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.237]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.247] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.247] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.247]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.264] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.264] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.264]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.282] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.282] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.282]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.284] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.284] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.284]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.290] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.290] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.290]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.296] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.296] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.296]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.343] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.343] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.343]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.345] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.345] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.345]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.346] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.346] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.347]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.348] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.348] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.348]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.348] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.348] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.348]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.360] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.361] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.361]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.373] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.373] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.373]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.374] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.374] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.374]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.376] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.376] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.376]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.384] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.384] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.384]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.385] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.385] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.385]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.391] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.392] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.392]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.426] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.426] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.426]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.427] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.427] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.427]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.432] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.432] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.432]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.434] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.434] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.434]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.438] [LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.438] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.438] 
[01:13:52.438] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.438]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.438]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.440] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.440] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.440]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.441] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.441] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.441]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.446] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.447] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.447]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.447] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.447] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.447]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.454] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.454] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.454]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.454] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.454] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.454]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.455] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.455] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.455]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.460] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.460] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.460]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.469] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.469] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.469]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.500] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.500] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.500]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.520] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:52.520] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:52.520]   [API_FAILURE] API failed (timeout or max retries)
[01:13:52.653] 2025-08-20 01:13:52,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:52.656] 2025-08-20 01:13:52,656 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:52.660] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:52.780] 2025-08-20 01:13:52,778 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:52.782] 2025-08-20 01:13:52,781 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:52.785] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:52.928] 2025-08-20 01:13:52,928 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:52.928] 2025-08-20 01:13:52,928 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:52.931] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.051] 2025-08-20 01:13:53,050 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.051] 2025-08-20 01:13:53,051 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.053] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.182] 2025-08-20 01:13:53,182 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.182] 2025-08-20 01:13:53,182 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.183] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.314] 2025-08-20 01:13:53,314 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.315] 2025-08-20 01:13:53,315 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.316] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.444] 2025-08-20 01:13:53,443 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.444] 2025-08-20 01:13:53,444 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.450] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.572] 2025-08-20 01:13:53,572 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.574] 2025-08-20 01:13:53,574 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.580] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.729] 2025-08-20 01:13:53,729 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.730] 2025-08-20 01:13:53,730 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.731] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:53.864] 2025-08-20 01:13:53,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:53.865] 2025-08-20 01:13:53,865 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:53.866] Progress: 10/40 (Success: 0)
[01:13:53.866] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:54.006] 2025-08-20 01:13:54,005 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:54.009] 2025-08-20 01:13:54,009 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:54.014] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:54.179] 2025-08-20 01:13:54,179 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:54.180] 2025-08-20 01:13:54,179 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:54.181] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:54.327] 2025-08-20 01:13:54,327 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:54.328] 2025-08-20 01:13:54,328 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:54.329] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:54.513] 2025-08-20 01:13:54,512 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:54.514] 2025-08-20 01:13:54,513 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:54.516] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:54.754] 2025-08-20 01:13:54,754 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:54.754] 2025-08-20 01:13:54,754 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:54.765] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:54.897] 2025-08-20 01:13:54,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:54.897] 2025-08-20 01:13:54,897 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:54.899] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.022] 2025-08-20 01:13:55,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.022] 2025-08-20 01:13:55,022 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.023] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.164] 2025-08-20 01:13:55,163 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.166] 2025-08-20 01:13:55,165 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.180] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.304] 2025-08-20 01:13:55,303 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.305] 2025-08-20 01:13:55,304 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.307] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.446] 2025-08-20 01:13:55,445 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.446] 2025-08-20 01:13:55,446 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.447] Progress: 20/40 (Success: 0)
[01:13:55.447] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.587] 2025-08-20 01:13:55,587 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.587] 2025-08-20 01:13:55,587 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.589] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.730] 2025-08-20 01:13:55,730 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.731] 2025-08-20 01:13:55,731 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.732] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:55.857] 2025-08-20 01:13:55,857 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:55.857] 2025-08-20 01:13:55,857 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:55.875] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.048] 2025-08-20 01:13:56,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.049] 2025-08-20 01:13:56,049 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.052] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.176] 2025-08-20 01:13:56,176 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.177] 2025-08-20 01:13:56,177 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.179] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.311] 2025-08-20 01:13:56,311 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.311] 2025-08-20 01:13:56,311 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.313] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.437] 2025-08-20 01:13:56,437 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.437] 2025-08-20 01:13:56,437 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.438] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.577] 2025-08-20 01:13:56,576 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.577] 2025-08-20 01:13:56,577 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.582] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.708] 2025-08-20 01:13:56,707 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.708] 2025-08-20 01:13:56,708 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.710] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.848] 2025-08-20 01:13:56,848 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.849] 2025-08-20 01:13:56,848 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.850] Progress: 30/40 (Success: 0)
[01:13:56.850] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:56.989] 2025-08-20 01:13:56,989 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:56.989] 2025-08-20 01:13:56,989 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:56.991] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:57.131] 2025-08-20 01:13:57,130 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:57.131] 2025-08-20 01:13:57,131 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:57.132] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:57.275] 2025-08-20 01:13:57,275 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:57.276] 2025-08-20 01:13:57,276 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:57.283] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:57.424] 2025-08-20 01:13:57,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:57.424] 2025-08-20 01:13:57,424 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:57.425] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:57.561] 2025-08-20 01:13:57,561 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:57.562] 2025-08-20 01:13:57,562 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:57.568] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:57.763] 2025-08-20 01:13:57,763 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:57.764] 2025-08-20 01:13:57,764 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:57.778] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:57.928] 2025-08-20 01:13:57,928 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:57.929] 2025-08-20 01:13:57,929 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:57.930] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:58.074] 2025-08-20 01:13:58,074 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:58.075] 2025-08-20 01:13:58,075 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:58.076] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:58.205] 2025-08-20 01:13:58,205 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:58.207] 2025-08-20 01:13:58,207 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
