===== 分片 DeepSeek-R1-0528_easy_0 =====
时间: 2025-08-20T01:06:50.398204
模型: deepseek-r1-0528
实例: DeepSeek-R1-0528
命令: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528 --prompt-types optimal --difficulty easy --task-types all --num-instances 6 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[01:06:52.494] 2025-08-20 01:06:52,494 - faiss.loader - INFO - Loading faiss.
[01:06:52.510] 2025-08-20 01:06:52,509 - faiss.loader - INFO - Successfully loaded faiss.
[01:06:53.707] [INFO] 使用Parquet存储格式
[01:06:54.184] [INFO] 使用Parquet存储格式
[01:06:54.188] [INFO] 使用PARQUET存储格式
[01:06:54.189] 
[01:06:54.189] ============================================================
[01:06:54.189] 智能批测试: deepseek-r1-0528 (idealab)
[01:06:54.189] Prompt types: ['optimal']
[01:06:54.189] 难度: easy
[01:06:54.189] 目标: 每种配置 6 个实例
[01:06:54.189] ============================================================
[01:06:54.189] ○ simple_task         :   0/  6 已完成 (需要补充 6 个)
[01:06:54.189] ○ basic_task          :   0/  6 已完成 (需要补充 6 个)
[01:06:54.189] ○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
[01:06:54.189] ○ api_integration     :   0/  6 已完成 (需要补充 6 个)
[01:06:54.189] ○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)
[01:06:54.189] 
[01:06:54.189] ⏳ 需要运行 30 个新测试
[01:06:54.189] 
[01:06:54.189] ▶ 准备 simple_task (6 个实例)...
[01:06:54.189] 
[01:06:54.189] ▶ 准备 basic_task (6 个实例)...
[01:06:54.189] 
[01:06:54.189] ▶ 准备 data_pipeline (6 个实例)...
[01:06:54.189] 
[01:06:54.189] ▶ 准备 api_integration (6 个实例)...
[01:06:54.189] 
[01:06:54.189] ▶ 准备 multi_stage_pipeline (6 个实例)...
[01:06:54.189] 
[01:06:54.189] ▶ 开始执行 30 个测试...
[01:06:54.189] 📦 批量提交模式：每20个测试保存一次
[01:06:54.189] 🚀 检测到Azure API，使用超高并发: workers=100, qps=200.0
[01:06:54.191] 2025-08-20 01:06:54,191 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[01:06:54.244] 2025-08-20 01:06:54,244 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[01:06:54.245] 2025-08-20 01:06:54,244 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[01:06:54.245] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - ============================================================
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - Batch test runner initialized
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_010654.log
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - ============================================================
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - Running 30 tests with 100 workers, QPS limit: 200.0
[01:06:54.245] 2025-08-20 01:06:54,245 - batch_test_runner - INFO - Initializing test components...
[01:06:54.571] 2025-08-20 01:06:54,571 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[01:06:54.571] 2025-08-20 01:06:54,571 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[01:06:54.571] 2025-08-20 01:06:54,571 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[01:06:54.571] [DEBUG] Creating new ToolCapabilityManager instance
[01:06:54.571] [OperationEmbeddingIndex] Initializing with unified API client manager
[01:06:54.571] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[01:06:54.572] 2025-08-20 01:06:54,572 - api_client_manager - INFO - Loaded configuration from config/config.json
[01:06:54.578] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[01:06:54.578] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[01:06:54.578] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[01:06:55.708] 2025-08-20 01:06:55,707 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[01:06:55.718] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[01:06:55.780] [INFO] Loaded 4150 embeddings from persistent cache
[01:06:55.780] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[01:06:55.781] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[01:06:55.782] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[01:06:55.782] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[01:06:55.787] [INFO] Successfully loaded FAISS index with dimension 3072
[01:06:55.787] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[01:06:55.787] [INFO] Loaded 15 operations with dimension 3072
[01:06:55.787] [INFO] Successfully loaded cached index
[01:06:55.787] [INFO] Operation semantic index initialized
[01:06:55.787] [INFO] Using device: cpu
[01:06:55.788] [INFO] Initialized tool success tracking attributes
[01:06:55.788] [INFO] Initializing embedding manager for enhanced tool selection
[01:06:55.788] [MCPEmbeddingManager] Creating new singleton instance
[01:06:55.788] [MCPEmbeddingManager] Initializing with unified API client manager
[01:06:55.797] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[01:06:55.797] [MCPEmbeddingManager] Client initialized successfully
[01:06:55.797] 2025-08-20 01:06:55,797 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:06:55.914] 2025-08-20 01:06:55,914 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:06:56.144] 2025-08-20 01:06:56,144 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[01:06:56.144] 2025-08-20 01:06:56,144 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[01:06:56.168] 2025-08-20 01:06:56,168 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:06:56.253] 2025-08-20 01:06:56,253 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:06:56.480] 2025-08-20 01:06:56,480 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[01:06:56.480] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[01:06:56.480] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[01:06:56.480] 2025-08-20 01:06:56,480 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:56.500] 2025-08-20 01:06:56,500 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:56.500] 2025-08-20 01:06:56,500 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:56.500] 2025-08-20 01:06:56,500 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:56.503] [SUCCESS] Loaded 30 tool embeddings
[01:06:56.503] 2025-08-20 01:06:56,503 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[01:06:56.503] [SUCCESS] Embedding manager initialized with 30 tools
[01:06:56.503] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[01:06:56.503] [INFO] Loading full MCP protocol registry...
[01:06:56.504] 2025-08-20 01:06:56,504 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:56.504] [INFO] Loaded full tool registry with 30 tools
[01:06:56.504] 2025-08-20 01:06:56,504 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:06:56.504] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:06:56.504] [INFO] Embedding manager ready with 30 tools
[01:06:56.505] [WARNING] Embedding manager exists but has no embeddings
[01:06:56.505] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[01:06:56.505] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[01:06:56.505] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[01:06:56.505] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:06:56.505] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[01:06:56.505] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[01:06:56.505] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:06:56.505] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:06:56.505] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:06:56.505] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:06:56.505] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[01:06:56.505] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:06:56.505] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:06:56.505] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[01:06:56.505] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[01:06:56.505] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[01:06:56.505] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:06:56.505] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:06:56.505] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:06:56.505] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[01:06:56.505] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[01:06:56.505] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[01:06:56.505] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[01:06:56.505] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[01:06:56.505] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[01:06:56.505] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[01:06:56.505] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[01:06:56.505] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[01:06:56.505] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[01:06:56.505] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[01:06:56.505] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[01:06:56.505] 2025-08-20 01:06:56,505 - mdp_workflow_generator - INFO - Loaded 30 tools
[01:06:56.505] [INFO] Setting default state_dim based on loaded tools
[01:06:56.505] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[01:06:56.505] 2025-08-20 01:06:56,505 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[01:06:56.505] [INFO] Setting default action_dim based on loaded tools
[01:06:56.505] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[01:06:56.505] 2025-08-20 01:06:56,505 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[01:06:56.505] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[01:06:56.505] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[01:06:56.505] [INFO] ⚡ Will use pre-generated workflows or random policy
[01:06:56.505] 2025-08-20 01:06:56,505 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[01:06:56.505] [INFO] Initializing TaskManager...
[01:06:58.261] 2025-08-20 01:06:58,260 - unified_training_manager - INFO - Using device: cpu
[01:06:58.400] 2025-08-20 01:06:58,399 - unified_training_manager - INFO - Task filtering results:
[01:06:58.400] 2025-08-20 01:06:58,399 - unified_training_manager - INFO -   Total: 5040 -> 5040
[01:06:58.400] 2025-08-20 01:06:58,400 - unified_training_manager - INFO -   simple_task: 320 -> 320
[01:06:58.400] 2025-08-20 01:06:58,400 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[01:06:58.400] 2025-08-20 01:06:58,400 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[01:06:58.400] 2025-08-20 01:06:58,400 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[01:06:58.400] 2025-08-20 01:06:58,400 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[01:06:58.400] 2025-08-20 01:06:58,400 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[01:06:58.403] 2025-08-20 01:06:58,403 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[01:06:58.404] [TaskManager] Difficulty level 'easy': 1096 tasks
[01:06:58.404] [TaskManager] Difficulty level 'very_easy': 856 tasks
[01:06:58.404] [TaskManager] Difficulty level 'medium': 1136 tasks
[01:06:58.404] [TaskManager] Difficulty level 'hard': 1096 tasks
[01:06:58.404] [TaskManager] Difficulty level 'very_hard': 856 tasks
[01:06:58.406] [INFO] TaskManager initialized with 5040 tasks
[01:06:58.406] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:06:58.406] [INFO] Initializing ToolCallVerifier...
[01:06:58.407] [INFO] ToolCallVerifier initialized with 30 tools
[01:06:58.407] [INFO] Output tools identified: 1
[01:06:58.407] [INFO] Component initialization status:
[01:06:58.407]   - embedding_manager: initialized
[01:06:58.407]   - task_manager: initialized
[01:06:58.407]   - output_verifier: initialized
[01:06:58.407]   - tool_capability_manager: initialized
[01:06:58.407]   - tool_success_rates: initialized with 0 entries
[01:06:58.407] [INFO] MDPWorkflowGenerator initialization complete
[01:06:58.407] 2025-08-20 01:06:58,407 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[01:06:58.407] 2025-08-20 01:06:58,407 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[01:06:58.407] 2025-08-20 01:06:58,407 - batch_test_runner - INFO -   - task_manager: ✓
[01:06:58.407] 2025-08-20 01:06:58,407 - batch_test_runner - INFO -   - output_verifier: ✓
[01:06:58.407] 2025-08-20 01:06:58,407 - batch_test_runner - INFO -   - embedding_manager: ✓
[01:06:58.407] 2025-08-20 01:06:58,407 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[01:06:58.407] 2025-08-20 01:06:58,407 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[01:06:58.407] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.407] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.407] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:06:58.407] [FlawedWorkflowGenerator] RAG support: disabled
[01:06:58.408] DEBUG: Checking generator attributes
[01:06:58.408]   - has tool_capabilities: True
[01:06:58.408]   - has tool_capability_manager: True
[01:06:58.408]   - has task_manager: True
[01:06:58.408] [INFO] Loaded 30 tools from generator
[01:06:58.408] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[01:06:58.408] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.408] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.408] [INFO] Initializing LLM client using APIClientManager
[01:06:58.416] [INFO] Using Azure OpenAI client
[01:06:58.416] [DEBUG] Checking if generator has tool_capability_manager attribute
[01:06:58.417] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[01:06:58.417] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.417] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.417] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:06:58.417] [FlawedWorkflowGenerator] RAG support: enabled
[01:06:58.417] [INFO] FlawedWorkflowGenerator initialized successfully
[01:06:58.417] [INFO] Initializing StableScorer for Phase 2 scoring
[01:06:58.417] <tool_capability_manager.ToolCapabilityManager object at 0x323659df0>
[01:06:58.417] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.417] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.417] [INFO] Loaded tool success history for 0 tools
[01:06:58.417] [INFO] StableScorer initialized with semantic capability
[01:06:58.417] [INFO] StableScorer initialized successfully
[01:06:58.417] [INFO] Loading task instances...
[01:06:58.417] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[01:06:58.423] [INFO] Loaded 630 task instances
[01:06:58.424] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:06:58.424] 2025-08-20 01:06:58,423 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[01:06:58.424] 2025-08-20 01:06:58,424 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[01:06:58.825] 2025-08-20 01:06:58,824 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[01:06:58.825] 2025-08-20 01:06:58,824 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[01:06:58.842] 2025-08-20 01:06:58,842 - batch_test_runner - INFO - Initialization complete
[01:06:58.958] 2025-08-20 01:06:58,958 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[01:06:58.958] 2025-08-20 01:06:58,958 - batch_test_runner - INFO - Starting batch test with 30 tasks, 100 workers
[01:06:58.958] 2025-08-20 01:06:58,958 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[01:06:58.959] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.960] 2025-08-20 01:06:58,960 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for DeepSeek-R1-0528
[01:06:58.962] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.963] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.965] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.966] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.966] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.967] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.987] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:58.987] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:58.987] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:58.987] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:58.988] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:58.988] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:58.989] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:58.989] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:58.989] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.989] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.989] 2025-08-20 01:06:58,989 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:58.990] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:58.990] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:58.990] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.990] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:58.990] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.990] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.990] 2025-08-20 01:06:58,990 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:58.991] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.991] 
[01:06:58.992] 2025-08-20 01:06:58,991 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:58.995] [InteractiveExecutor] API model name: DeepSeek-R1-0528[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:58.995] 
[01:06:58.995] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:58.995] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:58.997] 2025-08-20 01:06:58,997 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:58.998] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:58.998] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:58.998] 
[01:06:58.998] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:58.998] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:58.999] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.004] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.004] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.004] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.005] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.005] [InteractiveExecutor] API model name: DeepSeek-R1-0528[InteractiveExecutor] No LLM client provided, initializing from api_client_manager[MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.006] 
[01:06:59.006] 
[01:06:59.006] 2025-08-20 01:06:59,006 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.006] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.006] [MCPEmbeddingManager] Current cache size: 30 embeddings[MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.006] 
[01:06:59.007] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-05282025-08-20 01:06:59,007 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.008] 
[01:06:59.008] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.013] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.013] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.014] 2025-08-20 01:06:59,014 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.015] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.015] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.015] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.016] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.017] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.017] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.020] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.020] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.021] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.034] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.034] 2025-08-20 01:06:59,034 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.036] 2025-08-20 01:06:59,036 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.037] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.038] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.038] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.042] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.045] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.045] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.045] 2025-08-20 01:06:59,045 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.054] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.054] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.072] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.072] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.078] 2025-08-20 01:06:59,078 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.078] 2025-08-20 01:06:59,078 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.078] 2025-08-20 01:06:59,078 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.081] [INFO] Tool embedding index loaded successfully
[01:06:59.094] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.101] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.106] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.106] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.107] 2025-08-20 01:06:59,107 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.107] 2025-08-20 01:06:59,107 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.108] 2025-08-20 01:06:59,108 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.108] 
[01:06:59.108] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.112] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.112] 2025-08-20 01:06:59,112 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.115] [INFO] Tool embedding index loaded successfully
[01:06:59.115] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.115] 
[01:06:59.123] 2025-08-20 01:06:59,123 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.125] [INFO] Operation semantic index initialized
[01:06:59.125] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.125] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.125] [MCPEmbeddingManager] Current cache size: 17 embeddings
[01:06:59.129] 2025-08-20 01:06:59,129 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.129] 2025-08-20 01:06:59,129 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.129] 2025-08-20 01:06:59,129 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.132] [INFO] Tool embedding index loaded successfully
[01:06:59.133] 2025-08-20 01:06:59,133 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.133] 2025-08-20 01:06:59,133 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.133] 2025-08-20 01:06:59,133 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.140] 2025-08-20 01:06:59,140 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:06:59.143] [INFO] Tool embedding index loaded successfully
[01:06:59.156] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.156] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.160] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.160] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.178] 2025-08-20 01:06:59,178 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.178] 2025-08-20 01:06:59,178 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.178] 2025-08-20 01:06:59,178 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.180] [INFO] Tool embedding index loaded successfully
[01:06:59.182] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.182] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.182] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.182] 2025-08-20 01:06:59,182 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.183] 2025-08-20 01:06:59,183 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.183] 2025-08-20 01:06:59,183 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.183] 2025-08-20 01:06:59,183 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.185] [INFO] Tool embedding index loaded successfully
[01:06:59.188] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.194] [INFO] Operation semantic index initialized[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.199] 
[01:06:59.199] 
[01:06:59.200] [INFO] Operation semantic index initialized
[01:06:59.206] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.207] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.213] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.219] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.220] [INFO] Operation semantic index initialized2025-08-20 01:06:59,220 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.220] 2025-08-20 01:06:59,220 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.220] 2025-08-20 01:06:59,220 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:06:59.222] [INFO] Tool embedding index loaded successfully
[01:06:59.225] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-20 01:06:59,225 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.225] 2025-08-20 01:06:59,225 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.225] 2025-08-20 01:06:59,225 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:06:59.228] [INFO] Tool embedding index loaded successfully
[01:06:59.232] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.232] [INFO] Operation semantic index initialized
[01:06:59.233] 2025-08-20 01:06:59,233 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.233] 2025-08-20 01:06:59,233 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.233] 2025-08-20 01:06:59,233 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.235] [INFO] Tool embedding index loaded successfully
[01:06:59.237] 
[01:06:59.237] 
[01:06:59.240] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.241] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.241] [INFO] Operation semantic index initialized[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.242] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.242] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.242] 
[01:06:59.243] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.243] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.243] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.243] [INFO] Operation semantic index initialized
[01:06:59.243] 2025-08-20 01:06:59,243 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.244] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.245] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.247] [INFO] Operation semantic index initialized
[01:06:59.247] [INFO] Operation semantic index initialized
[01:06:59.247] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.254] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.254] 
[01:06:59.254] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.254] 2025-08-20 01:06:59,254 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.275] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.276] 
[01:06:59.276] [TURN 1/10]
[01:06:59.277] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.277] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.278] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.278] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.278] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.278] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.279] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.279] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.286] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.286] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.287] 
[01:06:59.288] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.290] 
[01:06:59.290] [TURN 1/10]
[01:06:59.298] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.298] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.298] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.298] 2025-08-20 01:06:59,298 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.298] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.298] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.298] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.298] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.298] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.299] 
[01:06:59.299] [TURN 1/10]
[01:06:59.299] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.300] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.300] 2025-08-20 01:06:59,299 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.304] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.304] [TURN 1/10]
[01:06:59.304] 
[01:06:59.304] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.304] 2025-08-20 01:06:59,304 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.304] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.310] 2025-08-20 01:06:59,309 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.310] 2025-08-20 01:06:59,310 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.310] 2025-08-20 01:06:59,310 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.313] [INFO] Tool embedding index loaded successfully
[01:06:59.314] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.314] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.315] [InteractiveExecutor] API model name: DeepSeek-R1-0528[InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.315] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.318] 
[01:06:59.318] [TURN 1/10]
[01:06:59.318] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.321] 2025-08-20 01:06:59,321 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.321] 
[01:06:59.321] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.321] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.321] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.321] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.321] 2025-08-20 01:06:59,321 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.321] 2025-08-20 01:06:59,321 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.326] 
[01:06:59.326] [TURN 1/10]
[01:06:59.327] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.328] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.341] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.341] [INFO] Operation semantic index initialized
[01:06:59.358] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.360] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.360] [MCPEmbeddingManager] Current cache size: 12 embeddings
[01:06:59.360] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.381] 2025-08-20 01:06:59,381 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.381] 2025-08-20 01:06:59,381 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.381] 2025-08-20 01:06:59,381 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.385] [INFO] Tool embedding index loaded successfully
[01:06:59.387] 2025-08-20 01:06:59,386 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.395] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.425] 2025-08-20 01:06:59,425 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.425] 2025-08-20 01:06:59,425 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.425] 2025-08-20 01:06:59,425 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.428] [INFO] Tool embedding index loaded successfully
[01:06:59.429] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.434] 
[01:06:59.434] [TURN 1/10]
[01:06:59.435] 
[01:06:59.448] [TURN 1/10][InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.448] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.453] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.453] 
[01:06:59.460] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.462] [INFO] Operation semantic index initialized
[01:06:59.466] [INFO] Operation semantic index initialized
[01:06:59.467] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.468] 2025-08-20 01:06:59,468 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.468] 2025-08-20 01:06:59,468 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.474] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.487] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.487] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.487] [MCPEmbeddingManager] Current cache size: 18 embeddings
[01:06:59.494] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.495] 2025-08-20 01:06:59,468 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.496] 2025-08-20 01:06:59,481 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.498] [INFO] Tool embedding index loaded successfully
[01:06:59.500] 2025-08-20 01:06:59,492 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.500] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.501] 2025-08-20 01:06:59,492 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.513] 2025-08-20 01:06:59,495 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.513] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.513] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.516] 
[01:06:59.516] [TURN 1/10]
[01:06:59.517] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.517] 2025-08-20 01:06:59,498 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.520] 2025-08-20 01:06:59,501 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.533] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.533] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.533] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.539] [INFO] Operation semantic index initialized
[01:06:59.539] 
[01:06:59.539] [TURN 1/10]
[01:06:59.539] 2025-08-20 01:06:59,513 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.547] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.547] 2025-08-20 01:06:59,513 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.550] [INFO] Tool embedding index loaded successfully
[01:06:59.550] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.550] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.550] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.550] 2025-08-20 01:06:59,517 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.557] 2025-08-20 01:06:59,520 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.560] [INFO] Tool embedding index loaded successfully
[01:06:59.573] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.573] [TURN 1/10]
[01:06:59.573] 2025-08-20 01:06:59,539 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.577] 2025-08-20 01:06:59,541 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.582] 2025-08-20 01:06:59,550 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:06:59.589] [INFO] Tool embedding index loaded successfully
[01:06:59.589] 
[01:06:59.590] [TURN 1/10]
[01:06:59.590] 
[01:06:59.590] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.590] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.590] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.590] 2025-08-20 01:06:59,564 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.590] 2025-08-20 01:06:59,590 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.590] 2025-08-20 01:06:59,590 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.602] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:06:59.602] [TURN 1/10]
[01:06:59.605] [INFO] Tool embedding index loaded successfully
[01:06:59.605] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.610] 
[01:06:59.610] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.610] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.610] 
[01:06:59.610] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.611] 2025-08-20 01:06:59,590 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.624] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.624] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.624] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.624] 2025-08-20 01:06:59,590 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.625] [INFO] Operation semantic index initialized
[01:06:59.625] 
[01:06:59.625] [TURN 1/10]
[01:06:59.626] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.626] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.626] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.626] 2025-08-20 01:06:59,592 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.627] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.627] 2025-08-20 01:06:59,576 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.630] [INFO] Tool embedding index loaded successfully
[01:06:59.630] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.631] [INFO] Operation semantic index initialized
[01:06:59.631] 
[01:06:59.631] [TURN 1/10]
[01:06:59.632] [INFO] Operation semantic index initialized2025-08-20 01:06:59,577 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.633] 2025-08-20 01:06:59,611 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.634] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.634] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.634] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.640] 
[01:06:59.640] 
[01:06:59.640] [TURN 1/10]
[01:06:59.645] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.647] 2025-08-20 01:06:59,624 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.647] 2025-08-20 01:06:59,624 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.647] 2025-08-20 01:06:59,624 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.647] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.648] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.649] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.650] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.650] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.650] 2025-08-20 01:06:59,626 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.650] 2025-08-20 01:06:59,650 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.650] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.650] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.652] [INFO] Operation semantic index initialized
[01:06:59.652] 
[01:06:59.652] [TURN 1/10]
[01:06:59.652] [INFO] Operation semantic index initialized
[01:06:59.652] 
[01:06:59.653] [TURN 1/10]
[01:06:59.657] [INFO] Tool embedding index loaded successfully2025-08-20 01:06:59,633 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.658] 2025-08-20 01:06:59,634 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.658] 2025-08-20 01:06:59,644 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.661] [INFO] Tool embedding index loaded successfully
[01:06:59.662] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.662] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.662] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.662] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.664] 2025-08-20 01:06:59,647 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.666] 2025-08-20 01:06:59,649 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.666] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528
[01:06:59.666] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:06:59.666] 2025-08-20 01:06:59,649 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.669] [INFO] Tool embedding index loaded successfully
[01:06:59.670] 2025-08-20 01:06:59,632 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.670] 
[01:06:59.681] 2025-08-20 01:06:59,662 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.681] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.681] 2025-08-20 01:06:59,664 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.687] [INFO] Tool embedding index loaded successfully
[01:06:59.689] [InteractiveExecutor] API model name: DeepSeek-R1-0528
[01:06:59.689] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13485435760)
[01:06:59.689] 2025-08-20 01:06:59,666 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.689] 2025-08-20 01:06:59,670 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.692] [INFO] Tool embedding index loaded successfully
[01:06:59.693] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.697] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json[MCPEmbeddingManager] Current cache size: 30 embeddings
[01:06:59.698] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.698] [INFO] Operation semantic index initialized
[01:06:59.699] 2025-08-20 01:06:59,688 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.699] 2025-08-20 01:06:59,699 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.699] 
[01:06:59.699] 
[01:06:59.699] [TURN 1/10]
[01:06:59.699] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.700] 2025-08-20 01:06:59,689 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.702] [INFO] Tool embedding index loaded successfully
[01:06:59.703] 2025-08-20 01:06:59,699 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.705] [INFO] Tool embedding index loaded successfully
[01:06:59.706] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.706] [INFO] Operation semantic index initialized
[01:06:59.706] 
[01:06:59.706] [TURN 1/10]
[01:06:59.706] [INFO] Operation semantic index initialized
[01:06:59.706] 
[01:06:59.706] [TURN 1/10]
[01:06:59.708] 2025-08-20 01:06:59,699 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:06:59.709] [INFO] Operation semantic index initialized
[01:06:59.710] 
[01:06:59.710] [TURN 1/10]
[01:06:59.712] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.713] [INFO] Operation semantic index initialized
[01:06:59.716] 
[01:06:59.716] [TURN 1/10]
[01:06:59.717] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.717] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.717] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.719] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.721] [INFO] Operation semantic index initialized
[01:06:59.723] 
[01:06:59.723] [TURN 1/10]
[01:06:59.730] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528[LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.732] [INFO] Operation semantic index initialized
[01:06:59.732] 
[01:06:59.732] [TURN 1/10]
[01:06:59.733] 
[01:06:59.737] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.747] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.748] 2025-08-20 01:06:59,748 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.748] 2025-08-20 01:06:59,748 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.748] 2025-08-20 01:06:59,748 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.751] [INFO] Tool embedding index loaded successfully
[01:06:59.764] 2025-08-20 01:06:59,764 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.764] 2025-08-20 01:06:59,764 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.765] 2025-08-20 01:06:59,764 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.767] [INFO] Tool embedding index loaded successfully
[01:06:59.769] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.777] [INFO] Operation semantic index initialized
[01:06:59.777] 
[01:06:59.777] [TURN 1/10]
[01:06:59.777] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.778] [INFO] Operation semantic index initialized
[01:06:59.781] 
[01:06:59.781] [TURN 1/10]
[01:06:59.782] 2025-08-20 01:06:59,782 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.782] 2025-08-20 01:06:59,782 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.782] 2025-08-20 01:06:59,782 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.785] [INFO] Tool embedding index loaded successfully
[01:06:59.785] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.788] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.794] [INFO] Operation semantic index initialized
[01:06:59.798] 
[01:06:59.798] [TURN 1/10][LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.799] 
[01:06:59.800] 2025-08-20 01:06:59,800 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.800] 2025-08-20 01:06:59,800 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.800] 2025-08-20 01:06:59,800 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.802] [INFO] Tool embedding index loaded successfully
[01:06:59.813] 2025-08-20 01:06:59,813 - mcp_embedding_manager - INFO - FAISS index loaded
[01:06:59.813] 2025-08-20 01:06:59,813 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:06:59.813] 2025-08-20 01:06:59,813 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:06:59.816] [INFO] Tool embedding index loaded successfully
[01:06:59.817] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.817] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.818] [INFO] Operation semantic index initialized
[01:06:59.818] 
[01:06:59.818] [TURN 1/10]
[01:06:59.819] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:06:59.819] [INFO] Operation semantic index initialized
[01:06:59.819] 
[01:06:59.819] [TURN 1/10]
[01:06:59.823] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:06:59.824] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:08:34.266] 2025-08-20 01:08:34,265 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:08:34.271]   [SEARCH] Query: data parser
[01:08:34.273] 
[01:08:34.273] [TURN 2/10]
[01:08:34.274] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:08:40.488] 2025-08-20 01:08:40,487 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:08:40.491]   [SEARCH] Query: file reader
[01:08:40.491] 
[01:08:40.491] [TURN 2/10]
[01:08:40.493] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:08:56.903] 2025-08-20 01:08:56,902 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:08:56.907]   [SEARCH] Query: data validation schema
[01:08:56.909] 
[01:08:56.909] [TURN 2/10]
[01:08:56.922] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:08:59.598] 2025-08-20 01:08:59,598 - openai._base_client - INFO - Retrying request to /chat/completions in 0.434941 seconds
[01:08:59.649] 2025-08-20 01:08:59,649 - openai._base_client - INFO - Retrying request to /chat/completions in 0.498329 seconds
[01:08:59.654] 2025-08-20 01:08:59,654 - openai._base_client - INFO - Retrying request to /chat/completions in 0.438559 seconds
[01:08:59.766] 2025-08-20 01:08:59,766 - openai._base_client - INFO - Retrying request to /chat/completions in 0.377119 seconds
[01:08:59.789] 2025-08-20 01:08:59,789 - openai._base_client - INFO - Retrying request to /chat/completions in 0.436110 seconds
[01:08:59.821] 2025-08-20 01:08:59,821 - openai._base_client - INFO - Retrying request to /chat/completions in 0.467248 seconds
[01:08:59.862] 2025-08-20 01:08:59,862 - openai._base_client - INFO - Retrying request to /chat/completions in 0.463461 seconds
[01:08:59.872] 2025-08-20 01:08:59,871 - openai._base_client - INFO - Retrying request to /chat/completions in 0.479708 seconds
[01:08:59.906] 2025-08-20 01:08:59,905 - openai._base_client - INFO - Retrying request to /chat/completions in 0.462164 seconds
[01:08:59.906] 2025-08-20 01:08:59,906 - openai._base_client - INFO - Retrying request to /chat/completions in 0.471747 seconds
[01:08:59.907] 2025-08-20 01:08:59,907 - openai._base_client - INFO - Retrying request to /chat/completions in 0.461998 seconds
[01:08:59.917] 2025-08-20 01:08:59,916 - openai._base_client - INFO - Retrying request to /chat/completions in 0.445131 seconds
[01:08:59.924] 2025-08-20 01:08:59,923 - openai._base_client - INFO - Retrying request to /chat/completions in 0.401554 seconds
[01:08:59.935] 2025-08-20 01:08:59,935 - openai._base_client - INFO - Retrying request to /chat/completions in 0.444808 seconds
[01:08:59.940] 2025-08-20 01:08:59,939 - openai._base_client - INFO - Retrying request to /chat/completions in 0.489933 seconds
[01:08:59.962] 2025-08-20 01:08:59,962 - openai._base_client - INFO - Retrying request to /chat/completions in 0.490190 seconds
[01:08:59.974] 2025-08-20 01:08:59,973 - openai._base_client - INFO - Retrying request to /chat/completions in 0.474692 seconds
[01:08:59.991] 2025-08-20 01:08:59,991 - openai._base_client - INFO - Retrying request to /chat/completions in 0.492498 seconds
[01:08:59.992] 2025-08-20 01:08:59,992 - openai._base_client - INFO - Retrying request to /chat/completions in 0.472836 seconds
[01:09:00.010] 2025-08-20 01:09:00,000 - openai._base_client - INFO - Retrying request to /chat/completions in 0.458250 seconds
[01:09:00.011] 2025-08-20 01:09:00,011 - openai._base_client - INFO - Retrying request to /chat/completions in 0.498360 seconds
[01:09:00.011] 2025-08-20 01:09:00,011 - openai._base_client - INFO - Retrying request to /chat/completions in 0.422739 seconds
[01:09:00.033] 2025-08-20 01:09:00,033 - openai._base_client - INFO - Retrying request to /chat/completions in 0.449214 seconds
[01:09:00.048] 2025-08-20 01:09:00,048 - openai._base_client - INFO - Retrying request to /chat/completions in 0.453523 seconds
[01:09:00.081] 2025-08-20 01:09:00,080 - openai._base_client - INFO - Retrying request to /chat/completions in 0.380660 seconds
[01:09:00.081] 2025-08-20 01:09:00,080 - openai._base_client - INFO - Retrying request to /chat/completions in 0.421080 seconds
[01:09:00.081] 2025-08-20 01:09:00,081 - openai._base_client - INFO - Retrying request to /chat/completions in 0.483801 seconds
[01:10:34.303] 2025-08-20 01:10:34,300 - openai._base_client - INFO - Retrying request to /chat/completions in 0.437339 seconds
[01:10:40.500] 2025-08-20 01:10:40,500 - openai._base_client - INFO - Retrying request to /chat/completions in 0.439230 seconds
[01:10:56.930] 2025-08-20 01:10:56,929 - openai._base_client - INFO - Retrying request to /chat/completions in 0.406965 seconds
[01:11:00.323] 2025-08-20 01:11:00,323 - openai._base_client - INFO - Retrying request to /chat/completions in 0.762380 seconds
[01:11:00.349] 2025-08-20 01:11:00,348 - openai._base_client - INFO - Retrying request to /chat/completions in 0.891438 seconds
[01:11:00.398] 2025-08-20 01:11:00,397 - openai._base_client - INFO - Retrying request to /chat/completions in 0.761416 seconds
[01:11:00.398] 2025-08-20 01:11:00,398 - openai._base_client - INFO - Retrying request to /chat/completions in 0.941523 seconds
[01:11:00.483] 2025-08-20 01:11:00,483 - openai._base_client - INFO - Retrying request to /chat/completions in 0.915861 seconds
[01:11:00.564] 2025-08-20 01:11:00,564 - openai._base_client - INFO - Retrying request to /chat/completions in 0.915488 seconds
[01:11:00.569] 2025-08-20 01:11:00,569 - openai._base_client - INFO - Retrying request to /chat/completions in 0.889648 seconds
[01:11:00.570] 2025-08-20 01:11:00,570 - openai._base_client - INFO - Retrying request to /chat/completions in 0.885274 seconds
[01:11:00.601] 2025-08-20 01:11:00,601 - openai._base_client - INFO - Retrying request to /chat/completions in 0.908586 seconds
[01:11:00.616] 2025-08-20 01:11:00,615 - openai._base_client - INFO - Retrying request to /chat/completions in 0.872777 seconds
[01:11:00.648] 2025-08-20 01:11:00,648 - openai._base_client - INFO - Retrying request to /chat/completions in 0.861709 seconds
[01:11:00.648] 2025-08-20 01:11:00,648 - openai._base_client - INFO - Retrying request to /chat/completions in 0.980307 seconds
[01:11:00.648] 2025-08-20 01:11:00,648 - openai._base_client - INFO - Retrying request to /chat/completions in 0.766525 seconds
[01:11:00.648] 2025-08-20 01:11:00,648 - openai._base_client - INFO - Retrying request to /chat/completions in 0.792840 seconds
[01:11:00.678] 2025-08-20 01:11:00,678 - openai._base_client - INFO - Retrying request to /chat/completions in 0.809163 seconds
[01:11:00.703] 2025-08-20 01:11:00,703 - openai._base_client - INFO - Retrying request to /chat/completions in 0.841470 seconds
[01:11:00.703] 2025-08-20 01:11:00,703 - openai._base_client - INFO - Retrying request to /chat/completions in 0.758022 seconds
[01:11:00.705] 2025-08-20 01:11:00,705 - openai._base_client - INFO - Retrying request to /chat/completions in 0.909127 seconds
[01:11:00.712] 2025-08-20 01:11:00,712 - openai._base_client - INFO - Retrying request to /chat/completions in 0.792935 seconds
[01:11:00.712] 2025-08-20 01:11:00,712 - openai._base_client - INFO - Retrying request to /chat/completions in 0.776513 seconds
[01:11:00.715] 2025-08-20 01:11:00,715 - openai._base_client - INFO - Retrying request to /chat/completions in 0.817176 seconds
[01:11:00.734] 2025-08-20 01:11:00,734 - openai._base_client - INFO - Retrying request to /chat/completions in 0.991444 seconds
[01:11:00.734] 2025-08-20 01:11:00,734 - openai._base_client - INFO - Retrying request to /chat/completions in 0.780874 seconds
[01:11:00.755] 2025-08-20 01:11:00,755 - openai._base_client - INFO - Retrying request to /chat/completions in 0.941109 seconds
[01:11:00.779] 2025-08-20 01:11:00,778 - openai._base_client - INFO - Retrying request to /chat/completions in 0.927296 seconds
[01:11:00.809] 2025-08-20 01:11:00,808 - openai._base_client - INFO - Retrying request to /chat/completions in 0.752329 seconds
[01:11:00.868] 2025-08-20 01:11:00,868 - openai._base_client - INFO - Retrying request to /chat/completions in 0.965791 seconds
[01:12:31.350] 2025-08-20 01:12:31,349 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:12:31.351] 2025-08-20 01:12:31,351 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:12:31.355]   [SEARCH] Query: file_operations_reader  [SEARCH] Query: api fetch
[01:12:31.356] 
[01:12:31.357] 
[01:12:31.357] [TURN 2/10]
[01:12:31.357] [TURN 2/10]
[01:12:31.357] 
[01:12:31.358] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:12:31.360] [LLM_CALL] Using model: DeepSeek-R1-0528, API name: DeepSeek-R1-0528
[01:12:35.139] 2025-08-20 01:12:35,138 - openai._base_client - INFO - Retrying request to /chat/completions in 0.878989 seconds
[01:12:41.199] 2025-08-20 01:12:41,199 - openai._base_client - INFO - Retrying request to /chat/completions in 0.818777 seconds
[01:12:57.605] 2025-08-20 01:12:57,598 - openai._base_client - INFO - Retrying request to /chat/completions in 0.790137 seconds
[01:13:01.395] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.395] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.395]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.404] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:01.410] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.411] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.411]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.497] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.497] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.498]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.658] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.658] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.658]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.674] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.674] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.674]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.690] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.690] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.690]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.708] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.709] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.710]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.720] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.720] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.720]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.721] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.721] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.721]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.741] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.742] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.743]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.744] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.744] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.744]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.746] [LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.746] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.746]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.746] 
[01:13:01.746] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.747]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.756] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.756] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.756]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.759] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.759] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.759]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.761] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.761] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.761]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.775] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.775] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.775]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.803] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.803] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.803]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.811] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.811] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.811]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.824] 2025-08-20 01:13:01,824 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:01.828] 2025-08-20 01:13:01,828 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:01.831] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:01.898] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.898] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.898]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.948] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.948] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.948]   [API_FAILURE] API failed (timeout or max retries)
[01:13:01.973] 2025-08-20 01:13:01,973 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:01.973] 2025-08-20 01:13:01,973 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:01.974] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:01.984] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:01.984] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:01.984]   [API_FAILURE] API failed (timeout or max retries)
[01:13:02.027] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:02.027] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:02.027]   [API_FAILURE] API failed (timeout or max retries)
[01:13:02.056] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:02.056] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:02.056]   [API_FAILURE] API failed (timeout or max retries)
[01:13:02.081] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:02.082] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:02.082]   [API_FAILURE] API failed (timeout or max retries)
[01:13:02.105] 2025-08-20 01:13:02,105 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.106] 2025-08-20 01:13:02,106 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.108] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:02.229] 2025-08-20 01:13:02,229 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.230] 2025-08-20 01:13:02,230 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.234] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:02.354] 2025-08-20 01:13:02,353 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.355] 2025-08-20 01:13:02,354 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.374] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:02.516] 2025-08-20 01:13:02,515 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.517] 2025-08-20 01:13:02,517 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.520] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:02.642] 2025-08-20 01:13:02,641 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.642] 2025-08-20 01:13:02,642 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.644] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:02.783] 2025-08-20 01:13:02,783 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.785] 2025-08-20 01:13:02,784 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.792] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:02.930] 2025-08-20 01:13:02,930 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:02.930] 2025-08-20 01:13:02,930 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:02.932] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.050] 2025-08-20 01:13:03,050 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.050] 2025-08-20 01:13:03,050 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.051] Progress: 10/30 (Success: 0)
[01:13:03.051] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.183] 2025-08-20 01:13:03,182 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.183] 2025-08-20 01:13:03,183 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.186] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.306] 2025-08-20 01:13:03,306 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.307] 2025-08-20 01:13:03,307 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.311] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.435] 2025-08-20 01:13:03,434 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.435] 2025-08-20 01:13:03,435 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.438] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.582] 2025-08-20 01:13:03,582 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.583] 2025-08-20 01:13:03,583 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.590] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.717] 2025-08-20 01:13:03,716 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.718] 2025-08-20 01:13:03,718 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.720] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:03.848] 2025-08-20 01:13:03,846 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:03.848] 2025-08-20 01:13:03,848 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:03.851] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.033] 2025-08-20 01:13:04,033 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.034] 2025-08-20 01:13:04,034 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.036] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.182] 2025-08-20 01:13:04,182 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.183] 2025-08-20 01:13:04,183 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.184] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.392] 2025-08-20 01:13:04,391 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.393] 2025-08-20 01:13:04,392 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.396] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.536] 2025-08-20 01:13:04,536 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.537] 2025-08-20 01:13:04,537 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.540] Progress: 20/30 (Success: 0)
[01:13:04.540] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.679] 2025-08-20 01:13:04,679 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.680] 2025-08-20 01:13:04,680 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.683] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.800] 2025-08-20 01:13:04,800 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.800] 2025-08-20 01:13:04,800 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.801] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:04.945] 2025-08-20 01:13:04,945 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:04.945] 2025-08-20 01:13:04,945 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:04.947] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:05.095] 2025-08-20 01:13:05,095 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:05.096] 2025-08-20 01:13:05,096 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:05.097] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:05.218] 2025-08-20 01:13:05,217 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:05.219] 2025-08-20 01:13:05,219 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:14:31.372] 2025-08-20 01:14:31,372 - openai._base_client - INFO - Retrying request to /chat/completions in 0.387388 seconds
[01:14:31.373] 2025-08-20 01:14:31,372 - openai._base_client - INFO - Retrying request to /chat/completions in 0.461563 seconds
[01:14:36.309] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:14:36.310] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:14:36.310]   [API_FAILURE] API failed (timeout or max retries)
[01:14:36.317] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:14:42.456] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:14:42.456] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:14:42.456]   [API_FAILURE] API failed (timeout or max retries)
[01:14:42.457] [DEBUG] Got result for task: has_result=True, save_logs=True
