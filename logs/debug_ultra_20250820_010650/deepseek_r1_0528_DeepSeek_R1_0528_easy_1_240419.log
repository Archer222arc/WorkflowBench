===== 分片 DeepSeek-R1-0528_easy_1 =====
时间: 2025-08-20T01:07:20.422230
模型: deepseek-r1-0528
实例: DeepSeek-R1-0528-2
命令: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528-2 --prompt-types optimal --difficulty easy --task-types all --num-instances 6 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[01:07:22.076] 2025-08-20 01:07:22,075 - faiss.loader - INFO - Loading faiss.
[01:07:22.089] 2025-08-20 01:07:22,089 - faiss.loader - INFO - Successfully loaded faiss.
[01:07:22.987] [INFO] 使用Parquet存储格式
[01:07:23.347] [INFO] 使用Parquet存储格式
[01:07:23.349] [INFO] 使用PARQUET存储格式
[01:07:23.349] 
[01:07:23.349] ============================================================
[01:07:23.349] 智能批测试: deepseek-r1-0528 (idealab)
[01:07:23.349] Prompt types: ['optimal']
[01:07:23.349] 难度: easy
[01:07:23.349] 目标: 每种配置 6 个实例
[01:07:23.349] ============================================================
[01:07:23.349] ○ simple_task         :   0/  6 已完成 (需要补充 6 个)
[01:07:23.349] ○ basic_task          :   0/  6 已完成 (需要补充 6 个)
[01:07:23.349] ○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
[01:07:23.349] ○ api_integration     :   0/  6 已完成 (需要补充 6 个)
[01:07:23.349] ○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)
[01:07:23.349] 
[01:07:23.349] ⏳ 需要运行 30 个新测试
[01:07:23.349] 
[01:07:23.350] ▶ 准备 simple_task (6 个实例)...
[01:07:23.350] 
[01:07:23.350] ▶ 准备 basic_task (6 个实例)...
[01:07:23.350] 
[01:07:23.350] ▶ 准备 data_pipeline (6 个实例)...
[01:07:23.350] 
[01:07:23.350] ▶ 准备 api_integration (6 个实例)...
[01:07:23.350] 
[01:07:23.350] ▶ 准备 multi_stage_pipeline (6 个实例)...
[01:07:23.350] 
[01:07:23.350] ▶ 开始执行 30 个测试...
[01:07:23.350] 📦 批量提交模式：每20个测试保存一次
[01:07:23.350] 🚀 检测到Azure API，使用超高并发: workers=100, qps=200.0
[01:07:23.351] 2025-08-20 01:07:23,351 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[01:07:23.408] 2025-08-20 01:07:23,408 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[01:07:23.408] 2025-08-20 01:07:23,408 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[01:07:23.408] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[01:07:23.409] 2025-08-20 01:07:23,408 - batch_test_runner - INFO - ============================================================
[01:07:23.409] 2025-08-20 01:07:23,409 - batch_test_runner - INFO - Batch test runner initialized
[01:07:23.409] 2025-08-20 01:07:23,409 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[01:07:23.409] 2025-08-20 01:07:23,409 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_010723.log
[01:07:23.409] 2025-08-20 01:07:23,409 - batch_test_runner - INFO - ============================================================
[01:07:23.409] 2025-08-20 01:07:23,409 - batch_test_runner - INFO - Running 30 tests with 100 workers, QPS limit: 200.0
[01:07:23.409] 2025-08-20 01:07:23,409 - batch_test_runner - INFO - Initializing test components...
[01:07:23.701] 2025-08-20 01:07:23,701 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[01:07:23.701] 2025-08-20 01:07:23,701 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[01:07:23.701] 2025-08-20 01:07:23,701 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[01:07:23.701] [DEBUG] Creating new ToolCapabilityManager instance
[01:07:23.701] [OperationEmbeddingIndex] Initializing with unified API client manager
[01:07:23.701] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[01:07:23.702] 2025-08-20 01:07:23,702 - api_client_manager - INFO - Loaded configuration from config/config.json
[01:07:23.708] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[01:07:23.708] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[01:07:23.708] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[01:07:24.608] 2025-08-20 01:07:24,608 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[01:07:24.610] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[01:07:24.834] [INFO] Loaded 4150 embeddings from persistent cache
[01:07:24.834] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[01:07:24.835] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[01:07:24.835] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[01:07:24.835] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[01:07:24.841] [INFO] Successfully loaded FAISS index with dimension 3072
[01:07:24.841] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[01:07:24.841] [INFO] Loaded 15 operations with dimension 3072
[01:07:24.841] [INFO] Successfully loaded cached index
[01:07:24.841] [INFO] Operation semantic index initialized
[01:07:24.841] [INFO] Using device: cpu
[01:07:24.841] [INFO] Initialized tool success tracking attributes
[01:07:24.841] [INFO] Initializing embedding manager for enhanced tool selection
[01:07:24.841] [MCPEmbeddingManager] Creating new singleton instance
[01:07:24.841] [MCPEmbeddingManager] Initializing with unified API client manager
[01:07:24.852] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[01:07:24.853] [MCPEmbeddingManager] Client initialized successfully
[01:07:24.853] 2025-08-20 01:07:24,853 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:07:25.021] 2025-08-20 01:07:25,021 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:07:25.265] 2025-08-20 01:07:25,265 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[01:07:25.265] 2025-08-20 01:07:25,265 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[01:07:25.290] 2025-08-20 01:07:25,290 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[01:07:25.407] 2025-08-20 01:07:25,406 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[01:07:25.658] 2025-08-20 01:07:25,657 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[01:07:25.658] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[01:07:25.658] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[01:07:25.658] 2025-08-20 01:07:25,658 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:25.682] 2025-08-20 01:07:25,682 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:25.682] 2025-08-20 01:07:25,682 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:25.682] 2025-08-20 01:07:25,682 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:25.685] [SUCCESS] Loaded 30 tool embeddings
[01:07:25.685] 2025-08-20 01:07:25,685 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[01:07:25.685] [SUCCESS] Embedding manager initialized with 30 tools
[01:07:25.685] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[01:07:25.685] [INFO] Loading full MCP protocol registry...
[01:07:25.686] 2025-08-20 01:07:25,686 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:25.686] [INFO] Loaded full tool registry with 30 tools
[01:07:25.686] 2025-08-20 01:07:25,686 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:07:25.686] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[01:07:25.687] [INFO] Embedding manager ready with 30 tools
[01:07:25.687] [WARNING] Embedding manager exists but has no embeddings
[01:07:25.687] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[01:07:25.687] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:25.687] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:25.692] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:25.692] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[01:07:25.692] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[01:07:25.692] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:25.692] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:25.692] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:25.692] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:25.692] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:25.692] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:25.692] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[01:07:25.692] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:25.692] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:25.692] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[01:07:25.692] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:25.692] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:25.692] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[01:07:25.692] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:25.692] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:25.692] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:25.692] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[01:07:25.692] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[01:07:25.692] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[01:07:25.692] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[01:07:25.692] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[01:07:25.692] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[01:07:25.692] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[01:07:25.692] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[01:07:25.692] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[01:07:25.692] 2025-08-20 01:07:25,690 - mdp_workflow_generator - INFO - Loaded 30 tools
[01:07:25.692] [INFO] Setting default state_dim based on loaded tools
[01:07:25.692] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[01:07:25.692] 2025-08-20 01:07:25,690 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[01:07:25.692] [INFO] Setting default action_dim based on loaded tools
[01:07:25.692] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[01:07:25.692] 2025-08-20 01:07:25,690 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[01:07:25.692] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[01:07:25.692] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[01:07:25.692] [INFO] ⚡ Will use pre-generated workflows or random policy
[01:07:25.692] 2025-08-20 01:07:25,691 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[01:07:25.692] [INFO] Initializing TaskManager...
[01:07:27.271] 2025-08-20 01:07:27,271 - unified_training_manager - INFO - Using device: cpu
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO - Task filtering results:
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO -   Total: 5040 -> 5040
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO -   simple_task: 320 -> 320
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[01:07:27.384] 2025-08-20 01:07:27,384 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[01:07:27.386] 2025-08-20 01:07:27,386 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[01:07:27.386] [TaskManager] Difficulty level 'easy': 1096 tasks
[01:07:27.386] [TaskManager] Difficulty level 'very_easy': 856 tasks
[01:07:27.386] [TaskManager] Difficulty level 'medium': 1136 tasks
[01:07:27.386] [TaskManager] Difficulty level 'hard': 1096 tasks
[01:07:27.386] [TaskManager] Difficulty level 'very_hard': 856 tasks
[01:07:27.388] [INFO] TaskManager initialized with 5040 tasks
[01:07:27.388] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:07:27.388] [INFO] Initializing ToolCallVerifier...
[01:07:27.389] [INFO] ToolCallVerifier initialized with 30 tools
[01:07:27.389] [INFO] Output tools identified: 1
[01:07:27.389] [INFO] Component initialization status:
[01:07:27.389]   - embedding_manager: initialized
[01:07:27.390]   - task_manager: initialized
[01:07:27.390]   - output_verifier: initialized
[01:07:27.390]   - tool_capability_manager: initialized
[01:07:27.390]   - tool_success_rates: initialized with 0 entries
[01:07:27.390] [INFO] MDPWorkflowGenerator initialization complete
[01:07:27.390] 2025-08-20 01:07:27,389 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[01:07:27.390] 2025-08-20 01:07:27,389 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[01:07:27.390] 2025-08-20 01:07:27,389 - batch_test_runner - INFO -   - task_manager: ✓
[01:07:27.390] 2025-08-20 01:07:27,389 - batch_test_runner - INFO -   - output_verifier: ✓
[01:07:27.392] 2025-08-20 01:07:27,390 - batch_test_runner - INFO -   - embedding_manager: ✓
[01:07:27.392] 2025-08-20 01:07:27,392 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[01:07:27.392] 2025-08-20 01:07:27,392 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[01:07:27.392] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.392] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.392] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:07:27.392] [FlawedWorkflowGenerator] RAG support: disabled
[01:07:27.393] DEBUG: Checking generator attributes
[01:07:27.393]   - has tool_capabilities: True
[01:07:27.393]   - has tool_capability_manager: True
[01:07:27.393]   - has task_manager: True
[01:07:27.393] [INFO] Loaded 30 tools from generator
[01:07:27.393] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[01:07:27.393] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.393] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.393] [INFO] Initializing LLM client using APIClientManager
[01:07:27.404] [INFO] Using Azure OpenAI client
[01:07:27.405] [DEBUG] Checking if generator has tool_capability_manager attribute
[01:07:27.405] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[01:07:27.405] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.405] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.405] [FlawedWorkflowGenerator] Initialized with 30 tools
[01:07:27.405] [FlawedWorkflowGenerator] RAG support: enabled
[01:07:27.405] [INFO] FlawedWorkflowGenerator initialized successfully
[01:07:27.405] [INFO] Initializing StableScorer for Phase 2 scoring
[01:07:27.405] <tool_capability_manager.ToolCapabilityManager object at 0x174649f10>
[01:07:27.405] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.405] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.405] [INFO] Loaded tool success history for 0 tools
[01:07:27.405] [INFO] StableScorer initialized with semantic capability
[01:07:27.405] [INFO] StableScorer initialized successfully
[01:07:27.405] [INFO] Loading task instances...
[01:07:27.405] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[01:07:27.411] [INFO] Loaded 630 task instances
[01:07:27.412] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[01:07:27.412] 2025-08-20 01:07:27,412 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[01:07:27.412] 2025-08-20 01:07:27,412 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[01:07:27.746] 2025-08-20 01:07:27,746 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[01:07:27.746] 2025-08-20 01:07:27,746 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[01:07:27.762] 2025-08-20 01:07:27,761 - batch_test_runner - INFO - Initialization complete
[01:07:27.788] 2025-08-20 01:07:27,788 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[01:07:27.788] 2025-08-20 01:07:27,788 - batch_test_runner - INFO - Starting batch test with 30 tasks, 100 workers
[01:07:27.788] 2025-08-20 01:07:27,788 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[01:07:27.792] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.793] 2025-08-20 01:07:27,793 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for DeepSeek-R1-0528-2
[01:07:27.795] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.797] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.800] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.800] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.819] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.819] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.819] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.819] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.820] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.820] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.821] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.821] 
[01:07:27.821] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.821] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.822] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.823] 
[01:07:27.824] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.824] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.824] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[01:07:27.825] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.825] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.825] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.825] 2025-08-20 01:07:27,825 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.830] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.830] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.830] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.834] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.834] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.834] 
[01:07:27.835] 2025-08-20 01:07:27,835 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.835] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.835] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.835] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.840] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.840] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.841] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.841] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.849] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.849] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.849] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.849] 2025-08-20 01:07:27,847 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.849] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.849] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.849] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.849] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.849] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.849] 2025-08-20 01:07:27,848 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.867] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.867] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.867] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.867] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.869] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.869] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.869] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.869] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.869] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.869] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.873] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.874] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.874] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.883] 2025-08-20 01:07:27,877 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.887] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.888] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.888] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.888] 2025-08-20 01:07:27,885 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.888] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.888] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.888] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.888] 2025-08-20 01:07:27,886 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.899] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.899] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.899] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.900] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.900] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.900] 2025-08-20 01:07:27,899 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.903] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.904] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.904] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.905] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.905] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.905] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.905] 
[01:07:27.905] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.905] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.905] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.905] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.906] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.907] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.907] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.907] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.907] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.907] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.907] 2025-08-20 01:07:27,906 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.907] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.907] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.908] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.908] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.908] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.908] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.908] 
[01:07:27.908] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.908] 
[01:07:27.908] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.908] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.908] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.908] 
[01:07:27.908] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.908] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.908] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.909] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-20 01:07:27,909 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.909] 
[01:07:27.909] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-2
[01:07:27.909] 
[01:07:27.909] 
[01:07:27.910] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.910] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.910] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)[InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.910] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.910] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.910] [InteractiveExecutor] Using prompt type: optimal for API key selection
[01:07:27.911] 
[01:07:27.911] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.911] 
[01:07:27.911] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.911] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.911] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-20 01:07:27,909 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.911] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.911] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.911] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.912] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.912] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.912] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.912] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.912] 2025-08-20 01:07:27,909 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.913] 
[01:07:27.913] [InteractiveExecutor] API model name: DeepSeek-R1-0528-22025-08-20 01:07:27,911 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.919] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.919] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.919] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.919] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.919] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.919] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.919] 2025-08-20 01:07:27,913 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.921] 
[01:07:27.921] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.922] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.922] 
[01:07:27.922] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.922] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.923] 2025-08-20 01:07:27,913 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.923] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2[InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.923] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.923] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.923] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.923] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.923] 2025-08-20 01:07:27,918 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.923] 
[01:07:27.923] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.925] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-20 01:07:27,921 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.925] 
[01:07:27.926] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.926] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.926] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.926] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.926] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.929] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.929] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.929] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.930] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.936] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.936] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.940] 2025-08-20 01:07:27,922 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.946] 2025-08-20 01:07:27,923 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.948] [InteractiveExecutor] API model name: DeepSeek-R1-0528-2
[01:07:27.949] [MCPEmbeddingManager] Reusing existing singleton instance (id: 5707131760)
[01:07:27.950] 2025-08-20 01:07:27,923 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.950] 2025-08-20 01:07:27,924 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.950] 2025-08-20 01:07:27,925 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.955] [MCPEmbeddingManager] Current cache size: 30 embeddings
[01:07:27.957] 2025-08-20 01:07:27,926 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.959] 2025-08-20 01:07:27,926 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.961] 2025-08-20 01:07:27,929 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:27.989] 2025-08-20 01:07:27,933 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:28.002] 2025-08-20 01:07:27,936 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:28.002] 2025-08-20 01:07:27,940 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:28.055] 2025-08-20 01:07:27,948 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:28.061] 2025-08-20 01:07:27,959 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[01:07:28.069] 2025-08-20 01:07:28,023 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.090] 2025-08-20 01:07:28,061 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.092] 2025-08-20 01:07:28,081 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.095] 2025-08-20 01:07:28,084 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.098] 2025-08-20 01:07:28,090 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.106] 2025-08-20 01:07:28,092 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.109] [INFO] Tool embedding index loaded successfully
[01:07:28.135] 2025-08-20 01:07:28,095 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.156] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.167] [INFO] Operation semantic index initialized
[01:07:28.167] 
[01:07:28.167] [TURN 1/10]
[01:07:28.180] 2025-08-20 01:07:28,098 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.183] [INFO] Tool embedding index loaded successfully
[01:07:28.227] 2025-08-20 01:07:28,135 - mcp_embedding_manager - INFO - Index loaded successfully: 15 tools
[01:07:28.230] [INFO] Tool embedding index loaded successfully
[01:07:28.245] 2025-08-20 01:07:28,141 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.251] 2025-08-20 01:07:28,163 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.256] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.266] 2025-08-20 01:07:28,225 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.267] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.276] [INFO] Operation semantic index initialized
[01:07:28.281] 
[01:07:28.281] [TURN 1/10]
[01:07:28.292] 2025-08-20 01:07:28,239 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.312] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.315] 2025-08-20 01:07:28,245 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.321] [INFO] Operation semantic index initialized
[01:07:28.328] 2025-08-20 01:07:28,251 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.329] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.330] 2025-08-20 01:07:28,267 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.344] 
[01:07:28.344] [TURN 1/10]
[01:07:28.359] 2025-08-20 01:07:28,272 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.389] 2025-08-20 01:07:28,274 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.391] 2025-08-20 01:07:28,292 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.392] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.399] 2025-08-20 01:07:28,306 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.408] 2025-08-20 01:07:28,315 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:07:28.418] [INFO] Tool embedding index loaded successfully2025-08-20 01:07:28,327 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.418] 
[01:07:28.442] 2025-08-20 01:07:28,328 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[01:07:28.445] [INFO] Tool embedding index loaded successfully
[01:07:28.452] 2025-08-20 01:07:28,329 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.463] 2025-08-20 01:07:28,330 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.463] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.474] 2025-08-20 01:07:28,387 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.476] [INFO] Tool embedding index loaded successfully
[01:07:28.483] 2025-08-20 01:07:28,389 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.502] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.502] 2025-08-20 01:07:28,389 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.513] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.513] [INFO] Operation semantic index initialized
[01:07:28.513] 
[01:07:28.513] [TURN 1/10]
[01:07:28.513] [INFO] Operation semantic index initialized
[01:07:28.514] [INFO] Operation semantic index initialized2025-08-20 01:07:28,390 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.515] 2025-08-20 01:07:28,391 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.517] [INFO] Tool embedding index loaded successfully
[01:07:28.517] 
[01:07:28.517] 
[01:07:28.517] [TURN 1/10]
[01:07:28.517] 2025-08-20 01:07:28,399 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.517] 2025-08-20 01:07:28,517 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.517] 2025-08-20 01:07:28,517 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.518] 
[01:07:28.518] [TURN 1/10]
[01:07:28.518] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.521] [INFO] Tool embedding index loaded successfully
[01:07:28.522] 2025-08-20 01:07:28,418 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.522] 2025-08-20 01:07:28,420 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.522] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.529] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.530] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.535] [INFO] Operation semantic index initialized2025-08-20 01:07:28,425 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.537] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.537] 
[01:07:28.537] 
[01:07:28.537] [TURN 1/10]
[01:07:28.538] [INFO] Operation semantic index initialized
[01:07:28.538] 2025-08-20 01:07:28,426 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.548] 2025-08-20 01:07:28,451 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.548] 
[01:07:28.548] [TURN 1/10]
[01:07:28.548] 2025-08-20 01:07:28,452 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.549] 2025-08-20 01:07:28,463 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[01:07:28.552] [INFO] Tool embedding index loaded successfully
[01:07:28.552] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.552] 2025-08-20 01:07:28,468 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.553] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.555] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.555] [INFO] Operation semantic index initialized
[01:07:28.555] 
[01:07:28.555] [TURN 1/10]
[01:07:28.555] 2025-08-20 01:07:28,481 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.565] 2025-08-20 01:07:28,483 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.566] 2025-08-20 01:07:28,502 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.566] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.567] 2025-08-20 01:07:28,502 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.577] 2025-08-20 01:07:28,502 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.580] [INFO] Tool embedding index loaded successfully
[01:07:28.580] 2025-08-20 01:07:28,514 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.590] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.590] 2025-08-20 01:07:28,515 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.590] [INFO] Operation semantic index initialized
[01:07:28.591] 2025-08-20 01:07:28,400 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.591] 
[01:07:28.591] [TURN 1/10]
[01:07:28.591] 2025-08-20 01:07:28,522 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.593] [INFO] Tool embedding index loaded successfully
[01:07:28.593] 2025-08-20 01:07:28,404 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.593] 2025-08-20 01:07:28,523 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.594] 2025-08-20 01:07:28,537 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.594] 2025-08-20 01:07:28,537 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.594] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.594] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.595] 2025-08-20 01:07:28,538 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.595] 2025-08-20 01:07:28,548 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.595] [INFO] Operation semantic index initialized
[01:07:28.595] 2025-08-20 01:07:28,548 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.595] 2025-08-20 01:07:28,548 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.595] 
[01:07:28.595] [TURN 1/10]
[01:07:28.598] [INFO] Tool embedding index loaded successfully2025-08-20 01:07:28,552 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.598] 
[01:07:28.598] 2025-08-20 01:07:28,555 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.598] 2025-08-20 01:07:28,565 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.601] [INFO] Tool embedding index loaded successfully
[01:07:28.601] 2025-08-20 01:07:28,566 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.601] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.602] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.603] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.603] [INFO] Operation semantic index initialized
[01:07:28.603] 
[01:07:28.603] [TURN 1/10]
[01:07:28.603] [INFO] Operation semantic index initialized
[01:07:28.603] 2025-08-20 01:07:28,567 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.603] 
[01:07:28.603] [TURN 1/10]
[01:07:28.603] 2025-08-20 01:07:28,573 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.603] 2025-08-20 01:07:28,580 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.607] [INFO] Tool embedding index loaded successfully
[01:07:28.607] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.609] 2025-08-20 01:07:28,590 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.609] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.609] 2025-08-20 01:07:28,590 - mcp_embedding_manager - INFO - FAISS index loaded
[01:07:28.609] 2025-08-20 01:07:28,590 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.609] 2025-08-20 01:07:28,609 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.614] [INFO] Tool embedding index loaded successfully
[01:07:28.614] 2025-08-20 01:07:28,591 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.615] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.615] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.616] 2025-08-20 01:07:28,594 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.618] [INFO] Tool embedding index loaded successfully
[01:07:28.618] [INFO] Operation semantic index initialized
[01:07:28.619] 2025-08-20 01:07:28,594 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.621] [INFO] Tool embedding index loaded successfully
[01:07:28.621] 
[01:07:28.621] [TURN 1/10]
[01:07:28.621] [INFO] Operation semantic index initialized
[01:07:28.622] 
[01:07:28.622] [TURN 1/10]
[01:07:28.622] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.623] 2025-08-20 01:07:28,594 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.623] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.624] 2025-08-20 01:07:28,595 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.626] [INFO] Tool embedding index loaded successfully
[01:07:28.626] 2025-08-20 01:07:28,595 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.629] [INFO] Tool embedding index loaded successfully
[01:07:28.629] [INFO] Operation semantic index initialized
[01:07:28.629] 2025-08-20 01:07:28,595 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.629] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.630] 
[01:07:28.630] [TURN 1/10]
[01:07:28.630] [INFO] Operation semantic index initialized[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.630] [INFO] Operation semantic index initialized
[01:07:28.630] 
[01:07:28.631] [TURN 1/10]
[01:07:28.631] 2025-08-20 01:07:28,598 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.633] [INFO] Tool embedding index loaded successfully
[01:07:28.633] 
[01:07:28.633] 
[01:07:28.634] [TURN 1/10]
[01:07:28.634] 2025-08-20 01:07:28,598 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.636] [INFO] Tool embedding index loaded successfully
[01:07:28.637] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.637] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.638] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.638] [INFO] Operation semantic index initialized
[01:07:28.639] 
[01:07:28.639] [TURN 1/10]
[01:07:28.639] 2025-08-20 01:07:28,603 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.641] [INFO] Tool embedding index loaded successfully
[01:07:28.641] 2025-08-20 01:07:28,603 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.642] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.645] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.646] 2025-08-20 01:07:28,603 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.648] [INFO] Tool embedding index loaded successfully
[01:07:28.649] [INFO] Operation semantic index initialized
[01:07:28.649] 
[01:07:28.649] [TURN 1/10]
[01:07:28.649] 2025-08-20 01:07:28,609 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.649] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.651] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-20 01:07:28,609 - mcp_embedding_manager - INFO - Updated dimension to 3072
[01:07:28.651] 
[01:07:28.651] [INFO] Operation semantic index initialized
[01:07:28.651] 2025-08-20 01:07:28,593 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.654] [INFO] Tool embedding index loaded successfully
[01:07:28.654] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.654] 
[01:07:28.654] [TURN 1/10]
[01:07:28.655] 2025-08-20 01:07:28,614 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.658] [INFO] Tool embedding index loaded successfully2025-08-20 01:07:28,623 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.659] 
[01:07:28.662] [INFO] Tool embedding index loaded successfully[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.662] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.662] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.663] 
[01:07:28.664] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-20 01:07:28,629 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.667] [INFO] Tool embedding index loaded successfully
[01:07:28.667] 2025-08-20 01:07:28,641 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.667] 
[01:07:28.667] [INFO] Operation semantic index initialized
[01:07:28.667] 
[01:07:28.667] [TURN 1/10]
[01:07:28.671] [INFO] Tool embedding index loaded successfully2025-08-20 01:07:28,649 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.671] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.674] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2[INFO] Tool embedding index loaded successfully
[01:07:28.674] 
[01:07:28.675] 2025-08-20 01:07:28,651 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[01:07:28.678] [INFO] Tool embedding index loaded successfully
[01:07:28.678] [INFO] Operation semantic index initialized
[01:07:28.679] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json[INFO] Operation semantic index initialized
[01:07:28.679] 
[01:07:28.680] 
[01:07:28.680] [TURN 1/10]
[01:07:28.680] 
[01:07:28.680] 
[01:07:28.681] 
[01:07:28.681] [TURN 1/10][INFO] Operation semantic index initialized
[01:07:28.681] 
[01:07:28.681] [INFO] Operation semantic index initialized
[01:07:28.681] 
[01:07:28.681] [TURN 1/10]
[01:07:28.682] 
[01:07:28.682] [TURN 1/10]
[01:07:28.682] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.682] [INFO] Operation semantic index initialized
[01:07:28.682] 
[01:07:28.682] [TURN 1/10]
[01:07:28.740] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.740] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.741] [INFO] Operation semantic index initialized
[01:07:28.741] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.742] 
[01:07:28.742] [TURN 1/10]
[01:07:28.743] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.743] 
[01:07:28.743] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.743] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.744] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.746] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[01:07:28.746] [INFO] Operation semantic index initialized
[01:07:28.746] 
[01:07:28.746] [TURN 1/10]
[01:07:28.746] [INFO] Operation semantic index initialized
[01:07:28.746] 
[01:07:28.746] [TURN 1/10]
[01:07:28.746] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:07:28.747] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:09:09.498] 2025-08-20 01:09:09,497 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-2/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
[01:09:09.509]   [SEARCH] Query: file_operations_reader
[01:09:09.514] 
[01:09:09.514] [TURN 2/10]
[01:09:09.515] [LLM_CALL] Using model: DeepSeek-R1-0528-2, API name: DeepSeek-R1-0528-2
[01:09:28.637] 2025-08-20 01:09:28,637 - openai._base_client - INFO - Retrying request to /chat/completions in 0.377543 seconds
[01:09:28.688] 2025-08-20 01:09:28,688 - openai._base_client - INFO - Retrying request to /chat/completions in 0.472593 seconds
[01:09:28.739] 2025-08-20 01:09:28,738 - openai._base_client - INFO - Retrying request to /chat/completions in 0.495058 seconds
[01:09:28.798] 2025-08-20 01:09:28,798 - openai._base_client - INFO - Retrying request to /chat/completions in 0.476677 seconds
[01:09:28.800] 2025-08-20 01:09:28,800 - openai._base_client - INFO - Retrying request to /chat/completions in 0.400331 seconds
[01:09:28.804] 2025-08-20 01:09:28,804 - openai._base_client - INFO - Retrying request to /chat/completions in 0.411860 seconds
[01:09:28.819] 2025-08-20 01:09:28,819 - openai._base_client - INFO - Retrying request to /chat/completions in 0.451318 seconds
[01:09:28.822] 2025-08-20 01:09:28,822 - openai._base_client - INFO - Retrying request to /chat/completions in 0.376327 seconds
[01:09:28.829] 2025-08-20 01:09:28,828 - openai._base_client - INFO - Retrying request to /chat/completions in 0.430207 seconds
[01:09:28.846] 2025-08-20 01:09:28,846 - openai._base_client - INFO - Retrying request to /chat/completions in 0.421783 seconds
[01:09:28.847] 2025-08-20 01:09:28,847 - openai._base_client - INFO - Retrying request to /chat/completions in 0.431676 seconds
[01:09:28.875] 2025-08-20 01:09:28,875 - openai._base_client - INFO - Retrying request to /chat/completions in 0.475263 seconds
[01:09:28.879] 2025-08-20 01:09:28,879 - openai._base_client - INFO - Retrying request to /chat/completions in 0.402375 seconds
[01:09:28.881] 2025-08-20 01:09:28,881 - openai._base_client - INFO - Retrying request to /chat/completions in 0.416552 seconds
[01:09:28.897] 2025-08-20 01:09:28,896 - openai._base_client - INFO - Retrying request to /chat/completions in 0.382947 seconds
[01:09:28.898] 2025-08-20 01:09:28,898 - openai._base_client - INFO - Retrying request to /chat/completions in 0.454034 seconds
[01:09:28.900] 2025-08-20 01:09:28,900 - openai._base_client - INFO - Retrying request to /chat/completions in 0.440888 seconds
[01:09:28.900] 2025-08-20 01:09:28,900 - openai._base_client - INFO - Retrying request to /chat/completions in 0.477878 seconds
[01:09:28.908] 2025-08-20 01:09:28,908 - openai._base_client - INFO - Retrying request to /chat/completions in 0.440559 seconds
[01:09:28.945] 2025-08-20 01:09:28,944 - openai._base_client - INFO - Retrying request to /chat/completions in 0.437573 seconds
[01:09:28.949] 2025-08-20 01:09:28,949 - openai._base_client - INFO - Retrying request to /chat/completions in 0.447966 seconds
[01:09:28.995] 2025-08-20 01:09:28,994 - openai._base_client - INFO - Retrying request to /chat/completions in 0.447887 seconds
[01:09:29.001] 2025-08-20 01:09:29,000 - openai._base_client - INFO - Retrying request to /chat/completions in 0.408745 seconds
[01:09:29.007] 2025-08-20 01:09:29,007 - openai._base_client - INFO - Retrying request to /chat/completions in 0.456718 seconds
[01:09:29.012] 2025-08-20 01:09:29,012 - openai._base_client - INFO - Retrying request to /chat/completions in 0.405154 seconds
[01:09:29.012] 2025-08-20 01:09:29,012 - openai._base_client - INFO - Retrying request to /chat/completions in 0.416979 seconds
[01:09:29.014] 2025-08-20 01:09:29,014 - openai._base_client - INFO - Retrying request to /chat/completions in 0.384017 seconds
[01:09:29.015] 2025-08-20 01:09:29,015 - openai._base_client - INFO - Retrying request to /chat/completions in 0.441106 seconds
[01:09:29.015] 2025-08-20 01:09:29,015 - openai._base_client - INFO - Retrying request to /chat/completions in 0.428274 seconds
[01:11:09.526] 2025-08-20 01:11:09,525 - openai._base_client - INFO - Retrying request to /chat/completions in 0.442649 seconds
[01:11:29.326] 2025-08-20 01:11:29,325 - openai._base_client - INFO - Retrying request to /chat/completions in 0.828392 seconds
[01:11:29.437] 2025-08-20 01:11:29,437 - openai._base_client - INFO - Retrying request to /chat/completions in 0.920663 seconds
[01:11:29.459] 2025-08-20 01:11:29,458 - openai._base_client - INFO - Retrying request to /chat/completions in 0.823403 seconds
[01:11:29.459] 2025-08-20 01:11:29,459 - openai._base_client - INFO - Retrying request to /chat/completions in 0.957223 seconds
[01:11:29.473] 2025-08-20 01:11:29,472 - openai._base_client - INFO - Retrying request to /chat/completions in 0.791841 seconds
[01:11:29.510] 2025-08-20 01:11:29,509 - openai._base_client - INFO - Retrying request to /chat/completions in 0.907667 seconds
[01:11:29.525] 2025-08-20 01:11:29,524 - openai._base_client - INFO - Retrying request to /chat/completions in 0.884203 seconds
[01:11:29.529] 2025-08-20 01:11:29,529 - openai._base_client - INFO - Retrying request to /chat/completions in 0.925411 seconds
[01:11:29.543] 2025-08-20 01:11:29,542 - openai._base_client - INFO - Retrying request to /chat/completions in 0.821725 seconds
[01:11:29.543] 2025-08-20 01:11:29,543 - openai._base_client - INFO - Retrying request to /chat/completions in 0.860488 seconds
[01:11:29.543] 2025-08-20 01:11:29,543 - openai._base_client - INFO - Retrying request to /chat/completions in 0.976531 seconds
[01:11:29.543] 2025-08-20 01:11:29,543 - openai._base_client - INFO - Retrying request to /chat/completions in 0.912179 seconds
[01:11:29.544] 2025-08-20 01:11:29,544 - openai._base_client - INFO - Retrying request to /chat/completions in 0.986169 seconds
[01:11:29.585] 2025-08-20 01:11:29,585 - openai._base_client - INFO - Retrying request to /chat/completions in 0.976070 seconds
[01:11:29.603] 2025-08-20 01:11:29,603 - openai._base_client - INFO - Retrying request to /chat/completions in 0.841115 seconds
[01:11:29.604] 2025-08-20 01:11:29,603 - openai._base_client - INFO - Retrying request to /chat/completions in 0.986320 seconds
[01:11:29.604] 2025-08-20 01:11:29,604 - openai._base_client - INFO - Retrying request to /chat/completions in 0.931655 seconds
[01:11:29.605] 2025-08-20 01:11:29,605 - openai._base_client - INFO - Retrying request to /chat/completions in 0.961670 seconds
[01:11:29.630] 2025-08-20 01:11:29,630 - openai._base_client - INFO - Retrying request to /chat/completions in 0.853439 seconds
[01:11:29.635] 2025-08-20 01:11:29,635 - openai._base_client - INFO - Retrying request to /chat/completions in 0.983218 seconds
[01:11:29.665] 2025-08-20 01:11:29,665 - openai._base_client - INFO - Retrying request to /chat/completions in 0.831404 seconds
[01:11:29.675] 2025-08-20 01:11:29,675 - openai._base_client - INFO - Retrying request to /chat/completions in 0.905291 seconds
[01:11:29.677] 2025-08-20 01:11:29,676 - openai._base_client - INFO - Retrying request to /chat/completions in 0.990425 seconds
[01:11:29.677] 2025-08-20 01:11:29,677 - openai._base_client - INFO - Retrying request to /chat/completions in 0.997206 seconds
[01:11:29.691] 2025-08-20 01:11:29,691 - openai._base_client - INFO - Retrying request to /chat/completions in 0.903758 seconds
[01:11:29.699] 2025-08-20 01:11:29,699 - openai._base_client - INFO - Retrying request to /chat/completions in 0.895908 seconds
[01:11:29.706] 2025-08-20 01:11:29,705 - openai._base_client - INFO - Retrying request to /chat/completions in 0.968525 seconds
[01:11:29.706] 2025-08-20 01:11:29,706 - openai._base_client - INFO - Retrying request to /chat/completions in 0.820466 seconds
[01:11:29.719] 2025-08-20 01:11:29,718 - openai._base_client - INFO - Retrying request to /chat/completions in 0.754663 seconds
[01:13:10.235] 2025-08-20 01:13:10,233 - openai._base_client - INFO - Retrying request to /chat/completions in 0.821069 seconds
[01:13:30.421] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.421] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.421]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.449] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:30.511] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.511] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.511]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.529] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.529] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.529]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.707] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.708] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.708]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.711] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.712] [TIMEOUT] API call timed out after 120 seconds, not retrying[LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.712] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.712]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.717] [LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.[LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.717] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.717]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.717] 
[01:13:30.717] 
[01:13:30.717]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.717] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.717] 
[01:13:30.717]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.717] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.718]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.789] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.789] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.789]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.791] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.791] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.791]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.792] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.792] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.792]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.793] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.793] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.794]   [API_FAILURE] API failed (timeout or max retries)[LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.794] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.794] 
[01:13:30.794]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.820] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.820] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.820]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.882] 2025-08-20 01:13:30,881 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:30.886] 2025-08-20 01:13:30,886 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:30.891] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:30.917] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.917] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.917]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.918] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.918] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.918]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.943] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.943] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.943]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.944] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.944] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.944]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.945] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.945] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.945]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.945] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.945] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.945]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.946] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.946] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.946]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.947] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.947] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.947]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.947] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.947] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.947]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.948] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.948] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.948]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.954] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.954] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.954]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.993] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.993] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.993]   [API_FAILURE] API failed (timeout or max retries)
[01:13:30.993] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:30.993] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:30.993]   [API_FAILURE] API failed (timeout or max retries)
[01:13:31.066] 2025-08-20 01:13:31,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:31.066] 2025-08-20 01:13:31,066 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:31.072] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:31.073] [LLM_ERROR] Attempt 1/5: Request timed out.
[01:13:31.074] [TIMEOUT] API call timed out after 120 seconds, not retrying
[01:13:31.074]   [API_FAILURE] API failed (timeout or max retries)
[01:13:31.256] 2025-08-20 01:13:31,255 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:31.256] 2025-08-20 01:13:31,256 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:31.260] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:31.474] 2025-08-20 01:13:31,474 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:31.474] 2025-08-20 01:13:31,474 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:31.478] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:31.643] 2025-08-20 01:13:31,643 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:31.645] 2025-08-20 01:13:31,645 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:31.647] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:31.906] 2025-08-20 01:13:31,906 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:31.907] 2025-08-20 01:13:31,907 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:31.911] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:32.183] 2025-08-20 01:13:32,183 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:32.184] 2025-08-20 01:13:32,184 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:32.186] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:32.349] 2025-08-20 01:13:32,349 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:32.349] 2025-08-20 01:13:32,349 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:32.351] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:32.471] 2025-08-20 01:13:32,470 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:32.471] 2025-08-20 01:13:32,471 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:32.473] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:32.630] 2025-08-20 01:13:32,630 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:32.631] 2025-08-20 01:13:32,631 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:32.633] Progress: 10/30 (Success: 0)
[01:13:32.633] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:32.754] 2025-08-20 01:13:32,753 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:32.754] 2025-08-20 01:13:32,754 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:32.756] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:32.907] 2025-08-20 01:13:32,907 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:32.907] 2025-08-20 01:13:32,907 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:32.910] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:33.053] 2025-08-20 01:13:33,052 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:33.053] 2025-08-20 01:13:33,053 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:33.054] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:33.196] 2025-08-20 01:13:33,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:33.197] 2025-08-20 01:13:33,197 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:33.200] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:33.325] 2025-08-20 01:13:33,325 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:33.326] 2025-08-20 01:13:33,326 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:33.328] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:33.448] 2025-08-20 01:13:33,448 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:33.449] 2025-08-20 01:13:33,448 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:33.451] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:33.597] 2025-08-20 01:13:33,595 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:33.597] 2025-08-20 01:13:33,597 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:33.599] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:33.797] 2025-08-20 01:13:33,796 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:33.797] 2025-08-20 01:13:33,797 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:33.799] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:34.011] 2025-08-20 01:13:34,011 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:34.012] 2025-08-20 01:13:34,012 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:34.014] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:34.248] 2025-08-20 01:13:34,247 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:34.249] 2025-08-20 01:13:34,248 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:34.252] Progress: 20/30 (Success: 0)
[01:13:34.252] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:34.392] 2025-08-20 01:13:34,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:34.392] 2025-08-20 01:13:34,392 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:34.394] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:34.645] 2025-08-20 01:13:34,645 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:34.646] 2025-08-20 01:13:34,645 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:34.648] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:34.766] 2025-08-20 01:13:34,765 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:34.766] 2025-08-20 01:13:34,766 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:34.770] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:34.900] 2025-08-20 01:13:34,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:34.900] 2025-08-20 01:13:34,900 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:34.920] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:35.119] 2025-08-20 01:13:35,118 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:35.120] 2025-08-20 01:13:35,119 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:35.123] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:35.272] 2025-08-20 01:13:35,272 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:35.273] 2025-08-20 01:13:35,273 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:35.277] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:35.414] 2025-08-20 01:13:35,413 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:35.415] 2025-08-20 01:13:35,415 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:35.424] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:35.632] 2025-08-20 01:13:35,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:35.633] 2025-08-20 01:13:35,633 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[01:13:35.637] [DEBUG] Got result for task: has_result=True, save_logs=True
[01:13:35.774] 2025-08-20 01:13:35,773 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[01:13:35.775] 2025-08-20 01:13:35,774 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
