=== 测试开始时间: 2025年 8月31日 星期日 15时51分12秒 EDT ===
=== 执行命令: python3 ./ultra_parallel_runner.py --model qwen2.5-7b-instruct --prompt-types baseline --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 3 ===
INFO:__main__:初始化实例池: 17个实例 (2个Azure + 6个IdealLab)
INFO:__main__:📜 使用传统数据库写入模式
INFO:__main__:资源池状态: 17个实例, 容量1306
INFO:__main__:
🎯 检测到Qwen模型，使用队列调度器
INFO:__main__:   模型: qwen2.5-7b-instruct → Key0
INFO:__main__:   Prompt类型: baseline
INFO:__main__:   难度: easy
INFO:__main__:🔄 Key0: 执行 qwen2.5-7b-instruct-easy
INFO:__main__:🎯 使用qwen智能分片策略: qwen2.5-7b-instruct
INFO:__main__:🔄 真正多Key并发策略:
INFO:__main__:   模型: qwen2.5-7b-instruct (规模: 7b)
INFO:__main__:   使用Keys: key0, key1, key2
INFO:__main__:   总实例数: 20
INFO:__main__:   分片数: 3 (每个key独立分片)
INFO:__main__:   实例分配: [7, 7, 6]
INFO:__main__:   🚀 启用3倍API并发！
INFO:__main__:🚀 启动3个分片并发执行
INFO:__main__:  IdealLab qwen模型限制: qwen-key0 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 0
INFO:__main__:🚀 启动分片 qwen2.5-7b-instruct_easy_baseline_key0: qwen-key0
INFO:__main__:   实例数: 7, 模型: qwen2.5-7b-instruct
INFO:__main__:   设置STORAGE_FORMAT=json给子进程
INFO:__main__:   设置USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   设置TASK_LOAD_COUNT=20给子进程
INFO:__main__:   设置SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   设置USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   设置KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片1: qwen-key0 (7个实例)
INFO:__main__:  IdealLab qwen模型限制: qwen-key1 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 1
INFO:__main__:🚀 启动分片 qwen2.5-7b-instruct_easy_baseline_key1: qwen-key1
INFO:__main__:   实例数: 7, 模型: qwen2.5-7b-instruct
INFO:__main__:   设置STORAGE_FORMAT=json给子进程
INFO:__main__:   设置USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   设置TASK_LOAD_COUNT=20给子进程
INFO:__main__:   设置SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   设置USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   设置KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片2: qwen-key1 (7个实例)
INFO:__main__:  使用IdealLab API Key 2
INFO:__main__:🚀 启动分片 qwen2.5-7b-instruct_easy_baseline_key2: qwen-key2
INFO:__main__:   实例数: 6, 模型: qwen2.5-7b-instruct
INFO:__main__:   设置STORAGE_FORMAT=json给子进程
INFO:__main__:   设置USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   设置TASK_LOAD_COUNT=20给子进程
INFO:__main__:   设置SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   设置USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   设置KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片3: qwen-key2 (6个实例)
INFO:__main__:等待分片1完成（20实例×50workers，最多等待50分钟）...
2025-08-31 15:51:12,712 - faiss.loader - INFO - Loading faiss.
2025-08-31 15:51:12,712 - faiss.loader - INFO - Loading faiss.
2025-08-31 15:51:12,712 - faiss.loader - INFO - Loading faiss.
2025-08-31 15:51:12,750 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 15:51:12,750 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 15:51:12,750 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 15:51:13,734 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-31 15:51:13,734 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-31 15:51:13,734 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-31 15:51:13,734 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-31 15:51:13,734 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-31 15:51:13,734 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-31 15:51:13,734 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-31 15:51:13,734 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-31 15:51:13,734 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-31 15:51:13,735 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-31 15:51:13,736 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-31 15:51:13,736 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-31 15:51:13,736 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-31 15:51:13,736 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-31 15:51:13,736 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-31 15:51:13,736 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-31 15:51:13,736 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-31 15:51:13,736 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-31 15:51:13,736 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-31 15:51:13,737 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 15:51:13,737 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 15:51:13,799 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:51:13,799 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-31 15:51:13,799 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:51:13,799 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:51:13,799 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-31 15:51:13,799 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-31 15:51:13,799 - batch_test_runner - INFO - ============================================================
2025-08-31 15:51:13,799 - batch_test_runner - INFO - ============================================================
2025-08-31 15:51:13,800 - batch_test_runner - INFO - ============================================================
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_155113.log
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_155113.log
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 15:51:13,800 - batch_test_runner - INFO - ============================================================
2025-08-31 15:51:13,800 - batch_test_runner - INFO - ============================================================
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_155113.log
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Initializing test components...
2025-08-31 15:51:13,800 - batch_test_runner - INFO - ============================================================
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Initializing test components...
2025-08-31 15:51:13,800 - batch_test_runner - INFO - Initializing test components...
2025-08-31 15:51:14,277 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 15:51:14,277 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 15:51:14,277 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 15:51:14,278 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 15:51:14,278 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 15:51:14,278 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 15:51:14,278 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 15:51:14,278 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 15:51:14,283 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 15:51:14,283 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 15:51:14,283 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 15:51:14,284 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 15:51:14,857 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:14,865 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:14,881 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:15,045 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:51:15,046 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:51:15,048 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:51:15,591 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:51:15,591 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:51:15,591 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:51:16,113 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 15:51:16,114 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 15:51:16,114 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 15:51:16,114 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 15:51:16,114 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 15:51:16,114 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 15:51:16,197 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:51:16,202 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:51:16,205 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:51:16,326 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:51:16,333 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:51:16,334 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:51:16,894 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 15:51:16,897 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:16,908 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 15:51:16,908 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 15:51:16,909 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:16,910 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:17,368 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:17,369 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:17,369 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:17,371 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:17,371 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:17,371 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:17,371 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:17,371 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:17,371 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:17,380 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 15:51:17,381 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:51:17,382 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:51:17,384 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 15:51:17,384 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 15:51:17,385 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:51:17,385 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:51:17,385 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:51:17,385 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:51:17,392 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 15:51:17,393 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 15:51:17,393 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 15:51:17,393 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 15:51:17,393 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 15:51:17,393 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 15:51:17,394 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 15:51:17,394 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 15:51:17,394 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 15:51:17,395 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 15:51:17,396 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 15:51:17,398 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 15:51:20,298 - unified_training_manager - INFO - Using device: cpu
2025-08-31 15:51:20,298 - unified_training_manager - INFO - Using device: cpu
2025-08-31 15:51:20,298 - unified_training_manager - INFO - Using device: cpu
2025-08-31 15:51:21,470 - unified_training_manager - INFO - Task filtering results:
2025-08-31 15:51:21,470 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 15:51:21,470 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 15:51:21,470 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 15:51:21,470 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 15:51:21,470 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 15:51:21,470 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 15:51:21,470 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 15:51:21,474 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 15:51:21,479 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 15:51:21,479 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-31 15:51:21,479 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-31 15:51:21,479 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-31 15:51:21,479 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-31 15:51:21,479 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 15:51:21,479 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 15:51:21,509 - unified_training_manager - INFO - Task filtering results:
2025-08-31 15:51:21,509 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 15:51:21,509 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 15:51:21,509 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 15:51:21,509 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 15:51:21,509 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 15:51:21,509 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 15:51:21,509 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 15:51:21,515 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:51:21,521 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-31 15:51:21,521 - result_merger - INFO - ResultMerger初始化完成
2025-08-31 15:51:21,522 - merger_lock - INFO - 获得合并器锁 (PID: 36688)
2025-08-31 15:51:21,522 - result_merger - INFO - 🚀 启动ResultMerger，合并间隔: 10秒
2025-08-31 15:51:21,522 - result_merger - INFO - ResultMerger开始运行，智能停止阈值: 3轮
2025-08-31 15:51:21,523 - result_merger - INFO - ✅ ResultMerger后台线程已启动，支持智能停止机制
2025-08-31 15:51:21,527 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 15:51:21,533 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 15:51:21,533 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-31 15:51:21,533 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-31 15:51:21,533 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-31 15:51:21,533 - unified_training_manager - INFO - Task filtering results:
2025-08-31 15:51:21,533 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 15:51:21,533 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-31 15:51:21,533 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 15:51:21,533 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 15:51:21,533 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 15:51:21,534 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 15:51:21,533 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 15:51:21,534 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 15:51:21,534 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 15:51:21,534 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 15:51:21,539 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 15:51:21,549 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 15:51:21,550 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 15:51:21,559 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 15:51:21,559 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-31 15:51:21,560 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-31 15:51:21,560 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-31 15:51:21,560 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-31 15:51:21,560 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 15:51:21,560 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 15:51:21,571 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:51:21,578 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-31 15:51:21,578 - result_merger - INFO - ResultMerger初始化完成
2025-08-31 15:51:21,580 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-31 15:51:21,598 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:51:21,598 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-31 15:51:21,598 - result_merger - INFO - ResultMerger初始化完成
2025-08-31 15:51:21,599 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-31 15:51:21,603 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 15:51:21,603 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 15:51:21,628 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 15:51:21,628 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 15:51:22,106 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 15:51:22,106 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 15:51:22,167 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 15:51:22,167 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 15:51:22,194 - batch_test_runner - INFO - Initialization complete
2025-08-31 15:51:22,201 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 15:51:22,201 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 15:51:22,239 - batch_test_runner - INFO - Initialization complete
2025-08-31 15:51:22,267 - batch_test_runner - INFO - Initialization complete
2025-08-31 15:51:22,317 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-31 15:51:22,317 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 15:51:22,317 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-31 15:51:22,319 - smart_model_router - INFO - Using idealab for qwen2.5-7b-instruct
2025-08-31 15:51:22,326 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:22,326 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:22,327 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:22,330 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:22,384 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-31 15:51:22,384 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 15:51:22,385 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-31 15:51:22,385 - smart_model_router - INFO - Using idealab for qwen2.5-7b-instruct
2025-08-31 15:51:22,394 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:22,394 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:22,394 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:22,394 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:22,395 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:22,396 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:22,398 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:22,409 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-31 15:51:22,409 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 15:51:22,410 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-31 15:51:22,411 - smart_model_router - INFO - Using idealab for qwen2.5-7b-instruct
2025-08-31 15:51:22,418 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:22,418 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:22,418 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:22,418 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:22,419 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:22,419 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:22,421 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:22,436 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:22,436 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:22,436 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:22,472 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:22,472 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:22,472 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:22,477 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:22,477 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:22,477 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:22,501 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:22,501 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:22,501 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:24,013 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:24,053 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:24,188 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:24,188 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:24,348 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:24,499 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:24,990 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:25,131 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:25,277 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:25,499 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:25,765 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:25,779 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:25,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:26,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:26,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:26,520 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:26,701 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:26,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:26,999 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:27,374 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:27,467 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:27,609 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:27,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:27,862 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:28,196 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:28,386 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:28,580 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:28,910 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:28,927 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:29,192 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:29,216 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:29,436 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:29,613 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:29,959 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:30,173 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:30,293 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:30,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:30,693 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:30,736 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,007 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,435 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,804 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:31,964 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:32,439 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:32,461 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:32,611 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:32,768 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:32,907 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:33,104 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:33,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:33,641 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:33,641 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:33,680 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:33,680 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:33,680 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:33,931 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:34,155 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:34,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:34,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:34,165 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:34,166 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:34,181 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:34,182 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:34,214 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:34,214 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:34,214 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:34,227 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:34,227 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:34,227 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:34,681 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:34,700 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:34,700 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:34,729 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:34,729 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:34,729 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:35,049 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:35,057 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:35,058 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:35,122 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:35,122 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:35,122 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:35,341 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:35,474 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:35,482 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:35,482 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:35,509 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:35,509 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:35,509 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:35,546 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:35,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:35,965 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:36,344 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:36,476 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:36,780 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:36,846 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:36,977 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:37,081 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:37,304 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-7b-instruct (idealab)
Prompt types: ['baseline']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x119607740>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[INFO] 后台合并进程已启动（每10秒合并一次）2025-08-31 15:51:37,505 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:37,856 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:37,989 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:38,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:38,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:38,495 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:38,912 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:39,085 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:39,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-7b-instruct (idealab)
Prompt types: ['baseline']
难度: easy
目标: 每种配置 6 个实例
============================================================
○ simple_task         :   0/  6 已完成 (需要补充 6 个)
○ basic_task          :   0/  6 已完成 (需要补充 6 个)
○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
○ api_integration     :   0/  6 已完成 (需要补充 6 个)
○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)

⏳ 需要运行 30 个新测试

▶ 准备 simple_task (6 个实例)...

▶ 准备 basic_task (6 个实例)...

▶ 准备 data_pipeline (6 个实例)...

▶ 准备 api_integration (6 个实例)...

▶ 准备 multi_stage_pipeline (6 个实例)...

▶ 开始执行 30 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x10a78a810>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[INFO] 后台合并进程已启动（每10秒合并一次）2025-08-31 15:51:39,454 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:39,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:39,632 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:39,926 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-7b-instruct (idealab)
Prompt types: ['baseline']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x113b12b50>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[INFO] 后台合并进程已启动（每10秒合并一次）2025-08-31 15:51:40,021 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:40,117 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:40,456 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:40,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:40,687 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:40,879 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:40,978 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:41,333 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:41,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:41,600 - result_merger - INFO - 🛑 连续3轮无新文件，自动停止合并器防止hang住
2025-08-31 15:51:41,600 - result_merger - INFO - 🏁 ResultMerger合并循环已结束
2025-08-31 15:51:41,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:41,654 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:41,658 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:42,066 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:42,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:42,114 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:42,406 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:42,867 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:42,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:43,287 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:43,386 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:43,468 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:43,597 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:43,867 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:43,990 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:44,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:44,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:44,861 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:44,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:45,173 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:45,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:45,593 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:46,284 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:46,302 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:46,317 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:46,317 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:46,351 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:46,351 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:46,351 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:46,448 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:46,464 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:46,464 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:46,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:46,495 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:46,496 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:46,497 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:46,497 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:46,497 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:46,510 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:46,528 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:46,528 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:46,528 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:47,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:47,492 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:47,493 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:47,521 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:47,521 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:47,521 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:47,700 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:47,791 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:47,793 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:47,802 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:47,802 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:47,824 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:47,824 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:47,824 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:47,838 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:48,069 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:48,108 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:48,535 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:48,543 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:48,544 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:48,567 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:48,567 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:48,567 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:48,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:48,891 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:48,994 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:48,996 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:49,192 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:49,786 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:49,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:49,982 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:50,106 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:50,108 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:50,415 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:50,754 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:50,845 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:51,224 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:51,467 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:51,718 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:51,767 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:51,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:52,013 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:52,540 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:52,585 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:52,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:52,882 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:52,945 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:53,356 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:53,567 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:53,615 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:53,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:54,353 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:54,515 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:54,614 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:54,684 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:54,693 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:54,774 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:55,348 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:55,659 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:55,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:55,910 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:55,996 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:56,183 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:56,202 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:56,354 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:56,525 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:56,708 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:51:56,895 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:57,125 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:57,295 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:57,373 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:57,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,069 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,280 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,320 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,470 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:51:58,591 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,596 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,683 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:51:58,804 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:51:58,821 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:51:58,829 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:51:58,830 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:51:58,851 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:51:58,851 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:51:58,851 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:51:58,952 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:51:59,139 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:51:59,443 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x113677080>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - TIMEOUT: Operation timed out (after 20 seconds)

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13844
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13844
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...2025-08-31 15:51:59,853 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:00,097 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x13d8f9740>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14436
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14436
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: CSV format)

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct2025-08-31 15:52:00,271 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:00,377 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x13c712020>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14472
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14472
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...2025-08-31 15:52:00,428 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:00,810 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:00,901 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:01,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:01,672 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:02,066 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:02,178 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:02,475 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:02,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:02,819 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:03,053 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:04,389 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:04,975 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:05,441 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:05,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:05,702 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:06,143 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:06,465 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:08,764 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:08,777 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:08,778 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:08,810 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:08,810 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:08,810 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:09,400 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:09,401 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:09,427 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:09,427 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:09,427 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:09,498 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:10,158 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:10,166 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:10,167 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:10,189 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:10,189 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:10,189 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:10,337 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:10,348 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:10,348 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:10,394 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:10,394 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:10,394 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:10,517 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:10,524 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:10,525 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:10,553 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:10,553 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:10,553 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:10,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:10,778 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:10,778 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:10,802 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:10,802 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:10,802 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:10,898 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:11,228 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:11,387 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:11,505 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:11,527 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:11,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:12,006 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:12,591 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:12,960 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:13,060 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:13,307 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:13,392 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:13,566 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:14,348 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:14,348 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:14,534 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:14,534 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:15,630 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14450
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14450
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14440
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14440
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16447
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16447
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566699185417921e80a7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566699196656461e87f8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [SEARCH] Query: data validation parser

[TURN 2/10]2025-08-31 15:52:16,225 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:16,282 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:16,706 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:16,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:17,225 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21061
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21061
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data processing parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14455
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14455
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: data processing parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21339
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21339
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e004f17566699182836156ee5f3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007617566699187657507e11c6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007f17566699192632378eea02'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:52:17,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:17,912 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:18,532 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14452
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14452
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14459
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14459
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20813
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20813
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566699185115732eefef'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007517566699189608358ef11d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566699201084598e8cad'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:52:18,541 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:18,541 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:18,565 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:18,565 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:18,565 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:19,278 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:19,940 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:19,948 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:19,948 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:19,970 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:19,970 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:19,970 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:20,416 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:20,674 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:20,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:20,954 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:20,954 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:21,042 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:21,042 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:21,042 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:21,174 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:21,183 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:21,183 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:21,208 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:21,208 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:21,208 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:21,696 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:21,699 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:21,705 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:21,705 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:21,740 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:21,740 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:21,740 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:21,950 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:21,974 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:22,400 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:22,408 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:22,408 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:22,431 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:22,432 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:22,432 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:22,447 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:22,747 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:22,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:22,923 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:23,081 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:52:24,084 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:24,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:24,754 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:25,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:25,040 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:25,074 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:25,616 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:25,698 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:25,707 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:26,134 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:26,591 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:26,731 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:26,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:27,115 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:27,141 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:27,237 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:27,684 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:27,802 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:28,164 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:28,365 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:28,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:28,468 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:28,748 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:28,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:29,232 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:29,459 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:29,505 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:29,754 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:29,797 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:29,819 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:30,369 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:30,468 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:30,859 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:30,931 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:30,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:31,022 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:31,380 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:31,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:31,966 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:32,030 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:32,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:32,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:32,616 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:33,130 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:33,166 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:33,408 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:33,430 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:33,660 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:33,705 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:33,764 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:33,809 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:34,191 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:34,540 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:34,557 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct

[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566699202582107e811b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e069217566699213752315e8273'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566699218944571ee626'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566699228736614e7fd5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043b17566699254628963e259b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566699259662569eef29'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.76
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14462
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14462
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215044da17566699300836777e805b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215042ae17566699305897628e926c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e03e217566699313367608e1eb6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215041d717566699318265953e341f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045b817566699327147737e825d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566699332184824e23c0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215040be17566699341733227edfc4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11319
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11319
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150448717566699354618758e7e9c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching2025-08-31 15:52:34,557 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:34,594 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:34,594 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:34,594 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:34,812 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:35,092 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:35,100 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:35,101 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:35,122 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:35,124 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:35,124 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:35,124 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:35,263 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:35,405 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:35,413 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:35,413 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:35,441 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:35,441 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:35,441 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566699200596825e8a3f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006017566699214697488ee3c3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566699226325290e6f66'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062b17566699242018158e7f87'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566699252564820e0bd3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.9s before retry...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17073
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17073
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566699299685613e799a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150457a17566699307198444e0cc7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150413117566699311424150eea19'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007f17566699316053514eed3c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c817566699328845579e82ba'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065917566699333885973e82de'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150417d17566699341706215e118d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18661
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18661
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e011517566699365232028e9187'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566699370293471e8077'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...2025-08-31 15:52:35,878 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:36,285 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:36,386 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:36,400 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:36,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:36,598 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:36,607 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:36,608 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:36,632 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:36,632 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:36,632 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:36,878 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:36,922 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:37,912 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:37,955 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:38,015 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:38,016 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:38,126 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:38,134 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063717566699206133718e890d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566699219672256eea0f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566699224548807e7a56'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c817566699247955527e8245'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006b17566699255302338eebc7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006017566699285864167ee217'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15723
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15723
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566699293228193e8900'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150409517566699303341179eead9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041717566699310537804e97f8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566699313383168e8a4c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064617566699324107905e09ef'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416a17566699331142390edd4a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416417566699343236731e11a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566699360406060e8246'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007317566699367945533ee4d5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e03d917566699383558362e1ff1'}2025-08-31 15:52:38,135 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:38,157 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:38,157 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:38,157 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:38,297 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:38,979 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:39,026 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:39,369 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:39,383 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:39,478 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:39,485 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:39,486 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:39,509 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:39,509 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:39,509 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:39,513 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:39,518 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:39,704 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:39,955 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:40,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:40,596 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:40,748 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:40,962 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:41,127 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:41,564 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:41,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:41,843 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:42,147 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:42,226 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:42,567 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:42,651 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:42,891 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:42,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:43,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:43,573 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:43,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:43,758 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:43,926 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:44,127 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:44,720 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:44,969 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:45,114 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:45,115 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:45,264 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:45,343 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:45,464 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:45,688 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:46,171 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:46,180 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:46,180 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:46,204 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:46,204 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:46,204 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:46,419 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:46,424 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:46,670 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:46,728 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:47,092 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:47,565 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:47,721 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:47,790 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:48,196 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:48,207 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:48,208 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:48,232 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:48,232 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:48,232 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:48,306 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:48,454 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:48,650 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:48,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:49,156 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:49,166 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:49,167 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:49,191 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:49,191 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:49,191 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:49,455 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:49,704 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:49,840 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:49,939 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:50,024 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:50,074 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:50,082 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:50,082 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:50,103 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:50,103 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:50,103 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:50,424 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:50,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:50,899 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:51,110 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:51,388 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:51,400 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:51,524 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:51,589 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:52,074 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:52,341 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:52,350 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:52,350 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:52,372 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:52,372 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:52,372 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:52,425 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:52,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:52,534 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:52,536 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:52,931 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:53,140 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:53,148 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:53,148 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:53,172 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:53,172 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:53,172 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:53,492 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:53,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:53,853 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:53,975 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215042f917566699373202968e1c5f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566699377301504e8197'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566699397673372e8270'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007517566699405028563ef06d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566699407694704e8143'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566699415168346e8a3a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007b17566699417842856eee7a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14412
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14412
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566699427228011e815f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3496
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3496
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)2025-08-31 15:52:54,074 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:54,485 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:54,555 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:54,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:54,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:55,065 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:55,488 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:55,527 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:55,721 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:55,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:56,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:56,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:56,636 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:56,678 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:56,827 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:57,034 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:57,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:57,183 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:57,225 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:57,525 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:57,693 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:57,810 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:57,958 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:52:58,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:58,333 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:58,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:58,612 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:58,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,116 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,488 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065517566699391097506e82e5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e03e217566699402126496e1cc7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c317566699415194432e792a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e011517566699422544017e9314'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566699425533291e899e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=parameter_config_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 19949
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19949
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3448
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3448
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 15:52:59,632 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,680 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,698 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:52:59,698 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:52:59,713 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,736 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:52:59,736 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:52:59,736 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:52:59,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,950 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:52:59,967 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:00,147 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566699409837567e2087'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007217566699417427016eeabe'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566699421437173ee750'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566699428725781e88ee'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3136
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3136
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3443
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3443
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct2025-08-31 15:53:00,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:00,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:00,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:01,198 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:01,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:01,602 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:01,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:02,327 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:02,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:02,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:02,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:03,293 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:03,378 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:03,667 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:04,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:04,339 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:04,440 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:04,569 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:05,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:05,748 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:06,070 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:06,116 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:06,251 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:06,602 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:08,076 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:08,100 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:08,100 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:08,132 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:08,132 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:08,132 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:08,537 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:08,871 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:08,883 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:08,905 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:08,906 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:08,942 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:08,942 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:08,942 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:09,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:10,106 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:10,121 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:10,122 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:10,151 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:10,151 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:10,151 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:10,210 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:10,504 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:10,752 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:11,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:11,258 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:11,275 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:11,276 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:11,310 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:11,310 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:11,310 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:11,557 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:11,572 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:11,572 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:11,612 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:11,612 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:11,612 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:11,884 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:12,020 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:12,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:12,292 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3487
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3487
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20550
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20550
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.92
Progress: 10/35 (Success: 5)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22561
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22561
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]2025-08-31 15:53:12,293 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:12,330 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:12,330 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:12,330 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:12,362 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:12,778 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:12,997 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:13,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:13,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:13,590 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:13,670 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3447
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3447
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13895
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13895
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=dependency_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20995
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20995
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c217566699793094372e8273'}2025-08-31 15:53:13,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:14,098 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:14,193 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:14,302 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:14,872 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:15,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22683
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22683
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23036
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23036
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
Progress: 10/35 (Success: 1)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21018
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21018
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(partial_success)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14465
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14465
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566699798818346e7f5d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:53:15,899 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:15,965 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:16,530 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:16,590 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:16,593 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:16,696 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:16,696 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:16,696 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:16,727 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:17,077 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:17,281 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:17,307 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:17,554 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:17,778 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:18,602 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:18,827 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:19,940 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:19,961 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:19,962 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:19,999 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:19,999 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:19,999 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:20,446 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:20,662 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:21,165 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:21,177 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:21,178 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:21,210 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:21,210 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:21,210 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:21,753 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:21,772 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:21,773 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:21,810 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:21,811 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:21,811 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:22,010 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:22,519 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:22,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:22,614 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:22,615 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:22,642 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:22,642 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:22,642 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:22,696 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:22,752 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:23,218 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:23,741 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:23,771 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:24,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:24,268 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:24,447 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:24,904 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:53:25,052 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:25,078 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:25,842 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:26,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:26,165 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:26,365 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:26,645 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:27,194 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:27,197 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:27,221 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:27,611 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:27,731 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:27,780 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:28,169 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:28,240 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:28,297 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:28,665 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:28,751 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:28,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:29,291 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:29,649 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:29,690 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:29,755 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:29,854 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:30,046 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:30,224 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:30,334 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062b17566699801126587e7e22'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566699806186814e8896'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566699814215158e897b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150454417566699826882820e809c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566699831936966e8061'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
Progress: 10/30 (Success: 3)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21273
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21273
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045c117566699843755984e8112'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c317566699854015965e7c82'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066e17566699878874890e81b8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566699887008791e89e7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20553
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20553
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066317566699903263079e8228'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e080f17566699910631116e0d27'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566699917098025e80a7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007617566699921763702e12ae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566699934855984e8c7c'}2025-08-31 15:53:30,674 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:30,744 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:30,927 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:31,191 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:31,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:31,222 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:31,406 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:31,648 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:31,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:32,239 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20571
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20571
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e069217566699797974135e833a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007e17566699811564787eedac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215040aa17566699824888141ee706'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045b817566699835003226e7f25'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566699841203666e8277'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066417566699859313689e8208'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20579
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20579
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566699864193733e82c7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566699883362439e3e19'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566699913777108e820b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566699920932552e6e7f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct2025-08-31 15:53:32,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:32,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:32,781 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:32,925 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:33,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:33,340 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:33,586 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:33,755 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:33,812 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:33,829 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:34,446 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:34,756 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:34,756 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e058a17566699803847526e347e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566699809674107e7f7e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150455f17566699817265056e80e3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045c117566699822765384e8317'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566699830741234e3d30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064617566699838282937e0b5c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 5.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c817566699855568283e8215'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007a17566699887002739ee252'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14228
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14228
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006b17566699893461705eeb43'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215041de17566699898562480e363e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150454117566699905574620e7962'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150435d17566699908297775e20a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566699918473531e2234'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e011517566699928843784e9524'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006c17566699934105178e1345'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类2025-08-31 15:53:35,390 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:35,432 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:35,433 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:35,461 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:35,502 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:35,502 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:35,502 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:35,627 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:36,007 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:36,063 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:36,065 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:36,095 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:36,100 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:36,100 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:36,100 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:36,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:36,861 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:37,378 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:37,378 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:37,437 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:37,460 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:37,461 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:37,500 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:37,501 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:37,501 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:37,751 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:37,904 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:38,015 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:38,038 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:38,039 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:38,076 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:38,077 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:38,077 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:38,425 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:38,427 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:38,433 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:39,094 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:39,118 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:39,137 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:39,138 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:39,155 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:39,165 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:39,165 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:39,166 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:39,167 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:39,167 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:39,285 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:39,287 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:39,291 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:39,568 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:39,617 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:39,651 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:39,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:40,161 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:40,527 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:40,640 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:40,705 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:40,819 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:41,097 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:41,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:41,612 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:41,671 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:41,950 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:42,170 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:42,265 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:42,462 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:42,621 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:42,773 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:43,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:43,246 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:43,458 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:43,548 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:43,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:43,784 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:44,195 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:44,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:44,238 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:44,572 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:45,016 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:45,051 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:45,390 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:45,416 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:45,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:45,918 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:46,163 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:46,291 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:46,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:46,836 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:47,157 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:47,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:47,485 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:47,520 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:47,621 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:47,864 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:47,936 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:48,006 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:49,148 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:49,203 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:49,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:49,312 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:49,313 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:49,313 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:49,324 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:49,325 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:49,346 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:49,346 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:49,346 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:49,374 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:49,374 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:49,374 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:49,582 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:49,587 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:50,166 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:50,654 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:50,656 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:50,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:50,794 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:50,795 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:50,830 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:50,830 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:50,830 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:50,869 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:51,217 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:51,278 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:51,292 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:53:51,292 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:51,323 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:51,323 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:51,323 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:52,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:52,086 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:52,194 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:52,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:52,414 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 19182
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19182
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566699940185738e799a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566699957718758e1509'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e081017566699963523377e0b90'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007c17566699971046695ef143'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566699973685593e810a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064b17566699986571872e7950'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e057b17566700002672069e3f13'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566700009934233e7f63'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e069217566700018013180e815c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064e17566700030308688e82fb'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e069217566700035381012e8339'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17890
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17890
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3341
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
2025-08-31 15:53:52,414 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:52,439 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:52,439 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:52,439 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:52,582 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:52,605 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:52,614 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct

[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062017566699926045245e831e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20597
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20597
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c817566699931126655e80cc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566699935705438e1464'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006b17566699940797793eeabf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566699946982635e8a6d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566699965544647e82bf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11153
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11153
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566699976041600e7f82'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566699984052341e7fa2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566700024301924e89d7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007a17566700046844157ee462'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14248
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14248
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected2025-08-31 15:53:52,614 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:53:52,637 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:53:52,637 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:53:52,637 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:53:53,014 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:53,174 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:53,179 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:53,774 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[AI_DEBUG] 生成的txt_content长度: 19631
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19631
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566699957216502e785c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566699968912278e7f51'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065117566699997558071e8067'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566700004885126e7a09'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059717566700015622231e35a1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006817566700023322655ee49a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3368
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3368
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064e17566700025715579e80db'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566700035525019eef8d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3353
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3353
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected2025-08-31 15:53:53,820 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:53,880 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:54,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:54,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:54,233 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:54,461 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:54,717 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:54,839 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:54,901 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:54,906 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:55,203 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:55,336 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:55,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:55,808 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:55,817 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:55,993 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:56,354 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:56,361 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:56,411 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:56,898 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:56,914 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:56,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:57,598 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:57,826 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:57,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:57,953 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:57,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:57,978 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:58,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:58,921 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:59,205 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:59,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:59,627 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:59,653 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:59,666 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:53:59,669 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039668490.json
2025-08-31 15:53:59,670 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039669676.json
2025-08-31 15:53:59,670 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039670343.json
2025-08-31 15:53:59,671 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039670836.json
2025-08-31 15:53:59,672 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039671254.json
2025-08-31 15:53:59,672 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039672471.json
2025-08-31 15:53:59,673 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039673067.json
2025-08-31 15:53:59,673 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039673579.json
2025-08-31 15:53:59,674 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039673980.json
2025-08-31 15:53:59,674 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039674426.json
2025-08-31 15:53:59,675 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039674876.json
2025-08-31 15:53:59,675 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039675329.json
2025-08-31 15:53:59,676 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039675715.json
2025-08-31 15:53:59,676 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039676128.json
2025-08-31 15:53:59,677 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039676503.json
2025-08-31 15:53:59,677 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039677198.json
2025-08-31 15:53:59,678 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039677981.json
2025-08-31 15:53:59,678 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039678368.json
2025-08-31 15:53:59,679 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039678706.json
2025-08-31 15:53:59,679 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670039679045.json
2025-08-31 15:53:59,681 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:53:59,922 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:00,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:00,147 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:00,151 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040150415.json
2025-08-31 15:54:00,152 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040151793.json
2025-08-31 15:54:00,154 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040152786.json
2025-08-31 15:54:00,156 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040155109.json
2025-08-31 15:54:00,157 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040156618.json
2025-08-31 15:54:00,157 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040157366.json
2025-08-31 15:54:00,158 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040158029.json
2025-08-31 15:54:00,158 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040158584.json
2025-08-31 15:54:00,159 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040159073.json
2025-08-31 15:54:00,161 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040159981.json
2025-08-31 15:54:00,161 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040161459.json
2025-08-31 15:54:00,162 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040161902.json
2025-08-31 15:54:00,162 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040162399.json
2025-08-31 15:54:00,163 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040162841.json
2025-08-31 15:54:00,163 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040163282.json
2025-08-31 15:54:00,164 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040163999.json
2025-08-31 15:54:00,165 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040164646.json
2025-08-31 15:54:00,165 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040165171.json
2025-08-31 15:54:00,166 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040165662.json
2025-08-31 15:54:00,166 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670040166090.json
2025-08-31 15:54:00,172 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:00,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:00,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:00,300 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:00,447 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:00,651 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:00,803 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:01,651 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:01,839 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:01,876 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:01,906 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:02,358 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:02,402 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:02,417 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:03,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:03,594 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:04,121 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:04,207 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:04,645 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:04,978 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:05,059 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:05,318 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:05,693 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:05,788 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:06,925 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:06,942 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:07,789 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:08,166 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:08,194 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:08,195 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:08,233 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:08,233 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:08,233 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:08,332 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:08,678 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:09,049 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:09,067 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:09,068 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:09,105 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:09,105 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:09,105 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
  - ai_classifier=True
  - txt_content_len=3341
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.58
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3390
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3390
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20451
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20451
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct2025-08-31 15:54:09,389 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:09,771 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:10,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:11,109 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:11,159 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:11,159 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:11,199 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:11,200 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:11,200 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:11,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21239
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21239
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20677
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20677
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21365
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21365
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct2025-08-31 15:54:11,362 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:11,363 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:11,406 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:11,406 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:11,406 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:11,455 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:11,466 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:11,467 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:11,492 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:11,492 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:11,492 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:11,611 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3411
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3411
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21177
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21177
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.9
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20721
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20721
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 15:54:11,626 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:11,626 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:11,656 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:11,656 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:11,656 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:11,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:12,053 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:12,343 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:12,542 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:12,634 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:12,849 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:13,069 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:13,201 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:13,561 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:13,823 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:13,828 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053826172.json
2025-08-31 15:54:13,829 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053828202.json
2025-08-31 15:54:13,829 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053829239.json
2025-08-31 15:54:13,831 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053830083.json
2025-08-31 15:54:13,833 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053831843.json
2025-08-31 15:54:13,834 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053833355.json
2025-08-31 15:54:13,836 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053834839.json
2025-08-31 15:54:13,838 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053837164.json
2025-08-31 15:54:13,839 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053838673.json
2025-08-31 15:54:13,840 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053839586.json
2025-08-31 15:54:13,840 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053840211.json
2025-08-31 15:54:13,842 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053841065.json
2025-08-31 15:54:13,843 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053842820.json
2025-08-31 15:54:13,844 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053843551.json
2025-08-31 15:54:13,844 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053844105.json
2025-08-31 15:54:13,844 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053844561.json
2025-08-31 15:54:13,845 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053844995.json
2025-08-31 15:54:13,845 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053845425.json
2025-08-31 15:54:13,846 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053845834.json
2025-08-31 15:54:13,846 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670053846556.json
2025-08-31 15:54:13,911 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:14,110 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:14,303 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:15,292 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:15,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:15,782 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:15,993 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:16,529 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:17,074 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:17,576 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:18,602 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:19,001 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:19,550 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:19,735 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:19,753 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:19,753 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:19,788 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:19,788 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:19,788 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:20,169 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:20,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:20,690 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:20,713 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:20,713 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:20,750 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:20,750 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:20,750 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:21,456 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:21,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:21,751 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:21,799 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:21,816 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:21,817 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:21,856 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:21,856 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:21,856 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:21,943 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:22,092 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:22,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:22,140 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:22,140 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:22,140 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:22,467 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:22,483 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:22,484 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:22,499 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:22,509 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:22,509 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:22,509 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:22,798 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:22,825 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:22,825 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:22,852 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:22,852 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:22,852 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:23,035 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21557
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21557
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22656
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22656
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566700398731992eecb6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007617566700404686559e1439'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006917566700416496646ee13c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e080f17566700421778393e0bbb'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060917566700439042890e700b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566700444094503e8993'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566700454691100e7846'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23202
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23202
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566700475177402e809a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c217566700488645271e8021'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]2025-08-31 15:54:23,134 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:23,242 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:23,854 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:24,039 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:24,240 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:24,342 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:25,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20753
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20753
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 2)
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566700400807516e76da'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007c17566700416935201ef118'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06ba17566700422168722e8b47'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566700428996873e8024'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566700434073498e7635'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566700450843565e8099'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007d17566700456006846ef275'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007417566700479848661eed7c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18058
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18058
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066c17566700484911579e7887'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06ba17566700492141245e8958'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006b17566700506022750eec09'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064e17566700511218740e82d5'}2025-08-31 15:54:25,387 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:25,467 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:25,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:25,817 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:26,202 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:26,320 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:26,488 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:26,824 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21459
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21459
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 5)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20595
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20595
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006f17566700400821573ee477'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566700406138831ee96a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566700417271565e135c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065917566700422201333e826b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566700440337139e12d9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566700447978579e82ab'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566700467521330e801e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e04ea17566700481337173e3487'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566700509307052e8b00'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14939
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14939
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e081017566700514318929e0a01'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:54:26,865 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:26,968 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:27,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:27,561 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:27,925 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:27,940 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:28,430 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:28,977 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:28,998 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:29,103 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:29,165 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:29,282 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:29,471 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:29,920 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:29,923 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:30,078 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:30,184 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:30,422 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:30,753 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:30,878 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:31,051 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:31,068 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:31,172 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:31,177 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:31,485 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:31,972 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:32,023 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:32,256 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:32,497 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:32,675 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:33,020 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:33,124 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:33,140 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:33,300 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:33,481 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:33,652 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:33,661 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:34,139 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:34,289 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:34,614 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:34,637 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:34,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:35,076 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:35,208 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:35,579 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:35,579 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:35,756 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:35,782 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:35,783 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:35,843 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:35,844 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:35,844 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:35,915 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:36,298 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:36,298 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:36,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:36,823 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:36,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:36,909 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:36,910 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:36,949 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:36,949 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:36,949 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:37,156 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:37,162 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:37,185 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:37,185 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:37,224 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:37,224 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:37,224 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:37,493 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:38,081 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:38,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:38,199 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:38,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:38,410 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:38,463 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:39,101 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:39,122 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:39,123 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:39,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:39,157 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:39,157 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:39,157 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:39,259 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:39,464 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:39,795 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:54:40,097 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:40,823 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:40,825 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:41,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:41,066 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:41,070 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:41,071 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:41,118 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:41,118 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:41,118 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:41,167 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:41,692 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:41,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:42,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:42,395 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:42,426 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:42,949 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:43,116 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:43,136 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:43,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:43,316 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:43,317 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:43,348 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:43,348 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:43,349 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:43,463 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:43,521 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:44,010 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:44,326 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:44,497 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:44,689 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:44,706 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:44,886 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:45,215 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:45,305 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566700495952457e8147'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566700512253863e1295'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566700517163034e8745'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566700524514542e79b1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c317566700530315201e7ab4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/30 (Success: 3)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17004
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17004
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566700537321095e7f32'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c217566700563363652e8039'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041917566700568514568e2d22'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063717566700584231568e8a57'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043a17566700605213601e1df9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066d17566700612716317e80e4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 19167
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19167
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416017566700628546177ef041'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:54:45,580 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:45,739 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:45,756 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:45,972 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:46,070 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:46,375 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:46,981 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:47,011 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566700518488122e7fa3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566700523511619e8af1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a017566700528927108e76bc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.83
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21163
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21163
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566700552807748e7ffe'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a017566700558018476e7761'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566700573743764e88f3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e063817566700595543973e7ff4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3171
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3171
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150416417566700603067581e123f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150439017566700616912560e27fc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150430917566700622102750e1e12'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e058a17566700629395101e34b1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150415b17566700649134545ee518'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching2025-08-31 15:54:47,153 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:47,312 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:47,313 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:47,317 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:47,352 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:47,640 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:48,235 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:48,779 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:48,883 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:48,894 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:49,030 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:49,212 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:49,236 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:49,237 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:49,274 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:49,275 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:49,275 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:49,408 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:49,773 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:50,260 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:50,463 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:50,517 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06bc17566700521614414e80dd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a117566700526683816e8b6c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566700533754225e0d1d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566700539215478e81c4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566700550986877e889d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566700556015321e20a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06a217566700588074197e827d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566700593071356e8247'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 19134
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19134
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060b17566700616124844e89fd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c117566700623216117e8923'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066017566700626194649e8b23'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062017566700636668061e8216'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150454117566700666467774e7941'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:54:50,538 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:50,540 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:50,610 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:50,610 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:50,610 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:50,675 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:50,688 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:50,688 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:50,716 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:50,716 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:50,716 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:51,007 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:51,198 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:51,316 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:51,345 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:51,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:51,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:52,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:52,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:52,599 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:52,784 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:52,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:52,983 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:53,004 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:53,005 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:53,055 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:53,055 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:53,055 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:53,077 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:53,257 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:53,649 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:53,938 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:53,960 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:53,961 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:54,000 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:54,000 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:54,000 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:54,028 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:54,356 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:54,454 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:54,485 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:54,707 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:55,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:55,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:55,501 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:55,700 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:55,727 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:55,863 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:55,877 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:54:55,878 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:54:55,915 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:54:55,915 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:54:55,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:54:56,227 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:56,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:56,355 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:56,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:56,749 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:57,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:57,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:57,278 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:57,454 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:57,670 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:58,125 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:58,320 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:58,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:58,378 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:58,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:54:59,173 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:59,259 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:59,709 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:59,712 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:59,799 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:54:59,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:00,123 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:00,417 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,271 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,271 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,272 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,280 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,303 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,555 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:01,556 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:02,154 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:02,383 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:02,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:02,730 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:02,740 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:02,902 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:02,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:02,944 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:02,959 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:02,960 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:02,995 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:02,995 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:02,995 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:03,248 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:03,249 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:03,457 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:03,942 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:03,943 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:03,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:04,418 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:04,457 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:04,499 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150457117566700630528219e7b40'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e03e217566700638524748e1b7d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3265
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3265
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3170
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3170
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566700765942278e22b8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150415b17566700779094999ee662'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006a17566700796113782ee218'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns2025-08-31 15:55:04,974 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:05,659 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[RETRY] Connection issue, waiting 0.6s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.66
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3188
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3188
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06c017566700656295483e8140'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060a17566700661307064e8b00'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23202
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23202
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22504
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22504
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.882025-08-31 15:55:05,870 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:06,096 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:06,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:06,384 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:06,863 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:07,459 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:07,570 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:07,757 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:08,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:09,374 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3160
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3160
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150449a17566700753914847e82e7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.73
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3151
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3151
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23303
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23303
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-31 15:55:09,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:09,745 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:10,063 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:10,525 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:10,910 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:11,755 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:11,779 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:11,780 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:11,818 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:11,818 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:11,818 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:12,186 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:12,212 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:12,213 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:12,279 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:12,279 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:12,280 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:12,476 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:13,004 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:13,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:13,021 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:13,022 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:13,068 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:13,068 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:13,068 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:13,684 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:13,694 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:13,700 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:13,725 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:13,726 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:13,760 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:13,761 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:13,761 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:14,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:14,574 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:14,705 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:14,922 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:16,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:16,311 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:16,827 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:17,360 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:19,164 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:19,660 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:19,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:20,340 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:20,341 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23204
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23204
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.83
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23202
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23202
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e080f17566701019671274e0d27'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e064d17566701030223897e82c7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20448
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20448
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059717566701037658845e34a4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007d17566701053983238ef10a'}2025-08-31 15:55:20,535 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:21,245 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:21,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:24,370 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:24,388 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:24,388 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:24,437 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:24,437 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:24,437 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:24,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:24,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:25,293 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:25,387 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:55:25,434 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:25,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:26,437 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:26,464 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:26,794 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:27,373 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:27,749 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:27,822 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:28,363 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:28,436 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:28,583 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:28,877 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:28,956 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:29,380 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:29,485 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22656
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22656
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23162
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23162
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215042ae17566701027621685e907c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566701032802436e3cae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20549
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20549
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007017566701042734507eea30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b617566701047894358e7f36'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566701056905111e7e38'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566701061983274e7f50'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007317566701072323302ee501'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e01f617566701092007892e12b8'}2025-08-31 15:55:29,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:29,826 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129825035.json
2025-08-31 15:55:29,829 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129827379.json
2025-08-31 15:55:29,830 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129829567.json
2025-08-31 15:55:29,832 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129831167.json
2025-08-31 15:55:29,833 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129832702.json
2025-08-31 15:55:29,834 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129833573.json
2025-08-31 15:55:29,834 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129834313.json
2025-08-31 15:55:29,835 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129834838.json
2025-08-31 15:55:29,836 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129835697.json
2025-08-31 15:55:29,837 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129836325.json
2025-08-31 15:55:29,837 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-7b-instruct:30)
2025-08-31 15:55:29,843 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 30 个结果到收集器: qwen2.5-7b-instruct_36688_1756670129838078.json
2025-08-31 15:55:29,843 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-7b-instruct:30)
2025-08-31 15:55:29,902 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:29,912 - batch_test_runner - INFO - Database saved successfully
2025-08-31 15:55:29,912 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 15:55:29,912 - batch_test_runner - INFO - ============================================================
2025-08-31 15:55:29,913 - batch_test_runner - INFO - Batch test completed at 2025-08-31T15:55:29.913051
2025-08-31 15:55:29,913 - batch_test_runner - INFO - Summary:
2025-08-31 15:55:29,913 - batch_test_runner - INFO -   - Total tests: 30
2025-08-31 15:55:29,913 - batch_test_runner - INFO -   - Successful: 3
2025-08-31 15:55:29,913 - batch_test_runner - INFO -   - Failed: 27
2025-08-31 15:55:29,913 - batch_test_runner - INFO -   - Success rate: 10.0%
2025-08-31 15:55:29,913 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_155113.log
2025-08-31 15:55:29,913 - batch_test_runner - INFO - ============================================================
2025-08-31 15:55:29,913 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-31 15:55:29,913 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-31 15:55:29,914 - result_merger - INFO - 发现71个新的结果文件
2025-08-31 15:55:29,961 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:55:29,961 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-31 15:55:29,982 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:30,477 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:30,956 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:30,964 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:31,244 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:31,517 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:32,212 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:32,318 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:32,516 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:32,518 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:33,250 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:33,355 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:34,002 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:34,036 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:34,513 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:34,551 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:35,227 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:35,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:36,177 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:36,203 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:36,298 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:36,576 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:36,599 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:36,600 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:36,630 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:36,635 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error. The error message is Unknown error with 0 tool coverage, providing no basis to judge 
2025-08-31 15:55:36,667 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:36,667 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:36,668 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:36,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:36,949 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:36,950 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:37,010 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:37,010 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:37,010 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:37,588 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:37,779 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:37,789 - api_client_manager - INFO - Created idealab client for model qwen2.5-7b-instruct
2025-08-31 15:55:37,789 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:55:37,815 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:55:37,815 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:55:37,815 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:55:38,003 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:38,183 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:38,256 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:39,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:39,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:40,069 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:40,495 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:41,173 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:41,640 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:41,734 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:42,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:42,709 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:43,338 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:43,631 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:44,293 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:44,605 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:44,874 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:45,316 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:45,609 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:45,613 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no required tools to select or execute (tool coverage is 0/0) and no tool execution occurred. The error message is Unknown error, and there are 
2025-08-31 15:55:45,875 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:46,359 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:47,195 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:47,775 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:48,565 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:48,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:49,206 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 15:55:51,692 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e060c17566701059036489e8ace'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566701075506470e79e8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e068217566701080538858e792d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059d17566701095685912e34f9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.84
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e05ab17566701114803015e3427'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16337
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16337
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007517566701122228629ef13e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566701127465932e8203'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e06b717566701134992294e78e0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 215045f517566701140061799e8118'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150460817566701147258431e7a7a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065c17566701161047345e83cf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566701171761018e3c12'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150435d17566701195953427e2088'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007317566701200861426ee47d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.7s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
Progress: 30/35 (Success: 2)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3348
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3348
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-31 15:55:52,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:52,971 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool for the api_integration task, leading to 0% tool coverage and complete failure. This is a tool choice 
2025-08-31 15:55:55,956 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:58,110 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:58,113 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required data_pipeline tools; no tools were invoked, leading to a complete lack of workflow execution.",
  
2025-08-31 15:55:59,264 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:55:59,267 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159266609.json
2025-08-31 15:55:59,268 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159267619.json
2025-08-31 15:55:59,268 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159268165.json
2025-08-31 15:55:59,269 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159268692.json
2025-08-31 15:55:59,269 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159269172.json
2025-08-31 15:55:59,271 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159270002.json
2025-08-31 15:55:59,271 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159271173.json
2025-08-31 15:55:59,272 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159271796.json
2025-08-31 15:55:59,274 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159272804.json
2025-08-31 15:55:59,274 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159274118.json
2025-08-31 15:55:59,275 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159274727.json
2025-08-31 15:55:59,275 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159275389.json
2025-08-31 15:55:59,276 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159276132.json
2025-08-31 15:55:59,277 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159276749.json
2025-08-31 15:55:59,279 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159278055.json
2025-08-31 15:55:59,280 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-7b-instruct:35)
2025-08-31 15:55:59,286 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 35 个结果到收集器: qwen2.5-7b-instruct_36686_1756670159281402.json
2025-08-31 15:55:59,286 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-7b-instruct:35)
2025-08-31 15:55:59,443 - batch_test_runner - INFO - Database saved successfully
2025-08-31 15:55:59,443 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 15:55:59,443 - batch_test_runner - INFO - ============================================================
2025-08-31 15:55:59,444 - batch_test_runner - INFO - Batch test completed at 2025-08-31T15:55:59.444018
2025-08-31 15:55:59,444 - batch_test_runner - INFO - Summary:
2025-08-31 15:55:59,444 - batch_test_runner - INFO -   - Total tests: 35
2025-08-31 15:55:59,444 - batch_test_runner - INFO -   - Successful: 2
2025-08-31 15:55:59,444 - batch_test_runner - INFO -   - Failed: 33
2025-08-31 15:55:59,444 - batch_test_runner - INFO -   - Success rate: 5.7%
2025-08-31 15:55:59,444 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_155113.log
2025-08-31 15:55:59,444 - batch_test_runner - INFO - ============================================================
2025-08-31 15:55:59,444 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-31 15:55:59,444 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-31 15:55:59,444 - result_merger - INFO - 发现16个新的结果文件
2025-08-31 15:55:59,465 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:55:59,465 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-31 15:56:04,055 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:04,069 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decisions can be evaluated: no tools were selected or executed, no parameters set, and no sequence followed. The error message 'Unknown erro
2025-08-31 15:56:05,115 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:05,184 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The task defined no required tools and there were no tools executed or parameters set. With zero tool usage, there is no basis for tool-selection, paramete
2025-08-31 15:56:09,178 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:09,180 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error. The task log shows an Unknown error with 0 tools executed, so there is no tool_selection_errors, parameter_
2025-08-31 15:56:09,545 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:09,546 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize the required tool(s) for the api_integration task; no tools were chosen or configured, resulting in immediat
2025-08-31 15:56:14,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:14,454 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or a workflow defined for an unknown task; the agent did not choose an appropriate tool or plan, effectively making a tool-
2025-08-31 15:56:15,342 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:15,344 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and there is no identifiable agent decision path (tool choice, parameters, sequence, or dependencies) to attribute the failure to. T
2025-08-31 15:56:22,365 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:22,373 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Partial success with an unknown tool error; there is no clear evidence of a wrong agent decision (tool selection, parameter config, or sequence). Insuffici
2025-08-31 15:56:23,062 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:23,065 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The task had no required tools and the agent did not execute any tools or define a workflow. There is no explicit agent decision (tool choice, parameteriza
2025-08-31 15:56:27,539 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:27,541 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and/or propose any of the required tools for the multi_stage_pipeline task; no tools were executed and there is no defi
2025-08-31 15:56:29,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:29,201 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed for the task; there was no tool invocation despite a task context existing, indicating a failure in the agent's t
2025-08-31 15:56:33,443 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:33,445 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tool for the basic_task; no tool was engaged, indicating a tool-selection decision error that prevente
2025-08-31 15:56:34,068 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:34,069 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute or configure any stages in the required multi-stage pipeline (no tools selected or run). This indicates a failure to est
2025-08-31 15:56:38,266 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:38,269 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The partial success and quality issues suggest the agent executed workflow steps out of the required order or violated logical dependencies (e.g.,
2025-08-31 15:56:41,042 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:41,045 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed, and there is no evidence of a wrong tool choice, incorrect parameters, bad sequence, or unmet dependencies. The 'Unknow
2025-08-31 15:56:46,243 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:46,245 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Observed complete failure with zero tool usage and no explicit error message. There is insufficient signal to attribute the failure to tool_selection_error
2025-08-31 15:56:47,332 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:47,333 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "In a multi_stage_pipeline, no tools were selected or executed, indicating the agent failed to satisfy prerequisite dependencies or trigger subsequent 
2025-08-31 15:56:50,232 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:50,233 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed due to an unknown/system error; there is no evidence of the agent selecting the wrong tool, misconfiguring parameters, executing in 
2025-08-31 15:56:53,146 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:53,169 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence found: no tools were selected or executed and the error is unknown. This does not demonstrate a mischoice of tool, incorrect par
2025-08-31 15:56:54,611 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:54,613 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no tools executed (no tool decisions to evaluate) and the error message indicates an unknown/system error rather than a wrong agent decision. Be
2025-08-31 15:56:59,263 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:56:59,264 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence available: the task ended with an Unknown error and there were no tool executions, parameter settings, or workflow steps to eval
2025-08-31 15:57:00,031 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:00,033 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "In a multi_stage_pipeline task, the agent did not perform the required sequential stages (A→B→C). No tools were executed and no pipeline steps wer
2025-08-31 15:57:07,489 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:07,490 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No stages of the multi_stage_pipeline were executed and no execution order was established; the agent failed to instantiate or sequence the requir
2025-08-31 15:57:07,507 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:07,508 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent-level decision errors (tool selection, parameter configuration, sequence order, or dependency handling). The task shows zero tool usag
2025-08-31 15:57:09,054 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2025-08-31 15:57:09,057 - batch_test_runner - ERROR - Test failed with exception: Error code: 500 - {'error': ''}
2025-08-31 15:57:09,076 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229074910.json
2025-08-31 15:57:09,076 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229076165.json
2025-08-31 15:57:09,076 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229076656.json
2025-08-31 15:57:09,077 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229077015.json
2025-08-31 15:57:09,078 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229077847.json
2025-08-31 15:57:09,078 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229078360.json
2025-08-31 15:57:09,079 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229078867.json
2025-08-31 15:57:09,080 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229079927.json
2025-08-31 15:57:09,080 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229080453.json
2025-08-31 15:57:09,081 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229080770.json
2025-08-31 15:57:09,081 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229081121.json
2025-08-31 15:57:09,081 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229081656.json
2025-08-31 15:57:09,082 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229081972.json
2025-08-31 15:57:09,082 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229082279.json
2025-08-31 15:57:09,083 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 1 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229082857.json
2025-08-31 15:57:09,084 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-7b-instruct:35)
2025-08-31 15:57:09,088 - result_collector - INFO - 📤 已提交 qwen2.5-7b-instruct 的 35 个结果到收集器: qwen2.5-7b-instruct_36687_1756670229085369.json
2025-08-31 15:57:09,089 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-7b-instruct:35)
2025-08-31 15:57:09,145 - batch_test_runner - INFO - Database saved successfully
2025-08-31 15:57:09,145 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 15:57:09,145 - batch_test_runner - INFO - ============================================================
2025-08-31 15:57:09,145 - batch_test_runner - INFO - Batch test completed at 2025-08-31T15:57:09.145824
2025-08-31 15:57:09,145 - batch_test_runner - INFO - Summary:
2025-08-31 15:57:09,145 - batch_test_runner - INFO -   - Total tests: 35
2025-08-31 15:57:09,145 - batch_test_runner - INFO -   - Successful: 5
2025-08-31 15:57:09,145 - batch_test_runner - INFO -   - Failed: 30
2025-08-31 15:57:09,145 - batch_test_runner - INFO -   - Success rate: 14.3%
2025-08-31 15:57:09,146 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_155113.log
2025-08-31 15:57:09,146 - batch_test_runner - INFO - ============================================================
2025-08-31 15:57:09,146 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-31 15:57:09,146 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-31 15:57:09,146 - result_merger - INFO - 发现16个新的结果文件
2025-08-31 15:57:09,165 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:57:09,165 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-31 15:57:10,568 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:10,571 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the api_integration task; the agent failed to choose the required tool(s) (e.g., API client/data loader) to 
2025-08-31 15:57:13,631 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:13,634 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not implement or follow the required multi-stage pipeline sequence; no stages were executed, implying a failure to arrange tasks in 

[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150460817566701241815520e7b51'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150430c17566701251883308e2185'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 3248
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3248
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=max_turns_errors, confidence=0.7
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20455
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20455
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 6056272672)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22177
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22177
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 206972025-08-31 15:57:14,120 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:14,141 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure appears to be an external/tool-level unknown error with no executed tools or agent decisions to evaluate. Since there were no tool selections, 

[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20697
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
💾 智能Checkpoint: 保存15个结果...
   触发原因: 数量=15, 时间=119.1s, 强制=True
✅ Checkpoint完成: 成功保存 15/15 个结果

[INFO] Batch writing 35 records to database (qwen2.5-7b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-7b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_155559.json
[SAVE_ENHANCED] 开始增强保存，时间: 15:55:59
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.75) - No agent-level decisions can be evaluated: no tool
[V3_UPDATE] 创建新prompt类型结构: qwen2.5-7b-instruct -> baseline
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-7b-instruct -> baseline -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - No evidence of a specific agent decision error. Th
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - No tools were selected or a workflow defined for a
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 2)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No tools were selected or executed, and there is n
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.72) - In a multi_stage_pipeline, no tools were selected 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision evidence found: no tools were se
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 2)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 5)2025-08-31 15:57:16,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:16,364 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initiate the required tools for the data_pipeline task; no tools were invoked, indicating a wrong tool decision or fail


[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20697
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20697
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.9
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22624
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22624
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json processor

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22441
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22441
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5345317296)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: CSV format)

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20585
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20585
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e006b17566701025456582eeb01'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062017566701030526511e8237'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065417566701038042724e7e53'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566701043061477e0c99'}2025-08-31 15:57:19,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:19,760 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed (tool selection step failed); the agent did not choose any tool appropriate to progress the task, leading to ze
2025-08-31 15:57:21,781 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:21,783 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool selection, parameter config, sequence, or dependencies). The error is reported as Unknown error with no tool ex
2025-08-31 15:57:24,451 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:24,452 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or use any required tools for the multi-stage pipeline; tool coverage is 0% (no tools chosen), indicating an incorrect to
2025-08-31 15:57:26,220 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:26,228 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error. There were no tools selected or executed (task context is unknown, required tools coverage is 0%, and the error is repo
2025-08-31 15:57:28,404 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:28,405 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any appropriate API integration tool; no tools were used for an api_integration task, resulting in 0% coverage a

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.0s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566701120038700e2003'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16337
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16337
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e041717566701127427222e9900'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e066417566701135263867e80e8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059d17566701142547546e355c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150448717566701145277947e7e5a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e043517566701161276405e2bc4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150458717566701166282090e8056'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e001317566701189782155e0b70'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150456117566701194808723e8199'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.6s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.65
Progress: 30/35 (Success: 5)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20769
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20769
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 2150452b17566701210295184e79b9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e081017566701251085874e0aca'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.72
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct2025-08-31 15:57:31,103 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:31,104 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute a specific agent decision error. No tools were executed (0% coverage) and the error message is a generic 'Unknown err
2025-08-31 15:57:32,024 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:32,026 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no pipeline steps were performed, indicating the agent failed to follow or establish the required data_pipeline sequenc
2025-08-31 15:57:35,411 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:35,412 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed; with unknown task and 0% required tool coverage, there is insufficient evidence to attribute the fail
2025-08-31 15:57:35,799 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:35,800 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize a tool appropriate for the task (no tools were executed). This effectively represents an incorrect tool deci
2025-08-31 15:57:37,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:37,067 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be identified: no tools were selected/executed and the error is labeled 'Unknown error'. Since there is no evidence of wrong tool cho
2025-08-31 15:57:39,677 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:39,680 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize the required tools for the multi_stage_pipeline task (no tools executed), resulting in 0% tool coverage and
2025-08-31 15:57:40,318 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:40,327 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any data pipeline tools (e.g., data_loader, transformer, sink) for the data_pipeline task, and no execution
2025-08-31 15:57:41,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:41,709 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool selection, parameter config, sequence, or dependencies). The failure is described as an unknown/system-level er
2025-08-31 15:57:43,878 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:43,908 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable tool usage or agent decision data is available. The failure is described as an Unknown error, which appears to be a system/tool-level issue r
2025-08-31 15:57:46,954 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:46,960 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or activate any tool to perform the simple_task; there was no tool execution, indicating a wrong decision at the tool selecti
2025-08-31 15:57:47,510 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:47,513 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and/or invoke the appropriate tool for the API integration task (no tools executed). This failure to choose the required to
2025-08-31 15:57:51,498 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:51,501 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No detectable agent decision error: no tools were selected or executed (coverage 0%), and the failure appears to be an external/tooling/unknown error rathe
2025-08-31 15:57:53,043 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:53,045 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the multi_stage_pipeline task, resulting in 0% coverage. The agent did not choose the required tools (e.g.,
2025-08-31 15:57:57,186 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:57,189 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to accomplish the basic_task; effectively choosing 'no tool' or stalling, which is a wrong tool-related de
2025-08-31 15:57:57,278 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:57,279 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The error is generic/unknown with no tools executed, suggesting
2025-08-31 15:57:58,374 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:57:58,377 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool required for the api_integration task, resulting in no execution steps and 0% tool coverage.",
  "co
2025-08-31 15:58:02,898 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:02,899 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the API integration task; the agent failed to initiate any tool-based workflow, effectively failing to choo
2025-08-31 15:58:04,773 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:04,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not execute the required API integration workflow steps; no tools were invoked, effectively breaking the intended sequence (A→B→C). This
2025-08-31 15:58:06,191 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:06,197 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tooling was selected or invoked for a data_pipeline task; the agent failed to choose an appropriate tool (or any tool) given the task context. 
2025-08-31 15:58:07,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:07,977 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of incorrect agent decisions (no tool selections, parameter settings, or sequence provided). The reported 'Unknown error' points to an environm
2025-08-31 15:58:11,588 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:11,589 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No steps were executed and no workflow sequence was defined or followed. The agent failed to initiate or plan the required api_integration workflo
2025-08-31 15:58:12,112 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:12,113 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence available: the task details are unknown and no tools were executed. The error message 'Unknown error' indicates a system/unknown
2025-08-31 15:58:14,399 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:14,400 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error occurred because there were 0 required tools (0/0). The error 'Unknown error' appears to be an external/system fault, not a mistake
2025-08-31 15:58:19,352 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:19,353 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool appropriate for the api_integration task, resulting in no progress. This is a wrong initial tool decision 
2025-08-31 15:58:21,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:21,363 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the api_integration task; the agent failed to choose a required tool or to request clarifications, resultin
2025-08-31 15:58:22,110 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:22,111 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision was made: the task is unknown and no tools were selected or configured. The error appears to stem from missing task details rather than a
2025-08-31 15:58:24,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:24,698 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any appropriate tool to begin the multi-stage pipeline for the unknown task; no tools were invoked and no s
2025-08-31 15:58:27,162 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:27,164 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No required tools were selected or invoked. The agent failed to pick and initialize the appropriate data_pipeline tools (no tool usage), effective
2025-08-31 15:58:27,496 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:27,498 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool for the api_integration task, effectively failing to engage the required tooling workflow. This is
2025-08-31 15:58:30,993 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:30,995 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameter config, sequence, or dependencies). The error message is generic ('Unknown error'
2025-08-31 15:58:32,116 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:32,118 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were invoked and no workflow steps were performed, indicating the agent failed to establish or follow the required api_integration execut
2025-08-31 15:58:35,895 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:35,897 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize the required tooling (no tools were executed; coverage 0%). In a multi-stage pipeline, the first step is to
2025-08-31 15:58:36,275 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:36,277 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task specified no required tools, yet the agent did not perform any action or select any fallback/default workflow, indicating a decision erro
2025-08-31 15:58:36,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:36,519 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool suitable for api_integration; no tools were executed, indicating a failure at the tool-selection decis
2025-08-31 15:58:42,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:42,833 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or apply any appropriate tool for the basic_task (effectively choosing 'no tool'), which is a tool-selection error since th
2025-08-31 15:58:43,045 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:43,046 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The task failed to coordinate prerequisites for the multi-stage pipeline; no tools were executed, indicating the agent did not satisfy or sequence the
2025-08-31 15:58:43,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:43,412 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The task context is unknown, and the agent did not establish or resolve the prerequisite information needed to proceed (no tools selected/executed). T
2025-08-31 15:58:49,347 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:49,353 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is insufficient information to attribute the failure to a specific agent decision (tool selection, parameter config, sequence, or dependencies). The 
2025-08-31 15:58:49,353 - result_merger - INFO - 模型qwen2.5-7b-instruct保存50/50条记录
2025-08-31 15:58:49,358 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-31 15:58:49,372 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-31 15:58:49,373 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.16s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 4)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.13s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 4)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 12)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: max_turns_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'max_turns_errors' -> 'max_turns_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: max_turns_errors -> max_turns_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.65) - No observable agent decision error. There were no 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: sequence_order_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision can be identified: no tools were
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of a wrong agent decision (tool select
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.72) - Agent failed to select and/or invoke the appropria
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 18)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of incorrect agent decisions (no tool 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.82) - No agent decision error occurred because there wer
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.62) - No tools were selected or executed for the api_int
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: dependency_errors (confidence: 0.62) - The task context is unknown, and the agent did not
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - There is insufficient information to attribute the
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 27)
[INFO] 最终合并完成: 16 个文件
2025-08-31 15:58:49,628 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-31 15:58:49,628 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-31 15:58:49,739 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:49,742 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error could be identified. There were no tool selections, parameter configurations, or dependency/sequence decisions recorded, a
2025-08-31 15:58:49,863 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:49,866 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or deploy any tool for the data_pipeline task (no tools executed and no required tools identified due to unknown task). This 
INFO:__main__:✅ 分片1完成
INFO:__main__:等待分片2完成（20实例×50workers，最多等待50分钟）...
2025-08-31 15:58:53,399 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:53,401 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize the required tools for the multi_stage_pipeline (no tools were executed). This is a tool-selection decision
2025-08-31 15:58:55,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:55,502 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to establish or follow a valid multi-stage pipeline because the task is unknown. This lack of task clarification led to no planne
2025-08-31 15:58:58,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:58:58,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed; insufficient information to attribute to a specific agent decision. The error message 'Unknown error' and zero tool usa
2025-08-31 15:59:01,041 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:01,041 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or used and no task-specific plan was defined, indicating the agent failed to choose an appropriate tool/approach for the g
2025-08-31 15:59:05,180 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:05,180 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any required data_pipeline tools (no data_loader/reader invoked). This is a wrong tool decision at the outse
2025-08-31 15:59:07,279 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:07,283 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no workflow steps were completed, indicating the agent did not establish or follow the required A→B→C data_pipeline seq
2025-08-31 15:59:11,415 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:11,418 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to begin the multi_stage_pipeline, effectively failing to initialize the required tool sequence. This 
2025-08-31 15:59:14,882 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:14,883 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools or pipeline steps were selected or executed for the given unknown task, effectively a failure to identify/choose the appropriate toolset.
2025-08-31 15:59:19,017 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:19,020 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any actions or produce an output for a basic_task, effectively halting the workflow. This represents an incorrect sequen
2025-08-31 15:59:21,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:21,203 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is insufficient information to identify a specific agent decision error. No tools were executed, no parameters were provided, and there is no explici
2025-08-31 15:59:23,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:23,023 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and no agent decisions were observable. The error is unspecified ('Unknown error'), so there is insufficient evidence to diagnose a 
2025-08-31 15:59:26,220 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:26,221 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or configure any tool to perform the data_pipeline task (no tool invocations were executed). In a data_pipeline flow, a t
2025-08-31 15:59:28,050 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:28,051 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is labeled 'Unknown error'. There is insufficient evidence of any agent decision (tool choice, parameters, sequence, d
2025-08-31 15:59:31,891 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:31,895 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task is a multi-stage pipeline requiring a defined A→B→C sequence; due to complete failure with no explicit error, the most plausible agent er
2025-08-31 15:59:34,282 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:34,284 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tool for the data_pipeline task, resulting in 0% tool coverage and complete failure. This omission con
2025-08-31 15:59:40,803 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:40,805 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed and no required tool usage was identified. In a multi-stage pipeline, failing to select and run the necessary tool constitu
2025-08-31 15:59:40,838 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:40,839 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any of the required data_pipeline tools (e.g., data_loader, data_processor) to start the workflow, resulting in

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e065e17566701061445657e7e45'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e007617566701066845002e12cf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.7
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e042d17566701092904450e20a8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e059617566701103364868e3bc7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPM限流', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPM限流, traceId: 213e062917566701135015950e8006'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11727
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11727
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13399
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13399
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.82
Progress: 30/30 (Success: 3)
💾 智能Checkpoint: 保存10个结果...
   触发原因: 数量=10, 时间=76.0s, 强制=True
✅ Checkpoint完成: 成功保存 10/10 个结果

[INFO] Batch writing 30 records to database (qwen2.5-7b-instruct:30)
[INFO] Successfully wrote 30/30 records (qwen2.5-7b-instruct:30)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_155529.json
[SAVE_ENHANCED] 开始增强保存，时间: 15:55:29
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.65) - Insufficient information to identify a specific ag
[V3_UPDATE] 创建新prompt类型结构: qwen2.5-7b-instruct -> baseline
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-7b-instruct -> baseline -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.85) - There were no required tools to select or execute 
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.60) - Agent did not select or initialize any tool for th
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.85) - No tools were executed and there is no identifiabl
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.60) - Partial success with an unknown tool error; there 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 4)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.55) - No tool was selected or executed for the task; the
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.54)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.85) - No tools were executed due to an unknown/system er
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - There were no tools executed (no tool decisions to
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent decision evidence available: the task end
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.60) - No evidence of a wrong agent decision (tool select
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - Insufficient information to attribute a specific a
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85) - Agent failed to select and initialize a tool appro
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.80)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.60) - No tooling was selected or invoked for a data_pipe
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision evidence available: the task det
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.80) - No agent decision was made: the task is unknown an
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.75) - Agent did not select or deploy any tool for the da
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.72) - The agent failed to establish or follow a valid mu
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85) - No tools were selected or used and no task-specifi
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.62) - No tools were executed and no agent decisions were
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.62) - No tools were executed and the error is labeled 'U
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.62)
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: parameter_config_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'parameter_config_errors' -> 'parameter_config_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: parameter_config_errors -> parameter_config_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 19)
[INFO] Buffer full (3 records), triggering flush...2025-08-31 15:59:46,627 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:46,629 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision path is available: the task reported an unknown error with no tools executed, so there is insufficient information to identify a tool_sel
2025-08-31 15:59:47,833 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:47,834 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision could be evaluated because the task produced an unknown error with no tool executions. This prevents diagnosing tool_selection, par
2025-08-31 15:59:55,408 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:55,411 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools or steps were executed, indicating the agent failed to perform the required workflow sequence for a simple_task. There is no data process
2025-08-31 15:59:56,001 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:59:56,004 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is an unknown/system-level failure with no tool executions and no observable agent decision steps. Without tool usage or parameter/sequence/dependenc
2025-08-31 16:00:02,263 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:02,266 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error can be determined from the report: no tools were executed and the error is listed as 'Unknown error'. Without executed t
2025-08-31 16:00:02,377 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:02,378 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and initialize any tools appropriate for the multi-stage pipeline, resulting in 0% tool coverage and no tools executed.
2025-08-31 16:00:07,235 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:07,236 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable data on agent decisions: the error is reported as 'Unknown error' with no tools executed or tool usage details. Without evidence of tool sele
2025-08-31 16:00:08,254 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:08,255 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed; there is insufficient information to determine a specific agent decision error (tool selection, param
2025-08-31 16:00:11,695 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:11,697 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no tool executions available to assess agent decision quality; the error is reported as Unknown, suggesting a system-level or external failure r
2025-08-31 16:00:14,123 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:14,128 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the api_integration task, causing the agent to fail to initiate any tooling path. This indicates a flawed in

  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 20535
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20535
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-7b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-7b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5555109744)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json processor

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22336
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22336
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-7b-instruct, API name: qwen2.5-7b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.7
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21364
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21364
  - task_model=qwen2.5-7b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[LLM_ERROR] Attempt 1/5: Error code: 500 - {'error': ''}
[DEBUG] Got result for task: has_result=True, save_logs=False
💾 智能Checkpoint: 保存15个结果...
   触发原因: 数量=15, 时间=189.4s, 强制=False
✅ Checkpoint完成: 成功保存 15/15 个结果

[INFO] Batch writing 35 records to database (qwen2.5-7b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-7b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_155709.json
[SAVE_ENHANCED] 开始增强保存，时间: 15:57:09
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-7b-instruct的新prompt_type: baseline
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.78) - The failure appears to be an external/tool-level u
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct unknown: tool_selection_errors (confidence: 0.60) - No tools were selected or executed (tool selection
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> unknown
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> unknown (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75) - The agent did not select or use any required tools
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct unknown: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.82)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No actionable tool usage or agent decision data is
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.60) - No detectable agent decision error: no tools were 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.60) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: sequence_order_errors (confidence: 0.42)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.11s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75) - The agent did not select or initialize any appropr
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.60) - No evidence of a specific agent decision error (to
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60) - The agent did not select or initialize the require
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No tools were selected or executed; insufficient i
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: sequence_order_errors (confidence: 0.44) - No tools were executed and no workflow steps were 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - No tools or pipeline steps were selected or execut
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60) - No tools were executed and no required tool usage 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent-level decision could be evaluated because
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 10)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.60) - There is an unknown/system-level failure with no t
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-7b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 9)2025-08-31 16:00:18,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:18,242 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required data_pipeline tools (no tool execution occurred). This indicates a wrong initial tool selection/decisi
2025-08-31 16:00:19,369 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:19,370 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure is due to a server-side 500/tool/API error rather than any incorrect agent decision (no tools were required or used for this task: 0/0). Thus, 
2025-08-31 16:00:19,371 - result_merger - INFO - 模型qwen2.5-7b-instruct保存50/50条记录
2025-08-31 16:00:19,382 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-31 16:00:19,387 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-31 16:00:19,393 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 20)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 14)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - The failure is due to a server-side 500/tool/API e
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 24)
[INFO] 最终合并完成: 16 个文件
2025-08-31 16:00:19,623 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-31 16:00:19,624 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片2完成
INFO:__main__:等待分片3完成（20实例×50workers，最多等待50分钟）...
2025-08-31 16:00:26,682 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:26,684 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps to accomplish the basic_task, effectively failing to follow the expected workflow sequence for this task (no a
2025-08-31 16:00:32,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:32,427 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no workflow sequence was established. The complete failure indicates the agent did not set up or follow the required A→
2025-08-31 16:00:38,404 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:38,406 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not identify or select an appropriate tool to handle an unknown task; no tool usage occurred and no clarifying questions or plan wer
2025-08-31 16:00:43,320 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:43,322 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: no tools were selected or executed (coverage 0%), and the failure appears to be a system-level/unknown error rather than 
2025-08-31 16:00:49,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:49,622 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute an agent decision error: no tool usage, parameters, or sequence were executed; the error is reported as Unknown error
2025-08-31 16:00:56,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:00:56,362 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps or follow the expected execution sequence for the basic_task, effectively halting the workflow and producing a
2025-08-31 16:01:02,516 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:02,517 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool(s) were selected or invoked for the api_integration task; the agent failed to initiate the workflow by choosing an appropriate integration
2025-08-31 16:01:09,331 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:09,333 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required initiating data_pipeline tooling (e.g., data_loader/pdf_reader), but the agent did not select or invoke any tools. This inaction
2025-08-31 16:01:18,664 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:18,666 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not engage any tool or select an appropriate tool for the task, leading to an incomplete result. Given the task’s unknown nature, a clar
2025-08-31 16:01:24,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:24,135 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated: no tools were selected or executed, no parameters set, and no sequence attempted. The error appears to be an unknown/
2025-08-31 16:01:30,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:30,776 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence available: no tools were executed and tool coverage is 0/0. The error message is Unknown error, which is indistinguishable from 
2025-08-31 16:01:38,285 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:38,287 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not perform any actionable steps and did not follow the expected workflow sequence. The partial result indicates a skipped or incomplete
2025-08-31 16:01:43,100 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:43,101 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform the required multi-stage pipeline steps in the correct sequence (no tools were executed, effectively halting the workflo
2025-08-31 16:01:47,712 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:47,713 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize an appropriate API integration tool for the api_integration task; no tools were executed, indicating a poor 
2025-08-31 16:01:52,922 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:52,923 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision could be identified: Task had Unknown error with no required tools and no executed steps, so there is no evidence of tool sele
2025-08-31 16:01:59,401 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:01:59,442 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task context shows an unknown task with no defined required tools. The agent did not identify or request a clarifying approach or establish a 
2025-08-31 16:02:04,857 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:04,859 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of incorrect tool choice, misconfigured parameters, wrong execution order, or unmet dependencies. There were 0/0 tools executed and the error a
2025-08-31 16:02:10,610 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:10,612 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and execute any required tool for the task (no tools were executed, though a simple_task typically requires an action).
2025-08-31 16:02:16,025 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:16,026 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were performed; no sequence was applied to accomplish the basic_task. The agent did not initiate any steps, effectively failing to esta
2025-08-31 16:02:22,663 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:22,665 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool for a task that requires tool interaction; no tool was chosen despite the task needing one, leading to a c
2025-08-31 16:02:31,327 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:31,331 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The task context is unknown; no tools were selected, no parameters configured, and no execution sequence established. This indicates a decision-gap due to 
2025-08-31 16:02:37,225 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:37,229 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is a generic 'Unknown error' with no observable agent decision path. This appears to be a tool/system issue rather tha
2025-08-31 16:02:44,921 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:44,922 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be evaluated due to missing task details and absence of any tool execution. The error message is Unknown error and there is no eviden
2025-08-31 16:02:52,431 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:52,432 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task context specifies no required tools (Required Tools: 0). The current result shows a complete failure with no tools executed, implying the
2025-08-31 16:02:59,583 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:02:59,586 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No action was taken and no tools were invoked, effectively breaking the intended simple-task workflow sequence (A→B→C) by omitting the initial ste
2025-08-31 16:03:11,546 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:11,549 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "There were effectively no actionable steps required for a simple_task with no tools; the correct outcome is to do nothing or produce a trivial res
2025-08-31 16:03:17,151 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:17,154 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or attempted; the agent did not choose an appropriate tool (or any tool) for the task, resulting in a failure at the initial 
2025-08-31 16:03:26,796 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:26,799 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision could be made due to unknown task context and missing tool requirements. The agent did not select tools, configure parameters,
2025-08-31 16:03:33,657 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:33,659 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error with no tools executed and no clear tool requirements provided; cannot attribute failure to a specific agent decision (selection, parameters,

[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 20)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 26)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors2025-08-31 16:03:41,754 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:41,754 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no evidence of an agent decision error (no tools required, and no wrong tool/parameters/sequence/dependency were identifiable
2025-08-31 16:03:50,947 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:50,949 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The agent did not provide or infer adequate configuration/parameters for the task, resulting in incomplete quality. There were no tool invocatio
2025-08-31 16:03:55,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:55,424 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize the appropriate API client/tool for the integration task; no tools were executed, indicating a missing or in
2025-08-31 16:03:59,665 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:03:59,666 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "Partial success with quality issues suggests the agent used incorrect or suboptimal tool parameters/settings, leading to insufficient result qua
2025-08-31 16:04:06,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:06,600 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a concrete agent decision error (no tool chosen, no parameters set, no sequence defined, and no dependencies to manage). The error 
2025-08-31 16:04:10,763 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:10,763 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete evidence of a specific agent decision error (tool selection, parameter configuration, sequence, or dependencies). The report only indicates Par
2025-08-31 16:04:18,590 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:18,590 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not invoke any tools for a task that likely requires at least a basic processing step; effectively a wrong tool decision by skipping too
2025-08-31 16:04:27,137 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:27,140 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be identified; the task required no tools and no explicit actions were taken. The complete failure appears to stem from inaction rath
2025-08-31 16:04:34,509 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:34,512 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error detected. The task had no required tools listed and there is no evidence of incorrect tool choice, wrong parameters, wrong
2025-08-31 16:04:40,743 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:40,746 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is insufficient evidence to attribute the failure to any specific agent decision (tool selection, parameter config, sequence order, or dependency han
2025-08-31 16:04:46,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:46,242 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task; the agent failed to choose any appropriate tool(s) given the task context, indicatin
2025-08-31 16:04:53,546 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:53,546 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error is evident: there is no evidence of wrong tool selection, incorrect parameters, wrong execution order, or missing dependen
2025-08-31 16:04:57,358 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:04:57,361 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize the required tools for the multi_stage_pipeline, resulting in no tools being used and the workflow not being
2025-08-31 16:05:02,683 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:02,683 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and configure any required data_pipeline tools (no tools executed). This constitutes an incorrect tool decision at the outs
2025-08-31 16:05:10,471 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:10,473 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Partial success due to incorrect/unfinished workflow order; the agent did not follow the required sequence for the simple_task, resulting in quali
2025-08-31 16:05:15,941 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:15,947 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute the failure to a specific agent decision. No tools were executed and no workflow steps or parameters are recorded, so
2025-08-31 16:05:23,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:23,958 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the task, indicating a failure to choose the appropriate tooling. Since the task details are unknown, the a
2025-08-31 16:05:28,675 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:28,675 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task is unknown and requires no specific tool, yet the agent proceeded with a tool-driven approach, effectively selecting an inappropriate or 
2025-08-31 16:05:34,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:34,165 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not establish or execute a correct sequence of pipeline stages for the multi_stage_pipeline; no steps were performed, indicating a failu
2025-08-31 16:05:40,802 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:40,803 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or select any tools, effectively failing to start the required task workflow. No sequence of actions (A→B→C) w
2025-08-31 16:05:48,331 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:48,332 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "no_agent_error",
  "reason": "There is no evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The task required no tools, and the partial success 
2025-08-31 16:05:48,332 - focused_ai_classifier - WARNING - Unknown category from AI: no_agent_error, defaulting to OTHER
2025-08-31 16:05:55,162 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:05:55,163 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool execution or agent decision is evidenced; the error message is 'Unknown error' with no task context or tool usage. This suggests a systemic/unknown
2025-08-31 16:06:02,972 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:02,972 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool_selection, parameter_config, sequence_order, or dependency) due to missing task/tool details and no to
2025-08-31 16:06:07,584 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:07,585 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any appropriate tool for the (unknown) task, effectively making a wrong tool decision (tool_selection_errors)."
2025-08-31 16:06:13,049 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:13,049 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No required data_pipeline tools were selected or executed; 0% tool coverage indicates the agent did not choose the appropriate tools for the task,
2025-08-31 16:06:19,164 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:19,167 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tool usage; there is no identifiable agent decision (tool choice, parameters, sequence, or dependencies) to attribute a pr
2025-08-31 16:06:28,449 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:28,450 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed; there is no evidence of a wrong agent decision (no tool chosen, no parameters set, no sequence). The 
2025-08-31 16:06:33,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:33,251 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be assessed: there were no tool selections or executions due to missing task details and an Unknown error, indicating a system-leve
2025-08-31 16:06:40,572 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:40,575 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Execution halted with an 'Unknown error' but no tools were executed or configured; therefore there is no evidence of a tool_selection_errors, parameter_con
2025-08-31 16:06:44,499 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:44,500 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of agent mis-decision (no tools executed, no parameters set, no sequence attempted). The error message 'Unknown error' suggests a syst
2025-08-31 16:06:49,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:49,665 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to initiate and execute the required data_pipeline sequence (no tools were invoked, effectively not following the A→B→C workflow). Th
2025-08-31 16:06:56,866 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:06:56,869 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any tool or take any action for a basic_task, effectively abstaining from execution. This represents a wrong tool decision/se
2025-08-31 16:07:03,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:03,913 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle TOOL DEPENDENCIES: downstream stages were triggered before upstream data/tools were ready, violating prerequisite order in the 
2025-08-31 16:07:08,025 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:08,031 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identifiable: the failure appears to be an unknown/system-level error (Error Message: Unknown error) that prevented any tool execut
2025-08-31 16:07:17,467 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:17,467 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no required tools and no agent actions executed. The error message indicates an unknown failure at the task level, not a misdecision by the agen
2025-08-31 16:07:24,560 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:24,561 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tools to handle the data_pipeline task; no executable steps were chosen, indicating a failure in the to
2025-08-31 16:07:29,141 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:29,141 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize the required tools for a multi_stage_pipeline, resulting in no tools executed. This indicates an incorrect/
2025-08-31 16:07:36,700 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:36,701 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any execution steps or follow an execution sequence for the simple_task. No tools were invoked and no steps were complet
2025-08-31 16:07:43,033 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:43,033 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No data_pipeline tools were selected or executed. The task requires tool(s) to perform data ingestion/processing, but the agent did not pick or ca
2025-08-31 16:07:49,610 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:49,610 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage and no actionable agent decision could be inferred; error reported as Unknown error. Since there is zero tool coverage and no evidence of wro
2025-08-31 16:07:59,034 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:07:59,036 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked; the agent failed to choose an appropriate tool or request clarification, indicating a wrong initial tool decisi
2025-08-31 16:08:07,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:07,846 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task produced partial success with zero tool coverage (Required Tools Coverage: 0%), and there is no record of any tool execution. This implie

[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 12)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision path is available: the task repo
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.65) - No observable agent decision error can be determin
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.62) - No actionable data on agent decisions: the error i
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.75) - There were no tool executions available to assess 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 30)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.70) - The agent did not identify or select an appropriat
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No agent decision error detected: no tools were se
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.68) - Insufficient information to attribute an agent dec
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.63)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.55) - Agent did not engage any tool or select an appropr
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No agent decision could be evaluated: no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No agent decision evidence available: no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No actionable agent decision could be identified: 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.60) - The task context shows an unknown task with no def
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.75) - No evidence of incorrect tool choice, misconfigure
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 32)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.85) - The task context is unknown; no tools were selecte
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.72) - No tools were executed and the error is a generic 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.65) - No agent decision can be evaluated due to missing 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 24)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.65) - No tool was selected or attempted; the agent did n
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No actionable agent decision could be made due to 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.72) - Unknown error with no tools executed and no clear 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 21)2025-08-31 16:08:13,591 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:13,592 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any data processing tool for the data_pipeline task, effectively choosing no tool instead of initiating the req
2025-08-31 16:08:19,872 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:19,873 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision data available. The task reports no required tools and there were no executed tools, so there is no evidence of incorrect tool c
2025-08-31 16:08:27,629 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:27,632 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error: there were no tools selected or executed for this simple_task; the partial success appears to be due to output quality/precision r
2025-08-31 16:08:35,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:35,203 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Partial success with quality issues suggests actions were not executed in the correct order (e.g., processing or analysis steps occurred before pr
2025-08-31 16:08:40,986 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:40,988 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or use any tool for an unknown task; no tools were engaged. This indicates a wrong initial decision to proceed without cl
2025-08-31 16:08:46,199 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:46,200 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there were 0 required tools, and no tool was selected or configured. The reported 'Partial success - quality issues detec
2025-08-31 16:08:52,358 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:52,365 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required/executed for this task; there is no evidence of a wrong agent decision (tool selection, parameters, sequence, or dependencies). Part
2025-08-31 16:08:57,882 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:08:57,886 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision (tool selection, parameter config, sequence order, or dependency handling). No tools were selected or executed, 
2025-08-31 16:09:06,551 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:06,563 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "no_agent_error",
  "reason": "No tool was selected or executed, and no agent decision was made. The task shows Partial success due to quality issues, but there is no evidence of a wro
2025-08-31 16:09:06,564 - focused_ai_classifier - WARNING - Unknown category from AI: no_agent_error, defaulting to OTHER
2025-08-31 16:09:10,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:10,643 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select any tool or did not designate an appropriate tool to handle the unknown task, resulting in zero tooling coverage and comple
2025-08-31 16:09:19,072 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:19,074 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a decision error by the agent (no tool was required or used, and no wrong tool/parameter/sequence/dependency was evident). The task
2025-08-31 16:09:24,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:24,082 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is reported as Unknown error with no task details. Because there is no evidence of any agent decision (tool selection,
2025-08-31 16:09:32,587 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:32,590 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "For a basic_task that requires no tools, the agent should complete without invoking any tool. The complete failure with zero tools executed implie
2025-08-31 16:09:38,859 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:38,859 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or used for the basic_task, resulting in no action taken. This indicates a wrong or missing tool decision by the agent (i.e.,
2025-08-31 16:09:45,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:45,700 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision data available: no tools were selected or executed and there is no explicit error message. Without evidence of a specific agent misdecisi
2025-08-31 16:09:51,407 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:51,408 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute the failure to a specific agent decision. No tools were executed and the error is listed as 'Unknown error', so there
2025-08-31 16:09:59,307 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:09:59,308 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameters, sequence, or dependencies). The task shows an Unknown error with no tools execu
2025-08-31 16:10:04,478 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:04,479 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of wrong agent decisions (tool_selection_errors, parameter_config_errors, sequence_order_errors, dependency_errors). The error message is Unkno
2025-08-31 16:10:13,213 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:13,218 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No required tools were specified for the task, yet the failure implies an action occurred that did not align with the task’s tool requirements. Gi
2025-08-31 16:10:20,515 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:20,516 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool necessary for a data_pipeline task (no data_loader/data_reader was chosen; no steps were executed). 
2025-08-31 16:10:26,031 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:26,033 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API integration tool was selected or invoked; the agent failed to choose and/or initialize an appropriate tool for performing the api_integrati
2025-08-31 16:10:30,804 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:10:30,805 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and no agent decisions (tool selection, parameter config, sequence, or dependencies) could have caused the failure. The error is unk
2025-08-31 16:10:30,805 - result_merger - INFO - 模型qwen2.5-7b-instruct保存100/100条记录
2025-08-31 16:10:30,806 - result_merger - INFO - 合并完成，共处理71个文件，保存100条记录
2025-08-31 16:10:30,810 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-31 16:10:30,813 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: parameter_config_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: parameter_config_errors (confidence: 0.75) - Partial success with quality issues suggests the a
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.65) - There is no evidence of a concrete agent decision 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.65) - No concrete evidence of a specific agent decision 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 30)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.11s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - There is insufficient evidence to attribute the fa
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.72) - No tools were selected or invoked for the data_pip
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No concrete agent decision error is evident: there
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - Insufficient information to attribute the failure 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.59) - No tools were selected or executed for the task, i
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.85) - The task is unknown and requires no specific tool,
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.20)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.65) - No tool execution or agent decision is evidenced; 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.64) - No evidence of a specific agent decision error (to
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85) - The agent did not select or invoke any appropriate
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent decision could be assessed: there were no
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.72) - Execution halted with an 'Unknown error' but no to
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 43)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There is no evidence of agent mis-decision (no too
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.10s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision error identifiable: the failure 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.70) - There were no required tools and no agent actions 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.60) - The agent did not select or initialize any tools t
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 43)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.75) - No tool usage and no actionable agent decision cou
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.62) - No tools were selected or invoked; the agent faile
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.85) - The task produced partial success with zero tool c
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 42)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.80)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: sequence_order_errors (confidence: 0.60) - Partial success with quality issues suggests actio
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.65) - The agent did not select or use any tool for an un
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error detected: there were 0 req
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 46)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.20)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.72) - Agent failed to select any tool or did not designa
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.85) - There is no evidence of a decision error by the ag
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 48)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.40) - No tools were executed and the error is reported a
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> basic_task (total: 49)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct basic_task: other_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.65) - Insufficient information to attribute the failure 
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 49)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct data_pipeline: other_errors (confidence: 0.85) - No evidence of a specific agent decision error (to
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> data_pipeline (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of wrong agent decisions (tool_selecti
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> api_integration (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct simple_task: tool_selection_errors (confidence: 0.40)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct data_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-7b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-7b-instruct simple_task: other_errors (confidence: 0.85) - No tools were executed and no agent decisions (too
[V3_UPDATE] 更新统计完成: qwen2.5-7b-instruct -> baseline -> simple_task (total: 51)
[INFO] 最终合并完成: 71 个文件
2025-08-31 16:10:31,240 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-31 16:10:31,241 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片3完成
INFO:__main__:📊 并发执行结果: 3/3 分片成功
INFO:__main__:✅ Key0: 完成 qwen2.5-7b-instruct-easy
INFO:__main__:最终利用率: 1.1%
=== 测试结束时间: 2025年 8月31日 星期日 16时10分33秒 EDT ===
=== 测试用时: 1161秒 ===
