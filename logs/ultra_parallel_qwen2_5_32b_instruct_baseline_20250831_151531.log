=== æµ‹è¯•å¼€å§‹æ—¶é—´: 2025å¹´ 8æœˆ31æ—¥ æ˜ŸæœŸæ—¥ 16æ—¶29åˆ†14ç§’ EDT ===
=== æ‰§è¡Œå‘½ä»¤: python3 ./ultra_parallel_runner.py --model qwen2.5-32b-instruct --prompt-types baseline --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 3 ===
INFO:__main__:åˆå§‹åŒ–å®ä¾‹æ± : 17ä¸ªå®ä¾‹ (2ä¸ªAzure + 6ä¸ªIdealLab)
INFO:__main__:ğŸ“œ ä½¿ç”¨ä¼ ç»Ÿæ•°æ®åº“å†™å…¥æ¨¡å¼
INFO:__main__:èµ„æºæ± çŠ¶æ€: 17ä¸ªå®ä¾‹, å®¹é‡1306
INFO:__main__:
ğŸ¯ æ£€æµ‹åˆ°Qwenæ¨¡å‹ï¼Œä½¿ç”¨é˜Ÿåˆ—è°ƒåº¦å™¨
INFO:__main__:   æ¨¡å‹: qwen2.5-32b-instruct â†’ Key1
INFO:__main__:   Promptç±»å‹: baseline
INFO:__main__:   éš¾åº¦: easy
INFO:__main__:ğŸ”„ Key1: æ‰§è¡Œ qwen2.5-32b-instruct-easy
INFO:__main__:ğŸ¯ ä½¿ç”¨qwenæ™ºèƒ½åˆ†ç‰‡ç­–ç•¥: qwen2.5-32b-instruct
INFO:__main__:ğŸ”„ çœŸæ­£å¤šKeyå¹¶å‘ç­–ç•¥:
INFO:__main__:   æ¨¡å‹: qwen2.5-32b-instruct (è§„æ¨¡: 32b)
INFO:__main__:   ä½¿ç”¨Keys: key0, key1, key2
INFO:__main__:   æ€»å®ä¾‹æ•°: 20
INFO:__main__:   åˆ†ç‰‡æ•°: 3 (æ¯ä¸ªkeyç‹¬ç«‹åˆ†ç‰‡)
INFO:__main__:   å®ä¾‹åˆ†é…: [7, 7, 6]
INFO:__main__:   ğŸš€ å¯ç”¨3å€APIå¹¶å‘ï¼
INFO:__main__:ğŸš€ å¯åŠ¨3ä¸ªåˆ†ç‰‡å¹¶å‘æ‰§è¡Œ
INFO:__main__:  IdealLab qwenæ¨¡å‹é™åˆ¶: qwen-key0 å¼ºåˆ¶ä½¿ç”¨ max_workers=1, qps=10
INFO:__main__:    æ³¨æ„: IdealLab APIå¹¶å‘é™åˆ¶ä¸¥æ ¼ï¼Œå¿½ç•¥--max-workersè®¾ç½®
INFO:__main__:  ä½¿ç”¨IdealLab API Key 0
INFO:__main__:ğŸš€ å¯åŠ¨åˆ†ç‰‡ qwen2.5-32b-instruct_easy_baseline_key0: qwen-key0
INFO:__main__:   å®ä¾‹æ•°: 7, æ¨¡å‹: qwen2.5-32b-instruct
INFO:__main__:   è®¾ç½®STORAGE_FORMAT=jsonç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®USE_PARTIAL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®TASK_LOAD_COUNT=20ç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®SKIP_MODEL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®USE_RESULT_COLLECTOR=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®KMP_DUPLICATE_LIB_OK=TRUEç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®PYTHONMALLOC=mallocç»™å­è¿›ç¨‹
INFO:__main__:   åˆ†ç‰‡1: qwen-key0 (7ä¸ªå®ä¾‹)
INFO:__main__:  IdealLab qwenæ¨¡å‹é™åˆ¶: qwen-key1 å¼ºåˆ¶ä½¿ç”¨ max_workers=1, qps=10
INFO:__main__:    æ³¨æ„: IdealLab APIå¹¶å‘é™åˆ¶ä¸¥æ ¼ï¼Œå¿½ç•¥--max-workersè®¾ç½®
INFO:__main__:  ä½¿ç”¨IdealLab API Key 1
INFO:__main__:ğŸš€ å¯åŠ¨åˆ†ç‰‡ qwen2.5-32b-instruct_easy_baseline_key1: qwen-key1
INFO:__main__:   å®ä¾‹æ•°: 7, æ¨¡å‹: qwen2.5-32b-instruct
INFO:__main__:   è®¾ç½®STORAGE_FORMAT=jsonç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®USE_PARTIAL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®TASK_LOAD_COUNT=20ç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®SKIP_MODEL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®USE_RESULT_COLLECTOR=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®KMP_DUPLICATE_LIB_OK=TRUEç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®PYTHONMALLOC=mallocç»™å­è¿›ç¨‹
INFO:__main__:   åˆ†ç‰‡2: qwen-key1 (7ä¸ªå®ä¾‹)
INFO:__main__:  ä½¿ç”¨IdealLab API Key 2
INFO:__main__:ğŸš€ å¯åŠ¨åˆ†ç‰‡ qwen2.5-32b-instruct_easy_baseline_key2: qwen-key2
INFO:__main__:   å®ä¾‹æ•°: 6, æ¨¡å‹: qwen2.5-32b-instruct
INFO:__main__:   è®¾ç½®STORAGE_FORMAT=jsonç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®USE_PARTIAL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®TASK_LOAD_COUNT=20ç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®SKIP_MODEL_LOADING=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®USE_RESULT_COLLECTOR=trueç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®KMP_DUPLICATE_LIB_OK=TRUEç»™å­è¿›ç¨‹
INFO:__main__:   è®¾ç½®PYTHONMALLOC=mallocç»™å­è¿›ç¨‹
INFO:__main__:   åˆ†ç‰‡3: qwen-key2 (6ä¸ªå®ä¾‹)
INFO:__main__:ç­‰å¾…åˆ†ç‰‡1å®Œæˆï¼ˆ20å®ä¾‹Ã—50workersï¼Œæœ€å¤šç­‰å¾…50åˆ†é’Ÿï¼‰...
2025-08-31 16:29:14,753 - faiss.loader - INFO - Loading faiss.
2025-08-31 16:29:14,753 - faiss.loader - INFO - Loading faiss.
2025-08-31 16:29:14,753 - faiss.loader - INFO - Loading faiss.
2025-08-31 16:29:14,779 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 16:29:14,779 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 16:29:14,779 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 16:29:15,589 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
2025-08-31 16:29:15,589 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
2025-08-31 16:29:15,589 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
2025-08-31 16:29:15,589 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
2025-08-31 16:29:15,589 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
2025-08-31 16:29:15,589 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
2025-08-31 16:29:15,589 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
2025-08-31 16:29:15,589 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
2025-08-31 16:29:15,589 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
2025-08-31 16:29:15,590 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
2025-08-31 16:29:15,590 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
2025-08-31 16:29:15,590 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
2025-08-31 16:29:15,590 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
2025-08-31 16:29:15,590 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
2025-08-31 16:29:15,590 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
2025-08-31 16:29:15,590 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
2025-08-31 16:29:15,590 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
2025-08-31 16:29:15,590 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
2025-08-31 16:29:15,591 - smart_result_collector - INFO - è‡ªåŠ¨ä¿å­˜çº¿ç¨‹å·²å¯åŠ¨
2025-08-31 16:29:15,591 - smart_result_collector - INFO - SmartResultCollectoråˆå§‹åŒ–å®Œæˆ
2025-08-31 16:29:15,591 - smart_result_collector - INFO -   - ä¸´æ—¶ç›®å½•: temp_results
2025-08-31 16:29:15,591 - smart_result_collector - INFO -   - å†…å­˜é˜ˆå€¼: 20
2025-08-31 16:29:15,591 - smart_result_collector - INFO -   - æ—¶é—´é˜ˆå€¼: 300ç§’
2025-08-31 16:29:15,591 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 16:29:15,591 - smart_result_collector - INFO -   - è‡ªåŠ¨ä¿å­˜: 60ç§’
2025-08-31 16:29:15,591 - smart_result_collector - INFO -   - è‡ªé€‚åº”é˜ˆå€¼: True
2025-08-31 16:29:15,591 - result_collector_adapter - INFO - âœ… ä½¿ç”¨SmartResultCollector
2025-08-31 16:29:15,591 - result_collector_adapter - INFO - AdaptiveResultCollectoråˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨: smart
2025-08-31 16:29:15,591 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 16:29:15,592 - smart_model_router - INFO - âœ¨ Using USER's Azure endpoint for gpt-5-nano
2025-08-31 16:29:15,643 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:29:15,643 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
2025-08-31 16:29:15,643 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:29:15,643 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
2025-08-31 16:29:15,643 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:29:15,643 - batch_test_runner - INFO - åŸºäºTXTæ–‡ä»¶çš„AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨ (ä½¿ç”¨gpt-5-nano)
2025-08-31 16:29:15,644 - batch_test_runner - INFO - ============================================================
2025-08-31 16:29:15,644 - batch_test_runner - INFO - ============================================================
2025-08-31 16:29:15,644 - batch_test_runner - INFO - ============================================================
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_162915.log
2025-08-31 16:29:15,644 - batch_test_runner - INFO - ============================================================
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_162915.log
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_162915.log
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Initializing test components...
2025-08-31 16:29:15,644 - batch_test_runner - INFO - ============================================================
2025-08-31 16:29:15,644 - batch_test_runner - INFO - ============================================================
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Initializing test components...
2025-08-31 16:29:15,644 - batch_test_runner - INFO - Initializing test components...
2025-08-31 16:29:16,131 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 16:29:16,132 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 16:29:16,132 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 16:29:16,133 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 16:29:16,134 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 16:29:16,135 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 16:29:16,135 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 16:29:16,136 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 16:29:16,136 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 16:29:16,136 - batch_test_runner - INFO - âš¡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 16:29:16,137 - batch_test_runner - INFO - âš¡ This saves ~350MB memory while keeping all functionality intact
2025-08-31 16:29:16,137 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 16:29:16,722 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:16,722 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:16,723 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:16,868 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:29:16,869 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:29:16,870 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:29:17,154 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:29:17,157 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:29:17,158 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:29:17,582 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 16:29:17,582 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 16:29:17,583 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 16:29:17,583 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 16:29:17,596 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 16:29:17,597 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 16:29:17,657 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:29:17,666 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:29:17,676 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 16:29:17,776 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:29:17,797 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:29:17,814 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 16:29:18,150 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 16:29:18,150 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:18,153 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 16:29:18,154 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:18,159 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 16:29:18,159 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:18,496 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:18,496 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:18,496 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:18,496 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:18,496 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:18,496 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:18,508 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 16:29:18,514 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:29:18,515 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:29:18,534 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 16:29:18,555 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:18,555 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:18,555 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:18,564 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:29:18,565 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:29:18,574 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 16:29:18,575 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 16:29:18,575 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 16:29:18,575 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 16:29:18,575 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 16:29:18,576 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 16:29:18,576 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 16:29:18,576 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 16:29:18,600 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 16:29:18,601 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:29:18,601 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 16:29:18,604 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 16:29:18,604 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 16:29:18,604 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 16:29:18,604 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 16:29:21,176 - unified_training_manager - INFO - Using device: cpu
2025-08-31 16:29:21,176 - unified_training_manager - INFO - Using device: cpu
2025-08-31 16:29:21,176 - unified_training_manager - INFO - Using device: cpu
2025-08-31 16:29:21,955 - unified_training_manager - INFO - Task filtering results:
2025-08-31 16:29:21,955 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 16:29:21,955 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 16:29:21,955 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 16:29:21,955 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 16:29:21,955 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 16:29:21,955 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 16:29:21,955 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 16:29:21,958 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 16:29:21,963 - unified_training_manager - INFO - Task filtering results:
2025-08-31 16:29:21,963 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 16:29:21,963 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 16:29:21,963 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 16:29:21,963 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 16:29:21,963 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 16:29:21,963 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 16:29:21,963 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 16:29:21,966 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 16:29:21,966 - batch_test_runner - INFO - âœ… MDPWorkflowGenerator initialized successfully:
2025-08-31 16:29:21,967 - batch_test_runner - INFO -   - task_manager: âœ“
2025-08-31 16:29:21,967 - batch_test_runner - INFO -   - output_verifier: âœ“
2025-08-31 16:29:21,967 - batch_test_runner - INFO -   - embedding_manager: âœ“
2025-08-31 16:29:21,967 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 16:29:21,967 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 16:29:21,969 - unified_training_manager - INFO - Task filtering results:
2025-08-31 16:29:21,970 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 16:29:21,970 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 16:29:21,970 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 16:29:21,970 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 16:29:21,970 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 16:29:21,970 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 16:29:21,970 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 16:29:21,970 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 16:29:21,974 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 16:29:21,976 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 16:29:21,976 - batch_test_runner - INFO - âœ… MDPWorkflowGenerator initialized successfully:
2025-08-31 16:29:21,976 - batch_test_runner - INFO -   - task_manager: âœ“
2025-08-31 16:29:21,976 - batch_test_runner - INFO -   - output_verifier: âœ“
2025-08-31 16:29:21,976 - batch_test_runner - INFO -   - embedding_manager: âœ“
2025-08-31 16:29:21,976 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 16:29:21,977 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 16:29:21,978 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 16:29:21,978 - batch_test_runner - INFO - âœ… MDPWorkflowGenerator initialized successfully:
2025-08-31 16:29:21,978 - batch_test_runner - INFO -   - task_manager: âœ“
2025-08-31 16:29:21,978 - batch_test_runner - INFO -   - output_verifier: âœ“
2025-08-31 16:29:21,978 - batch_test_runner - INFO -   - embedding_manager: âœ“
2025-08-31 16:29:21,978 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 16:29:21,978 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 16:29:21,995 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:29:21,995 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:29:21,996 - result_collector - INFO - ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
2025-08-31 16:29:21,996 - result_merger - INFO - ResultMergeråˆå§‹åŒ–å®Œæˆ
2025-08-31 16:29:21,996 - merger_lock - INFO - è·å¾—åˆå¹¶å™¨é” (PID: 43572)
2025-08-31 16:29:21,996 - result_merger - INFO - ğŸš€ å¯åŠ¨ResultMergerï¼Œåˆå¹¶é—´éš”: 10ç§’
2025-08-31 16:29:21,996 - result_collector - INFO - ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
2025-08-31 16:29:21,996 - result_merger - INFO - ResultMergeråˆå§‹åŒ–å®Œæˆ
2025-08-31 16:29:21,996 - result_merger - INFO - ResultMergerå¼€å§‹è¿è¡Œï¼Œæ™ºèƒ½åœæ­¢é˜ˆå€¼: 3è½®
2025-08-31 16:29:21,996 - result_merger - WARNING - å¦ä¸€ä¸ªåˆå¹¶å™¨å·²åœ¨è¿è¡Œ (PID: -1)
2025-08-31 16:29:21,996 - result_merger - INFO - âœ… ResultMergeråå°çº¿ç¨‹å·²å¯åŠ¨ï¼Œæ”¯æŒæ™ºèƒ½åœæ­¢æœºåˆ¶
2025-08-31 16:29:21,999 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:29:21,999 - result_collector - INFO - ResultCollectoråˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: temp_results
2025-08-31 16:29:21,999 - result_merger - INFO - ResultMergeråˆå§‹åŒ–å®Œæˆ
2025-08-31 16:29:22,000 - result_merger - WARNING - å¦ä¸€ä¸ªåˆå¹¶å™¨å·²åœ¨è¿è¡Œ (PID: -1)
2025-08-31 16:29:22,009 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 16:29:22,009 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 16:29:22,012 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 16:29:22,012 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 16:29:22,014 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 16:29:22,015 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 16:29:22,491 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 16:29:22,491 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 16:29:22,503 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 16:29:22,503 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 16:29:22,522 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 16:29:22,522 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 16:29:22,568 - batch_test_runner - INFO - Initialization complete
2025-08-31 16:29:22,580 - batch_test_runner - INFO - Initialization complete
2025-08-31 16:29:22,602 - batch_test_runner - INFO - Initialization complete
2025-08-31 16:29:22,726 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-31 16:29:22,727 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 16:29:22,727 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-31 16:29:22,728 - smart_model_router - INFO - Using idealab for qwen2.5-32b-instruct
2025-08-31 16:29:22,729 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-31 16:29:22,729 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 16:29:22,730 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-31 16:29:22,731 - smart_model_router - INFO - Using idealab for qwen2.5-32b-instruct
2025-08-31 16:29:22,736 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:22,736 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:22,737 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:22,738 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:22,739 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:22,739 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:22,739 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:22,740 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:22,749 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-31 16:29:22,749 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 16:29:22,750 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-31 16:29:22,751 - smart_model_router - INFO - Using idealab for qwen2.5-32b-instruct
2025-08-31 16:29:22,758 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:22,758 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:22,759 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:22,759 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:22,796 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:22,796 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:22,796 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:22,796 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:22,799 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:22,799 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:22,799 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:22,799 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:22,799 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:22,799 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:22,796 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:22,806 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:22,810 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:22,810 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:22,810 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:22,819 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:22,819 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:22,819 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:24,067 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:24,204 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:24,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:24,265 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:24,277 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:24,383 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:25,107 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:25,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:25,644 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:25,883 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:26,544 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:26,681 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:26,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:26,899 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:27,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:27,325 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:27,608 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:27,794 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:27,862 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:27,862 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:28,076 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:28,307 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:28,431 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:28,543 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:28,780 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,015 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,099 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,303 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,375 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,476 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,875 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,926 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:29,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:30,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:30,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:30,876 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:30,876 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:30,898 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:31,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:31,399 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:31,787 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:31,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,457 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,458 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,458 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,474 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,974 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,974 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:32,996 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:32,997 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:33,036 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:33,036 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:33,036 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:33,241 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:33,659 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:33,744 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:33,761 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:33,762 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:33,783 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:33,798 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:33,798 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:33,798 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:34,023 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:34,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:34,336 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:34,385 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:34,751 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:34,807 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:34,820 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:34,821 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:34,935 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:34,935 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:34,935 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:35,136 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:35,337 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:35,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:35,420 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:35,421 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:35,493 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:35,493 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:35,493 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:35,695 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:35,711 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:35,712 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:35,780 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:35,790 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:35,791 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:35,807 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:35,807 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:35,807 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:35,868 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:35,868 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:35,868 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:36,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:36,119 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:36,825 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:36,976 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼

============================================================
æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-32b-instruct (idealab)
Prompt types: ['baseline']
éš¾åº¦: easy
ç›®æ ‡: æ¯ç§é…ç½® 7 ä¸ªå®ä¾‹
============================================================
â—‹ simple_task         :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ basic_task          :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ data_pipeline       :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ api_integration     :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ multi_stage_pipeline:   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)

â³ éœ€è¦è¿è¡Œ 35 ä¸ªæ–°æµ‹è¯•

â–¶ å‡†å¤‡ simple_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ basic_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ data_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ api_integration (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ multi_stage_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å¼€å§‹æ‰§è¡Œ 35 ä¸ªæµ‹è¯•...
ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1254b62f0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] âš¡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[INFO] âš¡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[INFO] æ£€æµ‹åˆ°å¹¶å‘ç¯å¢ƒï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨æ¨¡å¼ï¼ˆResultCollectorï¼‰
[INFO] åå°åˆå¹¶è¿›ç¨‹å·²å¯åŠ¨ï¼ˆæ¯10ç§’åˆå¹¶ä¸€æ¬¡ï¼‰2025-08-31 16:29:37,018 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:37,169 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:37,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:37,738 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:37,852 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼

============================================================
æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-32b-instruct (idealab)
Prompt types: ['baseline']
éš¾åº¦: easy
ç›®æ ‡: æ¯ç§é…ç½® 7 ä¸ªå®ä¾‹
============================================================
â—‹ simple_task         :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ basic_task          :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ data_pipeline       :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ api_integration     :   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)
â—‹ multi_stage_pipeline:   0/  7 å·²å®Œæˆ (éœ€è¦è¡¥å…… 7 ä¸ª)

â³ éœ€è¦è¿è¡Œ 35 ä¸ªæ–°æµ‹è¯•

â–¶ å‡†å¤‡ simple_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ basic_task (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ data_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ api_integration (7 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ multi_stage_pipeline (7 ä¸ªå®ä¾‹)...

â–¶ å¼€å§‹æ‰§è¡Œ 35 ä¸ªæµ‹è¯•...
ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x106627400>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] âš¡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[INFO] âš¡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[INFO] æ£€æµ‹åˆ°å¹¶å‘ç¯å¢ƒï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨æ¨¡å¼ï¼ˆResultCollectorï¼‰
[INFO] åå°åˆå¹¶è¿›ç¨‹å·²å¯åŠ¨ï¼ˆæ¯10ç§’åˆå¹¶ä¸€æ¬¡ï¼‰2025-08-31 16:29:37,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:38,252 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼
[INFO] ä½¿ç”¨JSONå­˜å‚¨æ ¼å¼

============================================================
æ™ºèƒ½æ‰¹æµ‹è¯•: qwen2.5-32b-instruct (idealab)
Prompt types: ['baseline']
éš¾åº¦: easy
ç›®æ ‡: æ¯ç§é…ç½® 6 ä¸ªå®ä¾‹
============================================================
â—‹ simple_task         :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ basic_task          :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ data_pipeline       :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ api_integration     :   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)
â—‹ multi_stage_pipeline:   0/  6 å·²å®Œæˆ (éœ€è¦è¡¥å…… 6 ä¸ª)

â³ éœ€è¦è¿è¡Œ 30 ä¸ªæ–°æµ‹è¯•

â–¶ å‡†å¤‡ simple_task (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ basic_task (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ data_pipeline (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ api_integration (6 ä¸ªå®ä¾‹)...

â–¶ å‡†å¤‡ multi_stage_pipeline (6 ä¸ªå®ä¾‹)...

â–¶ å¼€å§‹æ‰§è¡Œ 30 ä¸ªæµ‹è¯•...
ğŸ“Š è‡ªé€‚åº”checkpoint_interval: 20
ğŸ“¦ æ‰¹é‡æäº¤æ¨¡å¼ï¼šæ¯20ä¸ªæµ‹è¯•ä¿å­˜ä¸€æ¬¡
âš ï¸  æ£€æµ‹åˆ°idealab APIï¼Œè°ƒæ•´å¹¶å‘: workers=2, qps=None
ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†
[AI_DEBUG] AIåˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1110ec140>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] âš¡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] âš¡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] âš¡ Memory optimization: Saving ~350MB by not loading model
[INFO] âš¡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[INFO] æ£€æµ‹åˆ°å¹¶å‘ç¯å¢ƒï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨æ¨¡å¼ï¼ˆResultCollectorï¼‰
[INFO] åå°åˆå¹¶è¿›ç¨‹å·²å¯åŠ¨ï¼ˆæ¯10ç§’åˆå¹¶ä¸€æ¬¡ï¼‰2025-08-31 16:29:38,305 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:38,566 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:38,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:38,639 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:38,740 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:38,743 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:38,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:39,267 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:39,342 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:39,532 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:39,789 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:39,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:39,944 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:40,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:40,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:40,461 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:40,632 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:40,837 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:40,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:41,214 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:41,227 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:41,257 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:41,365 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:41,895 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:41,895 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:41,947 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:42,057 - result_merger - INFO - ğŸ›‘ è¿ç»­3è½®æ— æ–°æ–‡ä»¶ï¼Œè‡ªåŠ¨åœæ­¢åˆå¹¶å™¨é˜²æ­¢hangä½
2025-08-31 16:29:42,057 - result_merger - INFO - ğŸ ResultMergeråˆå¹¶å¾ªç¯å·²ç»“æŸ
2025-08-31 16:29:42,291 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:42,411 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:42,495 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,031 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,055 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,078 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,457 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,458 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,528 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,541 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:43,541 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:43,572 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:43,572 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:43,572 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:43,814 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,820 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:43,983 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:44,390 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:44,410 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:44,430 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:44,431 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:44,471 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:44,471 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:44,471 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:44,511 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:44,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:44,891 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,353 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,366 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:45,366 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:45,395 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:45,395 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:45,395 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:45,555 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,556 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:45,846 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,984 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:45,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:46,082 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:46,121 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:46,122 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:46,154 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:46,154 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:46,154 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:46,325 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:46,638 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:46,668 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:46,738 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:47,144 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:47,165 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:47,165 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:47,171 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:47,202 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:47,202 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:47,202 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:47,240 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:47,252 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:29:47,252 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:29:47,287 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:29:47,287 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:29:47,287 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:29:47,434 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:47,661 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:48,364 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:48,413 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:48,464 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:48,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:48,825 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:49,004 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,066 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,444 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,752 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,752 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,868 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:49,883 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:50,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:50,303 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:50,501 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:50,697 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:50,800 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:51,054 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:51,058 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:51,325 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:51,691 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:51,710 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:51,847 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:52,070 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:52,165 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:52,202 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:52,373 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:52,374 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:52,636 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:52,649 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:29:52,715 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:52,719 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:52,897 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:52,992 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:53,129 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:53,239 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:53,600 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x117997980>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data structure validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24197
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24197
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data schema validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...2025-08-31 16:29:54,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x14c8bdac0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24223
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24223
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser2025-08-31 16:29:54,136 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:54,558 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:54,599 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:54,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x155e17000>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data structure validator

[TURN 2/10]
  [SEARCH] Query: data schema validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25215
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25215
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_validator2025-08-31 16:29:54,996 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:55,531 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:55,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:56,042 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:56,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:56,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:56,451 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:57,480 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:29:58,267 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:58,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:58,993 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:29:59,713 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:00,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:00,237 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:01,679 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:01,702 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:01,703 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:01,739 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:01,739 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:01,739 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:01,809 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:01,826 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:01,827 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:01,865 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:01,865 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:01,865 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:02,484 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:02,928 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:02,963 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:02,976 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:02,976 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:03,007 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:03,007 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:03,007 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:03,423 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:03,446 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:03,447 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:03,455 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:03,473 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:03,487 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:03,487 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:03,487 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:03,497 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:03,497 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:03,520 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:03,520 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:03,520 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:03,982 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:04,132 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:04,241 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:04,653 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:04,672 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:04,673 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:04,725 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:04,725 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:04,725 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:04,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:04,990 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:05,275 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:05,809 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:05,814 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:06,109 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:06,536 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:06,607 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:06,859 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:07,052 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:07,290 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:08,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:08,247 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:08,282 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:08,775 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:08,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:09,284 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:10,016 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 26841
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=26841
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25735
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25735
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data schema validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24226
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24226
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150458717566721925478186e7f2d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041de17566721929421272e342f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150423617566721938723074e0a54'}2025-08-31 16:30:10,518 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:10,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 26047
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=26047
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 23416
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23416
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: data schema validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 26565
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=26565
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150419d17566721925418093e2b42'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f817566721930475673e2671'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e043117566721939303995e20c2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150439017566721944311186e2757'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching2025-08-31 16:30:10,641 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:10,641 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:10,676 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:10,677 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:10,677 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:10,959 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:10,976 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct


[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25289
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25289
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24030
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24030
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25589
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25589
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150436a17566721921662849e22a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041a817566721926643688e34bd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.86
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430917566721934194110e1c42'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...2025-08-31 16:30:10,977 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:11,011 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:11,011 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:11,011 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:11,376 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:11,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:11,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:12,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:12,827 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:12,847 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:12,848 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:12,884 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:12,892 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:12,892 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:12,892 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:12,971 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:13,342 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:13,579 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:14,623 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:14,916 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:15,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:15,314 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:15,539 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:15,540 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:15,580 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:15,580 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:15,580 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:16,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:16,317 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:16,318 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:16,364 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:16,364 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:16,364 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:16,367 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:16,386 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:16,490 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:16,501 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:16,501 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:16,541 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:16,542 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:16,542 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:17,068 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:17,106 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:17,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:17,645 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:18,126 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:18,433 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:18,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:18,911 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:18,948 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:20,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:20,368 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:20,774 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:20,775 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:21,318 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:21,339 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:21,339 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:21,383 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:21,383 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:21,383 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:21,392 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:22,082 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:22,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:23,109 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:23,466 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:23,489 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:23,490 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:23,530 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:23,530 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:23,530 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:24,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:24,975 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:25,083 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:25,226 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:25,750 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:25,788 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:25,792 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:25,793 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:25,835 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:25,835 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:25,835 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:25,926 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:26,014 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:26,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:26,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:26,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e069217566721957727916e8193'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150436a17566721962782332e23f3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.84
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045a817566721994923987e80ba'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041de17566722000001243e363d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150439017566722015754484e27ba'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 15397
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15397
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f817566722023053180e2527'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215044eb17566722032934724e8099'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150413117566722038015380eec8b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150439017566722046743024e2548'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150429e17566722059263282e2107'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045af17566722064296845e7ebd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006e17566722080657370e12d5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150459f17566722086066605e822c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 17288
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17288
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150434117566722104515741e213a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-31 16:30:26,613 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:27,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:27,366 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:27,387 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:27,388 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:27,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:27,563 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:28,226 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:28,294 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:28,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:28,548 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006b17566721944147257eedd7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e060917566721957043989e6fea'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150409b17566721962091015e0809'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150419d17566721988172717e2be7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040ed17566721999113851ec052'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430917566722032338603e1eb7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 13490
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13490
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150439017566722039576790e2460'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150438d17566722044805825e2e27'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416417566722048164783e13a9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b717566722056365019e81b7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045c117566722063564365e81d9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415d17566722068586597e1316'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064617566722080962548e0d27'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b417566722086007440e8299'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064b17566722107822318e7b60'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)2025-08-31 16:30:28,633 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:29,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:29,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007d17566721943746134ef10a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.8
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062917566721953423850e80ec'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417717566721962081983edbc0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064d17566721980726237e8264'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041e117566721983912728e33d9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566722015031334eeeba'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22117
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22117
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data schema validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150436a17566722027753635e2477'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040ed17566722032898364ebee7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150436a17566722040643636e2477'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f917566722051052031e1a4e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040be17566722056418296edefd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150449a17566722066797135e80d7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065c17566722071035797e832b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 15361
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15361
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042ae17566722098283956e92cf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 16:30:29,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:29,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:29,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:29,659 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:29,852 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:30,151 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:30,644 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:30,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:30,659 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:30,701 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:31,169 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:31,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:31,694 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:31,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:32,218 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:32,218 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:32,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:32,484 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:32,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:33,078 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:33,176 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:33,266 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:33,512 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:33,552 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:33,699 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:33,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:34,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:34,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:34,212 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:34,316 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:34,536 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:34,695 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:34,712 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:34,713 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:34,746 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:34,746 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:34,746 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:34,855 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:35,135 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:35,147 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:35,161 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:35,162 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:35,217 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:35,217 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:35,217 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:35,460 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:35,480 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:35,480 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:35,540 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:35,540 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:35,540 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:35,677 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:35,693 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:35,694 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:35,744 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:35,745 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:35,745 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:35,888 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:36,119 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:36,427 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:36,631 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:36,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:36,800 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:36,801 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:36,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:36,833 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:36,833 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:36,833 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:36,956 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:37,109 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:37,127 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:37,127 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:37,168 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:37,168 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:37,168 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:37,311 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:37,462 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:37,682 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:37,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:38,010 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:38,327 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:38,371 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:38,383 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:38,720 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:38,801 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:39,802 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:39,839 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:40,083 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:40,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:40,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:40,384 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:40,457 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:40,630 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,142 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,217 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,276 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,293 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,656 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:41,760 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:42,078 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:42,184 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:42,194 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:42,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:42,559 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:42,704 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:42,704 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:42,994 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:43,049 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:43,236 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:43,462 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:43,753 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:43,753 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:43,943 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:44,098 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:44,276 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:44,566 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:44,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:44,801 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,136 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,616 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:45,643 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,660 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:45,661 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:45,670 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,695 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:45,698 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:45,698 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:45,698 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:46,119 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:46,166 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:46,186 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007917566722112848318eea24'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.6s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c117566722120201753e87fa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 17773
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17773
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150458117566722130717332e8071'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215044eb17566722146945045e81c2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006017566722162138276edfe3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f817566722169667857e2528'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b417566722182585791e804c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059d17566722187783686e3454'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3182
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3182
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045a817566722211855997e7ff4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06b617566722232801901e8148'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file operations reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3475
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3475
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]2025-08-31 16:30:46,187 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:46,193 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062017566722111857847e80d2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150414417566722116246865edb51'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041a817566722127915864e3310'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3455
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3455
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e04ea17566722151323020e3676'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417517566722161164407ee123'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059717566722168803403e34e8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065017566722179463886e813c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150436a17566722187366950e21c2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150411817566722205836995e0d19'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e041717566722211258878e989e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c117566722218965317e87f9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c217566722222805820e83bc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3486
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3486
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: file operations reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer2025-08-31 16:30:46,209 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:46,210 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:46,227 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:46,228 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:46,228 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:46,260 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:46,260 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:46,260 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:46,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:46,690 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:46,705 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:46,706 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:46,763 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:46,764 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:46,764 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:46,775 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:47,184 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:47,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:47,281 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:47,423 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:47,423 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:47,543 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:47,677 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:47,697 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:47,698 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:47,744 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:47,745 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:47,745 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f917566722103478211e1ca1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150459f17566722126416309e80e2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007617566722133736360e12ae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06a117566722144404461e8b9f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 11437
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11437
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150419d17566722162126561e2c8d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059617566722168844450e3ebe'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062917566722174747276e8191'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150439017566722185671385e25aa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06ba17566722200893056e8871'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059617566722205937427e3bc7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.52
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3384
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3384
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file operations reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected2025-08-31 16:30:48,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:48,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:48,471 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:48,486 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:30:48,486 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:30:48,517 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:30:48,517 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:30:48,517 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:30:48,559 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:48,995 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:49,026 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:49,395 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:49,559 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:49,859 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:49,876 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,045 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,252 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,290 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,386 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,669 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,736 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:50,912 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:51,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:51,876 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:51,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:52,143 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:52,337 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:52,508 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:52,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:52,834 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:53,098 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:53,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:53,190 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:53,191 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:53,515 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:53,544 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:53,713 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:54,240 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:54,240 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:54,242 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:54,548 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:54,607 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:54,630 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:55,120 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:55,145 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:55,287 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:55,374 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:55,529 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:55,720 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:55,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:56,216 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:56,232 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:30:56,243 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:56,750 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:57,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:57,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:57,154 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:57,543 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:57,549 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:57,609 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:57,728 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:58,264 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:58,614 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:30:58,806 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:59,307 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:30:59,546 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:00,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:00,042 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:00,359 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:00,546 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:01,871 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:02,490 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:02,753 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:02,771 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:02,771 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:02,797 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:02,797 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:02,797 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:02,800 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:02,980 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:03,262 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=other_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3476
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3476
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22905
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22905
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 16:31:04,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:04,551 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:04,552 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3480
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3480
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 8 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file operations reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22381
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22381
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
Progress: 10/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22379
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22379
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-31 16:31:04,571 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:04,572 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:04,609 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:04,610 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:04,610 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:04,726 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:04,730 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:04,746 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct


[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: file_operations_reader

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3481
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3481
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 7 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22138
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22138
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.86
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24167
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24167
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully2025-08-31 16:31:04,746 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:04,783 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:04,783 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:04,783 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:04,895 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:05,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:05,414 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:06,091 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:06,872 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:06,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:07,435 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:07,455 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:07,456 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:07,493 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:07,493 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:07,493 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:07,503 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:07,516 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:07,517 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:07,574 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:07,574 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:07,574 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:08,201 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:08,219 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:08,293 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:08,316 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:08,317 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:08,372 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:08,372 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:08,372 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:08,790 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:08,802 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:08,973 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:09,041 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:09,241 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:09,506 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:09,968 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:10,492 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:11,015 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:11,066 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:11,552 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:11,612 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:11,784 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:11,882 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:12,109 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:12,261 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:13,448 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:13,464 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:13,464 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:13,502 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:13,503 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:13,503 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:14,062 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:14,162 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:14,778 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:14,844 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:15,210 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:15,228 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:15,229 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:15,266 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:15,267 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:15,267 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:15,348 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:15,378 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:15,735 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:15,750 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:15,750 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:15,787 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:15,787 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:15,787 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:15,899 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:16,439 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:17,127 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:17,512 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:18,356 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:18,356 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22418
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22418
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064717566722550737164e8a62'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006a17566722555678898ee04b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007617566722568621779e13f8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25075
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25075
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e004f17566722573681202ee5f4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415b17566722593723182ee329'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e081017566722598633753e0a47'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150429e17566722623066494e2231'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566722628074459eec3c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150456617566722643743498e8034'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»2025-08-31 16:31:18,702 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:18,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 20181
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20181
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22480
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22480
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007517566722549691047ef016'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e060c17566722560575624e8aad'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e041917566722565633602e2b96'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059d17566722575498445e33f1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e01f617566722580696476e13ff'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24408
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24408
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e057b17566722597997693e3e8f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e011517566722603001495e947f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215044da17566722625757741e8294'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e001317566722630744654e0da0'}2025-08-31 16:31:18,721 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct

[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22368
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22368
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e066317566722555478485e80fe'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006717566722560421316ee030'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e066e17566722568998443e8059'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22501
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22501
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e03e217566722574216529e1e32'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e066c17566722586236236e79d2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007e17566722591221338eec83'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042f17566722601756557e236c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041a817566722626287212e33f7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430917566722645141915e1fbe'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 6 format helps, final result: failure
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 19456
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19456
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct2025-08-31 16:31:18,722 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:18,758 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:18,758 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:18,758 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:19,439 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:19,455 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:19,459 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:19,459 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:19,509 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:19,509 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:19,509 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:19,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:19,749 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:19,951 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:19,953 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:20,017 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:20,017 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:20,017 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:20,148 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:20,454 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:20,791 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:21,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:21,839 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:21,849 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:22,267 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:22,283 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:22,284 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:22,318 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:22,319 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:22,319 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:22,369 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:22,930 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:23,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:23,412 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:23,930 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:24,237 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:24,473 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:24,670 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:24,983 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:25,223 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:25,347 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:25,696 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:25,948 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:26,220 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:26,472 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:26,961 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:27,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:27,270 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:27,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:27,424 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,050 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,317 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,317 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,459 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,712 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,847 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:28,902 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:29,093 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:29,143 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:29,368 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:29,667 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:29,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:30,269 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:30,269 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:30,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:30,619 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:30,817 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:30,938 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:31,108 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:31,159 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:31,260 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:31,576 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:31,680 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:31,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,087 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,269 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:32,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,351 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,530 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,807 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,813 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:32,836 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:32,836 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:32,883 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:32,883 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:32,883 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:32,921 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:33,039 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:33,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:33,594 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:33,760 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:33,928 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:33,964 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:34,119 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:34,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:34,185 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:34,609 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:34,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,134 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,137 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,162 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:35,163 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:35,197 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,214 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 20423
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20423
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150454417566722647116037e8372'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430c17566722659226518e2185'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566722681108991eed6a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e011517566722686204842e9503'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415d17566722693376770e1417'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006f17566722702722520ee47a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566722707784600eef33'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e011517566722716911503e947f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 20635
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20635
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e03e217566722732691816e1d8d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f817566722739332624e2506'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e011517566722746684908e926f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150411617566722751727871ee766'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042f17566722769377437e232a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 11112
[AI_DEBUG] _ai_classify_with_txt_content called:2025-08-31 16:31:35,214 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:35,214 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:35,214 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:35,215 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:35,246 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:35,246 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:35,246 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:35,462 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,510 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,780 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:35,803 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:36,428 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:36,474 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:36,706 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:36,706 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:36,751 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:36,762 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:36,763 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:36,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:36,842 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:36,842 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:36,842 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:36,933 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:37,284 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:37,574 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:37,977 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:38,279 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:38,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:38,423 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 18458
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18458
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042f17566722651038645e22a6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040b917566722666833391ef075'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416417566722672434113e1091'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b017566722680246472e83ac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415c17566722685452319eec30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.9s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 18381
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18381
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150457a17566722690704004e0ce8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042f17566722715957432e232a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040ed17566722720797677ebdbf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c317566722745975542e7bdd'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.84
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417517566722755267426eddea'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3370
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3370
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e03e217566722762666121e1c64'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065a17566722781031791e841e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...2025-08-31 16:31:38,439 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:38,439 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:38,467 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:38,467 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:38,467 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:38,496 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:38,956 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:39,070 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:39,414 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:39,600 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150435d17566722652345839e2213'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150439017566722668095521e2736'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417517566722673234099edde9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150457a17566722680502811e0d6c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e00cd17566722687935515e94e4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c217566722697557330e816b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150409517566722708953853eea13'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14144
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14144
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417717566722714407879edab4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430c17566722738818049e1eb1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065a17566722749695177e8272'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e001317566722756962211e0b4f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006917566722773041607edf6e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3370
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3370
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c317566722785095288e79ee'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct2025-08-31 16:31:39,688 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:39,707 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:39,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:39,963 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:40,053 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:40,164 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:40,237 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:40,282 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:40,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:40,602 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:41,122 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:41,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:41,609 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:41,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:41,762 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:41,784 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:41,785 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:41,826 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:41,826 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:41,826 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:42,237 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:42,277 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:42,473 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:42,590 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:42,998 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:42,998 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:43,074 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:43,156 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:43,367 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:43,394 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:43,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:43,895 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:44,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:44,098 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:44,310 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:44,429 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:44,660 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:44,976 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:45,320 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:45,339 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:45,359 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:45,360 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:45,445 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:45,445 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:45,445 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:45,618 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:45,618 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:45,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:45,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:46,034 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:46,315 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:46,333 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:46,334 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:46,368 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:46,368 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:46,368 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:46,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:46,824 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:46,827 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:46,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:46,925 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:47,224 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:47,247 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:47,247 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:47,287 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:47,287 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:47,287 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:47,573 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:47,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:47,797 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:47,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:48,241 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:48,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:48,541 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:48,577 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:48,627 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:48,764 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:48,831 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:49,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:49,079 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:49,079 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309078163.json
2025-08-31 16:31:49,081 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309080121.json
2025-08-31 16:31:49,082 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309081295.json
2025-08-31 16:31:49,083 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309082656.json
2025-08-31 16:31:49,085 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309084213.json
2025-08-31 16:31:49,085 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309085307.json
2025-08-31 16:31:49,086 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309086185.json
2025-08-31 16:31:49,087 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309087121.json
2025-08-31 16:31:49,088 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309088076.json
2025-08-31 16:31:49,090 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309088942.json
2025-08-31 16:31:49,091 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309090855.json
2025-08-31 16:31:49,092 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309091629.json
2025-08-31 16:31:49,092 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309092287.json
2025-08-31 16:31:49,093 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309092741.json
2025-08-31 16:31:49,093 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309093165.json
2025-08-31 16:31:49,094 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309093750.json
2025-08-31 16:31:49,094 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309094186.json
2025-08-31 16:31:49,095 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309094557.json
2025-08-31 16:31:49,095 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309095362.json
2025-08-31 16:31:49,096 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672309095907.json
2025-08-31 16:31:49,289 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:49,301 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:49,301 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:49,330 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:49,330 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:49,330 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:49,608 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11112
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007e17566722793676566eef38'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059d17566722806118877e3455'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e04ea17566722816564904e335f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06b717566722820863118e7a4b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e041717566722828161642e9711'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042f17566722832376601e236c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c217566722842782293e8022'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=other_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3330
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3330
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3329
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3329
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct2025-08-31 16:31:49,674 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:49,884 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:50,198 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:50,217 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:50,217 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:50,273 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:50,273 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:50,273 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:31:50,347 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:50,489 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:50,744 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:50,918 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:51,097 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:51,387 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:51,465 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:51,511 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:51,774 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:51,818 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:52,168 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:52,239 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:52,245 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312243947.json
2025-08-31 16:31:52,247 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312245370.json
2025-08-31 16:31:52,248 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312247301.json
2025-08-31 16:31:52,249 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312248624.json
2025-08-31 16:31:52,249 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312249246.json
2025-08-31 16:31:52,250 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312249795.json
2025-08-31 16:31:52,250 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312250445.json
2025-08-31 16:31:52,251 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312251067.json
2025-08-31 16:31:52,251 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312251619.json
2025-08-31 16:31:52,252 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312252054.json
2025-08-31 16:31:52,252 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312252503.json
2025-08-31 16:31:52,253 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312253005.json
2025-08-31 16:31:52,253 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312253455.json
2025-08-31 16:31:52,254 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312253900.json
2025-08-31 16:31:52,254 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312254328.json
2025-08-31 16:31:52,255 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312254785.json
2025-08-31 16:31:52,255 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312255192.json
2025-08-31 16:31:52,256 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312255693.json
2025-08-31 16:31:52,256 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312256140.json
2025-08-31 16:31:52,257 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672312256528.json
2025-08-31 16:31:52,276 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:52,685 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:53,084 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:53,097 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:53,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:53,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:53,749 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:54,009 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:54,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:54,051 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:31:54,051 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:31:54,091 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:31:54,092 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:31:54,092 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06ba17566722792622078e8c2e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007f17566722795595373eebd1'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006817566722810074207ee4dc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007d17566722821785764ef33b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064e17566722827385698e80fc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06a217566722837483503e8113'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.8s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3364
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3364
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.62
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24898
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24898
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007d17566722965934138eefc0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215044eb17566722971055100e8078'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns2025-08-31 16:31:54,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:54,402 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:54,582 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:54,604 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:55,056 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:55,185 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:55,276 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:55,328 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065517566722792422442e82e5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06b617566722799685746e8171'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c817566722802396982e813c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064d17566722816546323e8264'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007c17566722850481039eef4b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=sequence_order_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3370
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3370
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215044fd17566722927427252e7f05'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25049
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25049
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns2025-08-31 16:31:55,331 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:55,372 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:55,580 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:55,644 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:55,768 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:56,106 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:56,231 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:56,252 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:31:56,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:56,734 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:56,832 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:57,154 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:57,158 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317157107.json
2025-08-31 16:31:57,159 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317159028.json
2025-08-31 16:31:57,162 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317159946.json
2025-08-31 16:31:57,164 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317162727.json
2025-08-31 16:31:57,164 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317164157.json
2025-08-31 16:31:57,165 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317164873.json
2025-08-31 16:31:57,166 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317165605.json
2025-08-31 16:31:57,167 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317166720.json
2025-08-31 16:31:57,168 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317167584.json
2025-08-31 16:31:57,168 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317168269.json
2025-08-31 16:31:57,169 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317168791.json
2025-08-31 16:31:57,169 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317169298.json
2025-08-31 16:31:57,170 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317169824.json
2025-08-31 16:31:57,170 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317170368.json
2025-08-31 16:31:57,171 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317170880.json
2025-08-31 16:31:57,171 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317171401.json
2025-08-31 16:31:57,172 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317171909.json
2025-08-31 16:31:57,173 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317172331.json
2025-08-31 16:31:57,173 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317173265.json
2025-08-31 16:31:57,174 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672317173692.json
2025-08-31 16:31:57,280 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:57,308 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:57,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:57,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:58,390 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:58,546 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:59,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:59,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:31:59,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:31:59,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:00,204 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:00,627 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:00,860 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:01,389 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:02,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:02,403 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:02,480 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:02,814 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:03,785 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:04,210 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:04,244 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:04,245 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:04,300 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:04,300 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:04,300 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:04,380 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:04,398 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:04,399 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:04,436 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:04,436 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:04,436 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:05,037 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:05,062 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:05,063 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:05,105 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:05,113 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:05,113 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:05,113 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:05,418 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:05,742 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:05,762 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:05,762 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:05,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:05,861 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:05,861 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:05,861 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:06,253 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:06,254 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:06,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:06,964 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:07,158 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:07,171 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:07,171 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:07,197 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:07,198 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:07,198 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:07,346 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25054
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25054
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150456617566723009618460e815e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25150
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25150
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.84
ğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜20ä¸ªç»“æœ...
   è§¦å‘åŸå› : æ•°é‡=20, æ—¶é—´=0.0s, å¼ºåˆ¶=False
âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ 20/20 ä¸ªç»“æœ
Progress: 20/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24796
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24796
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct2025-08-31 16:32:07,370 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:07,371 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:07,428 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:07,428 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:07,428 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:07,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:07,877 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:07,880 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:08,370 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:08,566 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:09,030 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:09,101 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e001317566722998751922e0a8a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150457a17566723003734056e0ce8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25170
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25170
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25055
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25055
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150409517566723150976358eec02'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]2025-08-31 16:32:09,544 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"


[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e081017566723000901579e0bef'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24832
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24832
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25018
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25018
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b417566723086455703e810d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416717566723097056899eee36'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415c17566723116364179eecd5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
ğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜20ä¸ªç»“æœ...
   è§¦å‘åŸå› : æ•°é‡=20, æ—¶é—´=0.0s, å¼ºåˆ¶=False
âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ 20/20 ä¸ªç»“æœ
Progress: 20/35 (Success: 0)
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24974
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24974
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-31 16:32:09,834 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:10,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:10,788 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:11,310 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:11,833 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:11,834 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:11,834 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:12,694 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:13,406 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:13,453 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:13,471 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:13,472 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:13,501 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:13,501 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:13,501 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:13,930 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:13,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:14,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:14,683 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:14,838 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:15,702 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:15,746 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:15,746 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:15,793 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:15,793 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:15,793 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:16,408 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:16,422 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:16,692 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:16,709 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:16,710 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:16,742 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:16,742 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:16,742 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:16,898 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:16,910 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:16,910 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:16,974 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:16,974 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:16,974 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:17,431 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:17,639 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:17,791 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:18,283 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:18,305 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:18,305 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:18,346 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:18,346 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:18,346 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:18,472 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:18,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:18,978 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:18,978 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:19,018 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:19,018 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:19,018 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:19,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:19,300 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:19,328 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:19,897 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:20,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:20,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:20,224 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:20,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:21,024 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:21,596 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25063
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25063
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f817566723153575317e2738'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040be17566723158453432ede16'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150421317566723166485872e36b2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040ed17566723171288652ebf4b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045be17566723183638612e8092'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007d17566723188831493ef0c8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e05ab17566723212155474e3427'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006d17566723223048548e1172'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e057b17566723242038543e3e2c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22983
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22983
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065117566723249216462e8277'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007217566723260728064eed30'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042b17566723271591115e1d3f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure2025-08-31 16:32:21,612 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:22,085 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:22,518 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:22,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:23,172 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:23,221 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:24,768 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:25,278 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:25,373 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:25,464 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:25,560 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:25,820 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:26,116 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:26,683 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:26,780 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:27,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:27,143 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:27,173 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:27,586 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:27,599 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:28,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:28,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:28,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150423617566723155847300e0c0a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e043a17566723161153986e1d55'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
ğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜20ä¸ªç»“æœ...
   è§¦å‘åŸå› : æ•°é‡=20, æ—¶é—´=0.0s, å¼ºåˆ¶=False
âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ 20/20 ä¸ªç»“æœ
Progress: 20/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25136
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25136
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040b917566723171024761eefb0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416317566723177065303e1595'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e063717566723194106921e894e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062b17566723204595538e80b9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007a17566723220775891ee549'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006717566723240387670edfee'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 21274
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21274
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062917566723255493957e80ec'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e080f17566723260532655e0af4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006e17566723267844626e15d4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042f17566723276985399e2495'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e041917566723281948261e2c3b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430c17566723289146742e1f14'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 16:32:28,159 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007b17566723160417822eecac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150456617566723165428481e815e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415d17566723176414139e10eb'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150414417566723181481900eddca'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06ba17566723200207765e8a1e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06ba17566723206817973e8872'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006b17566723226237370eeb85'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006d17566723236122244e1238'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007e17566723248545402eedee'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14661
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14661
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e001317566723255834626e0c35'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.5s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007c17566723264601320ef284'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042d17566723269783437e2024'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150455217566723276997647e7f9b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416717566723288452491eedf4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042ae17566723293624648e93d6'}2025-08-31 16:32:28,162 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:28,403 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:28,627 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:28,628 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:29,135 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:29,659 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:29,812 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,035 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,275 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,320 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,765 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:30,783 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,791 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:30,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:31,233 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:31,234 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:31,423 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:31,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,092 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,150 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,283 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,358 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,819 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,988 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:32,993 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:33,101 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:33,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:33,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:33,357 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:33,703 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:33,889 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:34,203 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:34,266 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:34,378 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:34,407 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:34,554 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:34,904 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:35,004 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:35,032 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:35,033 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:35,075 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:35,075 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:35,075 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:35,296 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:35,427 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:35,512 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:35,951 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:35,953 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:35,960 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:36,277 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:36,493 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:36,502 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:36,502 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:36,526 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:36,526 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:36,526 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:36,532 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:36,701 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:36,713 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:36,714 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:36,743 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:36,744 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:36,744 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:37,002 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:37,004 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:37,639 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:37,698 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:37,708 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:37,709 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:37,745 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:37,745 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:37,745 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:37,779 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:37,843 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:37,862 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:37,862 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:37,903 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:37,903 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:37,903 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:38,048 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:38,096 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:38,438 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:38,869 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:38,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:39,097 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:39,255 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:39,279 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:39,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:39,864 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:39,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:40,352 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:40,369 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:40,369 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:40,369 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:40,409 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:40,409 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:40,409 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:40,493 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:40,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:40,927 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:41,264 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:41,463 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:41,531 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:41,719 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:41,876 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:41,956 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:42,339 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:42,490 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:42,600 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:42,897 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415c17566723276621075eee62'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059617566723283893164e3ba6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042d17566723298891636e235e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566723306123427eeda8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c017566723315754695e815b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.6s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150411617566723332758044eeb01'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417d17566723337811153e118d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.9s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150434117566723345096641e1e41'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14950
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14950
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042d17566723362247876e23c0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e063817566723382874000e830c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045c117566723397225039e804c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150409517566723399934654eeb1b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.6s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3176
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3176
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b817566723414192974e825d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 16:32:43,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:43,059 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:43,155 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:43,372 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:43,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:43,965 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:43,973 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:44,036 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:44,050 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:44,169 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:44,175 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:44,441 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:44,656 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:44,907 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,087 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,109 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,460 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,608 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,913 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:45,940 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:45,941 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:46,057 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:46,063 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:46,078 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:46,078 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:46,078 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:46,325 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e057b17566723296498048e3fb9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.2s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14721
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14721
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150435d17566723325084941e2067'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042ae17566723332206437e9394'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e060917566723355074178e6fea'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040cc17566723362436432ed6ac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150429e17566723365092925e214a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e03e217566723372405816e1eb7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e081017566723376113388e0c36'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417717566723385831297edc44'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c317566723391443349e7af6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150457a17566723398502886e0d6c'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3213
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3213
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150409517566723424843804eeca8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150448717566723429925121e7df7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.0s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006b17566723456371528eecf0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]2025-08-31 16:32:46,492 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:46,493 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150452b17566723310914724e778a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e042b17566723315872493e1cdc'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e004f17566723336686546ee8a8'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.0s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14239
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14239
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065517566723367151094e8132'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150415c17566723374598111eef27'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150456117566723380982850e7f5f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045be17566723388345205e8116'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059d17566723391158319e359e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566723401406856eec7f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150411817566723414206569e0a34'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3145
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3145
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416417566723423361728e104e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150438d17566723451032270e2b0e'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150413117566723479818728eec6a'}2025-08-31 16:32:46,976 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:47,112 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:47,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:47,489 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:47,574 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:47,587 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:47,588 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:47,588 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:47,618 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:47,618 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:47,618 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:48,011 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:48,205 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:48,233 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:48,540 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:48,894 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,060 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,063 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,084 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:49,085 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:49,132 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:49,132 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:49,132 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:49,247 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,419 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,436 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:49,437 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:49,472 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:49,472 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:49,472 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:49,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,828 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:49,931 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:50,107 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:50,307 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:50,417 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:50,483 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:50,631 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:50,632 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:50,646 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:50,647 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:50,679 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:50,685 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:50,685 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:50,685 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:51,318 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:51,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:51,826 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,036 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,106 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,598 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,729 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,729 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,973 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:52,996 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:53,254 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:53,560 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:53,607 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:53,917 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:54,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:54,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:54,522 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:54,548 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:55,000 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:55,031 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:55,035 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:55,094 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:55,555 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:55,643 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:55,880 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:56,114 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:56,220 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:56,398 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:56,416 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:32:56,417 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:32:56,457 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:32:56,457 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:32:56,457 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:32:56,508 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:56,525 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:56,592 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:56,646 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:56,669 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:57,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:57,115 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:57,338 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:57,486 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:32:57,824 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b817566723430421119e8176'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [INFO] Tool info request: network_fetcher

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3170
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3170
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150435d17566723479814662e1fc2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25061
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25061
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25048
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25048
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]2025-08-31 16:32:58,108 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:58,310 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:58,640 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:58,678 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:59,616 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:32:59,624 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:32:59,715 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:00,406 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:00,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:01,158 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:01,207 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:01,356 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:01,972 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:02,535 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:03,373 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:03,760 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:04,145 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:04,839 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:06,039 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:06,068 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:33:06,068 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:33:06,107 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:33:06,107 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:33:06,107 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:33:06,445 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.8s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045f517566723484551509e815a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3161
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3161
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065417566723543753457e7efa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24845
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24845
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 23938
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23938
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct2025-08-31 16:33:06,469 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:33:06,469 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:33:06,506 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:33:06,507 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:33:06,507 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:33:07,238 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:07,289 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:07,625 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:08,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:08,039 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:33:08,040 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:33:08,071 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:33:08,071 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:33:08,071 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:33:08,543 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:09,048 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:09,070 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:33:09,071 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:33:09,107 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:33:09,107 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:33:09,107 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:33:09,311 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:09,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:10,078 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:10,115 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:10,686 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:10,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:12,178 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:12,488 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:12,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:12,668 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.88
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24952
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24952
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.79
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25224
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25224
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 22779
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22779
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150430c17566723771397281e1fd9'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007317566723776454333ee49f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 16:33:12,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:13,260 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:13,700 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:14,269 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:14,864 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:15,545 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:15,549 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395547701.json
2025-08-31 16:33:15,550 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395549994.json
2025-08-31 16:33:15,552 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395550739.json
2025-08-31 16:33:15,553 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395552759.json
2025-08-31 16:33:15,554 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395554030.json
2025-08-31 16:33:15,555 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395554873.json
2025-08-31 16:33:15,555 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395555388.json
2025-08-31 16:33:15,555 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395555713.json
2025-08-31 16:33:15,556 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395555933.json
2025-08-31 16:33:15,556 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395556148.json
2025-08-31 16:33:15,556 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-32b-instruct:30)
2025-08-31 16:33:15,558 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 30 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43573_1756672395556802.json
2025-08-31 16:33:15,558 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-32b-instruct:30)
2025-08-31 16:33:15,624 - batch_test_runner - INFO - Database saved successfully
2025-08-31 16:33:15,624 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 16:33:15,624 - batch_test_runner - INFO - ============================================================
2025-08-31 16:33:15,624 - batch_test_runner - INFO - Batch test completed at 2025-08-31T16:33:15.624808
2025-08-31 16:33:15,624 - batch_test_runner - INFO - Summary:
2025-08-31 16:33:15,624 - batch_test_runner - INFO -   - Total tests: 30
2025-08-31 16:33:15,624 - batch_test_runner - INFO -   - Successful: 0
2025-08-31 16:33:15,624 - batch_test_runner - INFO -   - Failed: 30
2025-08-31 16:33:15,624 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-31 16:33:15,625 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_162915.log
2025-08-31 16:33:15,625 - batch_test_runner - INFO - ============================================================
2025-08-31 16:33:15,625 - batch_test_runner - INFO - ğŸ§¹ æ­£åœ¨æ¸…ç†å­˜å‚¨é€‚é…å™¨èµ„æº...
2025-08-31 16:33:15,625 - result_merger - INFO - åˆå¹¶çº¿ç¨‹å·²ç»åœæ­¢ï¼Œæ— éœ€é‡å¤æ“ä½œ
2025-08-31 16:33:15,626 - result_merger - INFO - å‘ç°71ä¸ªæ–°çš„ç»“æœæ–‡ä»¶
2025-08-31 16:33:15,667 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:33:15,667 - result_merger - INFO - [MERGER_PROTECTION] ä½¿ç”¨managerå†…ç½®çš„å®‰å…¨åˆå¹¶æœºåˆ¶
2025-08-31 16:33:17,371 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:17,408 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:33:17,409 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:33:17,446 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:33:17,446 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:33:17,446 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:33:17,740 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:18,072 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:18,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"

[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150411617566723669335545ee78a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25275
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25275
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.86
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25012
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25012
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e03e217566723764188987e1e74'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007f17566723769192881eeb4d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417917566723779266501eeb98'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06b717566723784308923e78bf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.2s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065e17566723795144163e7f2f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040be17566723809826767ee1b4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.6s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150417d17566723817926164e13eb'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.1s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06b617566723839712473e82d3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064717566723862604094e8bac'}2025-08-31 16:33:18,582 - api_client_manager - INFO - Created idealab client for model qwen2.5-32b-instruct
2025-08-31 16:33:18,583 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 16:33:18,647 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 16:33:18,647 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 16:33:18,647 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 16:33:19,274 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:19,287 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:19,552 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:20,242 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:20,853 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:21,041 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:21,273 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:22,086 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:22,797 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-31 16:33:24,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:24,200 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the task (required tools coverage = 0%). This indicates a failure at the tool selection step, i.e., the 
2025-08-31 16:33:25,650 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:26,903 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:26,944 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:27,388 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:28,246 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:28,906 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:29,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:29,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:30,479 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:30,592 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:30,592 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong tool choice, misconfiguration, or incorrect sequence. The error is reported as Unknown error with no tool usage or dependency detail

[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=timeout_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 12218
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12218
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.75
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065517566723557493598e7fa4'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065517566723567763823e80ae'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 25008
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=25008
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064d17566723610834589e81e0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
  [SEARCH] Query: file reader writer

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24634
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24634
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]2025-08-31 16:33:31,010 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:32,050 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:32,652 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:32,839 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:33,417 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:33,953 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:34,158 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:34,210 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414209142.json
2025-08-31 16:33:34,211 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414210552.json
2025-08-31 16:33:34,211 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414211359.json
2025-08-31 16:33:34,212 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414212047.json
2025-08-31 16:33:34,213 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414212514.json
2025-08-31 16:33:34,213 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414213137.json
2025-08-31 16:33:34,214 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414214010.json
2025-08-31 16:33:34,215 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414214613.json
2025-08-31 16:33:34,215 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414215186.json
2025-08-31 16:33:34,217 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414215656.json
2025-08-31 16:33:34,218 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414217359.json
2025-08-31 16:33:34,218 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414218121.json
2025-08-31 16:33:34,219 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414218675.json
2025-08-31 16:33:34,219 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414219185.json
2025-08-31 16:33:34,220 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414220036.json
2025-08-31 16:33:34,220 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-32b-instruct:35)
2025-08-31 16:33:34,224 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 35 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43572_1756672414221067.json
2025-08-31 16:33:34,224 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-32b-instruct:35)
2025-08-31 16:33:34,286 - batch_test_runner - INFO - Database saved successfully
2025-08-31 16:33:34,287 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 16:33:34,287 - batch_test_runner - INFO - ============================================================
2025-08-31 16:33:34,287 - batch_test_runner - INFO - Batch test completed at 2025-08-31T16:33:34.287261
2025-08-31 16:33:34,287 - batch_test_runner - INFO - Summary:
2025-08-31 16:33:34,287 - batch_test_runner - INFO -   - Total tests: 35
2025-08-31 16:33:34,287 - batch_test_runner - INFO -   - Successful: 0
2025-08-31 16:33:34,287 - batch_test_runner - INFO -   - Failed: 35
2025-08-31 16:33:34,287 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-31 16:33:34,287 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_162915.log
2025-08-31 16:33:34,287 - batch_test_runner - INFO - ============================================================
2025-08-31 16:33:34,287 - batch_test_runner - INFO - ğŸ§¹ æ­£åœ¨æ¸…ç†å­˜å‚¨é€‚é…å™¨èµ„æº...
2025-08-31 16:33:34,287 - result_merger - INFO - åˆå¹¶çº¿ç¨‹å·²ç»åœæ­¢ï¼Œæ— éœ€é‡å¤æ“ä½œ
2025-08-31 16:33:34,287 - result_merger - INFO - å‘ç°16ä¸ªæ–°çš„ç»“æœæ–‡ä»¶
2025-08-31 16:33:34,321 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:33:34,321 - result_merger - INFO - [MERGER_PROTECTION] ä½¿ç”¨managerå†…ç½®çš„å®‰å…¨åˆå¹¶æœºåˆ¶
2025-08-31 16:33:34,331 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:35,197 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:35,323 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:35,383 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:36,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:36,632 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:37,296 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:37,297 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed due to lack of task details; there is no evidence of a wrong agent decision (tool choice, parameters, sequence, or depen
2025-08-31 16:33:37,415 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:38,232 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-31 16:33:39,296 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:39,298 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no tools required or executed (Required Tools Coverage 0%), and the error is listed as Unknown error. This indicates an external/system failure 
2025-08-31 16:33:40,831 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:41,256 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:41,258 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize a tool to perform the required simple_task; no tools were executed, indicating a tool selection/initializati
2025-08-31 16:33:44,808 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:44,810 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision that caused failure; there were no executed tools or explicit agent choices to audit. The error is reported as 'Unknown error'
2025-08-31 16:33:46,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:46,018 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were chosen or invoked for a task that requires tool usage; the agent effectively skipped execution, a wrong tool decision that prevents 
2025-08-31 16:33:46,386 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:46,390 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426388872.json
2025-08-31 16:33:46,391 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426390850.json
2025-08-31 16:33:46,392 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426391881.json
2025-08-31 16:33:46,394 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426392996.json
2025-08-31 16:33:46,396 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426394845.json
2025-08-31 16:33:46,397 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426396258.json
2025-08-31 16:33:46,399 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426397886.json
2025-08-31 16:33:46,400 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426399282.json
2025-08-31 16:33:46,400 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426400219.json
2025-08-31 16:33:46,401 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426400766.json
2025-08-31 16:33:46,401 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426401336.json
2025-08-31 16:33:46,402 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426401875.json
2025-08-31 16:33:46,402 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426402422.json
2025-08-31 16:33:46,404 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426402948.json
2025-08-31 16:33:46,405 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 1 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426404829.json
2025-08-31 16:33:46,405 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-32b-instruct:35)
2025-08-31 16:33:46,409 - result_collector - INFO - ğŸ“¤ å·²æäº¤ qwen2.5-32b-instruct çš„ 35 ä¸ªç»“æœåˆ°æ”¶é›†å™¨: qwen2.5-32b-instruct_43571_1756672426406098.json

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 14188
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14188
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007617566723870413617e1185'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e004f17566723878418730ee756'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007517566723883456928eee89'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007017566723891351347eeb17'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007417566723899188311eecb7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065017566723905114645e7eeb'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e006e17566723922814241e13fe'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.78
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 16299
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16299
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06b717566723930777942e7901'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06c217566723940923672e835a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.9s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06a117566723971418232e8bb5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215040c017566723978678903ee12b'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.7s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150443817566723983606316e8954'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted2025-08-31 16:33:46,410 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-32b-instruct:35)
2025-08-31 16:33:46,500 - batch_test_runner - INFO - Database saved successfully
2025-08-31 16:33:46,500 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-31 16:33:46,500 - batch_test_runner - INFO - ============================================================
2025-08-31 16:33:46,500 - batch_test_runner - INFO - Batch test completed at 2025-08-31T16:33:46.500945
2025-08-31 16:33:46,500 - batch_test_runner - INFO - Summary:
2025-08-31 16:33:46,501 - batch_test_runner - INFO -   - Total tests: 35
2025-08-31 16:33:46,501 - batch_test_runner - INFO -   - Successful: 0
2025-08-31 16:33:46,501 - batch_test_runner - INFO -   - Failed: 35
2025-08-31 16:33:46,501 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-31 16:33:46,501 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250831_162915.log
2025-08-31 16:33:46,501 - batch_test_runner - INFO - ============================================================
2025-08-31 16:33:46,501 - batch_test_runner - INFO - ğŸ§¹ æ­£åœ¨æ¸…ç†å­˜å‚¨é€‚é…å™¨èµ„æº...
2025-08-31 16:33:46,501 - result_merger - INFO - åˆå¹¶çº¿ç¨‹å·²ç»åœæ­¢ï¼Œæ— éœ€é‡å¤æ“ä½œ
2025-08-31 16:33:46,501 - result_merger - INFO - å‘ç°16ä¸ªæ–°çš„ç»“æœæ–‡ä»¶
2025-08-31 16:33:46,525 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 16:33:46,525 - result_merger - INFO - [MERGER_PROTECTION] ä½¿ç”¨managerå†…ç½®çš„å®‰å…¨åˆå¹¶æœºåˆ¶
2025-08-31 16:33:52,874 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:52,875 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error is 'Unknown error'. This appears to be a system/unknown failure rather than a wrong agent decision (no too
2025-08-31 16:33:54,205 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:54,206 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were defined or executed because the task lacked clear requirements or dependencies. The agent failed to resolve prerequisites needed to proc
2025-08-31 16:33:54,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:54,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were required for the task, yet the agent produced no output. This isnâ€™t a tool-selection, parameter, sequence, or d
2025-08-31 16:33:57,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:57,911 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of agent-level error (no tool selections, parameters, or sequence decisions were made). The error message is Unknown error with no too
2025-08-31 16:33:58,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:33:58,505 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or configured for the multi-stage pipeline; the agent failed to choose the required tools or define an execution plan, resu
2025-08-31 16:34:00,369 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:00,375 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision: no tools were executed, no parameters provided, and no sequence was attempted. The error is described as Unknown err
2025-08-31 16:34:02,666 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:02,668 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There are no required or executed tools (Required Tools Coverage: 0%), and the error message is generic ('Unknown error') without any identifiable agent de
2025-08-31 16:34:03,088 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:03,090 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the multi_stage_pipeline task. The pipeline requires sequential tool usage, but the agent did not choose/ini
2025-08-31 16:34:06,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:06,707 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke the necessary API integration tool(s); no tools were executed for an api_integration task, resulting in zero cov
2025-08-31 16:34:07,715 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:07,717 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool appropriate for an api_integration task; no tools were invoked, indicating a wrong or missing initia
2025-08-31 16:34:09,664 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:09,666 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error (no tool usage, parameters, or sequence to evaluate). The error is described as an unknown/tool-level failur
2025-08-31 16:34:13,096 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:13,101 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage occurred and the error is unspecified/system-level ('Unknown error'); there is no evidence of a wrong tool choice, incorrect parameters, or i
2025-08-31 16:34:14,714 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:14,718 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error can be identified: the task reports zero required tools and zero executed tools; there was no tool selection, parameter configurati
2025-08-31 16:34:17,564 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:17,570 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked for the task (zero tool usage) despite a data_pipeline context. The agent effectively made no tooling decision, in
2025-08-31 16:34:18,719 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:18,721 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required data_pipeline tools; no tools were executed, indicating a faulty tool-choice decision or failure t
2025-08-31 16:34:22,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:22,972 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a concrete agent decision error. No tools were executed (0% tool coverage) and there is no explicit error message, so 

[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.4s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e043b17566723784896848e22c5'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e066e17566723794116352e80f0'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007d17566723807555457ef31a'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.4s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215042f917566723811804480e1d87'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e05ab17566723835608811e3659'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.9s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e043517566723846548151e2df6'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 3.8s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064617566723858603594e0d28'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 20823
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=20823
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e065117566723874492229e8046'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e007517566723888411158ef016'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4691293984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e080f17566723896702667e0b57'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.6s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062917566723898467821e7e38'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e064b17566723907066940e7a16'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.3s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e066d17566723919701958e82ea'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.1s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 10978
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=10978
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e060b17566723924737534e87ac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.8s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e062b17566723934671089e815d'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 5.0s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150416717566723946815456eebe2'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.5s before retry...
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150411617566723975642166eeabf'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e059717566723991015866e36d7'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=timeout_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3319
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3319
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 11192
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11192
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=other_errors, confidence=0.72
ğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜15ä¸ªç»“æœ...
   è§¦å‘åŸå› : æ•°é‡=15, æ—¶é—´=105.1s, å¼ºåˆ¶=True
âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ 15/15 ä¸ªç»“æœ

[INFO] Batch writing 35 records to database (qwen2.5-32b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-32b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_163334.json
[SAVE_ENHANCED] å¼€å§‹å¢å¼ºä¿å­˜ï¼Œæ—¶é—´: 16:33:34
[SAVE_ENHANCED] ä½¿ç”¨æ–‡ä»¶é”æœºåˆ¶ä¿å­˜
[SAVE_ENHANCED] æ–‡ä»¶é”ä¿å­˜æˆåŠŸ

ğŸ“Š Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] æ­£åœ¨åœæ­¢ResultMerger...
[INFO] æ‰§è¡Œæœ€ç»ˆåˆå¹¶...
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There were no tools required or executed (Required
[V3_UPDATE] åˆ›å»ºæ–°promptç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline
[V3_UPDATE] åˆ›å»ºæ–°å·¥å…·æˆåŠŸç‡ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8
[V3_UPDATE] åˆ›å»ºæ–°éš¾åº¦ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - No observable agent decision that caused failure; 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: dependency_errors (confidence: 0.85) - No tools were defined or executed because the task
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No tool usage occurred and the error is unspecifie
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 2)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.65)
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 12)2025-08-31 16:34:24,537 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:24,539 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the simple_task; there is no evidence of required tool usage, indicating a wrong tool choic
2025-08-31 16:34:25,095 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:25,099 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the multi-stage pipeline; the agent failed to choose appropriate tooling to progress the task, resulting in 
2025-08-31 16:34:29,221 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:29,223 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable tool usage occurred and the error is not attributable to a wrong agent decision. The error message is unknown/system-level; there is insuffic
2025-08-31 16:34:30,653 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:30,656 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Task was undefined and no tools were selected or configured; the agent failed to establish a valid initial tool plan (tool selection step missing)
2025-08-31 16:34:34,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:34,518 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision data available: there were no tools executed, no parameters provided, and the error message is generic ('Unknown error'). This appears to
2025-08-31 16:34:35,137 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:35,138 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to perform any of the required initial workflow steps for the basic_taskâ€”no tools were executed and no actions were taken. This i
2025-08-31 16:34:39,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:39,245 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required tools for the multi_stage_pipeline task, effectively skipping the workflow. This is a tool selecti
2025-08-31 16:34:39,917 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:39,922 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or run any tool for a task whose requirements are unknown, effectively making a tool selection decision error by not choo
2025-08-31 16:34:40,276 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:40,277 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task. The agent failed to choose and execute any required data processing tools, leaving t
2025-08-31 16:34:46,037 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:46,044 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were executed or steps performed, indicating the agent did not establish or respect the required tool dependencies/initialization sequence fo
2025-08-31 16:34:46,383 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:46,388 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision (no tools selected/used; required tools coverage 0%). The error message is unknown and cannot be attributed to t
2025-08-31 16:34:47,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:47,916 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool activity occurred and the error message indicates an external/system failure ('Unknown error') rather than a concrete agent decision mistake (tool 
2025-08-31 16:34:51,111 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:51,114 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision or tool usage recorded to diagnose a tool-selection, parameter, sequence, or dependency error. The failure is reported as an unknown erro
2025-08-31 16:34:52,385 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:52,386 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the multi_stage_pipeline task; the agent did not choose the required tool sequence and produced 0% tool cove
2025-08-31 16:34:53,417 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:53,420 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke the necessary tools for the multi_stage_pipeline (no tools were executed), indicating a failure to choose the r
2025-08-31 16:34:56,992 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:56,992 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:56,994 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any tool due to the task being unknown, indicating a failure in initial tool selection; no appropriate tool was chosen to
2025-08-31 16:34:56,994 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision or tool usage; the failure is described as an unknown error with no tools executed. Without observable agent cho
2025-08-31 16:34:58,862 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:34:58,863 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute or initialize the required multi-stage workflow at all, effectively failing to follow the expected Aâ†’Bâ†’C sequence. No pi
2025-08-31 16:35:00,666 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:00,670 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision or tool usage to analyze. The error message is 'Unknown error' with no executed tools, so there is no evidence of tool selection, p
2025-08-31 16:35:01,762 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:01,767 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed; insufficient information to identify a specific agent decision error (tool selection, parameter confi
2025-08-31 16:35:05,154 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:05,160 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the API integration task despite the need for tool-based integration steps; the agent did not choose or init
2025-08-31 16:35:07,499 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:07,505 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for an api_integration task, leading to immediate failure. The agent should have chosen and/or invoked an approp
2025-08-31 16:35:08,186 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:08,190 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized to perform the data_pipeline task; there is no evidence of any tool execution, indicating a wrong tool-selec
2025-08-31 16:35:12,405 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:12,410 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initiate any tool/plan for the unknown multi-stage task, effectively making no tool choice (a wrong or missing tool decisi
2025-08-31 16:35:12,719 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:12,721 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any tool/step necessary to perform the api_integration task, effectively stalling the workflow. This indicate
2025-08-31 16:35:18,049 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:18,050 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error. The task record shows an 'Unknown error' with no tools executed, providing no basis to judge tool selection
2025-08-31 16:35:18,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:18,124 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actionable steps were executed for a 'simple_task' and no tools were used (0/0). This implies the agent failed to perform the required sequence
2025-08-31 16:35:20,651 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:20,658 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the api_integration task; there is no executed tool and no progress, indicating a failing i
2025-08-31 16:35:22,443 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:22,453 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and no specific agent decision (tool choice, parameters, or sequence) was made. The failure appears due to an unknown/sy
2025-08-31 16:35:26,715 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:26,717 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any of the required tools for the multi_stage_pipeline task; no tools were executed, indicating a tool-selection fa
2025-08-31 16:35:27,172 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:27,178 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for an unknown task; the agent did not choose an appropriate tool (or any tool) to proceed, indicating a decisi
2025-08-31 16:35:28,872 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:28,873 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool appropriate for the api_integration task, effectively leaving the workflow unexecuted. This constitute
2025-08-31 16:35:33,067 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:33,073 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to execute the required multi-stage pipeline steps in the correct order (no tools were invoked, effectively halting the Aâ†’Bâ†’C wor
2025-08-31 16:35:33,181 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:33,185 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No data indicating a wrong agent decision (tool choice, parameters, or sequence). The task shows an unknown error with no tool execution details provided. 
2025-08-31 16:35:35,567 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:35,569 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked; the task remained unoperational, causing an Unknown error. This constitutes an agent decision error related to to
2025-08-31 16:35:38,933 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:38,935 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any required tool for the data_pipeline task, effectively skipping execution. No tools were invoked (Required
2025-08-31 16:35:42,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:42,201 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error message is Unknown error, making it impossible to attribute the failure to any specific agent decision (tool selection
2025-08-31 16:35:42,605 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:42,606 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision errors detected: there were no tool selections or parameter/sequence choices to critique. The task context shows an unknown task
2025-08-31 16:35:42,721 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:42,724 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or initiated for the required api_integration task, effectively opting out of the necessary tool that would allow progress. T
2025-08-31 16:35:48,401 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:48,402 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no agent-driven tool decisions (no tools executed, 0% tool coverage) due to an unknown/system-level error. Without any tool usage, there is no b
2025-08-31 16:35:49,160 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:49,162 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision or tool usage due to unknown task and missing execution details; error reported as Unknown error with 0 tools executed. Unable
2025-08-31 16:35:51,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:51,201 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were taken at all; the task implies a workflow to be executed, but the agent did not initiate or follow any sequence of steps. This ina
2025-08-31 16:35:53,933 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:53,934 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tooling for the api_integration task, effectively failing to choose the appropriate tool(s) to perform
2025-08-31 16:35:54,668 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:54,670 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or any API integration steps initiated; the task context is unknown, indicating a failure in tool choice/initial action rat
2025-08-31 16:35:57,077 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:57,080 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error detectable: the task reports require 0 tools and there is no evidence of wrong tool choice, incorrect parameters, improper
2025-08-31 16:35:58,726 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:35:58,728 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and/or execute any tool required for api_integration; no action was taken, indicating a flawed tool selection/decision step
2025-08-31 16:36:01,327 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:01,328 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to initiate or follow the required multi-stage workflow sequence; no tools were invoked and no stages were executed, effectively 
2025-08-31 16:36:01,900 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:01,902 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task; there was no initiation of required ingestion/processing tools, indicating a tool se
2025-08-31 16:36:05,935 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:05,942 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any of the required tools for the multi_stage_pipeline; no tools were chosen or executed, preventing any pr
2025-08-31 16:36:06,978 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:06,985 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error. The task indicates 0 required tools (0/0) and there were no tool executions. The complete failure cannot be traced to
2025-08-31 16:36:08,304 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:08,308 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to determine a specific agent decision error; no tools were executed and the error message is generic 'Unknown error'. Without too
2025-08-31 16:36:10,081 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:10,082 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the task; the agent did not choose any required tool(s), resulting in 0% tool coverage and a complete failu
2025-08-31 16:36:12,494 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:12,495 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not execute the required workflow steps in the expected order (no actions were taken, effectively skipping the Aâ†’Bâ†’C sequence). There we

[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 4)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 9)
[INFO] Buffer full (3 records), triggering flush...2025-08-31 16:36:14,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:14,849 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified. The task reported 0 required tools (0/0 coverage) and the error message is 'Unknown error' without any tool execution d
2025-08-31 16:36:15,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:15,240 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of an incorrect agent decision (no tool usage to judge against). The failure appears to be a generic unknown/tool-level error preventi
2025-08-31 16:36:19,863 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:19,868 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable evidence of a specific agent decision error. The error summary shows an 'Unknown error' with 0% required tool coverage and no tools executed,
2025-08-31 16:36:20,412 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:20,414 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed; the error message is generic ('Unknown error') with 0% tool coverage. There is no evidence of a wrong tool choice, inco
2025-08-31 16:36:20,483 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:20,484 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required tools for the multi-stage pipeline, resulting in zero tool execution and no progression toward ful
2025-08-31 16:36:24,671 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:24,673 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision evidence available. The task failed with an unspecified system-level error before any tools were invoked, and there is no clea
2025-08-31 16:36:24,674 - result_merger - INFO - æ¨¡å‹qwen2.5-32b-instructä¿å­˜50/50æ¡è®°å½•
2025-08-31 16:36:24,683 - result_merger - INFO - åˆå¹¶å®Œæˆï¼Œå…±å¤„ç†16ä¸ªæ–‡ä»¶ï¼Œä¿å­˜50æ¡è®°å½•
2025-08-31 16:36:24,685 - batch_test_runner - INFO - âœ… å­˜å‚¨é€‚é…å™¨èµ„æºæ¸…ç†å®Œæˆ
2025-08-31 16:36:24,686 - batch_test_runner - INFO - ğŸ”š å­è¿›ç¨‹æµ‹è¯•å®Œæˆï¼Œä¸»åŠ¨é€€å‡º

[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - Task was undefined and no tools were selected or c
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60) - The agent did not select or run any tool for a tas
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.70) - No tool activity occurred and the error message in
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65) - Agent did not select or initiate any tool/plan for
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.55) - No evidence of a concrete agent decision error. Th
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 26)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.70) - No tools were selected or executed and no specific
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.65) - No tool was selected or initiated for the required
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.72) - There were no agent-driven tool decisions (no tool
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 20)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.62) - No tools were selected or any API integration step
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: sequence_order_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.65) - No actionable evidence of a specific agent decisio
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.65) - No actionable agent decision evidence available. T
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 26)
[INFO] æœ€ç»ˆåˆå¹¶å®Œæˆ: 16 ä¸ªæ–‡ä»¶
2025-08-31 16:36:24,868 - smart_result_collector - INFO - SmartResultCollector æ­£åœ¨å…³é—­...
2025-08-31 16:36:24,868 - smart_result_collector - INFO - SmartResultCollector å·²å…³é—­
2025-08-31 16:36:25,745 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:25,748 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task is an api_integration task which requires using an API/HTTP client tool, but the agent did not select or initialize any tool and no API c

  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5590108576)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215045b017566723990996889e8446'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e05ab17566723993701273e371f'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.0s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3231
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3231
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e060917566724006698119e6e80'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 215041a817566724010898184e3418'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e060c17566724018326407e88df'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150454117566724026132419e7aac'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 2.7s before retry...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: data parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_selection_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 3250
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=3250
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=other_errors, confidence=0.6
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 23030
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23030
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24144
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24144
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.88
ğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜15ä¸ªç»“æœ...
   è§¦å‘åŸå› : æ•°é‡=15, æ—¶é—´=114.1s, å¼ºåˆ¶=True
âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ 15/15 ä¸ªç»“æœ

[INFO] Batch writing 35 records to database (qwen2.5-32b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-32b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_163346.json
[SAVE_ENHANCED] å¼€å§‹å¢å¼ºä¿å­˜ï¼Œæ—¶é—´: 16:33:46
[SAVE_ENHANCED] ä½¿ç”¨æ–‡ä»¶é”æœºåˆ¶ä¿å­˜
[SAVE_ENHANCED] æ–‡ä»¶é”ä¿å­˜æˆåŠŸ

ğŸ“Š Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] æ­£åœ¨åœæ­¢ResultMerger...
[INFO] æ‰§è¡Œæœ€ç»ˆåˆå¹¶...
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.70) - No tools were selected or executed and the error i
[V3_UPDATE] åˆ›å»ºæ–°promptç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline
[V3_UPDATE] åˆ›å»ºæ–°å·¥å…·æˆåŠŸç‡ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8
[V3_UPDATE] åˆ›å»ºæ–°éš¾åº¦ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.78) - There is no evidence of agent-level error (no tool
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.70) - There are no required or executed tools (Required 
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - No tools were selected or invoked for the multi-st
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No actionable tool usage occurred and the error is
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 4)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.62) - No agent decision data available: there were no to
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.72) - There is no evidence of any agent decision or tool
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.85) - No agent-level decision or tool usage to analyze. 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 4)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.60) - No tools were selected or invoked for an api_integ
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.85) - No data indicating a wrong agent decision (tool ch
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.74) - No concrete agent decision errors detected: there 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No observable agent decision or tool usage due to 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65) - No tools were selected or executed for the task; t
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.75) - There is no evidence of an incorrect agent decisio
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.09s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 4)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors2025-08-31 16:36:29,299 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:29,306 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or action taken to perform the simple_task. The task requires at least an action/tool to complete, but the agent did not choo
2025-08-31 16:36:33,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:33,016 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be evaluated: task lacked details, required tools undefined, and no tools were executed. The error message 'Unknown error' indicates 
2025-08-31 16:36:33,017 - result_merger - INFO - æ¨¡å‹qwen2.5-32b-instructä¿å­˜50/50æ¡è®°å½•
2025-08-31 16:36:33,022 - result_merger - INFO - åˆå¹¶å®Œæˆï¼Œå…±å¤„ç†16ä¸ªæ–‡ä»¶ï¼Œä¿å­˜50æ¡è®°å½•
2025-08-31 16:36:33,023 - batch_test_runner - INFO - âœ… å­˜å‚¨é€‚é…å™¨èµ„æºæ¸…ç†å®Œæˆ
2025-08-31 16:36:33,028 - batch_test_runner - INFO - ğŸ”š å­è¿›ç¨‹æµ‹è¯•å®Œæˆï¼Œä¸»åŠ¨é€€å‡º

[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 22)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 22)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.60) - No agent decision can be evaluated: task lacked de
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 27)
[INFO] æœ€ç»ˆåˆå¹¶å®Œæˆ: 16 ä¸ªæ–‡ä»¶
2025-08-31 16:36:33,169 - smart_result_collector - INFO - SmartResultCollector æ­£åœ¨å…³é—­...
2025-08-31 16:36:33,169 - smart_result_collector - INFO - SmartResultCollector å·²å…³é—­
2025-08-31 16:36:34,281 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:34,282 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any API integration tool; no tooling was used for an api_integration task, indicating a wrong tool selection/de
INFO:__main__:âœ… åˆ†ç‰‡1å®Œæˆ
INFO:__main__:ç­‰å¾…åˆ†ç‰‡2å®Œæˆï¼ˆ20å®ä¾‹Ã—50workersï¼Œæœ€å¤šç­‰å¾…50åˆ†é’Ÿï¼‰...
INFO:__main__:âœ… åˆ†ç‰‡2å®Œæˆ
INFO:__main__:ç­‰å¾…åˆ†ç‰‡3å®Œæˆï¼ˆ20å®ä¾‹Ã—50workersï¼Œæœ€å¤šç­‰å¾…50åˆ†é’Ÿï¼‰...
2025-08-31 16:36:41,853 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:41,855 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to determine a concrete agent decision error. No tools were required or executed (required tools coverage 0%), so there is no evid
2025-08-31 16:36:45,743 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:45,745 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions were made (no tools were selected or executed). The task lacked defined context and resulted in a generic 'Unknown error' without any to
2025-08-31 16:36:51,294 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:51,296 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the task; the agent did not choose a required tool or start the workflow, leading to complete failure. T
2025-08-31 16:36:57,585 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:36:57,586 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the pipeline (tool coverage 0%). This indicates the agent failed to choose the required tools to begin t
2025-08-31 16:37:04,040 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:04,042 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required executing a data_pipeline workflow, but the agent delivered no tool usage (no data_loader/processor tools were selected or initi
2025-08-31 16:37:11,433 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:11,434 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any required tooling to start the data_pipeline task (no tools were executed). This is a tool-selection decisio
2025-08-31 16:37:17,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:17,865 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute the failure to a specific agent decision. There is no explicit error message, no tool usage or parameter details, and
2025-08-31 16:37:23,166 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:23,168 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or specify any appropriate tool for the given unknown task, resulting in 0% tool coverage and a complete failure.",
  "conf
2025-08-31 16:37:29,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:29,760 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error. The failure appears as an unknown error with zero tool usage and no execution details, suggesting a system/tool failu
2025-08-31 16:37:34,285 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:34,287 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or agent decision was performed for the task (Required Tools: 0; Executed Tools: 0). The failure reported as an Unknown error appears to be a
2025-08-31 16:37:42,265 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:42,266 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or any action taken to perform the simple_task, effectively a no-decision by the agent. Although no tools were required, the 
2025-08-31 16:37:52,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:52,651 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle TOOL DEPENDENCIES; no tools were executed and there was no preparatory data loading/initialization, indicating prerequisites we

[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 2150457a17566723703885406e0c64'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.2s before retry...
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24823
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24823
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-32b-instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: qwen2.5-32b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5500203104)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[ASSISTED] Task received 6 format helps, final result: failure
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 24647
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=24647
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-32b-instruct, API name: qwen2.5-32b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e057b17566723768324610e3f55'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 0.9s before retry...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e00cd17566723781277871e96d3'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e063817566723802231763e82eb'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 1.7s before retry...
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.86
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'success': False, 'message': 'TPM/RPMé™æµ', 'data': None, 'code': 'PL-002', 'detailMessage': 'TPM/RPMé™æµ, traceId: 213e06a217566723823342509e81fa'}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Client does not support deployment switching
[RETRY] Connection issue, waiting 4.9s before retry...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] æµ‹è¯•éå®Œå…¨æˆåŠŸ(failure)ï¼Œå‡†å¤‡è°ƒç”¨AIåˆ†ç±»
[AI_DEBUG] ç”Ÿæˆçš„txt_contenté•¿åº¦: 18060
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18060
  - task_model=qwen2.5-32b-instruct
[AI_CLASSIFIER] ç›´æ¥ä½¿ç”¨AIåˆ†æå®Œæ•´äº¤äº’è®°å½•ï¼ˆè·³è¿‡è§„åˆ™åŒ¹é…ï¼‰
[AI_DEBUG] AIåˆ†ç±»ç»“æœ: category=tool_call_format_errors, confidence=0.78
Progress: 30/30 (Success: 0)
ğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜10ä¸ªç»“æœ...
   è§¦å‘åŸå› : æ•°é‡=10, æ—¶é—´=78.4s, å¼ºåˆ¶=True
âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ 10/10 ä¸ªç»“æœ

[INFO] Batch writing 30 records to database (qwen2.5-32b-instruct:30)
[INFO] Successfully wrote 30/30 records (qwen2.5-32b-instruct:30)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250831_163315.json
[SAVE_ENHANCED] å¼€å§‹å¢å¼ºä¿å­˜ï¼Œæ—¶é—´: 16:33:15
[SAVE_ENHANCED] ä½¿ç”¨æ–‡ä»¶é”æœºåˆ¶ä¿å­˜
[SAVE_ENHANCED] æ–‡ä»¶é”ä¿å­˜æˆåŠŸ

ğŸ“Š Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] æ­£åœ¨åœæ­¢ResultMerger...
[INFO] æ‰§è¡Œæœ€ç»ˆåˆå¹¶...
[INFO] Enhanced manager: AIé”™è¯¯åˆ†ç±»ç³»ç»Ÿå·²å¯ç”¨
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.85) - No tools were selected or initialized for the task
[V3_UPDATE] åˆ›å»ºæ–°promptç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline
[V3_UPDATE] åˆ›å»ºæ–°å·¥å…·æˆåŠŸç‡ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8
[V3_UPDATE] åˆ›å»ºæ–°éš¾åº¦ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> simple_task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.85) - No evidence of a wrong tool choice, misconfigurati2025-08-31 16:37:58,925 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:37:58,927 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform the required workflow steps (no tools executed) for the simple_task, effectively breaking the intended sequence/ordering
2025-08-31 16:38:05,545 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:05,547 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked for the task, indicating a flawed tool choice/selection decision by the agent (i.e., the agent failed to choose an
2025-08-31 16:38:11,068 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:11,069 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select an appropriate tool for the data_pipeline task (no tool was chosen/executed). The task requires tool usage, but the agent d
2025-08-31 16:38:17,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:17,410 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Cannot identify a specific agent decision error from the provided data: the error is labeled 'Unknown error' with no details on tool usage, parameters, or 
2025-08-31 16:38:27,862 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:27,864 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed and no steps were performed in the expected workflow; the agent did not initiate or follow any sequence appropriate for t
2025-08-31 16:38:31,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:31,775 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and use any required data_pipeline tool; no tool was chosen for the task, leading to complete failure.",
  "confidence": 0.
2025-08-31 16:38:39,185 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:39,187 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected and no steps were taken. The task had no explicitly required tools listed, yet the agent did not initiate any action. This appears to 
2025-08-31 16:38:46,524 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:46,545 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool for the api_integration task (no required tools specified and Executed Tools is empty). This indicates
2025-08-31 16:38:50,443 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:50,445 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool execution occurred and the error is reported as unknown. There is insufficient information to attribute the failure to an agent decision (tool sele
2025-08-31 16:38:55,629 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:38:55,630 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient task context and missing tool execution log prevent identifying any specific agent decision error (tool selection, parameter config, sequence,
2025-08-31 16:39:02,935 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:02,936 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed; there is no evidence of a wrong tool choice, incorrect parameters, incorrect sequence, or unmet depen
2025-08-31 16:39:07,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:07,394 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No essential tools were selected or invoked for the multi_stage_pipeline task; the agent failed to choose/activate the required tools (leading to 
2025-08-31 16:39:13,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:13,236 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error identifiable. The task shows 0 required tools (0/0 coverage) and no tools were executed, implying no agent action or decis
2025-08-31 16:39:21,771 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:21,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error message is 'Unknown error'; there is insufficient information to judge any specific agent decision (tool selection, pa
2025-08-31 16:39:26,553 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:26,555 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error message is unknown; there is insufficient information to attribute the failure to a specific agent decision (tool_sele
2025-08-31 16:39:33,344 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:33,345 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed due to an undefined task; this indicates a failure in tool selection decision by the agent or a request for cla
2025-08-31 16:39:39,473 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:39,474 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool to execute the data_pipeline task; no tools were invoked, so no actions were taken, causing complete
2025-08-31 16:39:47,088 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:47,090 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or invoke any tool for a task labeled as basic_task (no tools listed as required or executed). This indicates a tool-usage 
2025-08-31 16:39:52,174 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:39:52,176 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There was no explicit error and no tools were invoked; the task likely did not require tool usage, so there is no identifiable agent decision (tool choice,
2025-08-31 16:40:00,563 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:00,565 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision could be evaluated: the task is labeled as Unknown with no required tools and no tools executed. Therefore there is no evidence of 
2025-08-31 16:40:05,073 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:05,074 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated: no tools were selected or executed; the error appears to be an unknown/system error rather than a wrong tool choice, 
2025-08-31 16:40:09,117 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:09,118 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No appropriate tool was selected or initialized for the unknown data_pipeline task; the agent did not choose a valid starting tool (leading to zer
2025-08-31 16:40:14,539 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:14,541 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any of the required tools for a multi-stage pipeline (no data_loader/pdf_reader/etc. chosen). This represents a
2025-08-31 16:40:21,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:21,533 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision was made: the task required no tools and no steps were executed, so there is no tool_selection_errors, parameter_config_errors
2025-08-31 16:40:27,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:27,301 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to execute the required data_pipeline steps in the proper sequence (no pipeline actions were performed). This indicates an omissi
2025-08-31 16:40:33,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:33,604 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision error can be identified: no tools were selected or executed, no parameters set, and no sequence defined. The failure is reported as
2025-08-31 16:40:39,159 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:39,161 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There was no agent decision or tool usage to evaluate. The error message 'Unknown error' appears to be a system/unknown failure rather than a misselection 
2025-08-31 16:40:47,492 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:47,493 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed and there is insufficient information about the task to proceed; the agent failed to select or propose an appropriate tool/
2025-08-31 16:40:58,383 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:40:58,384 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools, yet the agent produced no action at all. This indicates a failure in selecting or invoking an appropriate action (tool
2025-08-31 16:41:03,608 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:03,610 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool(s) necessary for the api_integration task, resulting in no actions taken. This is a tool-selection
2025-08-31 16:41:11,350 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:11,353 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the required basic_task, effectively opting to take no action. This indicates a wrong decis
2025-08-31 16:41:16,642 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:16,646 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identifiable: no tools were executed, no parameters set, and no processing sequence was applied. The error appears external/unknown
2025-08-31 16:41:21,491 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:21,493 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was executed and the error remains Unknown, suggesting a non-decision-level failure (likely system/tool-layer issue) rather than an identifiable ag
2025-08-31 16:41:26,277 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:26,277 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected. The task shows an unknown system error with zero tool executions (coverage 0/0). Since there was no wrong tool choice, in
2025-08-31 16:41:34,438 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:34,439 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions or tool executions were performed, effectively failing to follow any required workflow sequence. The task remained unaddressed (no Aâ†’Bâ†’
2025-08-31 16:41:38,383 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:38,385 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task; the agent did not choose the required tooling (e.g., data_loader) and thus failed t
2025-08-31 16:41:44,715 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:44,718 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No data_pipeline tools were selected or invoked (no tool usage recorded). The agent failed to choose an appropriate tool or define the workflow fo
2025-08-31 16:41:50,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:50,912 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or an inappropriate tool was chosen for an unknown task, leading to no actionable processing. The agent failed to pick a requ
2025-08-31 16:41:56,003 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:41:56,005 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision. There are no tool executions, parameters, or sequence details to evaluate. The error message 'Unknown error' with no
2025-08-31 16:42:05,007 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:05,008 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to address the data_pipeline task, resulting in a complete lack of execution steps. This reflects a to

[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.75) - No tools were selected or executed due to lack of 
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> basic_task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.65) - No evidence of a wrong agent decision: no tools we
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.70) - No evidence of a concrete agent decision error (no
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72) - No tool was selected or invoked for the task (zero
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: sequence_order_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.72) - There is no evidence of any agent decision (no too
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent decision or tool usage recorded to diagno
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.65) - The agent did not select any tool due to the task 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 8)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.64)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.60) - No tools were selected or executed for an unknown 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.85) - No tool was selected or invoked; the task remained
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.65) - No tools were executed and the error message is Un
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.82)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.70) - Insufficient information to determine a specific a
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.78) - No agent decision error identified. The task repor
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> api_integration
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.75) - No tools were selected or executed; the error mess
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent decisions were made (no tools were select
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.65) - No tools were selected or initialized for the task
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 8)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - No tools were selected or initialized for the pipe
[V3_UPDATE] åˆ›å»ºæ–°ä»»åŠ¡ç±»å‹ç»“æ„: qwen2.5-32b-instruct -> baseline -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.63)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.72) - Agent failed to select or specify any appropriate 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.85) - No identifiable agent decision error. The failure 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.75) - No tool usage or agent decision was performed for 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 14)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: dependency_errors (confidence: 0.76)2025-08-31 16:42:11,140 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:11,141 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were performed and no workflow steps were executed, effectively a no-op. The agent failed to follow the required task sequence (no step
2025-08-31 16:42:15,693 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:15,694 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke the necessary data_pipeline tools (no data_loader or subsequent pipeline steps executed). This represents a tool
2025-08-31 16:42:20,115 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:20,119 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any required data_pipeline tooling; no tools were executed, indicating a missing or incorrect tool selectio
2025-08-31 16:42:27,507 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:27,509 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence: no tools were selected or executed. The error message 'Unknown error' appears to be an external/system failure (timeout/network
2025-08-31 16:42:33,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:33,133 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or used because the task was unknown/ambiguous. The agent failed to choose an initial tool to start the workflow, effectively
2025-08-31 16:42:38,898 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:38,899 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure is described as an unknown error with no tool executions or explicit agent decisions available to attribute to a tool selection, parameter, seq
2025-08-31 16:42:44,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:44,960 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or instantiate any appropriate API integration tool for the task, resulting in zero tool execution and no parameters. Thi
2025-08-31 16:42:49,128 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:49,128 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No pipeline stages were executed; the agent did not initiate or follow the required Aâ†’Bâ†’C workflow, effectively omitting steps and failing to esta
2025-08-31 16:42:57,584 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:42:57,585 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to initiate or complete any steps to fulfill the simple_task; there was no tool usage or output created, indicating a decision to
2025-08-31 16:43:01,626 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:01,626 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision was made (no tools selected, no parameters provided, no execution sequence). The failure appears to be an unknown/system-level erro
2025-08-31 16:43:07,010 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:07,011 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error. The error message is Unknown with no tool usage details, so we cannot attribute the failure to tool selecti
2025-08-31 16:43:12,878 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:12,878 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent tool usage or decision could be evaluated because the error occurred before any action was taken (Unknown error). Therefore there is no identifiab
2025-08-31 16:43:19,952 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:19,952 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any action/tool for the basic_task, effectively performing a no-op. This represents a wrong tool selection/init
2025-08-31 16:43:27,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:27,502 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task required no tool execution, yet the agent produced no final output. This represents a failure to complete the final step of the workflow 
2025-08-31 16:43:35,132 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:35,133 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task required no tools, yet the agent produced no output or action. This indicates a misstep in the execution sequence (failing to perform the
2025-08-31 16:43:39,916 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:39,917 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There was no agent decision error; the failure stems from an unknown system/tool-level error that prevented any tool execution. Since no tool was selected,
2025-08-31 16:43:45,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:45,886 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected and no workflow was defined because the task details are unknown ('Unknown error'). There is no evidence of sequencing, par
2025-08-31 16:43:50,727 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:50,727 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a targeted agent decision error: no tools were selected or executed and the error is labeled Unknown error, suggesting an unspecified system
2025-08-31 16:43:55,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:43:55,753 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API integration tool was chosen or invoked for the task; the agent did not select an appropriate integration tool and performed no tool actions
2025-08-31 16:44:02,980 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:02,980 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any tools necessary for the data_pipeline task; no required tooling was engaged, indicating a tool selection/omi
2025-08-31 16:44:08,306 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:08,307 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any tool for the simple_task, effectively taking no action. This constitutes a faulty tool decision (choosing
2025-08-31 16:44:12,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:12,411 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error is reported as an unknown/system-level error. With zero tool usage, there is no agent decision to evaluate
2025-08-31 16:44:21,680 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:21,681 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were selected or executed, and no workflow sequence was initiated (Aâ†’Bâ†’C) due to an 'Unknown error'. This suggests the agent failed to es
2025-08-31 16:44:26,989 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:26,993 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the task; the agent did not identify or request any required tooling, effectively making a poor tool choice
2025-08-31 16:44:34,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:34,243 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and instantiate the appropriate data_pipeline tools (no tools were invoked). This indicates a flawed tool-selection/ini
2025-08-31 16:44:40,546 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:40,548 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No action was taken for a simple_task; there were no required tools or steps and yet the task remained incomplete, indicating an incorrect or missing agent
2025-08-31 16:44:48,769 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:48,770 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool for a task described as basic_task. No tools were executed, effectively choosing to take no action, wh
2025-08-31 16:44:53,117 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:53,118 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of agent-made decisions (no tools executed, no tool selections, parameters, or sequence to evaluate) and the error is labeled as Unkno
2025-08-31 16:44:59,407 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:44:59,408 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a primary agent decision error: the task details are unknown, no tools were executed, and the error message is generic
2025-08-31 16:45:08,920 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:08,923 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool or plan (no tools executed) and produced an 'Unknown error', indicating a misdecision at the outse
2025-08-31 16:45:17,036 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:17,037 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed. The task reports zero required tools (0/0 coverage), yet the result is a complete failure. With the p
2025-08-31 16:45:21,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:21,775 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tool for the data_pipeline task, effectively an omission or incorrect tool decision.",
  "confidence":
2025-08-31 16:45:33,580 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:33,582 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no workflow steps were defined or followed. The task would require a defined execution sequence to reach full success, 
2025-08-31 16:45:41,396 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:41,396 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool for the task (0% tool coverage), effectively halting workflow before any action. Given an unknown 
2025-08-31 16:45:47,166 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:47,166 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision occurred: task context is Unknown and no tools were executed. The failure appears to be a system/environment error rather than a wr
2025-08-31 16:45:52,884 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:45:52,884 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a primary agent decision error. The task reports an 'Unknown error' with no tools executed or configured, implying a possible system/tool-le
2025-08-31 16:46:01,338 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:01,338 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The basic_task required 0 tools (no tools specified). Any decision to engage tools would indicate an incorrect tool selection for this task, i.e.,
2025-08-31 16:46:07,218 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:07,221 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool(s) needed for the multi_stage_pipeline; effectively chose a 'no-tool' path, resulting in zero tool cov
2025-08-31 16:46:14,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:14,905 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool to perform the data_pipeline task; no tooling was invoked, indicating a misstep in tool selection/init

[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.62) - No tool was selected or invoked for the task, indi
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72) - Agent failed to select an appropriate tool for the
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.75) - Cannot identify a specific agent decision error fr
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.64) - The agent did not select or invoke any tool for th
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No tool execution occurred and the error is report
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.65) - Insufficient task context and missing tool executi
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.60) - No tools were executed and the error message is 'U
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85) - No tools were executed and the error message is un
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.85) - No tools were selected or executed due to an undef
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.62) - No agent-level decision could be evaluated: the ta
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.65) - No agent decision could be evaluated: no tools wer
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72) - No appropriate tool was selected or initialized fo
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.60) - No agent-level decision error can be identified: n
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.85) - There was no agent decision or tool usage to evalu
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.65) - No tools were executed and there is insufficient i
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.09s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.75) - No agent decision error identifiable: no tools wer
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.65) - No tool was executed and the error remains Unknown
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.80) - No agent decision error detected. The task shows a
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 20)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.62) - No tool was selected or an inappropriate tool was 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.72) - No evidence of a wrong agent decision. There are n
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.62) - The agent did not select or invoke any tool to add
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 24)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.08s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.74) - No agent decision evidence: no tools were selected
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - No tool was selected or used because the task was 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.72) - The failure is described as an unknown error with 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85) - No agent-level decision was made (no tools selecte
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.65) - No evidence of a specific agent decision error. Th
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.70) - No agent tool usage or decision could be evaluated
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 24)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.88) - There was no agent decision error; the failure ste
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.65) - No tools were selected and no workflow was defined
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.85) - No evidence of a targeted agent decision error: no
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 29)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.48)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.85) - No tools were selected or executed and the error i
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.60) - No tools were selected or executed, and no workflo
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.62) - No tools were selected or executed for the task; t
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.65) - There is no evidence of agent-made decisions (no t
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.60) - Insufficient information to identify a primary age
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.85) - The agent did not select or initialize any tool or
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.85) - The agent did not select or initialize any tool fo
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent-level decision occurred: task context is 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.85) - No evidence of a primary agent decision error. The
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 36)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 37)2025-08-31 16:46:20,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:20,978 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of any agent decision error (no tool selection, parameter config, sequence, or dependency issue). There were no tools executed and the error is
2025-08-31 16:46:27,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:27,301 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of any agent decision or tool usage: the logs only show an 'Unknown error' with unknown task and no executed tools. Without concrete tool selec
2025-08-31 16:46:33,507 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:33,508 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Error arose before any agent tool choice or action; there is no discernible agent decision (no tool selection, parameters, sequence, or dependencies were e
2025-08-31 16:46:38,388 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:38,390 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or activated for the simple_task, resulting in no progress. The agent failed to choose an appropriate action/tool according t
2025-08-31 16:46:42,915 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:42,915 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not establish or execute any steps in the expected data_pipeline sequence (e.g., load â†’ analyze â†’ output). No tools were invoked and
2025-08-31 16:46:49,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:49,287 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and no error details are provided, therefore there is no discernible agent decision error (tool selection, parameter con
2025-08-31 16:46:55,305 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:46:55,306 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated because there were no tools executed and the error is reported as Unknown error. With required tools set to 0 and no t
2025-08-31 16:47:00,108 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:00,109 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to determine which agent decision error occurred. No tool usage details, parameters, or execution sequence are provided beyond a g
2025-08-31 16:47:10,485 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:10,486 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision or tool usage could be evaluated due to missing task details; error manifested as Unknown error with 0 tool coverage. Since there is no e
2025-08-31 16:47:18,202 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:18,202 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision or tool usage was recorded (Executed Tools: <none>, Required Tools Coverage: 0/0). There are no tool selections, parameter configurations
2025-08-31 16:47:24,114 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:24,115 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not execute any steps or tools, effectively skipping the required workflow sequence. No actions were taken, so the expected Aâ†’Bâ†’C sequen
2025-08-31 16:47:30,047 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:30,048 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool suitable for an API integration task; no tools were executed, indicating a wrong or missing tool choic
2025-08-31 16:47:36,411 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:36,412 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No detectable agent decision error (tool_selection, parameter_config, sequence, or dependencies) can be identified from the provided data. The error messag
2025-08-31 16:47:42,068 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:42,069 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is labeled 'Unknown error'. There is insufficient evidence of any agent decision (tool choice, parameter settings, seq
2025-08-31 16:47:47,060 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:47,061 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision can be evaluated because no tools were executed and the error is reported as 'Unknown error.' There is insufficient data to at
2025-08-31 16:47:53,224 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:53,224 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to execute the required workflow steps; no actions were performed (no data loading, analysis, or output). This indicates the agent di
2025-08-31 16:47:59,369 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:47:59,369 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to initiate or execute any steps in the required workflow sequence; no tools were invoked, effectively breaking the expected workflow
2025-08-31 16:48:04,581 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:48:04,582 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not establish or execute the required multi-stage pipeline sequence (Aâ†’Bâ†’C). No tools were invoked, indicating missing or incorrect 
2025-08-31 16:48:10,326 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 16:48:10,327 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed; the agent did not make a valid tool choice for the task (effectively choosing none), which prevented any progres
2025-08-31 16:48:10,331 - result_merger - INFO - æ¨¡å‹qwen2.5-32b-instructä¿å­˜100/100æ¡è®°å½•
2025-08-31 16:48:10,344 - result_merger - INFO - åˆå¹¶å®Œæˆï¼Œå…±å¤„ç†71ä¸ªæ–‡ä»¶ï¼Œä¿å­˜100æ¡è®°å½•

[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 41)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 42)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 43)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 34)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 39)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 40)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 36)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 37)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 41)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 42)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 14)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)2025-08-31 16:48:10,354 - batch_test_runner - INFO - âœ… å­˜å‚¨é€‚é…å™¨èµ„æºæ¸…ç†å®Œæˆ
2025-08-31 16:48:10,357 - batch_test_runner - INFO - ğŸ”š å­è¿›ç¨‹æµ‹è¯•å®Œæˆï¼Œä¸»åŠ¨é€€å‡º

[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 14)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.85) - No evidence of any agent decision error (no tool s
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct data_pipeline: other_errors (confidence: 0.65) - No evidence of any agent decision or tool usage: t
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> data_pipeline (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.68) - Error arose before any agent tool choice or action
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 45)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct data_pipeline: sequence_order_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.62) - No agent decision could be evaluated because there
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.65) - Insufficient information to determine which agent 
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 48)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct api_integration: other_errors (confidence: 0.85) - No agent decision or tool usage could be evaluated
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> api_integration (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct basic_task: other_errors (confidence: 0.75) - No detectable agent decision error (tool_selection
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> basic_task (total: 51)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: other_errors (confidence: 0.85) - No tools were executed and the error is labeled 'U
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 49)
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No actionable agent decision can be evaluated beca
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> multi_stage_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct simple_task: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-32b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-NEW] qwen2.5-32b-instruct simple_task: tool_selection_errors (confidence: 0.65) - No tool was selected or executed; the agent did no
[V3_UPDATE] æ›´æ–°ç»Ÿè®¡å®Œæˆ: qwen2.5-32b-instruct -> baseline -> simple_task (total: 51)
[INFO] æœ€ç»ˆåˆå¹¶å®Œæˆ: 71 ä¸ªæ–‡ä»¶
2025-08-31 16:48:10,482 - smart_result_collector - INFO - SmartResultCollector æ­£åœ¨å…³é—­...
2025-08-31 16:48:10,482 - smart_result_collector - INFO - SmartResultCollector å·²å…³é—­
INFO:__main__:âœ… åˆ†ç‰‡3å®Œæˆ
INFO:__main__:ğŸ“Š å¹¶å‘æ‰§è¡Œç»“æœ: 3/3 åˆ†ç‰‡æˆåŠŸ
INFO:__main__:âœ… Key1: å®Œæˆ qwen2.5-32b-instruct-easy
INFO:__main__:æœ€ç»ˆåˆ©ç”¨ç‡: 1.1%
=== æµ‹è¯•ç»“æŸæ—¶é—´: 2025å¹´ 8æœˆ31æ—¥ æ˜ŸæœŸæ—¥ 16æ—¶48åˆ†12ç§’ EDT ===
=== æµ‹è¯•ç”¨æ—¶: 1138ç§’ ===
