===== 分片 qwen2.5-72b-instruct_easy_key2 =====
时间: 2025-08-20T22:25:56.465681
模型: qwen2.5-72b-instruct
实例: qwen-key2
命令: python -u smart_batch_runner.py --model qwen2.5-72b-instruct --deployment qwen-key2 --prompt-types optimal --difficulty easy --task-types all --num-instances 1 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[22:25:58.372] 2025-08-20 22:25:58,371 - faiss.loader - INFO - Loading faiss.
[22:25:58.388] 2025-08-20 22:25:58,387 - faiss.loader - INFO - Successfully loaded faiss.
[22:25:59.626] [INFO] 使用Parquet存储格式
[22:26:00.102] [INFO] 使用Parquet存储格式
[22:26:00.108] [INFO] 使用PARQUET存储格式
[22:26:00.109] 
[22:26:00.109] ============================================================
[22:26:00.109] 智能批测试: qwen2.5-72b-instruct (idealab)
[22:26:00.109] Prompt types: ['optimal']
[22:26:00.109] 难度: easy
[22:26:00.109] 目标: 每种配置 1 个实例
[22:26:00.109] ============================================================
[22:26:00.166] ○ simple_task         :   0/  1 已完成 (需要补充 1 个)
[22:26:00.174] ○ basic_task          :   0/  1 已完成 (需要补充 1 个)
[22:26:00.179] ○ data_pipeline       :   0/  1 已完成 (需要补充 1 个)
[22:26:00.184] ○ api_integration     :   0/  1 已完成 (需要补充 1 个)
[22:26:00.188] ○ multi_stage_pipeline:   0/  1 已完成 (需要补充 1 个)
[22:26:00.188] 
[22:26:00.188] ⏳ 需要运行 5 个新测试
[22:26:00.188] 
[22:26:00.188] ▶ 准备 simple_task (1 个实例)...
[22:26:00.188] 
[22:26:00.188] ▶ 准备 basic_task (1 个实例)...
[22:26:00.188] 
[22:26:00.188] ▶ 准备 data_pipeline (1 个实例)...
[22:26:00.188] 
[22:26:00.188] ▶ 准备 api_integration (1 个实例)...
[22:26:00.188] 
[22:26:00.188] ▶ 准备 multi_stage_pipeline (1 个实例)...
[22:26:00.188] 
[22:26:00.188] ▶ 开始执行 5 个测试...
[22:26:00.188] 📦 批量提交模式：每20个测试保存一次
[22:26:00.188] ⚠️  检测到idealab API，调整并发: workers=3, qps=5.0
[22:26:00.190] 2025-08-20 22:26:00,190 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[22:26:00.299] 2025-08-20 22:26:00,299 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[22:26:00.300] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1748d96a0>
[22:26:00.300] 2025-08-20 22:26:00,299 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[22:26:00.300] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - ============================================================
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - Batch test runner initialized
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_222600.log
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - ============================================================
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - Running 5 tests with 3 workers, QPS limit: 5.0
[22:26:00.300] 2025-08-20 22:26:00,300 - batch_test_runner - INFO - Initializing test components...
[22:26:00.597] 2025-08-20 22:26:00,597 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[22:26:00.597] 2025-08-20 22:26:00,597 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[22:26:00.597] 2025-08-20 22:26:00,597 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[22:26:00.597] [DEBUG] Creating new ToolCapabilityManager instance
[22:26:00.597] [OperationEmbeddingIndex] Initializing with unified API client manager
[22:26:00.597] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[22:26:00.597] 2025-08-20 22:26:00,597 - api_client_manager - INFO - Loaded configuration from config/config.json
[22:26:00.606] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[22:26:00.606] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[22:26:00.606] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[22:26:01.487] 2025-08-20 22:26:01,487 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[22:26:01.490] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[22:26:01.548] [INFO] Loaded 4150 embeddings from persistent cache
[22:26:01.548] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[22:26:01.549] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[22:26:01.549] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[22:26:01.549] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[22:26:01.561] [INFO] Successfully loaded FAISS index with dimension 3072
[22:26:01.561] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[22:26:01.561] [INFO] Loaded 15 operations with dimension 3072
[22:26:01.561] [INFO] Successfully loaded cached index
[22:26:01.561] [INFO] Operation semantic index initialized
[22:26:01.561] [INFO] Using device: cpu
[22:26:01.562] [INFO] Initialized tool success tracking attributes
[22:26:01.562] [INFO] Initializing embedding manager for enhanced tool selection
[22:26:01.562] [MCPEmbeddingManager] Creating new singleton instance
[22:26:01.562] [MCPEmbeddingManager] Initializing with unified API client manager
[22:26:01.569] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[22:26:01.569] [MCPEmbeddingManager] Client initialized successfully
[22:26:01.569] 2025-08-20 22:26:01,569 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[22:26:01.814] 2025-08-20 22:26:01,814 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[22:26:02.191] 2025-08-20 22:26:02,191 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[22:26:02.191] 2025-08-20 22:26:02,191 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[22:26:02.220] 2025-08-20 22:26:02,220 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[22:26:02.397] 2025-08-20 22:26:02,397 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[22:26:02.789] 2025-08-20 22:26:02,788 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[22:26:02.789] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[22:26:02.789] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[22:26:02.789] 2025-08-20 22:26:02,789 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[22:26:03.402] 2025-08-20 22:26:03,401 - mcp_embedding_manager - INFO - FAISS index loaded
[22:26:03.402] 2025-08-20 22:26:03,402 - mcp_embedding_manager - INFO - Updated dimension to 3072
[22:26:03.402] 2025-08-20 22:26:03,402 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[22:26:03.404] [SUCCESS] Loaded 30 tool embeddings
[22:26:03.404] 2025-08-20 22:26:03,404 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[22:26:03.404] [SUCCESS] Embedding manager initialized with 30 tools
[22:26:03.404] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[22:26:03.404] [INFO] Loading full MCP protocol registry...
[22:26:03.406] 2025-08-20 22:26:03,406 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[22:26:03.406] [INFO] Loaded full tool registry with 30 tools
[22:26:03.406] 2025-08-20 22:26:03,406 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[22:26:03.406] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[22:26:03.407] [INFO] Embedding manager ready with 30 tools
[22:26:03.407] [WARNING] Embedding manager exists but has no embeddings
[22:26:03.407] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[22:26:03.407] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[22:26:03.408] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[22:26:03.408] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[22:26:03.408] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[22:26:03.408] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[22:26:03.408] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[22:26:03.408] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[22:26:03.408] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[22:26:03.408] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[22:26:03.408] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[22:26:03.408] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[22:26:03.408] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[22:26:03.408] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[22:26:03.408] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[22:26:03.408] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[22:26:03.408] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[22:26:03.408] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[22:26:03.408] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[22:26:03.408] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[22:26:03.408] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[22:26:03.408] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[22:26:03.408] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[22:26:03.408] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[22:26:03.408] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[22:26:03.408] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[22:26:03.408] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[22:26:03.408] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[22:26:03.408] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[22:26:03.408] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[22:26:03.408] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[22:26:03.408] 2025-08-20 22:26:03,408 - mdp_workflow_generator - INFO - Loaded 30 tools
[22:26:03.408] [INFO] Setting default state_dim based on loaded tools
[22:26:03.408] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[22:26:03.408] 2025-08-20 22:26:03,408 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[22:26:03.408] [INFO] Setting default action_dim based on loaded tools
[22:26:03.408] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[22:26:03.408] 2025-08-20 22:26:03,408 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[22:26:03.408] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[22:26:03.408] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[22:26:03.408] [INFO] ⚡ Will use pre-generated workflows or random policy
[22:26:03.408] 2025-08-20 22:26:03,408 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[22:26:03.408] [INFO] Initializing TaskManager...
[22:26:04.521] 2025-08-20 22:26:04,521 - unified_training_manager - INFO - Using device: cpu
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO - Task filtering results:
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO -   Total: 5040 -> 5040
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO -   simple_task: 320 -> 320
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[22:26:04.645] 2025-08-20 22:26:04,645 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[22:26:04.647] 2025-08-20 22:26:04,647 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[22:26:04.647] [TaskManager] Difficulty level 'easy': 1096 tasks
[22:26:04.647] [TaskManager] Difficulty level 'very_easy': 856 tasks
[22:26:04.647] [TaskManager] Difficulty level 'medium': 1136 tasks
[22:26:04.647] [TaskManager] Difficulty level 'hard': 1096 tasks
[22:26:04.647] [TaskManager] Difficulty level 'very_hard': 856 tasks
[22:26:04.649] [INFO] TaskManager initialized with 5040 tasks
[22:26:04.649] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[22:26:04.649] [INFO] Initializing ToolCallVerifier...
[22:26:04.650] [INFO] ToolCallVerifier initialized with 30 tools
[22:26:04.650] [INFO] Output tools identified: 1
[22:26:04.650] [INFO] Component initialization status:
[22:26:04.650]   - embedding_manager: initialized
[22:26:04.650]   - task_manager: initialized
[22:26:04.650]   - output_verifier: initialized
[22:26:04.650]   - tool_capability_manager: initialized
[22:26:04.650]   - tool_success_rates: initialized with 0 entries
[22:26:04.650] [INFO] MDPWorkflowGenerator initialization complete
[22:26:04.650] 2025-08-20 22:26:04,650 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[22:26:04.650] 2025-08-20 22:26:04,650 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[22:26:04.650] 2025-08-20 22:26:04,650 - batch_test_runner - INFO -   - task_manager: ✓
[22:26:04.650] 2025-08-20 22:26:04,650 - batch_test_runner - INFO -   - output_verifier: ✓
[22:26:04.650] 2025-08-20 22:26:04,650 - batch_test_runner - INFO -   - embedding_manager: ✓
[22:26:04.650] 2025-08-20 22:26:04,650 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[22:26:04.650] 2025-08-20 22:26:04,650 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[22:26:04.650] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:04.650] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:04.650] [FlawedWorkflowGenerator] Initialized with 30 tools
[22:26:04.650] [FlawedWorkflowGenerator] RAG support: disabled
[22:26:04.651] DEBUG: Checking generator attributes
[22:26:04.651]   - has tool_capabilities: True
[22:26:04.651]   - has tool_capability_manager: True
[22:26:04.651]   - has task_manager: True
[22:26:04.651] [INFO] Loaded 30 tools from generator
[22:26:04.651] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[22:26:04.651] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:04.651] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:04.651] [INFO] Initializing LLM client using APIClientManager
[22:26:04.658] [INFO] Using Azure OpenAI client
[22:26:04.658] [DEBUG] Checking if generator has tool_capability_manager attribute
[22:26:04.658] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[22:26:04.658] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:04.658] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:04.658] [FlawedWorkflowGenerator] Initialized with 30 tools
[22:26:04.658] [FlawedWorkflowGenerator] RAG support: enabled
[22:26:04.658] [INFO] FlawedWorkflowGenerator initialized successfully
[22:26:04.658] [INFO] Initializing StableScorer for Phase 2 scoring
[22:26:04.658] <tool_capability_manager.ToolCapabilityManager object at 0x31d8cef00>
[22:26:04.658] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:04.658] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:04.658] [INFO] Loaded tool success history for 0 tools
[22:26:04.658] [INFO] StableScorer initialized with semantic capability
[22:26:04.658] [INFO] StableScorer initialized successfully
[22:26:04.658] [INFO] Loading task instances...
[22:26:04.658] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[22:26:04.667] [INFO] Loaded 630 task instances
[22:26:04.667] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[22:26:04.667] 2025-08-20 22:26:04,667 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[22:26:04.667] 2025-08-20 22:26:04,667 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[22:26:05.036] 2025-08-20 22:26:05,036 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[22:26:05.036] 2025-08-20 22:26:05,036 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[22:26:05.053] 2025-08-20 22:26:05,053 - batch_test_runner - INFO - Initialization complete
[22:26:05.081] 2025-08-20 22:26:05,081 - batch_test_runner - INFO - Starting batch test with 5 tasks, 3 workers
[22:26:05.081] 2025-08-20 22:26:05,081 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[22:26:05.082] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[22:26:05.088] 2025-08-20 22:26:05,088 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
[22:26:05.095] 2025-08-20 22:26:05,095 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[22:26:05.095] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[22:26:05.095] [InteractiveExecutor] Using prompt type: optimal for API key selection
[22:26:05.095] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[22:26:05.095] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:05.095] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:05.095] 2025-08-20 22:26:05,095 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[22:26:05.471] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[22:26:05.473] 2025-08-20 22:26:05,471 - mcp_embedding_manager - INFO - FAISS index loaded
[22:26:05.473] 2025-08-20 22:26:05,472 - mcp_embedding_manager - INFO - Updated dimension to 3072
[22:26:05.473] 2025-08-20 22:26:05,472 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[22:26:05.484] [INFO] Tool embedding index loaded successfully
[22:26:05.523] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[22:26:05.523] [INFO] Operation semantic index initialized
[22:26:05.528] 
[22:26:05.528] [TURN 1/10]
[22:26:05.560] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:05.567] 2025-08-20 22:26:05,567 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[22:26:05.567] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[22:26:05.567] [InteractiveExecutor] Using prompt type: optimal for API key selection
[22:26:05.569] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[22:26:05.570] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:05.570] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:05.570] 2025-08-20 22:26:05,570 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[22:26:05.608] 2025-08-20 22:26:05,608 - mcp_embedding_manager - INFO - FAISS index loaded
[22:26:05.608] 2025-08-20 22:26:05,608 - mcp_embedding_manager - INFO - Updated dimension to 3072
[22:26:05.608] 2025-08-20 22:26:05,608 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[22:26:05.611] [INFO] Tool embedding index loaded successfully
[22:26:05.611] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[22:26:05.611] [INFO] Operation semantic index initialized
[22:26:05.612] 
[22:26:05.612] [TURN 1/10]
[22:26:05.612] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:05.653] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[22:26:05.689] 2025-08-20 22:26:05,688 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[22:26:05.689] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[22:26:05.690] [InteractiveExecutor] Using prompt type: optimal for API key selection
[22:26:05.690] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[22:26:05.691] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:05.691] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:05.691] 2025-08-20 22:26:05,691 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[22:26:05.711] 2025-08-20 22:26:05,711 - mcp_embedding_manager - INFO - FAISS index loaded
[22:26:05.711] 2025-08-20 22:26:05,711 - mcp_embedding_manager - INFO - Updated dimension to 3072
[22:26:05.711] 2025-08-20 22:26:05,711 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[22:26:05.714] [INFO] Tool embedding index loaded successfully
[22:26:05.715] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[22:26:05.715] [INFO] Operation semantic index initialized
[22:26:05.715] 
[22:26:05.715] [TURN 1/10]
[22:26:05.716] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:06.538] 2025-08-20 22:26:06,538 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:06.540] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b0753b8-e6ea-9203-9788-8b4a39953775"}, traceId: 215040aa17557539663151750ee916'}
[22:26:06.540] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[22:26:06.542] 2025-08-20 22:26:06,542 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:06.543] 2025-08-20 22:26:06,543 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:06.543] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"30853cf1-8080-9482-a659-f42f14e0d3fa"}, traceId: 215040be17557539663086188edfc4'}
[22:26:06.544] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6af92b2e-561c-9f45-a14e-a23b30bbfa36"}, traceId: 215042f817557539663155055e27d2'}
[22:26:06.544] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[22:26:06.544] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[22:26:07.425] 2025-08-20 22:26:07,424 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:07.426] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"42b267a4-8945-95f3-b061-1c33403d094d"}, traceId: 215040be17557539672156191edfc4'}
[22:26:07.426] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[22:26:07.975] 2025-08-20 22:26:07,974 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:07.976] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1762769-3998-97bd-a72a-9409a864b654"}, traceId: 215040aa17557539677741757ee916'}
[22:26:07.976] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[22:26:08.713] 2025-08-20 22:26:08,713 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:08.714] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e66234cb-53ac-997e-aa6b-f33bb08a1adf"}, traceId: 215040be17557539685016196edfc4'}
[22:26:08.714] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[22:26:09.052] 2025-08-20 22:26:09,052 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:09.054]   [SEARCH] Query: file reader
[22:26:09.055] 
[22:26:09.055] [TURN 2/10]
[22:26:09.056] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:10.106] 2025-08-20 22:26:10,104 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:10.106] 2025-08-20 22:26:10,106 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:10.107]   [EARLY_EXIT] No actions taken, continuing...
[22:26:10.107] 
[22:26:10.107] [TURN 3/10]
[22:26:10.108] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8616ace5-26a2-9bf2-9f3a-73ece5fdd6c8"}, traceId: 215040aa17557539696731763ee916'}
[22:26:10.108] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[22:26:10.108] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:11.028] 2025-08-20 22:26:11,028 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:11.029]   [EARLY_EXIT] No actions taken, continuing...
[22:26:11.029] 
[22:26:11.029] [TURN 4/10]
[22:26:11.029] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:11.804] 2025-08-20 22:26:11,804 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:11.810] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e313de86-86d7-9723-b657-06f308686844"}, traceId: 215040be17557539716006212edfc4'}
[22:26:11.810] [RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[22:26:11.882] 2025-08-20 22:26:11,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:11.884]   [EARLY_EXIT] No actions taken, continuing...
[22:26:11.884] 
[22:26:11.884] [TURN 5/10]
[22:26:11.885] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:12.214] 2025-08-20 22:26:12,214 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:12.215] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f283c87-f611-92eb-8102-c8d160d57eb6"}, traceId: 215042f817557539720125112e27d2'}
[22:26:12.215] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[22:26:12.938] 2025-08-20 22:26:12,937 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:12.939] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed51fb98-ba28-9ae4-9f46-e5e58f0b4445"}, traceId: 215040aa17557539727211770ee916'}
[22:26:12.939] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[22:26:13.963] 2025-08-20 22:26:13,962 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:13.966]   [EARLY_EXIT] No actions taken, continuing...
[22:26:13.966] 
[22:26:13.966] [TURN 6/10]
[22:26:13.969] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:15.036] 2025-08-20 22:26:15,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:15.038]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[22:26:15.038] 
[22:26:15.038] [TURN 7/10]
[22:26:15.039] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:15.968] 2025-08-20 22:26:15,967 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:15.969]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[22:26:15.969] 
[22:26:15.969] [TURN 8/10]
[22:26:15.970] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:16.445] 2025-08-20 22:26:16,445 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:16.446] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe7dba12-1ef4-95ab-88ea-cab39cdab136"}, traceId: 215040aa17557539762401781ee916'}
[22:26:16.446] [ERROR] Max retries reached after 5 attempts
[22:26:16.446] [API_FAILURE] All retries exhausted
[22:26:16.446]   [API_FAILURE] API failed (timeout or max retries)
[22:26:16.450] [DEBUG] Got result for task: has_result=True, save_logs=True
[22:26:16.450] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[22:26:16.450] [AI_DEBUG] 生成的txt_content长度: 4710
[22:26:16.450] [AI_DEBUG] _ai_classify_with_txt_content called:
[22:26:16.450]   - use_ai_classification=True
[22:26:16.450]   - ai_classifier=True
[22:26:16.450]   - txt_content_len=4710
[22:26:16.450]   - task_model=qwen2.5-72b-instruct
[22:26:16.450] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[22:26:16.452] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[22:26:16.461] 2025-08-20 22:26:16,461 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[22:26:16.462] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[22:26:16.462] [InteractiveExecutor] Using prompt type: optimal for API key selection
[22:26:16.462] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[22:26:16.462] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:16.462] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:16.463] 2025-08-20 22:26:16,463 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[22:26:16.561] 2025-08-20 22:26:16,561 - mcp_embedding_manager - INFO - FAISS index loaded
[22:26:16.561] 2025-08-20 22:26:16,561 - mcp_embedding_manager - INFO - Updated dimension to 3072
[22:26:16.561] 2025-08-20 22:26:16,561 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[22:26:16.566] [INFO] Tool embedding index loaded successfully
[22:26:16.585] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[22:26:16.586] [INFO] Operation semantic index initialized
[22:26:16.587] 
[22:26:16.587] [TURN 1/10]
[22:26:16.593] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:16.814] 2025-08-20 22:26:16,814 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:16.819]   [SEARCH] Query: data validation parser
[22:26:16.821] 
[22:26:16.822] [TURN 2/10]
[22:26:16.822] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:16.856] 2025-08-20 22:26:16,856 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:16.858]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[22:26:16.858] 
[22:26:16.858] [TURN 9/10]
[22:26:16.860] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:17.211] 2025-08-20 22:26:17,211 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:17.212] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70c9491d-aa46-9924-a558-1c5a120602bc"}, traceId: 215040be17557539769526231edfc4'}
[22:26:17.212] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[22:26:17.354] 2025-08-20 22:26:17,354 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:17.358] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e752030f-ca93-92ec-ac25-f9853a2de512"}, traceId: 215044eb17557539771483197e8041'}
[22:26:17.358] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[22:26:17.851] 2025-08-20 22:26:17,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:17.852]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[22:26:17.852] 
[22:26:17.852] [TURN 10/10]
[22:26:17.869] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:18.748] 2025-08-20 22:26:18,748 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:18.750] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b5a1181e-c1f9-9a90-9c45-6898e895b63e"}, traceId: 215044eb17557539785193200e8041'}
[22:26:18.751] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[22:26:18.849] 2025-08-20 22:26:18,849 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:18.852]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[22:26:18.852] [ASSISTED] Task received 5 format helps, final result: failure
[22:26:18.856] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[22:26:18.864] 2025-08-20 22:26:18,864 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[22:26:18.864] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[22:26:18.864] [InteractiveExecutor] Using prompt type: optimal for API key selection
[22:26:18.864] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[22:26:18.864] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13385005776)
[22:26:18.864] [MCPEmbeddingManager] Current cache size: 30 embeddings
[22:26:18.864] 2025-08-20 22:26:18,864 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[22:26:18.885] 2025-08-20 22:26:18,885 - mcp_embedding_manager - INFO - FAISS index loaded
[22:26:18.885] 2025-08-20 22:26:18,885 - mcp_embedding_manager - INFO - Updated dimension to 3072
[22:26:18.885] 2025-08-20 22:26:18,885 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[22:26:18.887] [INFO] Tool embedding index loaded successfully
[22:26:18.888] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[22:26:18.888] [INFO] Operation semantic index initialized
[22:26:18.888] 
[22:26:18.888] [TURN 1/10]
[22:26:18.889] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:19.141] 2025-08-20 22:26:19,141 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:19.143]   [INFO] Tool info request: data_processing_parser
[22:26:19.143] 
[22:26:19.143] [TURN 3/10]
[22:26:19.143] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:19.807] 2025-08-20 22:26:19,807 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:19.808] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"36c37acd-6e8f-9563-b9b3-1ade995c2a43"}, traceId: 2150456617557539795486289e8055'}
[22:26:19.808] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[22:26:20.021] 2025-08-20 22:26:20,021 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:20.022]   [EARLY_EXIT] No actions taken, continuing...
[22:26:20.022] 
[22:26:20.022] [TURN 4/10]
[22:26:20.023] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:20.239] 2025-08-20 22:26:20,238 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:20.239] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c95e15ae-dc90-935c-b2c2-4cb71b9744aa"}, traceId: 215044eb17557539799863208e8041'}
[22:26:20.239] [RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[22:26:20.373] 2025-08-20 22:26:20,372 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:20.373] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"109462fc-920d-92ac-b1bb-5ddb32ee53b5"}, traceId: 215040be17557539801536248edfc4'}
[22:26:20.373] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[22:26:21.898] 2025-08-20 22:26:21,896 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:21.898] 2025-08-20 22:26:21,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:21.898] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4ccfa936-7316-98d0-9e73-a85bf342556e"}, traceId: 2150456617557539812046294e8055'}
[22:26:21.898] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[22:26:21.898] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c9d5dd14-d787-9fde-a8a1-153b9878e38d"}, traceId: 215040be17557539813446254edfc4'}
[22:26:21.898] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[22:26:23.220] 2025-08-20 22:26:23,220 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:23.224]   [SEARCH] Query: network api fetch
[22:26:23.224] 
[22:26:23.224] [TURN 2/10]
[22:26:23.225] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:23.441] 2025-08-20 22:26:23,441 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[22:26:23.445] [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[22:26:23.447] [DEBUG] Got result for task: has_result=True, save_logs=True
[22:26:23.447] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[22:26:23.447] [AI_DEBUG] 生成的txt_content长度: 14655
[22:26:23.447] [AI_DEBUG] _ai_classify_with_txt_content called:
[22:26:23.447]   - use_ai_classification=True
[22:26:23.447]   - ai_classifier=True
[22:26:23.447]   - txt_content_len=14655
[22:26:23.447]   - task_model=qwen2.5-72b-instruct
[22:26:23.447] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[22:26:23.700] 2025-08-20 22:26:23,700 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:23.700] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad3e8cf0-465a-9ad4-9970-66e2f854020f"}, traceId: 215040be17557539834796265edfc4'}
[22:26:23.700] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[22:26:24.061] 2025-08-20 22:26:24,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:24.062] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5edc63e0-f576-961a-8c0e-227f4f2d1b02"}, traceId: 2150456617557539838386300e8055'}
[22:26:24.062] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[22:26:24.141] 2025-08-20 22:26:24,141 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:24.145]   [EARLY_EXIT] No actions taken, continuing...
[22:26:24.145] 
[22:26:24.145] [TURN 3/10]
[22:26:24.146] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:24.475] 2025-08-20 22:26:24,474 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:24.478] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70e03c8e-9816-96a2-8daf-eee7d8012168"}, traceId: 215044eb17557539842673226e8041'}
[22:26:24.478] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[22:26:26.195] 2025-08-20 22:26:26,194 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:26.195] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a76daef-10e8-90fb-b5a3-96132a6d455d"}, traceId: 215044eb17557539856633233e8041'}
[22:26:26.196] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[22:26:26.557] 2025-08-20 22:26:26,556 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:26.558] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66846a3a-b176-921a-806e-20bac6ff56df"}, traceId: 215040be17557539860476272edfc4'}
[22:26:26.558] [RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[22:26:27.640] 2025-08-20 22:26:27,640 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:27.641] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ccafa1d0-4d04-9452-9487-8ad783197476"}, traceId: 2150456617557539874106313e8055'}
[22:26:27.641] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[22:26:28.704] 2025-08-20 22:26:28,704 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:28.704] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01ba9115-5013-96a1-9ea6-5580eb509814"}, traceId: 215044eb17557539884473245e8041'}
[22:26:28.704] [RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[22:26:30.252] 2025-08-20 22:26:30,251 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[22:26:30.257] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.75
[22:26:31.018] 2025-08-20 22:26:31,018 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:31.019] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b17e08fa-e375-9a61-8bdb-f0b03b1ec06d"}, traceId: 215040be17557539906386289edfc4'}
[22:26:31.019] [ERROR] Max retries reached after 5 attempts
[22:26:31.019] [API_FAILURE] All retries exhausted
[22:26:31.019]   [API_FAILURE] API failed (timeout or max retries)
[22:26:31.024] [DEBUG] Got result for task: has_result=True, save_logs=True
[22:26:31.025] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[22:26:31.025] [AI_DEBUG] 生成的txt_content长度: 9664
[22:26:31.025] [AI_DEBUG] _ai_classify_with_txt_content called:
[22:26:31.025]   - use_ai_classification=True
[22:26:31.025]   - ai_classifier=True
[22:26:31.025]   - txt_content_len=9664
[22:26:31.025]   - task_model=qwen2.5-72b-instruct
[22:26:31.025] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[22:26:31.048] 2025-08-20 22:26:31,048 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:31.049] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"acbcb7f7-4540-94c3-99e5-8ba5f4d7a26f"}, traceId: 2150456617557539907596343e8055'}
[22:26:31.049] [ERROR] Max retries reached after 5 attempts
[22:26:31.049] [API_FAILURE] All retries exhausted
[22:26:31.049]   [API_FAILURE] API failed (timeout or max retries)
[22:26:32.638] 2025-08-20 22:26:32,637 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:32.640]   [EARLY_EXIT] No actions taken, continuing...
[22:26:32.640] 
[22:26:32.640] [TURN 4/10]
[22:26:32.640] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:33.364] 2025-08-20 22:26:33,364 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:33.379] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a452ad8-a5cd-982e-915e-b65984e74900"}, traceId: 215044eb17557539927593266e8041'}
[22:26:33.379] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[22:26:35.100] 2025-08-20 22:26:35,100 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:35.103] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dc14369a-1137-92f0-9536-28a448408bff"}, traceId: 215044eb17557539949003275e8041'}
[22:26:35.103] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[22:26:36.307] 2025-08-20 22:26:36,306 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:36.310] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6256c92-b1a0-910a-9c4b-10aca6fa4ac0"}, traceId: 215044eb17557539960643278e8041'}
[22:26:36.310] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[22:26:38.923] 2025-08-20 22:26:38,923 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:38.925]   [EARLY_EXIT] No actions taken, continuing...
[22:26:38.925] 
[22:26:38.925] [TURN 5/10]
[22:26:38.925] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:39.824] 2025-08-20 22:26:39,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:39.825]   [EARLY_EXIT] No actions taken, continuing...
[22:26:39.826] 
[22:26:39.826] [TURN 6/10]
[22:26:39.826] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:40.165] 2025-08-20 22:26:40,165 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:40.168] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1bf42892-52f1-9811-9418-f6211c69cdf5"}, traceId: 215044eb17557539999453297e8041'}
[22:26:40.168] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[22:26:42.222] 2025-08-20 22:26:42,222 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:42.222] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03c16bcd-ce16-9bc1-81d4-a366b3330aca"}, traceId: 215044eb17557540017313305e8041'}
[22:26:42.222] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[22:26:42.252] 2025-08-20 22:26:42,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[22:26:42.253] [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[22:26:42.255] [DEBUG] Got result for task: has_result=True, save_logs=True
[22:26:42.255] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[22:26:42.255] [AI_DEBUG] 生成的txt_content长度: 4646
[22:26:42.255] [AI_DEBUG] _ai_classify_with_txt_content called:
[22:26:42.255]   - use_ai_classification=True
[22:26:42.255]   - ai_classifier=True
[22:26:42.255]   - txt_content_len=4646
[22:26:42.255]   - task_model=qwen2.5-72b-instruct
[22:26:42.255] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[22:26:44.644] 2025-08-20 22:26:44,644 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:44.646] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"19db31bf-822f-9995-b346-65eae74d0804"}, traceId: 215044eb17557540044473318e8041'}
[22:26:44.646] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[22:26:46.925] 2025-08-20 22:26:46,925 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:46.926]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[22:26:46.927] 
[22:26:46.927] [TURN 7/10]
[22:26:46.928] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:48.134] 2025-08-20 22:26:48,134 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:48.178]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[22:26:48.178] 
[22:26:48.178] [TURN 8/10]
[22:26:48.179] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:48.505] 2025-08-20 22:26:48,505 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[22:26:48.508] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d35438e5-1c14-923b-8dd1-d18f04f6f278"}, traceId: 215044eb17557540083013334e8041'}
[22:26:48.508] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[22:26:49.968] 2025-08-20 22:26:49,967 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:49.971]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[22:26:49.972] 
[22:26:49.972] [TURN 9/10]
[22:26:49.973] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:50.718] 2025-08-20 22:26:50,718 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[22:26:50.719] [AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[22:26:50.925] 2025-08-20 22:26:50,924 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:50.929]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[22:26:50.929] 
[22:26:50.929] [TURN 10/10]
[22:26:50.929] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[22:26:51.966] 2025-08-20 22:26:51,965 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[22:26:51.971]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[22:26:51.971] [ASSISTED] Task received 5 format helps, final result: failure
[22:26:51.974] [DEBUG] Got result for task: has_result=True, save_logs=True
[22:26:51.974] [AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[22:26:51.974] [AI_DEBUG] 生成的txt_content长度: 14750
[22:26:51.975] [AI_DEBUG] _ai_classify_with_txt_content called:
[22:26:51.975]   - use_ai_classification=True
[22:26:51.975]   - ai_classifier=True
[22:26:51.975]   - txt_content_len=14750
[22:26:51.975]   - task_model=qwen2.5-72b-instruct
[22:26:51.975] [AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[22:26:58.746] 2025-08-20 22:26:58,745 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[22:26:58.748] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[22:26:58.750] 
[22:26:58.750] [INFO] Batch writing 5 records to database (qwen2.5-72b-instruct:5)
[22:26:58.750] 2025-08-20 22:26:58,750 - batch_test_runner - INFO - Batch writing 5 records to database (qwen2.5-72b-instruct:5)
[22:26:58.750] [INFO] Successfully wrote 5/5 records (qwen2.5-72b-instruct:5)
[22:26:58.750] 2025-08-20 22:26:58,750 - batch_test_runner - INFO - Successfully wrote 5/5 records (qwen2.5-72b-instruct:5)
[22:26:58.751] [INFO] 数据已同步到Parquet存储
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO - Database saved successfully
[22:26:58.751] 
[22:26:58.751] 📊 Statistics saved to: /Users/ruichengao/WorkflowBench/scale_up/scale_up/pilot_bench_cumulative_results/master_database.json
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO - Statistics saved to: /Users/ruichengao/WorkflowBench/scale_up/scale_up/pilot_bench_cumulative_results/master_database.json
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO - ============================================================
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO - Batch test completed at 2025-08-20T22:26:58.751498
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO - Summary:
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO -   - Total tests: 5
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO -   - Successful: 0
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO -   - Failed: 5
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO -   - Success rate: 0.0%
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250820_222600.log
[22:26:58.751] 2025-08-20 22:26:58,751 - batch_test_runner - INFO - ============================================================
[22:26:58.751] 
[22:26:58.751] ✅ 批测试完成
[22:26:58.751]    成功: 0/5
[22:26:58.751]    失败: 5/5
[22:26:58.752] 
[22:26:58.752] 📤 最终保存5个测试结果...
[22:26:58.752] [DEBUG] 创建新的manager实例: key=True_
[22:26:58.752] ✅ 已保存 5 个测试结果到数据库
[22:26:58.831] [INFO] 已将 5 个汇总写入Parquet
[22:26:58.901] [INFO] 刷新manager缓存: key=True_

==================================================
分片 qwen2.5-72b-instruct_easy_key2 完成
退出码: 0
总行数: 606
运行时间: 64.0秒
时间: 2025-08-20T22:27:00.480434
