=== ÊµãËØïÂºÄÂßãÊó∂Èó¥: 2025Âπ¥ 8Êúà31Êó• ÊòüÊúüÊó• 15Êó∂02ÂàÜ06Áßí EDT ===
=== ÊâßË°åÂëΩ‰ª§: python3 ./ultra_parallel_runner.py --model Llama-3.3-70B-Instruct --prompt-types baseline --difficulty easy --task-types all --num-instances 20 --rate-mode fixed --max-workers 50 ===
INFO:__main__:ÂàùÂßãÂåñÂÆû‰æãÊ±†: 17‰∏™ÂÆû‰æã (2‰∏™Azure + 6‰∏™IdealLab)
INFO:__main__:üìú ‰ΩøÁî®‰º†ÁªüÊï∞ÊçÆÂ∫ìÂÜôÂÖ•Ê®°Âºè
INFO:__main__:ËµÑÊ∫êÊ±†Áä∂ÊÄÅ: 17‰∏™ÂÆû‰æã, ÂÆπÈáè1306
INFO:__main__:
üî• ÂêØÂä®Ë∂ÖÈ´òÂπ∂Ë°åÊµãËØï
INFO:__main__:   Ê®°Âûã: Llama-3.3-70B-Instruct
INFO:__main__:   PromptÁ±ªÂûã: baseline
INFO:__main__:   ÈöæÂ∫¶: easy
INFO:__main__:   ÂÆû‰æãÊï∞: 20
INFO:__main__:   ÈÄüÁéáÊ®°Âºè: fixed
INFO:__main__:LlamaÊ®°Âûã Llama-3.3-70B-Instruct ÊöÇÊó∂‰ΩøÁî®ÂçïÈÉ®ÁΩ≤Á≠ñÁï•ÔºàÈÅøÂÖçÂ§öÈÉ®ÁΩ≤Âπ∂ÂèëÈóÆÈ¢òÔºâ
INFO:__main__:ÂàõÂª∫‰ªªÂä°ÂàÜÁâá: 1‰∏™ÂÆû‰æãÂπ∂Ë°å
INFO:__main__:üìä ÂàõÂª∫‰∫Ü 1 ‰∏™Âπ∂Ë°åÂàÜÁâá
INFO:__main__:  AzureÂºÄÊ∫êÊ®°ÂûãËá™ÂÆö‰πâ: 1‰∏™prompt √ó 50 = 50 workers
INFO:__main__:üöÄ ÂêØÂä®ÂàÜÁâá Llama-3.3-70B-Instruct_easy_0: Llama-3.3-70B-Instruct
INFO:__main__:   ÂÆû‰æãÊï∞: 20, Ê®°Âûã: Llama-3.3-70B-Instruct
INFO:__main__:   ËÆæÁΩÆSTORAGE_FORMAT=jsonÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆUSE_PARTIAL_LOADING=trueÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆTASK_LOAD_COUNT=20ÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆSKIP_MODEL_LOADING=trueÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆUSE_RESULT_COLLECTOR=trueÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆKMP_DUPLICATE_LIB_OK=TRUEÁªôÂ≠êËøõÁ®ã
INFO:__main__:   ËÆæÁΩÆPYTHONMALLOC=mallocÁªôÂ≠êËøõÁ®ã
INFO:__main__:üöÄ Á¨¨‰∏Ä‰∏™ÂàÜÁâá Llama-3.3-70B-Instruct_easy_0 Á´ãÂç≥ÂêØÂä®
INFO:__main__:‚è≥ Âπ∂ÂèëÁ≠âÂæÖ 1 ‰∏™ÂàÜÁâáÂÆåÊàê...
2025-08-31 15:02:06,946 - faiss.loader - INFO - Loading faiss.
2025-08-31 15:02:06,961 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-31 15:02:07,897 - smart_result_collector - INFO - Ëá™Âä®‰øùÂ≠òÁ∫øÁ®ãÂ∑≤ÂêØÂä®
2025-08-31 15:02:07,897 - smart_result_collector - INFO - SmartResultCollectorÂàùÂßãÂåñÂÆåÊàê
2025-08-31 15:02:07,897 - smart_result_collector - INFO -   - ‰∏¥Êó∂ÁõÆÂΩï: temp_results
2025-08-31 15:02:07,897 - smart_result_collector - INFO -   - ÂÜÖÂ≠òÈòàÂÄº: 20
2025-08-31 15:02:07,897 - smart_result_collector - INFO -   - Êó∂Èó¥ÈòàÂÄº: 300Áßí
2025-08-31 15:02:07,897 - smart_result_collector - INFO -   - Ëá™Âä®‰øùÂ≠ò: 60Áßí
2025-08-31 15:02:07,897 - smart_result_collector - INFO -   - Ëá™ÈÄÇÂ∫îÈòàÂÄº: True
2025-08-31 15:02:07,897 - result_collector_adapter - INFO - ‚úÖ ‰ΩøÁî®SmartResultCollector
2025-08-31 15:02:07,897 - result_collector_adapter - INFO - AdaptiveResultCollectorÂàùÂßãÂåñÂÆåÊàêÔºå‰ΩøÁî®: smart
2025-08-31 15:02:07,900 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for gpt-5-nano
2025-08-31 15:02:07,954 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:02:07,954 - batch_test_runner - INFO - Âü∫‰∫éTXTÊñá‰ª∂ÁöÑAIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî® (‰ΩøÁî®gpt-5-nano)
2025-08-31 15:02:07,954 - batch_test_runner - INFO - ============================================================
2025-08-31 15:02:07,954 - batch_test_runner - INFO - Batch test runner initialized
2025-08-31 15:02:07,955 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-31 15:02:07,955 - batch_test_runner - INFO - Log file: logs/batch_test_20250831_150207.log
2025-08-31 15:02:07,955 - batch_test_runner - INFO - ============================================================
2025-08-31 15:02:07,955 - batch_test_runner - INFO - Running 100 tests with 50 workers, QPS limit: None
2025-08-31 15:02:07,955 - batch_test_runner - INFO - Initializing test components...
2025-08-31 15:02:08,495 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-31 15:02:08,495 - batch_test_runner - INFO - ‚ö° [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-31 15:02:08,495 - batch_test_runner - INFO - ‚ö° This saves ~350MB memory while keeping all functionality intact
2025-08-31 15:02:08,495 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-31 15:02:08,960 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:09,020 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:02:09,180 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:02:09,592 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-31 15:02:09,592 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-31 15:02:09,697 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-31 15:02:09,801 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-31 15:02:10,191 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-31 15:02:10,191 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:10,554 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:10,554 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:10,554 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:10,570 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-31 15:02:10,571 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:02:10,571 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-31 15:02:10,576 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-31 15:02:10,576 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-31 15:02:10,576 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-31 15:02:10,576 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-31 15:02:12,956 - unified_training_manager - INFO - Using device: cpu
2025-08-31 15:02:13,953 - unified_training_manager - INFO - Task filtering results:
2025-08-31 15:02:13,953 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-31 15:02:13,954 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-31 15:02:13,954 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-31 15:02:13,954 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-31 15:02:13,954 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-31 15:02:13,954 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-31 15:02:13,954 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-31 15:02:13,958 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-31 15:02:13,962 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-31 15:02:13,962 - batch_test_runner - INFO - ‚úÖ MDPWorkflowGenerator initialized successfully:
2025-08-31 15:02:13,962 - batch_test_runner - INFO -   - task_manager: ‚úì
2025-08-31 15:02:13,962 - batch_test_runner - INFO -   - output_verifier: ‚úì
2025-08-31 15:02:13,962 - batch_test_runner - INFO -   - embedding_manager: ‚úì
2025-08-31 15:02:13,962 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-31 15:02:13,962 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-31 15:02:13,985 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-31 15:02:13,987 - result_collector - INFO - ResultCollectorÂàùÂßãÂåñÔºå‰∏¥Êó∂ÁõÆÂΩï: temp_results
2025-08-31 15:02:13,987 - result_merger - INFO - ResultMergerÂàùÂßãÂåñÂÆåÊàê
2025-08-31 15:02:13,988 - result_merger - WARNING - Âè¶‰∏Ä‰∏™ÂêàÂπ∂Âô®Â∑≤Âú®ËøêË°å (PID: -1)
2025-08-31 15:02:14,006 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-31 15:02:14,007 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-31 15:02:14,503 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-31 15:02:14,503 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-31 15:02:14,582 - batch_test_runner - INFO - Initialization complete
2025-08-31 15:02:14,708 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
2025-08-31 15:02:14,709 - batch_test_runner - INFO - Starting batch test with 100 tasks, 50 workers
2025-08-31 15:02:14,709 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-31 15:02:14,715 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for Llama-3.3-70B-Instruct
2025-08-31 15:02:14,715 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,715 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,715 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,717 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,717 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,717 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,722 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,722 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,722 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,724 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,724 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,724 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,725 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,726 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,726 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,726 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,726 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,727 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,728 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,728 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,728 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,731 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,732 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,735 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,738 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,739 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,740 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,740 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,742 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,742 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,742 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,745 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,745 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,750 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,757 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,757 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,759 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,765 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,765 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,765 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,772 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,773 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,781 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,820 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,823 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,823 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,823 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,843 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:14,850 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:14,891 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,908 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,908 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,919 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,919 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,919 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,920 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:14,920 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:14,920 - mcp_embedding_manager - INFO - Index loaded successfully: 12 tools
2025-08-31 15:02:14,946 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:14,959 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:14,959 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:14,959 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:14,974 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:14,976 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:14,976 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:14,976 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:14,999 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:14,999 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:14,999 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,029 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,031 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,034 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,034 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,034 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,047 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,048 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,053 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,054 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,059 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,061 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,063 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,107 - batch_test_runner - INFO - Batch timeout set to 6000s (100.0 minutes) for 100 tasks
2025-08-31 15:02:15,081 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,107 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,122 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,122 - mcp_embedding_manager - INFO - FAISS index loaded
[INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè
[INFO] ‰ΩøÁî®JSONÂ≠òÂÇ®Ê†ºÂºè

============================================================
Êô∫ËÉΩÊâπÊµãËØï: Llama-3.3-70B-Instruct (user_azure)
Prompt types: ['baseline']
ÈöæÂ∫¶: easy
ÁõÆÊ†á: ÊØèÁßçÈÖçÁΩÆ 20 ‰∏™ÂÆû‰æã
============================================================
‚óã simple_task         :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã basic_task          :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã data_pipeline       :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã api_integration     :   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)
‚óã multi_stage_pipeline:   0/ 20 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 20 ‰∏™)

‚è≥ ÈúÄË¶ÅËøêË°å 100 ‰∏™Êñ∞ÊµãËØï

‚ñ∂ ÂáÜÂ§á simple_task (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á basic_task (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á data_pipeline (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á api_integration (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂáÜÂ§á multi_stage_pipeline (20 ‰∏™ÂÆû‰æã)...

‚ñ∂ ÂºÄÂßãÊâßË°å 100 ‰∏™ÊµãËØï...
üìä Ëá™ÈÄÇÂ∫îcheckpoint_interval: 20
üì¶ ÊâπÈáèÊèê‰∫§Ê®°ÂºèÔºöÊØè20‰∏™ÊµãËØï‰øùÂ≠ò‰∏ÄÊ¨°
üöÄ Ê£ÄÊµãÂà∞Azure APIÔºå‰ΩøÁî®Ë∂ÖÈ´òÂπ∂Âèë: workers=50, qps=None
üß† ÂêØÁî®SmartResultCollectorÊ®°ÂºèÔºåÊô∫ËÉΩÊï∞ÊçÆÁÆ°ÁêÜ
[AI_DEBUG] AIÂàÜÁ±ªÂô®ÂàùÂßãÂåñÊàêÂäü: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x113e7e4c0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ‚ö° SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ‚ö° Memory optimization: Saving ~350MB by not loading model
[INFO] ‚ö° Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî®
[INFO] Ê£ÄÊµãÂà∞Âπ∂ÂèëÁéØÂ¢ÉÔºå‰ΩøÁî®ÂÆâÂÖ®Â≠òÂÇ®Ê®°ÂºèÔºàResultCollectorÔºâ2025-08-31 15:02:15,129 - mcp_embedding_manager - INFO - Index loaded successfully: 14 tools
2025-08-31 15:02:15,143 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,143 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,156 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,159 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,161 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,177 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,202 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,208 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,208 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,208 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,225 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,254 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,256 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,257 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,258 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,273 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,273 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,273 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,313 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,313 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,313 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,327 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,327 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,327 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,328 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,328 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,328 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,339 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,342 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,357 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,357 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,357 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,373 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,375 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,375 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,377 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,378 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,380 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,380 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,380 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,381 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,465 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,465 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,488 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,496 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,516 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,528 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,528 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,528 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,549 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,571 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,571 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,571 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,634 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,634 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,634 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,650 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,650 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,650 - mcp_embedding_manager - INFO - Index loaded successfully: 28 tools
2025-08-31 15:02:15,666 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,666 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,666 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,667 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,667 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,667 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,671 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,671 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,671 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,689 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,690 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,690 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,691 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,691 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,691 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,693 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,700 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,700 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,708 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,715 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,755 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,755 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,755 - mcp_embedding_manager - INFO - Index loaded successfully: 20 tools
2025-08-31 15:02:15,778 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,779 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,782 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,783 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,785 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,786 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,787 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,789 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,790 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,809 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[INFO] ÂêéÂè∞ÂêàÂπ∂ËøõÁ®ãÂ∑≤ÂêØÂä®ÔºàÊØè10ÁßíÂêàÂπ∂‰∏ÄÊ¨°Ôºâ
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x144fcecb0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 29 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-31 15:02:15,815 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,820 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,824 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,825 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,825 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,826 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,830 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,831 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,839 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,839 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,839 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,841 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,857 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,858 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,869 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,871 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,889 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,902 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,902 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,902 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,918 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,918 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,918 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,938 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,938 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,938 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:15,941 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,941 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,941 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,956 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,956 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,956 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:15,957 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:15,989 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:15,989 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:15,989 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:15,990 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:15,991 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:15,992 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:15,992 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:16,009 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,010 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,010 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,010 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,018 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,018 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,018 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,019 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,023 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,023 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,023 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,028 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,029 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,031 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,036 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,036 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,036 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,047 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,047 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,048 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,049 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,049 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,056 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,056 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,056 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,056 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,072 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,079 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,080 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,080 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,081 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,081 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,081 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,086 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,086 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,086 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,109 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,131 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,135 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,135 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,135 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,136 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,154 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,155 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,159 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,165 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,165 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,166 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,166 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,166 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 26 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 15:02:16,167 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,170 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,197 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,205 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,214 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,214 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,214 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,220 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,220 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,220 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:16,233 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,233 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,235 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,241 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,241 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,241 - mcp_embedding_manager - INFO - Index loaded successfully: 12 tools
2025-08-31 15:02:16,264 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,264 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,264 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:16,284 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,284 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,284 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:16,308 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,310 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,317 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,317 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,318 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,326 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,326 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,326 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,346 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,359 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,364 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,371 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,372 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,384 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,384 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,384 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:16,403 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,403 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,403 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,421 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,421 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,421 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:16,481 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,490 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,490 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,490 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,491 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,491 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,495 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,495 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,495 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,498 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,547 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,570 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,572 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,572 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,579 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:16,611 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,619 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,688 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,622 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,623 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,661 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:16,683 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,685 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,687 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,704 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,721 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,723 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,727 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:16,730 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,731 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,733 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,735 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,784 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,801 - mcp_embedding_manager - INFO - Index loaded successfully: 14 tools
2025-08-31 15:02:16,803 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:16,843 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,848 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,867 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:16,868 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,893 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,897 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,899 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,913 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:16,924 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools


[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]

[TURN 1/10]
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager

[TURN 1/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-31 15:02:16,931 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:16,932 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:16,947 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,976 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,978 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:16,980 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,002 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,006 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,009 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,009 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:17,013 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,014 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,039 - mcp_embedding_manager - INFO - Index loaded successfully: 14 tools
2025-08-31 15:02:17,048 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,049 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,050 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,052 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,052 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,054 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:17,054 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,058 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,059 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,092 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,093 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,093 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,093 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,109 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,110 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,122 - mcp_embedding_manager - INFO - Index loaded successfully: 27 tools
2025-08-31 15:02:17,126 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,126 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,127 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,131 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,145 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,148 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,185 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,275 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,291 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,295 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,297 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,317 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,333 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,336 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,338 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,340 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,375 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,376 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,376 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,379 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,393 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,406 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,406 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,408 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,430 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,461 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,461 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,487 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,491 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,492 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,493 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,493 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,535 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,566 - mcp_embedding_manager - WARNING - Tool 'computation_analyzer' at index 19 not found in tool_embeddings
2025-08-31 15:02:17,576 - mcp_embedding_manager - INFO - Detected mismatch, rebuilding tool_names from embeddings
2025-08-31 15:02:17,591 - mcp_embedding_manager - INFO - Rebuilding FAISS index for synchronization
2025-08-31 15:02:17,601 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:17,601 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:17,601 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:17,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,623 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,624 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,625 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,632 - mcp_embedding_manager - WARNING - Invalid index 28 (tool_names length: 22)
2025-08-31 15:02:17,632 - mcp_embedding_manager - WARNING - Invalid index 29 (tool_names length: 22)
2025-08-31 15:02:17,632 - mcp_embedding_manager - WARNING - Invalid index 22 (tool_names length: 22)

[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 28 embeddings
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Operation semantic index initialized
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Tool embedding index loaded successfully
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 14 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 10 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 28 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
  [SEARCH] Query: data validation parser

[TURN 3/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 15:02:17,640 - mcp_embedding_manager - INFO - Rebuilt FAISS index with 22 tools
2025-08-31 15:02:17,708 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,751 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,850 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,858 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,876 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,886 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,951 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,960 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:17,968 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,025 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,034 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,037 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,130 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,130 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,131 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,148 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,151 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,162 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,210 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,225 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,242 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,257 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,267 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,295 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,301 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,318 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,342 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,411 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,432 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,441 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,460 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,505 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,518 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,547 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,553 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,650 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,651 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,659 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,681 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,705 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,708 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,729 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,734 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
  [SEARCH] Query: file reader
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 3/10]

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: json schema validation
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 2/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
  [SEARCH] Query: data validation parser

[TURN 3/10]

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[INFO] Operation semantic index initialized
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
  [SEARCH] Query: data validation compliance
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
  [SEARCH] Query: json data structure validator
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 4/10]

[TURN 2/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 4/10]2025-08-31 15:02:18,751 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,760 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,790 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,806 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,813 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,835 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,850 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,935 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,982 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:18,999 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,001 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,033 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,033 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,034 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,176 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,178 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,178 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,196 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,299 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,303 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,333 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,372 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,397 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,412 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,514 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,516 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,526 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,530 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,565 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,570 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,699 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,699 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,700 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,700 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,701 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,702 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,743 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,799 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,800 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,942 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:19,963 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,005 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,010 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data structure validation

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation schema checker
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]

[TURN 2/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: json to xml converter

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 5/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: JSON format)

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file operations reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 15:02:20,015 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,045 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,081 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,087 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,222 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,226 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,284 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,288 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,328 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,333 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,334 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,343 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,368 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,374 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,389 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,396 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,467 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,472 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,512 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,648 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,747 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,748 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,762 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,788 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,852 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:20,997 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,273 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,273 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,292 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,329 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,365 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,386 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,389 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,418 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,451 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,493 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,524 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,545 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
    Result: SUCCESS

[TURN 6/10]
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - TIMEOUT: Operation timed out (after 26 seconds)

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
  [SEARCH] Query: data reader

[TURN 4/10]
  [SEARCH] Query: data validation parser

[TURN 2/10]
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
    Result: FAILED - PERMISSION_DENIED: Insufficient permissions (required permission: write)

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data parsing alternatives

[TURN 6/10]
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader operations

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
  [SEARCH] Query: file permission manager
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
  [SEARCH] Query: file reader

[TURN 4/10]
    Result: SUCCESS

[TURN 4/10]
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 5/10]
    Result: SUCCESS

[TURN 4/10]
  [SEARCH] Query: data filter

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - TIMEOUT: Operation timed out (after 30 seconds)

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 15:02:21,633 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,692 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,699 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,799 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,852 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,884 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,895 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,901 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,902 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,905 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,908 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,940 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:21,954 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,008 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,180 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,199 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,225 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,321 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,321 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,323 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,331 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,339 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,345 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,370 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,379 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,415 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,642 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,675 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,693 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,845 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,845 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,846 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:22,909 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,030 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: JSON format)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    [PENALTY] Recent failures: 2, success rate reduced
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data processing transformer

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
  [SEARCH] Query: json data reader
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 6/10]
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: JSON format)

[TURN 7/10]
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: json formatter
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: FAILED - TIMEOUT: Operation timed out (after 34 seconds)

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: CSV format)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: FAILED - TIMEOUT: Operation timed out (after 36 seconds)

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [PENALTY] Recent failures: 1, success rate reduced
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 15:02:23,072 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,368 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,378 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,389 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,494 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,498 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,537 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,538 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,542 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,548 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,552 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,553 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,563 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,573 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,577 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,583 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,583 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,584 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,585 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,588 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,592 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,593 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,593 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:23,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,597 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,599 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,603 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,603 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,604 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,604 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,604 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,611 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,618 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,618 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,620 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,622 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,622 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,631 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,631 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,631 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,631 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,635 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,635 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,635 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,635 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:23,635 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,638 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,638 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,638 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,641 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,641 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,641 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,645 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,645 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2

  [SEARCH] Query: json formatter

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
    Result: SUCCESS

[TURN 4/10]
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
  [SEARCH] Query: file reader

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: file reader

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - TIMEOUT: Operation timed out (after 42 seconds)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: JSON format)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 8/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: permission grantor
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data processing filter

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data format converter

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: FAILED - TIMEOUT: Operation timed out (after 34 seconds)

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 9/10]
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
  [PARSE] Found tool call: file_operations_converter
  [EXECUTING] file_operations_converter
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    [PENALTY] Recent failures: 1, success rate reduced
    Result: FAILED - PERMISSION_DENIED: Insufficient permissions (required permission: read)

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data parsing alternatives

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_transformer2025-08-31 15:02:23,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,649 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,653 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,656 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,662 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,663 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,678 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,680 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,680 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,680 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,681 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,681 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:23,681 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,682 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,683 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,683 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,683 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,683 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,684 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,684 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,684 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,684 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,684 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:23,685 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,685 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,685 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,685 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:23,686 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,686 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,686 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,689 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,690 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:23,690 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,690 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,690 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,690 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,704 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,705 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,707 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,711 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,711 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,713 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,713 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,713 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,714 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,716 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,719 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,721 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,724 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,724 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,724 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,725 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,725 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,728 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,728 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,729 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,729 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,729 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,729 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,730 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,730 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:23,730 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,730 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,730 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,730 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,730 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,731 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,731 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,731 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,731 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,731 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,732 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,732 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,732 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,739 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,741 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,744 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,746 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

  [EXECUTING] data_processing_transformer
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: data format transformer

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: integration_authenticator
  [EXECUTING] integration_authenticator
    Result: FAILED - INVALID_INPUT: Input validation failed (expected: XML format)

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 3/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [COMPLETION] Task marked as completed - all required tools executed
[ASSISTED] Task received 1 format helps, final result: partial_success
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    [PENALTY] Recent failures: 1, success rate reduced
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 19386
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19386
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: FAILED - OPERATION_FAILED: Operation could not be completed

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
  [SEARCH] Query: json reader

[TURN 7/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [PARSE] Found tool call: file_operations_reader
  [EXECUTING] file_operations_reader
    Result: SUCCESS

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [SEARCH] Query: permission manager
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    [PENALTY] Recent failures: 1, success rate reduced
    Result: SUCCESS

[TURN 9/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 5/10]
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
    [PENALTY] Recent failures: 1, success rate reduced
    Result: SUCCESS2025-08-31 15:02:23,756 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,757 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,757 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,758 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,758 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,758 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,768 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,778 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,778 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,779 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,779 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,779 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,786 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,786 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,786 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,786 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,786 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,787 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,788 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,796 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,892 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,893 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,894 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,894 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,895 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,895 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,895 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,896 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,896 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,896 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,897 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,897 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:23,897 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,898 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,898 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,898 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,899 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,899 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,899 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,900 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,900 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,901 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,901 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,901 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,901 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,902 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,903 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,906 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,906 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,907 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,907 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,907 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,907 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,910 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,910 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,911 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,911 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,911 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,913 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,913 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,914 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,914 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,915 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,915 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,915 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,916 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,917 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,922 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,925 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,928 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,930 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:23,930 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,937 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"


[TURN 9/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 6/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2

[TURN 1/10]
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 15:02:23,938 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,938 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,938 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,938 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,938 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,946 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,948 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,948 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,949 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,949 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,949 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,949 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,949 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:23,949 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,950 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,950 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,950 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,950 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,950 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,950 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,950 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,950 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,951 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,951 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,951 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,955 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,955 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,955 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,956 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,956 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,956 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,957 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,957 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,957 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,957 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,958 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,959 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,962 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,964 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,964 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:23,967 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,970 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,973 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,973 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,973 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,974 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,974 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:23,974 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:23,974 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,974 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:23,974 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,975 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,975 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,975 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,975 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,975 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,975 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,976 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,976 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,976 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,983 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,985 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,987 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:23,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:23,998 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:23,998 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:23,999 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:23,999 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:23,999 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,006 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,012 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,012 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,012 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,013 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,013 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,013 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,019 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,022 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,040 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,040 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,040 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,040 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,041 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,041 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,041 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,042 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: FAILED - TIMEOUT: Operation timed out (after 21 seconds)

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
  [FORMAT_ISSUE] Turn 9: Detected potential tool 'd' in incorrect format
  [FORMAT_ISSUE] Potential tools detected: ['d']

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 5/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}2025-08-31 15:02:24,042 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,042 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,042 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,042 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,042 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,043 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,043 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,043 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,044 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,044 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,044 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,049 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,051 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,053 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,054 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,057 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,058 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,058 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,058 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,058 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,059 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,060 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,060 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,060 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,060 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,060 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,061 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,061 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,061 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,061 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,061 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,061 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,067 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,068 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,068 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,068 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,069 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,069 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,069 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,069 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,069 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,070 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,070 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,070 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,070 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,072 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,074 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,078 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,084 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,093 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,093 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,093 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,093 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,094 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,094 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,095 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,099 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,100 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,100 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,100 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,100 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,101 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,101 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,101 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,101 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,101 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,102 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,104 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,104 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,104 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,105 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,105 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,105 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,106 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,106 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,106 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,107 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,107 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,107 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,107 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,107 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,107 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,107 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,111 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}2025-08-31 15:02:24,112 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,112 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,112 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,112 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,112 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,112 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,114 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,117 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,118 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,122 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,122 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,122 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,122 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,122 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,123 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,123 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,123 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,123 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,124 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,124 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,124 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,127 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,128 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,128 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,129 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,129 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,130 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,130 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,134 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,136 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,139 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,140 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,143 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,147 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,148 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,148 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,148 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,148 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,148 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,149 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,149 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,150 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,150 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,150 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,150 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,151 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,151 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,151 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,161 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,164 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,167 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,170 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,170 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,171 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,171 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,172 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,172 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,176 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,179 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,181 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,184 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,185 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,186 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,186 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,186 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,186 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,186 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,187 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,187 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,187 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,194 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,194 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,194 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,195 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,195 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,230 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,230 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,230 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,231 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,233 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 52 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [SEARCH] Query: output writer

[TURN 9/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
    Result: SUCCESS

[TURN 7/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}2025-08-31 15:02:24,235 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,235 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,235 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,236 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,236 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,236 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,236 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,237 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,237 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,237 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,237 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,240 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,241 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,241 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,241 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,241 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,242 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,242 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,242 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,243 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,243 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,243 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,243 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,244 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,247 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,247 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,247 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,248 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,248 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,248 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,249 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,249 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,249 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,249 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,249 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,249 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,249 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,249 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,250 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,250 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,250 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,250 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,251 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,251 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,252 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,252 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,252 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,253 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,259 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,260 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,263 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,265 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,267 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,271 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,273 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,274 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,274 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,275 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,275 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,276 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,276 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,276 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,276 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,277 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,277 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,277 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,278 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,278 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,278 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,278 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,284 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,284 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,284 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,287 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,287 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,288 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,288 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 10/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [INFO] Tool info request: data_processing_validator

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
  [SEARCH] Query: data transformation

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
  [PARSE] Found tool call: data_processing_filter
  [EXECUTING] data_processing_filter
    Result: SUCCESS

[TURN 6/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}2025-08-31 15:02:24,288 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,288 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,289 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,290 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,290 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,291 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,291 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,291 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,291 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,291 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,292 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,292 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,292 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,293 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,295 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,298 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,301 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,301 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,302 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,303 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,303 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,305 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,310 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,311 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,312 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,314 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,319 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,322 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,323 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,324 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,325 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,325 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,327 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,329 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,329 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,332 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,335 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,335 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,337 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,338 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,339 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,339 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,349 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,358 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,364 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,370 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,370 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,370 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,370 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,375 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,375 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,376 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,376 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,376 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,381 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,379 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,380 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,395 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,395 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,379 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,396 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,413 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,419 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,419 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,419 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,420 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,422 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,422 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,422 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,424 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,424 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,425 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,426 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,429 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [COMPLETION] Task marked as completed - all required tools executed
[ASSISTED] Task received 2 format helps, final result: full_success
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct2025-08-31 15:02:24,430 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,430 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,433 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,433 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,434 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,434 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,436 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,436 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,436 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,437 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,437 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,438 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,438 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,438 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,439 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,443 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,445 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,445 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,450 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,449 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,449 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,449 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,451 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,448 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,460 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,461 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,461 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,461 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,465 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,465 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,465 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,462 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,466 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,466 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,473 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,479 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,479 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,480 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,481 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,481 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,482 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,482 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,483 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,483 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,483 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,483 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,483 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,484 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,484 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,484 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,485 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,485 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,485 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,486 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,486 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,501 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,501 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,502 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,502 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct

  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: full_success
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    Result: SUCCESS

[TURN 7/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser2025-08-31 15:02:24,502 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,502 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,503 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,503 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,504 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,504 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,507 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,507 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,508 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,511 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,512 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,516 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,515 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,515 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,517 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,516 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,516 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,516 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,516 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,516 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,516 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,516 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,516 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,516 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,515 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,516 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,515 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,517 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,518 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,518 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,518 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,518 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,518 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,519 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,519 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,519 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,519 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,520 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,522 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,522 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,526 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,530 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,530 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,536 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,537 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,537 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,537 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,540 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,540 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,541 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,541 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,541 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,541 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,543 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,543 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,544 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,544 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,544 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,557 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,557 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,558 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,559 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,560 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,561 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,561 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,565 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,566 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,566 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,571 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,572 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,573 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,582 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,574 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,582 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,582 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,574 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,582 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,582 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,573 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,574 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,574 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,586 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,588 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,590 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,590 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,591 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,611 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,611 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,611 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 3/10]
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
  [PARSE] Found tool call: data_processing_transformer
  [EXECUTING] data_processing_transformer
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
    Result: SUCCESS

[TURN 7/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_transformer (score: 0.716)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)2025-08-31 15:02:24,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,612 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,613 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,614 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,616 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,620 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,621 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,621 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,624 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,628 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,638 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,641 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,645 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,645 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,645 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,646 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,646 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,646 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,646 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,647 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,648 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,648 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,648 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,649 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2

[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
  [FORMAT_ISSUE] Turn 7: Detected potential tool 'r' in incorrect format
  [FORMAT_ISSUE] Potential tools detected: ['r']

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct2025-08-31 15:02:24,650 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,655 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,663 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,664 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,664 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,664 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,664 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,664 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,665 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,665 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,665 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,665 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,666 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,666 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,666 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,667 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,667 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,668 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,668 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,669 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,670 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,673 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,673 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,719 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,680 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,680 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,680 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:24,680 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,681 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,681 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,681 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,682 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,683 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,684 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,693 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,694 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,694 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,696 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,696 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,697 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,705 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,711 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,711 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,717 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,717 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,718 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,718 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,718 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,719 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,676 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,723 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,724 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,724 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,728 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,731 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,738 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,744 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,744 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,746 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,748 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,748 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,749 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,750 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,751 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,751 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,752 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,753 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,754 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,756 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct

[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}2025-08-31 15:02:24,756 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,798 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,757 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,758 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,759 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,774 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,798 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,775 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,778 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,778 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,778 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,778 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,780 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,780 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,780 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,780 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,781 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,782 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,783 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,783 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,784 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,785 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,785 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,786 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,798 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,798 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,802 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,798 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,798 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:24,798 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,799 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:24,775 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,799 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,799 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,800 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,800 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,800 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,800 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:24,800 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,800 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,801 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,801 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,801 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,801 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,801 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,801 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,801 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,801 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,801 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,801 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:24,802 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,757 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,802 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,802 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,802 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,814 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:24,814 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,814 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,814 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,815 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,815 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,815 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,815 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,828 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,829 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,829 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,831 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,831 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,831 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,831 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,833 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,833 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,847 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,833 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,848 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,834 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,834 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,836 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,836 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:24,837 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,843 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,843 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,844 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,844 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,844 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:24,846 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,846 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,833 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:24,849 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,849 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,850 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,833 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:24,853 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,854 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,855 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,855 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,857 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,858 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:24,859 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,860 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:24,860 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:24,860 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: failure
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}2025-08-31 15:02:24,943 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,943 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:24,944 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:24,980 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,016 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,016 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,016 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,016 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,020 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,021 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,021 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,036 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,036 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,036 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,043 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,046 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,056 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,057 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,060 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,062 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,062 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,062 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,063 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,063 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,063 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,064 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,064 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,066 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,066 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,069 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,070 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:25,070 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,074 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,075 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,078 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,078 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,084 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,086 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,088 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,090 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,093 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,093 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,094 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,095 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,095 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,096 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,098 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,099 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,103 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,106 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,108 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,109 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,110 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,111 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,118 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,122 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,125 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,163 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,163 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,148 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,148 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,149 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,149 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,149 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,149 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,149 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,161 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,162 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,162 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,163 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,129 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,164 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,164 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,132 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,164 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,164 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,165 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: partial_success
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_filter (score: 0.716)
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[DEBUG RAG] data_processing_validator semantically matched with data_processing_filter (score: 0.628)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: partial_success
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[DEBUG RAG] data_processing_filter semantically matched with data_processing_transformer (score: 0.716)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
  [NO_ACTION] Quick feedback provided - no valid action format detected

[TURN 8/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: partial_success
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-32025-08-31 15:02:25,165 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,165 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,170 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,170 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,171 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,172 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,173 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,173 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,173 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,175 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,176 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,181 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,181 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,182 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,182 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,184 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,185 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,186 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,186 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,188 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,189 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,190 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,194 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,194 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,195 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,199 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,199 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,199 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,200 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,204 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,204 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,205 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,205 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,206 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,208 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,210 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,216 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,224 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,227 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,244 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,245 - mcp_embedding_manager - INFO - FAISS index loaded

  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: partial_success
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] file_operations_reader semantically matched with data_processing_parser (score: 0.622)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_transformer (score: 0.716)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
    Result: SUCCESS

[TURN 6/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 51 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:25,252 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,252 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,253 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,259 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,262 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,262 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,263 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,263 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,265 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,266 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,267 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,268 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,275 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,288 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,289 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,289 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,290 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,295 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,295 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,300 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,301 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,301 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,302 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,302 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,308 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,308 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,311 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,313 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,315 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,317 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,319 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,324 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,324 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,324 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,330 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,337 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,337 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,349 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,349 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,349 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,349 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,350 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,351 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,351 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,352 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,353 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,353 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,353 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,354 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,357 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,357 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,359 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,360 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,361 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,393 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,363 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,374 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,428 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,374 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,374 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,374 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,374 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,374 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,375 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,375 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,375 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,434 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,435 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,375 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,387 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,388 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,389 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,436 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,390 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,391 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,437 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,427 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,374 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,374 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,430 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,430 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,431 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,431 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,431 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,432 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,475 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,475 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,432 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,387 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,436 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,437 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,390 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,439 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,441 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,428 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,445 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,445 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,446 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,461 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,461 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,461 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,461 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,461 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,475 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,475 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,475 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,476 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: full_success
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:25,436 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,387 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,478 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,478 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,483 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,483 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,486 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,486 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,487 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,502 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,505 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,511 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,511 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,512 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,513 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,513 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,514 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,514 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,515 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,521 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,521 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,521 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,522 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,523 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,523 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,526 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,526 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,526 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:25,531 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,532 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,532 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,532 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,546 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,546 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,551 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,555 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,556 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,558 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,558 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,559 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,562 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,563 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,565 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,567 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,570 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,570 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,570 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,572 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,572 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,573 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,573 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,575 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,575 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,576 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,584 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,591 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,592 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,599 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,599 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,592 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,599 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,599 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,593 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,594 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,616 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,616 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,617 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,618 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,595 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,619 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,596 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,619 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,619 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,620 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,620 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:25,620 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,599 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,621 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,622 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,625 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,627 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,628 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,629 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,629 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,629 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,629 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,629 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,629 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,630 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,634 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,632 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,633 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,633 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,634 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,634 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,632 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,634 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,637 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,637 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,639 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,639 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,640 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,641 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,641 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,642 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,643 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,643 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,644 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,644 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,645 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,645 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,646 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,646 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,646 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,646 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,647 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,648 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,648 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,648 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,648 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,649 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,650 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,650 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,650 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,652 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,653 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,654 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,654 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,654 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,654 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,656 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,658 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,671 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,671 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,684 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,684 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,671 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,678 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,678 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,679 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,679 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,679 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,681 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [PARSE] Found tool call: data_processing_parser
  [EXECUTING] data_processing_parser
    Result: SUCCESS

[TURN 4/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-32025-08-31 15:02:25,681 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,684 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,706 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,671 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,707 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,708 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,708 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,708 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,676 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,709 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,710 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:25,714 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,715 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,715 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,719 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,720 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,721 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,721 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,721 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,722 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,725 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,749 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,745 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,745 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,745 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:25,746 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,746 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,746 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,746 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,748 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,744 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,749 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,749 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,749 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,749 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,750 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,750 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,750 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:25,750 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,750 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,750 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,751 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,751 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,752 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,752 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,752 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,755 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,755 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,752 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,755 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,752 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,753 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,756 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,754 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,754 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,754 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,755 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,758 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,759 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,753 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:25,756 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,753 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,753 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,757 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,758 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,756 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,778 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,778 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,780 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,780 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,781 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,782 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,782 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,753 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,782 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,782 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,783 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,783 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,787 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3

[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct

[TURN 1/10]
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:25,787 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,788 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,790 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,803 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,790 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,792 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,805 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,805 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,805 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,794 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,801 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,801 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,807 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,802 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,807 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,802 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,792 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,794 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,801 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,797 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,807 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,802 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,802 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,808 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,808 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,808 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,811 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,811 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,821 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,821 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,821 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,822 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,824 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,825 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,825 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,825 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,831 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,826 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,827 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,827 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,827 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,829 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,833 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,830 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,831 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,834 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,831 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,825 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,832 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,833 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,833 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,830 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,833 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,831 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,834 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,834 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,835 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,835 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,835 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,837 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,835 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,836 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,838 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,837 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,841 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,841 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,837 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,842 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,836 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,840 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,836 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,843 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,840 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,843 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,844 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,844 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,845 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,847 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,850 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,850 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,851 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,851 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,851 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,852 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,852 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,852 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,855 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,855 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,855 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,857 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: SUCCESS

[TURN 3/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 5 format helps, final result: failure
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:25,858 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:25,863 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,863 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,864 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,865 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,870 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:25,876 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,876 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,878 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,879 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,880 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,882 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,889 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,889 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,890 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:25,894 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,901 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,902 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,903 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,912 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,912 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,913 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,913 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,915 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:25,923 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:25,923 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:25,927 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,927 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,927 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,930 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:25,930 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:25,930 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,931 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,932 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,946 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:25,949 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:25,990 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,991 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,991 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:25,992 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,003 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,004 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,004 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,004 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,005 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,011 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,011 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,011 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,018 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,018 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,018 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,031 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,031 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,032 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,032 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,032 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,032 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,032 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,032 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,033 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,033 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,033 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,045 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,045 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,045 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,046 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,046 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,046 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,046 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,047 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,047 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,047 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,048 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,048 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,048 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,072 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,072 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,072 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,072 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,073 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,075 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,075 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,075 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,075 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,075 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,076 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,076 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,076 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: partial_success
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[DEBUG RAG] data_processing_parser semantically matched with data_processing_filter (score: 0.684)
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:26,089 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,090 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,090 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,093 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,093 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,093 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,094 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,094 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,094 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,094 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,094 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,095 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,095 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,096 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,096 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,098 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,099 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,101 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,101 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,101 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,102 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,102 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,102 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,103 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,103 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,103 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,105 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,106 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,106 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,106 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,107 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,107 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,107 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,108 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,108 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,110 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,110 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,112 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,111 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,112 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,112 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,112 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,111 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,112 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,113 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,113 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,118 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,118 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,120 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,120 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,121 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,121 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,124 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,125 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,126 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,127 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,130 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:26,130 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,131 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,131 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,132 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,133 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,134 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,134 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,135 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}2025-08-31 15:02:26,135 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,136 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,136 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,139 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,136 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,137 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,137 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,137 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,139 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,137 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,140 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,140 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,140 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,141 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,142 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,143 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,144 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,145 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,146 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,147 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,151 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,152 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,156 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,156 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,155 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,154 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,154 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,157 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,157 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,159 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,159 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,158 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,158 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,158 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,160 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,158 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,160 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,161 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,159 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,163 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,164 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,164 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,164 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,164 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,165 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,165 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,165 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,169 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,172 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,172 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,175 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,188 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,188 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,194 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,194 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,197 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,199 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,201 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,202 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,203 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,204 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,205 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,205 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,206 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,207 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,207 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,209 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,209 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,210 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,211 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,213 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,218 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,219 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,220 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,220 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,221 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,222 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,223 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,223 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,223 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,225 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3

[TURN 1/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 50 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
  [PARSE] Found tool call: data_processing_validator
  [EXECUTING] data_processing_validator
    [DEPENDENCY] Missing: data_processing_parser, success rate reduced
    Result: SUCCESS

[TURN 4/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct2025-08-31 15:02:26,232 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,233 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,240 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,240 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,254 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,254 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,256 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,256 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,258 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,259 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,260 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,263 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,273 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,264 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,264 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,264 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,265 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,265 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,267 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,267 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,268 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,268 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,269 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,270 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,271 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,271 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,271 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,271 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,273 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,273 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,263 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,274 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,274 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,274 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,275 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,275 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,275 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,276 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,277 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,278 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,278 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,289 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,290 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,290 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,290 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,290 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,290 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct

[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: full_success
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-22025-08-31 15:02:26,290 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,291 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,292 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,292 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,292 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,292 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,293 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,293 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,294 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,295 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,326 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,295 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,308 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,308 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,311 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,313 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,331 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,331 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,316 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,316 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,317 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,319 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,319 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,320 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,325 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,325 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,325 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,326 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,326 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,326 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,295 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,326 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,326 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,328 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,329 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,331 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,314 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,315 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,332 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,332 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,332 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,333 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,338 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,338 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,345 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,345 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,345 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,345 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,346 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,346 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,346 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,346 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,346 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,360 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,373 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,360 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,361 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,362 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,362 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,362 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,376 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,363 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,363 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,363 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,368 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,368 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,369 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,372 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,373 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,373 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,360 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,374 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,375 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,375 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,375 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,376 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,362 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,376 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,379 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,382 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,383 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,383 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,385 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,386 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,386 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,386 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,387 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,387 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,388 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,390 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,390 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,391 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,394 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,395 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2

[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-22025-08-31 15:02:26,395 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,399 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,402 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,415 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,416 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,420 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,421 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,422 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,425 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,426 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,427 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,428 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,449 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,449 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,435 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,447 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,447 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,448 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,448 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,448 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,448 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,434 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,434 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,450 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,450 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,451 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,450 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,451 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,451 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,451 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,451 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,472 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,467 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,469 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,470 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,467 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,450 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,473 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,482 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,476 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,477 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,481 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,481 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,482 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,486 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,473 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,483 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,483 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,484 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,485 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,486 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,487 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,483 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,487 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,490 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,490 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,497 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,499 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,499 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,499 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,499 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,497 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,507 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,507 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,508 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,511 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,512 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,513 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,519 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,519 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,519 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,520 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,520 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,522 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,523 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,523 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,524 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,527 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,527 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,527 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,528 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,533 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,533 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,533 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,534 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,534 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:26,542 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,552 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,562 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,565 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,565 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,566 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,567 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,567 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3

[TURN 1/10]
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-22025-08-31 15:02:26,569 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,569 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,569 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,572 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,572 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,573 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,573 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,573 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,587 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,587 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,588 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,589 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,589 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,589 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,591 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,591 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,591 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,591 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,591 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,601 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,601 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,601 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,602 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,604 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,604 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,604 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,604 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,604 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,619 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,621 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,623 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,623 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,623 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,629 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,631 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,632 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,632 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,632 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,633 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,641 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,641 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,641 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,641 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,641 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,641 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,643 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,643 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,645 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,645 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,646 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,648 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,649 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,649 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,651 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,651 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,653 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,653 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,653 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,655 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,655 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,655 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error

  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_transformer (score: 0.716)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: full_success
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}2025-08-31 15:02:26,655 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,655 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,655 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,655 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,656 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,656 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,657 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,657 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,657 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,658 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,658 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,658 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,658 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,658 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,659 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,659 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,659 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,659 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,660 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,661 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,661 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,662 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,662 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,671 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,672 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,898 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,672 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,672 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,673 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,673 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,674 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,675 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,676 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,677 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,904 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,904 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,678 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,681 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,714 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,733 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,740 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,741 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,756 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,770 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,778 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,784 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,784 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,784 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:26,788 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,791 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,877 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error2025-08-31 15:02:26,897 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,898 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,898 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,672 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:26,898 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,899 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,900 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,901 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,904 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,679 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,905 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:26,905 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,680 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,906 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,906 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,906 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,906 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,907 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,907 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,907 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,907 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,907 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,907 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,908 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,908 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:26,908 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,911 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,912 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,912 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,912 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,912 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,912 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:26,912 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,912 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,913 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,913 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,913 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,914 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,914 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,914 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,915 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,915 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,915 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,915 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,916 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,916 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,916 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,916 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:26,916 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,916 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,916 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:26,916 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,913 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,917 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,007 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,917 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,931 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,931 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,944 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,957 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,984 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:26,985 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:26,998 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:26,998 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,002 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,007 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,007 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:26,917 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,008 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,009 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,010 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,012 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,018 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,018 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,014 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,015 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,015 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,016 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,016 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,016 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,026 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,026 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,017 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,018 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,027 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,014 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,019 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,028 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,026 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,028 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,026 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,026 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,026 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,026 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,027 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,017 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,017 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,027 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,013 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,026 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,032 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,029 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,031 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,031 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,031 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,031 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,031 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,032 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,037 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,032 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,036 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,039 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,039 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,026 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,044 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,044 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,044 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: partial_success
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}2025-08-31 15:02:27,047 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,048 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,050 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,050 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,053 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,054 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,057 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,054 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,060 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,068 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,071 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,071 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,071 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,071 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,071 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,071 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,071 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,080 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,081 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,081 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,081 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,083 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,091 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,099 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,123 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,128 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,132 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,132 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,132 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,132 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,146 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,147 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,147 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,152 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,157 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,159 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,159 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,160 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,161 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,161 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,165 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,165 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,167 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,168 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,175 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,176 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,180 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 49 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)2025-08-31 15:02:27,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,194 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,196 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,196 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,197 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,197 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,199 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,200 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,202 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,203 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,204 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,212 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,212 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,214 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,214 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,215 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,220 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,221 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,227 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,236 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,236 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,237 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,238 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,240 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,240 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,243 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,244 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,245 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,252 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,276 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,276 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,276 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,276 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,276 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,277 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,278 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,278 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,299 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,305 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,306 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,306 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,306 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,306 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,306 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,306 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,306 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,306 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,306 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,306 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,306 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: full_success
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct

[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 15:02:27,306 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,306 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,307 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,263 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,307 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,307 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,307 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,307 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,307 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,308 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,308 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,308 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,308 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,309 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,309 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,310 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,310 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,310 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,322 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,322 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,334 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,335 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,335 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,336 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,337 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,337 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,337 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,342 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,357 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,357 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,358 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,358 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,358 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,358 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,358 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,362 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,363 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,363 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,364 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,389 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,390 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,391 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,391 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,419 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,419 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,423 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,424 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,425 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,427 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,427 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,429 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,429 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,429 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,430 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,430 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,431 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,431 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,431 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,431 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,431 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,431 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,431 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,437 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,431 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,438 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,439 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,439 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,432 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,443 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,432 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,445 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,441 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,433 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,467 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,477 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,482 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,482 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,483 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,483 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,484 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,486 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,486 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,486 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,490 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,435 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,496 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,498 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,500 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,500 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)2025-08-31 15:02:27,500 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,500 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,500 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,500 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,500 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,501 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,502 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,502 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,502 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,502 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,504 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,504 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,504 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,504 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,506 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,510 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,512 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,512 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,517 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,526 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,568 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,571 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,571 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,589 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,589 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,589 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,607 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,607 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,608 - mcp_embedding_manager - INFO - Index loaded successfully: 20 tools
2025-08-31 15:02:27,619 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,620 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,628 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,629 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,644 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,644 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,656 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,656 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,657 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,657 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,658 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,658 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,660 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,661 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,661 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,661 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,663 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,665 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,665 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,665 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,666 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,673 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,673 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,673 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,674 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,674 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,675 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,675 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,682 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,691 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,694 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,694 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,694 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,696 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,696 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,698 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,698 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,699 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,699 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,699 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,699 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,699 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,700 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,700 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,700 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,700 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,700 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,712 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,713 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,716 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,716 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,713 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,713 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,716 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,714 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,717 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,717 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,721 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[INFO] Tool embedding index loaded successfully
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[INFO] Tool embedding index loaded successfully

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: full_success
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 15:02:27,721 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,726 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,727 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,727 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,727 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,732 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,733 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,735 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,735 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,735 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,735 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,735 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,737 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,737 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,737 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,737 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,738 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,738 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,738 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,738 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,739 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,739 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,739 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,740 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,740 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,740 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,741 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,741 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,741 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,741 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,741 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,741 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,742 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,742 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,743 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,743 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,743 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,743 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,743 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,743 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,743 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,745 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,745 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,745 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,746 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,746 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,746 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,746 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,746 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,747 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,747 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,747 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,747 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,747 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,747 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,747 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,748 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,750 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,750 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,750 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,753 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,757 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,760 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,761 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,761 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,761 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,762 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,762 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,762 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,763 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,763 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,763 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,764 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_parser semantically matched with file_operations_reader (score: 0.622)
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct2025-08-31 15:02:27,764 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,765 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,765 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,765 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,765 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,765 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,768 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,772 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,772 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,774 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,774 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,774 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,776 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,777 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,790 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,791 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,792 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,793 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,793 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,794 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,794 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,794 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,794 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,794 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,794 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,795 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,795 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,795 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,807 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,807 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,808 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,808 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,808 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,812 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,813 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,814 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,814 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,818 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,819 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,819 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,820 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,820 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,820 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,821 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:27,826 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,827 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,832 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,833 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,833 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,834 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,835 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,835 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,835 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,835 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,836 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,838 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:27,838 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,838 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,840 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,841 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,841 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,841 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,844 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,845 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,845 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,846 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,846 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,846 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,853 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:27,853 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,853 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,854 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct

[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:02:27,860 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,861 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,861 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,862 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,864 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,864 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,865 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,865 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,866 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,867 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,868 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,868 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,869 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,870 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,871 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,872 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,881 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,874 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,877 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,883 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,883 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,878 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,882 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,882 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,884 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,883 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,884 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,889 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,878 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,875 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,888 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,883 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,888 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,888 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,889 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,877 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,890 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,890 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,891 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,891 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,892 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,892 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:27,892 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,893 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,895 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,895 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,895 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,897 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,897 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,922 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,922 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:27,923 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,924 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,926 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,926 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3

[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 15:02:27,926 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,927 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,929 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,929 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,929 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,931 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,932 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,932 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,932 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,932 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,932 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:27,932 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,932 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,933 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-31 15:02:27,933 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,933 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,933 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,934 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,934 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,934 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,934 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,934 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,935 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,935 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:27,935 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,935 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,936 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,936 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,937 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,937 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,939 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,940 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,958 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,958 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,958 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,959 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,960 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,960 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,961 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,961 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,961 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,962 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,963 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:27,963 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,965 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,966 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,972 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,973 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,975 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,976 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,976 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,977 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:27,978 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,979 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,983 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:27,983 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,983 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,985 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,986 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,991 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:27,991 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:27,991 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,993 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:27,999 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,000 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,001 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,004 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,004 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,007 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,010 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,017 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,017 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,022 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-31 15:02:28,022 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-31 15:02:28,022 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-31 15:02:28,037 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,087 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,088 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,089 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,090 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,091 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,091 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,091 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,091 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,092 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,092 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,092 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,092 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,092 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,092 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,093 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,093 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,093 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,101 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,101 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,102 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,123 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,124 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,124 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,124 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,124 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,124 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,124 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,125 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,126 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,126 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,126 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,126 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,127 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,127 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: partial_success
[INFO] Tool embedding index loaded successfully
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[DEBUG RAG] data_processing_filter semantically matched with data_processing_transformer (score: 0.716)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[INFO] Operation semantic index initialized

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[InteractiveExecutor] Initialized client with model: Llama-3.3-70B-Instruct
[InteractiveExecutor] Using prompt type: baseline for API key selection
[InteractiveExecutor] API model name: Llama-3.3-70B-Instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5469448256)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}2025-08-31 15:02:28,127 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,127 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,127 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,129 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,129 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,129 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,129 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,129 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,133 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,135 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,136 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,138 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,148 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,149 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,149 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,149 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,149 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,149 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,150 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,150 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,150 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,150 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,150 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,153 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,153 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,153 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,154 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,154 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,154 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,158 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,160 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,162 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,175 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,175 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,175 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,176 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,176 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,176 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,176 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,177 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,177 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,177 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,177 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,177 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,178 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,178 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,178 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,178 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,178 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,178 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,184 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,186 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,187 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,193 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,193 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,193 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,194 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,194 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,194 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,194 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,194 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,194 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,194 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,194 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,196 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,196 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,196 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,196 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,196 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,202 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,203 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,203 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,205 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,205 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,205 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,206 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,207 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,207 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Tool embedding index loaded successfully
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[INFO] Operation semantic index initialized
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)

[TURN 1/10]
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: full_success
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[INFO] Tool embedding index loaded successfully
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: Llama-3.3-70B-Instruct, API name: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 48 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-22025-08-31 15:02:28,207 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,208 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,208 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,208 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,209 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,209 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,209 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,209 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,209 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,210 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,210 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,210 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,210 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,210 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,214 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,214 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,214 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,218 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,219 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,219 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,219 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,219 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,219 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,224 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,225 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,226 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,228 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,228 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,229 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,229 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,230 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,230 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,230 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,231 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,237 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,238 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,238 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,238 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,238 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,239 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,239 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,239 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,245 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,245 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,245 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,245 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,245 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,245 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,245 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,246 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,246 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,246 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,246 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,247 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,248 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,248 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,249 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,249 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,249 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,250 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,251 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,252 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,253 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,253 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,254 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,254 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,254 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,255 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,256 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,258 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,259 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,259 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,259 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,260 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,260 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,262 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,262 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,262 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,263 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,265 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,271 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,272 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,272 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,273 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3

[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error2025-08-31 15:02:28,274 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,274 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,274 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,274 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,274 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,275 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,275 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,275 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,275 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,275 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,282 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,283 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,284 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,285 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,285 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,286 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,286 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,286 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,293 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,297 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,298 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,298 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,298 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,298 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,298 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,300 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,301 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,301 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,301 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,301 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,301 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,302 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,302 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,302 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,303 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,303 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,303 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,306 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,310 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,310 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,313 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,313 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,313 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,314 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,314 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,314 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,318 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,318 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,319 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,319 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,319 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,319 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,321 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,326 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,330 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,331 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,331 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,331 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,331 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,331 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,334 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,336 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,336 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,337 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,337 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,337 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,338 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,338 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,338 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,339 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,339 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,339 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,342 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,347 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,350 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,350 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,351 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,351 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,351 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,352 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 15:02:28,354 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,354 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,356 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,357 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,358 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,358 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,359 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,363 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,363 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,364 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,366 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,366 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,370 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,378 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,383 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,385 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,385 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,386 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,387 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,387 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,387 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,387 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,387 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,388 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,388 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,388 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,388 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,389 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,389 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,389 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,389 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,390 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,390 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,390 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,391 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,391 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,391 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,391 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,392 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,392 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,392 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,392 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,392 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,393 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,393 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,393 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,393 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,393 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,393 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,394 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,394 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,394 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,395 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,396 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,396 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,396 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,396 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,396 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,399 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,405 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,406 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,407 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,408 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,409 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,410 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,414 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,414 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,415 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,415 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,415 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,415 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,415 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,415 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,415 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,416 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,416 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,416 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,423 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,424 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,489 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,489 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 15:02:28,489 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,489 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,489 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,490 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,497 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,522 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,524 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,524 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,524 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,524 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,531 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,616 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,616 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,616 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,617 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,617 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,617 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,617 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,617 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,617 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,618 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,618 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,618 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,625 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,626 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,650 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,650 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,651 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,651 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,651 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,662 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,682 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,682 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,682 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,682 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,683 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,683 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,683 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,690 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,698 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,698 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,698 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,698 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,706 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,724 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,724 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,724 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,724 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,724 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,724 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,766 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,770 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,771 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,771 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,772 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,772 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,777 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,777 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,778 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,779 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,779 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,779 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,781 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,781 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,781 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,781 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,784 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR]2025-08-31 15:02:28,785 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
 Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error2025-08-31 15:02:28,787 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,788 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,789 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,790 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,792 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,795 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,806 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,821 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,822 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,822 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,822 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,836 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,864 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,864 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,864 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,864 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,865 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,865 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,865 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,865 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,866 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,866 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,866 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,866 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:28,867 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,867 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,867 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,869 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,868 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,868 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,869 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,870 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,868 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,869 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,870 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,869 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,871 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,873 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,875 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,875 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,874 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,876 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,875 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,876 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,876 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,874 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,877 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,875 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,878 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,878 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,879 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,879 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,881 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,882 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,885 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,885 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,887 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,888 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,889 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,890 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,890 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,995 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,995 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:28,995 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,996 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,996 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,996 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,997 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,998 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:28,998 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:28,998 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error

[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}2025-08-31 15:02:28,998 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:28,998 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:28,999 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,999 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,999 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:28,999 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:28,999 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:28,999 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:28,999 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,000 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,000 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,000 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,000 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,000 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,002 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,002 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:29,002 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,002 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,003 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,003 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:29,003 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,003 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,003 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,003 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,003 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,003 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,003 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,004 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,008 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,008 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,009 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,009 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:29,009 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,010 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,011 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,011 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,011 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,016 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,016 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,069 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,070 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,070 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,071 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,071 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,071 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,071 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,080 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,170 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,171 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,171 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:29,171 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,171 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,172 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,172 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,180 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,225 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,227 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:29,227 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,227 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,228 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,228 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,234 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,234 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,234 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,234 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,234 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,236 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,242 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,284 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,284 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,284 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,284 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,284 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,284 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,292 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,338 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,339 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,339 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,339 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,339 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,339 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,346 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,436 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,437 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,437 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] No alternative deployment available for Llama-3.3-70B-Instruct
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error2025-08-31 15:02:29,437 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,437 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,437 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,445 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,459 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,460 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,460 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:29,460 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,460 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,460 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,460 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,468 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,471 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,472 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:29,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,472 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,472 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,480 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,549 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,549 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,549 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,550 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,550 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,550 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,558 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,659 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,661 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,661 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:29,661 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,662 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,662 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,662 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,662 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,662 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:29,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,663 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:29,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,663 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,663 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,663 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,674 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,674 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,674 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,675 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,678 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,683 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:29,693 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,693 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,693 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:29,693 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,694 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,694 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,694 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,702 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,780 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,780 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,780 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,781 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,781 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,781 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,785 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:29,785 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,785 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,785 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,785 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,788 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,793 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:29,802 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:29,803 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:29,803 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,803 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:29,803 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:29,803 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:29,810 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,229 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:30,229 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:30,229 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,229 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:30,229 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:30,229 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,238 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,342 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 47 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct2025-08-31 15:02:30,343 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:30,343 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,343 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:30,343 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:30,343 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,350 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:30,351 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:30,351 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:30,351 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:30,351 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:30,352 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:30,352 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:30,352 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:30,360 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:30,471 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:30,472 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:30,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:30,472 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:30,472 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:30,472 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:30,486 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:30,744 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:30,745 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:30,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:30,745 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:30,745 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:30,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:30,753 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:32,028 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:37,530 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:47,488 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:02:51,347 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:51,350 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:51,350 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:51,350 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:51,352 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:51,354 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:51,354 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:51,374 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:51,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:51,532 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:02:51,532 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:51,532 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:51,532 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:51,532 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:51,540 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:51,730 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:51,730 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:51,730 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:51,731 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:51,731 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:51,731 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:51,739 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:51,883 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:02:51,883 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:02:51,883 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:02:51,884 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:51,884 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:51,884 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:51,884 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:51,894 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-2
2025-08-31 15:02:52,003 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"

[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_validator (score: 0.617)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_validator (score: 0.628)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 46 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}2025-08-31 15:02:52,006 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-2 marked as unhealthy due to 429 error
2025-08-31 15:02:52,006 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:02:52,006 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:02:52,006 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:02:52,006 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:02:52,014 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:02:59,338 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:07,940 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:13,537 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:03:13,540 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct marked as unhealthy due to 429 error
2025-08-31 15:03:13,540 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:03:13,540 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:03:13,540 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:03:13,540 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-3
2025-08-31 15:03:13,555 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct-3
2025-08-31 15:03:13,744 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
2025-08-31 15:03:13,744 - smart_deployment_manager - WARNING - Deployment Llama-3.3-70B-Instruct-3 marked as unhealthy due to 429 error
2025-08-31 15:03:13,744 - smart_deployment_manager - WARNING - No healthy deployments available for Llama-3.3-70B-Instruct
2025-08-31 15:03:13,744 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct-2
2025-08-31 15:03:13,745 - api_client_manager - WARNING - Model Llama-3.3-70B-Instruct not in SUPPORTED_MODELS, attempting anyway
2025-08-31 15:03:13,745 - api_client_manager - INFO - Using smart deployment manager for Llama-3.3-70B-Instruct (has 3 deployments)
2025-08-31 15:03:13,745 - smart_deployment_manager - INFO - Selected deployment for Llama-3.3-70B-Instruct: Llama-3.3-70B-Instruct
2025-08-31 15:03:13,768 - api_client_manager - INFO - Created smart Azure client for Llama-3.3-70B-Instruct using deployment: Llama-3.3-70B-Instruct
2025-08-31 15:03:19,541 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:23,993 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:24,336 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:25,449 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:25,766 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:25,912 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:26,405 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:27,152 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:27,864 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:28,599 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:29,254 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:29,506 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:30,484 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:30,648 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:34,681 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:35,044 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:35,421 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:35,898 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:36,381 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:36,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:37,391 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:37,889 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:38,348 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"

[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG RAG] data_processing_validator semantically matched with data_processing_parser (score: 0.625)
[DEBUG RAG] data_processing_transformer semantically matched with data_processing_parser (score: 0.742)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 45 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG RAG] data_processing_filter semantically matched with data_processing_parser (score: 0.684)
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(failure)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 13279
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13279
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 22695
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22695
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[AI_DEBUG] AIÂàÜÁ±ªÁªìÊûú: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] ÊµãËØïÈùûÂÆåÂÖ®ÊàêÂäü(partial_success)ÔºåÂáÜÂ§áË∞ÉÁî®AIÂàÜÁ±ª
[AI_DEBUG] ÁîüÊàêÁöÑtxt_contentÈïøÂ∫¶: 27103
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=27103
  - task_model=Llama-3.3-70B-Instruct
[AI_CLASSIFIER] Áõ¥Êé•‰ΩøÁî®AIÂàÜÊûêÂÆåÊï¥‰∫§‰∫íËÆ∞ÂΩïÔºàË∑≥ËøáËßÑÂàôÂåπÈÖçÔºâ
[LLM_ERROR] Attempt 1/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct-2
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct
[LLM_ERROR] Attempt 2/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct
[429_ERROR] Marked Llama-3.3-70B-Instruct as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
[LLM_ERROR] Attempt 4/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-3
[429_ERROR] Marked Llama-3.3-70B-Instruct-3 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-3 to Llama-3.3-70B-Instruct
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-2
[LLM_ERROR] Attempt 5/5: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.', 'details': 'Rate limit of 400000 per 60s exceeded for UserByModelByMinuteTokens. Please wait 24 seconds before retrying.'}}
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...2025-08-31 15:03:38,873 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:39,005 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:39,041 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:39,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:40,603 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:40,851 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:41,355 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:41,689 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:42,342 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:42,949 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:43,086 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:43,341 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:44,490 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/Llama-3.3-70B-Instruct/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
2025-08-31 15:03:53,032 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-31 15:04:01,001 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
