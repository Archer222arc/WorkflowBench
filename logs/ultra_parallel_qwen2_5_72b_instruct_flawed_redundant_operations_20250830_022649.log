=== 测试开始时间: 2025年 8月30日 星期六 09时19分26秒 EDT ===
=== 环境变量 ===
USE_RESULT_COLLECTOR=true
STORAGE_FORMAT=json
CUSTOM_WORKERS=50
=== 命令执行 ===
INFO:__main__:使用环境变量 RATE_MODE: fixed
INFO:__main__:初始化实例池: 17个实例 (2个Azure + 6个IdealLab)
INFO:result_collector:ResultCollector初始化，临时目录: temp_results
INFO:result_collector:ResultAggregator初始化
INFO:__main__:🆕 启用ResultCollector模式，支持零冲突并发
INFO:__main__:资源池状态: 17个实例, 容量1306
INFO:__main__:
🎯 检测到Qwen模型，使用队列调度器
INFO:__main__:   模型: qwen2.5-72b-instruct → Key0
INFO:__main__:   Prompt类型: flawed_redundant_operations
INFO:__main__:   难度: easy
INFO:__main__:🔄 Key0: 执行 qwen2.5-72b-instruct-easy
INFO:__main__:🎯 使用qwen智能分片策略: qwen2.5-72b-instruct
INFO:__main__:🔄 真正多Key并发策略:
INFO:__main__:   模型: qwen2.5-72b-instruct (规模: 72b)
INFO:__main__:   使用Keys: key0, key1, key2
INFO:__main__:   总实例数: 20
INFO:__main__:   分片数: 3 (每个key独立分片)
INFO:__main__:   实例分配: [7, 7, 6]
INFO:__main__:   🚀 启用3倍API并发！
INFO:__main__:🚀 启动3个分片并发执行
INFO:__main__:  IdealLab qwen模型限制: qwen-key0 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 0
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_redundant_operations_key0: qwen-key0
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片1: qwen-key0 (7个实例)
INFO:__main__:  IdealLab qwen模型限制: qwen-key1 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 1
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_redundant_operations_key1: qwen-key1
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片2: qwen-key1 (7个实例)
INFO:__main__:  使用IdealLab API Key 2
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_redundant_operations_key2: qwen-key2
INFO:__main__:   实例数: 6, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片3: qwen-key2 (6个实例)
INFO:__main__:等待分片1完成（20实例×50workers，最多等待50分钟）...
2025-08-30 09:19:26,673 - faiss.loader - INFO - Loading faiss.
2025-08-30 09:19:26,674 - faiss.loader - INFO - Loading faiss.
2025-08-30 09:19:26,674 - faiss.loader - INFO - Loading faiss.
2025-08-30 09:19:26,684 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 09:19:26,686 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 09:19:26,686 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 09:19:27,272 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 09:19:27,272 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 09:19:27,272 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 09:19:27,272 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 09:19:27,272 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 09:19:27,272 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 09:19:27,272 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 09:19:27,273 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 09:19:27,273 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 09:19:27,273 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 09:19:27,274 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 09:19:27,274 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 09:19:27,274 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 09:19:27,274 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 09:19:27,274 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 09:19:27,274 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 09:19:27,274 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 09:19:27,274 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 09:19:27,274 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 09:19:27,274 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 09:19:27,274 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 09:19:27,275 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 09:19:27,324 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:19:27,324 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:19:27,324 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 09:19:27,324 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 09:19:27,324 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:19:27,324 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 09:19:27,324 - batch_test_runner - INFO - ============================================================
2025-08-30 09:19:27,324 - batch_test_runner - INFO - ============================================================
2025-08-30 09:19:27,324 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 09:19:27,324 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 09:19:27,324 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 09:19:27,324 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 09:19:27,325 - batch_test_runner - INFO - ============================================================
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_091927.log
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_091927.log
2025-08-30 09:19:27,325 - batch_test_runner - INFO - ============================================================
2025-08-30 09:19:27,325 - batch_test_runner - INFO - ============================================================
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Initializing test components...
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Initializing test components...
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_091927.log
2025-08-30 09:19:27,325 - batch_test_runner - INFO - ============================================================
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-30 09:19:27,325 - batch_test_runner - INFO - Initializing test components...
2025-08-30 09:19:27,809 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 09:19:27,809 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 09:19:27,809 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 09:19:27,810 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 09:19:27,816 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 09:19:27,817 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 09:19:27,817 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 09:19:27,817 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 09:19:27,817 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 09:19:27,817 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 09:19:27,817 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 09:19:27,818 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 09:19:28,336 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:19:28,338 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:19:28,358 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:19:28,454 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 09:19:28,454 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 09:19:28,454 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 09:19:28,824 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 09:19:28,825 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 09:19:28,826 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 09:19:29,284 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 09:19:29,285 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 09:19:29,311 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 09:19:29,311 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 09:19:29,315 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 09:19:29,319 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 09:19:29,367 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 09:19:29,409 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 09:19:29,414 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 09:19:29,452 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 09:19:29,512 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 09:19:29,516 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 09:19:29,790 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 09:19:29,790 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:29,835 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:29,835 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:29,835 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:29,841 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 09:19:29,841 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:29,846 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 09:19:29,847 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 09:19:29,847 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 09:19:29,853 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 09:19:29,853 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:29,857 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 09:19:29,858 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 09:19:29,858 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 09:19:29,858 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 09:19:29,876 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:29,876 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:29,876 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:29,887 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 09:19:29,888 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 09:19:29,888 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 09:19:29,892 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:29,892 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:29,892 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:29,895 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 09:19:29,896 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 09:19:29,896 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 09:19:29,896 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 09:19:29,909 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 09:19:29,911 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 09:19:29,911 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 09:19:29,915 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 09:19:29,916 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 09:19:29,916 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 09:19:29,916 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 09:19:32,525 - unified_training_manager - INFO - Using device: cpu
2025-08-30 09:19:32,525 - unified_training_manager - INFO - Using device: cpu
2025-08-30 09:19:32,526 - unified_training_manager - INFO - Using device: cpu
2025-08-30 09:19:33,418 - unified_training_manager - INFO - Task filtering results:
2025-08-30 09:19:33,419 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 09:19:33,419 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 09:19:33,419 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 09:19:33,419 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 09:19:33,419 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 09:19:33,419 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 09:19:33,419 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 09:19:33,427 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 09:19:33,439 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 09:19:33,439 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 09:19:33,439 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 09:19:33,440 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 09:19:33,440 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 09:19:33,440 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 09:19:33,440 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 09:19:33,463 - unified_training_manager - INFO - Task filtering results:
2025-08-30 09:19:33,464 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 09:19:33,464 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 09:19:33,464 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 09:19:33,464 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 09:19:33,464 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 09:19:33,464 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 09:19:33,464 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 09:19:33,466 - unified_training_manager - INFO - Task filtering results:
2025-08-30 09:19:33,466 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 09:19:33,466 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 09:19:33,466 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 09:19:33,466 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 09:19:33,466 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 09:19:33,466 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 09:19:33,467 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 09:19:33,468 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:19:33,470 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 09:19:33,472 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 09:19:33,474 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 09:19:33,474 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 09:19:33,475 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 09:19:33,475 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 09:19:33,475 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 09:19:33,475 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 09:19:33,475 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 09:19:33,475 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 09:19:33,475 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 09:19:33,475 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 09:19:33,476 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 09:19:33,476 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 09:19:33,476 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 09:19:33,476 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 09:19:33,476 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 09:19:33,476 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 09:19:33,476 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 09:19:33,490 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:19:33,490 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:19:33,491 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 09:19:33,491 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 09:19:33,491 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 09:19:33,491 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 09:19:33,491 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 09:19:33,491 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 09:19:33,491 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 09:19:33,492 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 09:19:33,524 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 09:19:33,524 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 09:19:33,533 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 09:19:33,533 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 09:19:33,961 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 09:19:33,961 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 09:19:33,969 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 09:19:33,969 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 09:19:34,008 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 09:19:34,008 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 09:19:34,023 - batch_test_runner - INFO - Initialization complete
2025-08-30 09:19:34,029 - batch_test_runner - INFO - Initialization complete
2025-08-30 09:19:34,065 - batch_test_runner - INFO - Initialization complete
2025-08-30 09:19:34,101 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-30 09:19:34,101 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 09:19:34,102 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-30 09:19:34,107 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-30 09:19:34,107 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 09:19:34,108 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-30 09:19:34,124 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 09:19:34,132 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 09:19:34,132 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:34,133 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:34,134 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:34,137 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:34,142 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:34,143 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:34,143 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:34,144 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:34,146 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-30 09:19:34,146 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 09:19:34,147 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-30 09:19:34,171 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 09:19:34,178 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:34,178 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:34,179 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:34,180 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:34,185 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:34,185 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:34,185 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:34,192 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:34,192 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:34,192 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:34,195 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:34,195 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:34,195 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:34,201 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:34,201 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:34,201 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:34,216 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:34,216 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:34,217 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:34,237 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:34,237 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:34,237 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:35,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:36,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:36,220 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:36,293 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:36,854 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:19:37,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:37,611 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:37,611 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:38,135 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:38,135 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:38,557 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:38,660 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:39,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:39,603 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:39,727 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:40,756 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:40,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:19:41,568 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:41,806 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:41,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:19:41,946 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:19:42,856 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:42,856 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:42,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:43,377 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:44,621 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:44,651 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:44,664 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:44,664 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:44,692 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:44,692 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:44,692 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:45,107 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:45,654 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:46,524 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_redundant_operations']
难度: easy
目标: 每种配置 6 个实例
============================================================
○ simple_task         :   0/  6 已完成 (需要补充 6 个)
○ basic_task          :   0/  6 已完成 (需要补充 6 个)
○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
○ api_integration     :   0/  6 已完成 (需要补充 6 个)
○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)

⏳ 需要运行 30 个新测试

▶ 准备 simple_task (6 个实例)...

▶ 准备 basic_task (6 个实例)...

▶ 准备 data_pipeline (6 个实例)...

▶ 准备 api_integration (6 个实例)...

▶ 准备 multi_stage_pipeline (6 个实例)...

▶ 开始执行 30 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1072c7410>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 09:19:46,613 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:46,624 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_redundant_operations']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x10c859320>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 09:19:46,625 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:46,648 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:46,648 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:46,648 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:46,650 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:46,786 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:47,571 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:48,242 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:48,499 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:49,538 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:51,142 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:51,154 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_redundant_operations']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x1119c58c0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 09:19:51,155 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:51,184 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:51,184 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:51,184 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:51,549 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:51,589 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:19:51,650 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:51,651 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:51,660 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:52,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:52,817 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:53,517 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:54,441 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:54,456 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:54,456 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:54,480 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:54,480 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:54,480 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:54,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:55,435 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:55,854 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:55,867 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:55,867 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:55,891 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:55,891 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:55,891 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:56,005 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:56,270 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:19:57,007 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:57,431 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:57,447 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:57,447 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:57,473 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:57,473 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:57,473 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:58,426 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:58,440 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:19:58,591 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:19:58,591 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:19:58,614 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:19:58,614 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:19:58,614 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:19:59,106 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:59,479 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:19:59,518 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:20:00,541 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:00,695 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:00,945 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:00,973 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:00,984 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:01,983 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:02,525 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:03,299 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:03,824 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:03,842 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:04,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:04,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:05,398 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:05,398 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:05,410 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:05,411 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:05,435 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:05,435 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:05,435 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:05,533 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:05,589 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:06,559 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:06,632 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:07,086 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:08,154 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x13713a730>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json

[TURN 1/10]
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06d058ef-f314-9cf7-9060-d49c3f1f5d35"}, traceId: 215042f817565599752878673e28c3'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc660a28-36b3-9cde-87e5-55b8b05c0e78"}, traceId: 215042f817565599768238677e28c3'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d5e9c99-9d33-9fa3-b21e-cd1074723904"}, traceId: 215042f817565599783284247e2650'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0689184-1f68-9af5-b158-33fabfaeb897"}, traceId: 215042f817565599783348683e28c3'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"41d4486a-2ee8-9b52-b92d-4b43b0892e27"}, traceId: 215042f817565599805198699e28c3'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d9ad009-6bc5-92dc-854b-ac43c7794bfc"}, traceId: 215042f817565599813374266e2650'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"468e94a0-bb30-9767-98f1-048cb042d936"}, traceId: 215042f817565599830624270e2650'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9182a51c-7c6c-91a5-92d9-79082cdb5a75"}, traceId: 215042f817565599838798712e28c3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5069
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5069
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a1c0154-26eb-923d-aed1-3a157a66f9f6"}, traceId: 215045be17565599856752583e800e'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...2025-08-30 09:20:08,222 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:08,233 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:08,234 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:08,256 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:08,256 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:08,256 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:08,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:08,771 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:08,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:09,986 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:10,256 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:10,258 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x12fac0fb0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6776f71-dcd3-958f-a0dd-4f6952be33dd"}, traceId: 2150458717565599754486494e8014'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81076642-aee4-93e0-b4d0-14a1f69bda2d"}, traceId: 215040ed17565599754637668ebc75'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f581f8a-5320-9b03-84e4-6f7b5a31f1b9"}, traceId: 2150458717565599772956505e8014'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4bff36b-c7b8-9451-9878-b76f31e63138"}, traceId: 215040ed17565599778127676ebc75'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"195841ea-da67-9ad6-b0e4-e7edb1e13c75"}, traceId: 2150458717565599788186512e8014'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"747e0f2a-bab0-92f6-87a1-86ea27b55bbb"}, traceId: 215040ed17565599794827684ebc75'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9478a701-a96c-998a-a619-0499122dcda7"}, traceId: 215040ed17565599815127690ebc75'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cdbc3354-5b4b-9711-8edb-3c2563a1b018"}, traceId: 2150458717565599825266532e8014'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"56c5811f-066b-9d5e-9165-b8215c016ce9"}, traceId: 2150458717565599848616540e8014'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"463d60d4-2568-91c0-8dda-9ac4bb31d694"}, traceId: 215040ed17565599858847744ebc75'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5259
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5259
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection2025-08-30 09:20:10,837 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:11,030 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:11,804 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x1263937a0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0eae5d6-75f3-9dbe-a878-5c0e57a51e8f"}, traceId: 2150434117565599755474772e1ea5'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47144fe4-cbcc-9d70-9f5b-672eb700ae91"}, traceId: 215040cc17565599773223601ed3d4'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2f26899-9ce7-9aac-a461-c00c679eee8e"}, traceId: 2150434117565599778354785e1ea5'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2067a991-fa52-94b2-886b-022c13bc5b5f"}, traceId: 215040cc17565599788513605ed3d4'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [SEARCH] Query: data processing parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8540c1ab-1bee-9396-827e-e66d63636099"}, traceId: 215040cc17565599820533626ed3d4'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0909416-b07e-90ac-9d79-3acb62ed673a"}, traceId: 2150434117565599825454820e1ea5'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18110187-2e59-97a3-9bc1-3b56cc13dd3b"}, traceId: 2150434117565599843854845e1ea5'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"334bda36-e323-9883-936f-43db03b7f391"}, traceId: 215040cc17565599854103677ed3d4'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de12cd62-bf4b-98ae-b25a-2e91135262bf"}, traceId: 2150434117565599860544875e1ea5'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ccfb79c-56c5-9957-a49f-4e4dec60b959"}, traceId: 215040cc17565599903873773ed3d4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13162
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13162
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct2025-08-30 09:20:11,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:12,631 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:13,081 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:13,283 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:14,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:14,067 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:14,616 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:15,884 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:20:15,884 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:15,897 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:15,898 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:15,922 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:15,922 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:15,922 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:15,955 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:16,407 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:16,411 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:16,980 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:17,115 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:17,457 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:18,137 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:18,556 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:19,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:20,077 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:20:20,077 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:20,095 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:21,019 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:21,031 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:21,031 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:21,059 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:21,059 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:21,059 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:21,126 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:21,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:22,450 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:22,508 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:22,950 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:22,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:23,365 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:23,373 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:23,825 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:23,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:23,887 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:24,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:24,419 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8896ea4-a72d-93f9-b7db-b96ed89b2568"}, traceId: 215042f817565599859094280e2650'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c132be0-34e3-9508-bbf0-9cbb9450028c"}, traceId: 2150457917565599882836357e8b05'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9bbfe0e0-6771-9b44-8838-5f2eb8ca3a2a"}, traceId: 215042f817565599908044303e2650'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7713542f-2c6e-93da-86de-64e21dacca03"}, traceId: 2150457917565599914263142e8979'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"52415c9e-df14-9b0e-9e69-f16adf008dec"}, traceId: 215040ed17565599933051592ebf6c'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f848015a-c3da-915b-a85b-6b5a87747263"}, traceId: 215042f817565599956314322e2650'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12874
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12874
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b0f9b691-12cc-9433-8aeb-514a94e6848a"}, traceId: 2150460817565599967073072e7a7a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4971cff8-ca55-98ce-be8f-a1090785bf99"}, traceId: 2150460817565599987463082e7a7a'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04f61bdb-9089-9f8b-a0e7-59261d47e140"}, traceId: 2150415b17565599999488547ee59c'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01bf8e7a-bc2f-9e91-b66e-2c36b9a3c684"}, traceId: 2150460817565600012443089e7a7a'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4eb192fd-92ac-93d1-9cfb-ba6044b867cf"}, traceId: 2150415b17565600017838555ee59c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50eaa569-a35a-9a4e-9432-b50d4d40931c"}, traceId: 2150460817565600040753097e7a7a'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b15fbd5-cb9e-9e8d-a366-38bce6e16812"}, traceId: 2150415b17565600046118570ee59c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5108
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5108
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct2025-08-30 09:20:25,179 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:25,587 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:26,097 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:26,607 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:26,797 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:27,165 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:28,522 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:29,024 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:29,674 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:29,689 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:29,689 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:29,716 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:29,716 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:29,716 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"65da0368-071b-9117-a0d6-0ca9792e620c"}, traceId: 215045be17565599873028657e7fdb'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2ed2fb2f-6311-961f-b6f9-e90e7e994252"}, traceId: 2150458717565599874886552e8014'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ef18320-de66-9444-b48e-3cad7e765739"}, traceId: 2150456617565599893285321e82c9'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4bf137ba-81e5-9915-aad0-1a768a1a0e77"}, traceId: 2150458717565599908766563e8014'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9f28f7a7-8b26-91f9-9a46-8543f2b5399e"}, traceId: 2150443817565599913308867e8a9e'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2d605c28-154d-9a04-bdf6-de5a7454c5fa"}, traceId: 215041de17565599946978430e33a1'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08f48d4f-dca6-931d-89be-291f1c2f4fba"}, traceId: 2150458717565599966786594e8014'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13273
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13273
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a97cf4ff-9843-9444-9e77-91514b55e81d"}, traceId: 215045b417565599983147830e80ab'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"144e6345-63af-9fe7-8bf0-a1038c8f3767"}, traceId: 213e057b17565599998158400e401b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6f3b72a-8504-9249-bce7-0919e27aa0c4"}, traceId: 215045b417565600002297841e80ab'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"56b4447a-80c3-9473-94c8-58b08fc93307"}, traceId: 2150417c17565600025242979ef0bc'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b14f01e-a0e9-9fc2-9c49-1511463ff226"}, traceId: 215045b417565600040747855e80ab'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.68
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3877f1b2-eaa3-95ac-8412-079aa7842c21"}, traceId: 2150454117565600058124089e78ff'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c628e3f3-512d-94de-a0ef-8b4d2843fb01"}, traceId: 215045b417565600063177865e80ab'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bfc898a3-76d8-9e5d-b8d8-4ff39793dbef"}, traceId: 215045b417565600095157878e80ab'}2025-08-30 09:20:30,433 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:30,564 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:30,657 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:30,780 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:30,795 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:30,795 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:30,821 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:30,821 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:30,821 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:31,176 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:31,395 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:31,705 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:32,135 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:32,436 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:33,826 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:34,041 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:34,852 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:35,350 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:35,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:35,595 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:35,595 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:35,619 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:35,619 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:35,619 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:36,015 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:36,745 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:36,757 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:36,757 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:36,780 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:36,781 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:36,781 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:36,855 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:36,864 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:37,393 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99cc59ba-fac6-9f00-a931-b4d2129d1f6b"}, traceId: 2150434117565599909024929e1ea5'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d35096e-6807-9b76-b391-af68b7c522cd"}, traceId: 2150421317565599920786078e3461'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9cf9b6e9-d50a-995d-9217-f47328ea6950"}, traceId: 2150434117565599941884937e1ea5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4f040c65-8782-9663-b61b-6252e20a700d"}, traceId: 2150417517565599939117728ee0c0'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"84f82fbb-4750-97e0-9414-d180cfb8584b"}, traceId: 2150454417565599952532319e830f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c3afe315-8967-9b33-b698-625c1977d0c3"}, traceId: 2150454417565599976932333e830f'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e9132654-71aa-90b8-a8c3-b39cebdee571"}, traceId: 213e004f17565599977204185ee75f'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6669cc3-4b08-93d3-8cb7-5e8bd35a41b4"}, traceId: 213e007d17565600002546512ef0a7'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d78bd876-8148-92e1-b1df-a0c6bbc23e2c"}, traceId: 2150454417565600007372349e830f'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac16c0be-41a5-96b0-9bde-f8d35d6dd14d"}, traceId: 2150454417565600035672355e830f'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c034fcc-1edc-90f5-8968-8fda6451ff42"}, traceId: 215040b917565600046072205ef264'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"62efe7b4-b8d5-9a0f-83e2-51f1009b707d"}, traceId: 2150416317565600063898728e1511'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"62f03ac5-fb17-993e-8ee7-4663bbe296f0"}, traceId: 2150416317565600085088740e1511'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac40fa5f-054f-9a58-b7ca-fcff3dd25a0b"}, traceId: 2150454417565600095152381e830f'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"918afee2-ed80-900f-815f-209cae786b28"}, traceId: 2150454417565600115582390e830f'}2025-08-30 09:20:37,529 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:37,916 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:37,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:38,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:38,723 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:39,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:40,046 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:40,549 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:40,549 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:40,555 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:41,564 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:41,575 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:41,576 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:41,601 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:41,601 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:41,601 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:41,755 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:41,871 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-30 09:20:41,945 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:42,991 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:43,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:43,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:43,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:44,134 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:45,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed8b03f5-46ee-9452-9a1a-74826bc84820"}, traceId: 2150460817565600074803115e7a7a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93031fcb-7747-98fc-b65b-0c009651443f"}, traceId: 2150415b17565600085298583ee59c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01dc14a7-4a59-971d-9632-5ed00e1473aa"}, traceId: 215045c117565600092595462e7fc8'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"16306db3-0bb1-936f-ad94-73a1b92685ff"}, traceId: 2150415b17565600105778590ee59c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fc02a40c-1926-9899-954d-e561a4a85fca"}, traceId: 215045b817565600124065308e7f6e'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"94972bad-2efb-9527-a2c0-c7f24c88a570"}, traceId: 2150415b17565600128438606ee59c'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5069
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5069
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6ba2135-5cfb-9ce7-acdb-04905c18c0aa"}, traceId: 2150415b17565600161778612ee59c'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d5cba81-12b2-9d45-bffe-350b3c1f3330"}, traceId: 2150415c17565600169014940eeb48'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"05112dcc-26b1-91eb-a3d0-b26e2e7696f1"}, traceId: 2150415b17565600202788628ee59c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce31e0c5-5f73-9ac5-a270-cbf949f771b0"}, traceId: 2150415c17565600208266425eeb69'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7174d1f4-eaca-953e-b643-c246b9836819"}, traceId: 2150417c17565600222624620ef11f'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13206
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13206
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01153b07-ca44-9f05-8054-1b6dcf049077"}, traceId: 213e062917565600234096951e7df4'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"26eac36a-843a-97c4-9dcb-507b42d675b4"}, traceId: 2150417c17565600236734627ef11f'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...2025-08-30 09:20:45,182 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:46,231 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:46,635 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:46,652 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:46,653 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:46,676 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:46,676 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:46,676 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:46,768 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:46,768 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:46,793 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:46,793 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:46,793 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:48,188 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:48,602 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:48,617 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:48,617 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:48,639 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:48,639 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:48,639 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:48,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:48,915 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:49,107 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6c081bc9-eb88-9ffa-9477-b2ddf5981a51"}, traceId: 2150430917565600103011677e1f19'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"689da1d1-699d-9d40-a6a1-1bd72939020c"}, traceId: 215045b417565600138157895e80ab'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3dfb4f17-895c-9d69-97ca-60ab8e92ead5"}, traceId: 2150409517565600156207684eec66'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13259
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13259
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66e3cd38-7340-977d-8b5b-685f219b93a0"}, traceId: 2150417c17565600167354863ef1e5'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20c40eb7-4189-96a2-ad17-196d9b8c2d96"}, traceId: 215045b417565600183097918e80ab'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f780ba86-c652-9de3-8acb-200f8ecc2da1"}, traceId: 2150417c17565600188224877ef1e5'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"159328fb-32f7-9e98-b7cf-0a3b20dc5ae9"}, traceId: 215045b417565600198367924e80ab'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f88a6c3e-67f1-9458-9bd9-580fe44b4118"}, traceId: 2150417c17565600203514881ef1e5'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"207b4f8a-f4b1-9acb-8467-868c25381dcf"}, traceId: 2150417c17565600231364898ef1e5'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b846404c-c3db-9045-a7f5-41dd25fd2314"}, traceId: 215045b417565600236347941e80ab'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e770e14-fcf1-9fa3-872c-9cc1a6516435"}, traceId: 215045b417565600258577955e80ab'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c438471-53fc-9a2c-9122-6c10108ecbfd"}, traceId: 215045b417565600282857972e80ab'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"48367682-6824-9cff-9794-7e27593691d2"}, traceId: 2150421317565600294407848e36f4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5105
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5105
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]2025-08-30 09:20:49,192 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:49,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:50,111 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:50,122 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:50,122 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:50,146 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:50,146 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:50,146 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:50,156 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:51,140 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:51,151 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:51,151 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:51,175 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:51,175 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:51,175 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:51,193 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:51,262 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:51,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:52,072 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:20:52,148 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:52,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:52,688 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:20:52,688 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:20:52,705 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:52,712 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:20:52,712 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:20:52,712 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:20:53,453 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:53,622 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:54,215 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:54,707 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:55,144 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:55,879 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:55,914 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:20:56,005 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:56,594 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:56,596 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:57,090 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:20:57,612 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:57,650 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:20:57,889 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:58,189 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:20:58,692 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:00,113 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:00,125 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:00,125 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:00,152 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:00,152 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:00,152 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:00,474 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:00,607 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:00,623 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed0ab45e-01ca-9e2f-bec1-61f033faf4fd"}, traceId: 2150454417565600133092403e830f'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e30ac62-33cc-9c61-8fab-742c3cb91637"}, traceId: 2150416317565600138248758e1511'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b12d535c-2d52-9b3d-81c9-643567bdf14b"}, traceId: 2150416317565600156458773e1511'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed5bc0b6-4e89-9eae-b0f4-8b8ba182b8fb"}, traceId: 2150454417565600166472412e830f'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"abc1bdfa-fd46-9669-9666-4e9d682182ae"}, traceId: 2150416317565600193328787e1511'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c30417a4-4268-964f-8d21-ae0f11e0a7ac"}, traceId: 2150454417565600226272436e830f'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"11aef066-8bfa-94b9-a9aa-5a52882e38f1"}, traceId: 2150416317565600236438808e1511'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63f47afd-5b5f-9495-91b7-3cebedaa67b1"}, traceId: 2150454417565600253462447e830f'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b66996d6-8811-94f7-af5a-885d03034a21"}, traceId: 2150454417565600263642451e830f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ba943a1-b4c2-97f0-9a65-3e5ec333a503"}, traceId: 2150454417565600277742455e830f'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0564598e-5b5f-94e0-b473-4dbd7a862010"}, traceId: 2150454417565600304022463e830f'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"394337b5-1340-93fe-bfe0-cea5f6617b30"}, traceId: 2150421317565600299866678e3460'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59f61f75-d6a6-9c64-b635-7fe6288b131d"}, traceId: 2150449a17565600316985771e81df'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"52b918c8-edbf-952b-b341-dc184c32758d"}, traceId: 2150430917565600341374305e1f1a'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d3bc8d7a-bac2-98e3-bcd8-4e3643d9a5a8"}, traceId: 213e06c317565600361686616e7a51'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"38b2a289-f68f-9aa0-8f43-5213e5e4bcd4"}, traceId: 2150454417565600366522495e830f'}2025-08-30 09:21:00,624 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:00,649 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:00,649 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:00,649 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:01,103 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:01,330 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:01,622 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:01,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:02,705 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:03,613 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:03,653 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:04,637 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d18bd81-c52e-95ff-aa98-afb1d2635546"}, traceId: 2150458117565600302315709e8305'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f980ee0f-077f-9530-92d0-cf8d6ea86d26"}, traceId: 215045b417565600309367989e80ab'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9a5983eb-4586-9676-be6c-03921c16006d"}, traceId: 213e043517565600314662675e2c72'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81315071-4ad3-9abe-bb39-8309ea54e567"}, traceId: 2150455f17565600336211223e807f'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa681592-58a6-9abc-ae40-c2ece9d27205"}, traceId: 215045b417565600346158012e80ab'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab2693ed-b614-9c63-a372-8544b2755dda"}, traceId: 213e011517565600376912084e93fc'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b90acd7-d3de-94ba-9ab5-c804062ec0c9"}, traceId: 215045b417565600371648032e80ab'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4f9b8788-e2c5-9750-9e01-dadb4beadaf5"}, traceId: 215045b417565600403088057e80ab'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"67429152-b018-96e9-97df-2fe70b6aa96c"}, traceId: 2150416017565600413561014eef18'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4685
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4685
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98f8216d-1cf7-9d64-b73b-870d1235c874"}, traceId: 215045b417565600427498071e80ab'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a8b87f86-44da-9646-b034-51e618164d96"}, traceId: 2150417917565600428448277eeef1'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47d7189a-1403-9ebd-8efb-7d602aa30f06"}, traceId: 2150417917565600438888298eeef1'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9b81d589-6fd1-9efa-801a-dcbeb21b4abe"}, traceId: 2150417917565600454178321eeef1'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1945e2be-9ddd-9a65-b8c4-1e6c81f5243f"}, traceId: 215045b417565600478648105e80ab'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"658373cf-09c1-9a12-b8b6-11978a91a475"}, traceId: 2150417917565600483718346eeef1'}2025-08-30 09:21:05,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:05,342 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:05,343 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:05,366 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:05,366 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:05,366 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:05,424 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:05,842 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:06,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:06,062 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab04b69e-6c1f-92b4-9d9d-7758bd7b8010"}, traceId: 213e05ab17565600265882108e369b'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fae75a0f-cde0-9c58-ae47-d4ac3e4a4792"}, traceId: 2150417c17565600269084642ef11f'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"11409a3f-4db1-9e3a-9623-ce8e395f7098"}, traceId: 2150413117565600297894367eea5a'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b7c070c-a912-959e-b613-27b844ffb5cc"}, traceId: 2150417c17565600313474665ef11f'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a5dc75b2-fa5f-90e7-9b92-6ee39158589b"}, traceId: 2150452b17565600353764410e7766'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14836
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14836
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2d514090-660b-9f88-a151-1ed572c09243"}, traceId: 2150417c17565600360024682ef11f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4053fefa-ca96-9f14-b86c-7ed7057c4c09"}, traceId: 2150417717565600367908788edc44'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f4641d86-d9b0-90fa-a81c-e89c994a0f97"}, traceId: 213e066417565600384127823e82f8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91ddfb7d-e68d-9d4c-9324-86dfb20f5ba0"}, traceId: 2150417717565600384848797edc44'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"221e0226-420d-91e1-8a0c-8ed44f2fcf2c"}, traceId: 2150454417565600398271936e8141'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9b8276c7-47ff-93be-a0a0-b059ae57dce5"}, traceId: 2150417717565600403098810edc44'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 429 - {'success': False, 'message': '平台限流', 'data': None, 'code': 'PL-002', 'detailMessage': '平台限流, traceId: 215044fd17565600417598672e8177'}
[RETRY] Rate limited, waiting 2.7s before retry...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5211
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5211
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"36d201f3-687b-9f3b-ae07-2e816c1b4d46"}, traceId: 2150417717565600427518821edc44'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a1d5bcb-2488-91bc-841a-ddc98db2fbc0"}, traceId: 215045ee17565600449271577e7b51'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...2025-08-30 09:21:06,062 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:06,086 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:06,086 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:06,086 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:06,575 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:06,775 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:07,372 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:07,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:07,914 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:07,924 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:07,924 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:07,947 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:07,947 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:07,947 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:08,534 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:08,545 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:08,545 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:08,568 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:08,569 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:08,569 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:08,899 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:09,423 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:10,188 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:10,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:21:11,482 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:11,489 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:11,530 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:11,638 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:12,047 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:12,863 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:13,050 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:14,141 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:14,162 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:14,549 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:15,067 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:15,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:15,782 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:15,830 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:15,847 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:15,847 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:15,868 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:15,868 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:15,868 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:16,337 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:16,504 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:17,164 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:17,846 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:17,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:19,098 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:19,263 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:19,865 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:19,876 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:19,877 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:19,900 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:19,900 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:19,900 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:20,371 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:20,697 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:21:20,873 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:21,581 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:21,791 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:22,407 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:22,616 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:22,635 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:22,954 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:24,202 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:24,224 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:24,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15214
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15214
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8df01c6d-42de-98ee-90f8-27bdef86ba3b"}, traceId: 215042f817565600495731036e262f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8df9e04d-26b4-9e1c-b4c3-ac5304357c48"}, traceId: 215042f817565600514511045e262f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"58905c93-c2b9-99c8-ab11-d39d2a099048"}, traceId: 2150417917565600519338379eeef1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06277231-e94a-963a-a075-1b08998b392f"}, traceId: 215044fd17565600532484920e7f64'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"80d165b1-8eb1-91c9-88ac-caec3cd734fc"}, traceId: 215042f817565600534831051e262f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db6feaf5-6c70-9253-9d74-7d4dd6f4b0e8"}, traceId: 215042f817565600558621072e262f'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc810881-7d07-93cc-88ac-28c2b020fdc8"}, traceId: 213e06a117565600563877626e8a42'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5123
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5123
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1694568-8384-9476-8043-ef32deab59fa"}, traceId: 213e007b17565600584851548eedb4'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"62048706-4182-9034-9647-f801afacd62f"}, traceId: 215042f817565600598731103e262f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8114ffb1-4c82-99a1-9020-f62e625a32e2"}, traceId: 2150416017565600608941022eefde'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ba5c3fc3-7422-9fa2-8ab8-f59b7a56ef8b"}, traceId: 215045a817565600611105863e7ecb'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b41d6b14-b9ef-936b-9c17-fe03e359090f"}, traceId: 215045a817565600634145880e7ecb'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2896d2c5-876a-92a7-a8cd-2b26d035d6fe"}, traceId: 215045a817565600639137244e7e03'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...2025-08-30 09:21:24,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:25,152 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:25,279 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:25,798 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e32910e8-e397-9771-b14c-05a55fb2c9e2"}, traceId: 2150454417565600402982517e830f'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0f8a65b3-8e96-97e9-902f-be45dc47cb8a"}, traceId: 2150430d17565600415275431e96ca'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b5b37dc-0682-9528-b871-8989f5a4dc7b"}, traceId: 2150454417565600422472524e830f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"019daade-a6c4-9468-a35f-cab5ecd4072d"}, traceId: 2150454417565600444002539e830f'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"19aa9e33-925b-93d8-99ed-917606e21f7f"}, traceId: 2150454417565600479642555e830f'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d88b4f36-d9c0-9b6b-aed4-9a5096f83008"}, traceId: 2150452b17565600493815542e78d3'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c84eab45-bdf6-99ff-a1c0-0f04ad043774"}, traceId: 2150454417565600504042570e830f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"30cd4267-e273-9813-946a-dbcf545b1846"}, traceId: 2150452b17565600514155559e78d3'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a123f64c-c892-981a-b8ed-cac9e37b915b"}, traceId: 2150417917565600528955613eec5e'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8a09be2b-af74-96c9-bcae-b9c903954beb"}, traceId: 2150452b17565600544735576e78d3'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b3db9685-345c-90d8-b818-9a9e963a66d9"}, traceId: 2150417917565600556495621eec5e'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"64b04a54-9d51-9ce6-ab13-541d78e1ffec"}, traceId: 2150452b17565600563495589e78d3'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c6a45fe6-7390-9126-8e5d-70c40d9c7115"}, traceId: 2150417917565600574325629eec5e'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c1fefa04-7a7f-9fb4-bff1-0404053df305"}, traceId: 2150452b17565600603525599e78d3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection2025-08-30 09:21:25,859 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:25,942 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:26,600 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8987f085-d1e0-93c7-8820-caafe0d6e5ad"}, traceId: 2150417717565600463948838edc44'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"60ca8b11-329a-9f8c-a5e4-cfc1ea19909b"}, traceId: 2150417517565600481356808ee145'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c73d9d40-3366-90ff-9f06-78280e28952d"}, traceId: 2150430c17565600499193022e2143'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1634c494-2857-9240-95ea-a1693010592b"}, traceId: 2150417517565600509446819ee145'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5193
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5193
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"80eecbd0-8028-9920-b28f-732514bbdd81"}, traceId: 2150449a17565600524646534e82c6'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78ad9392-ff67-9daa-a14e-f47ac974cc05"}, traceId: 2150449a17565600548966548e82c6'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6eaf9141-f6e3-939a-967e-10ed5809dbf3"}, traceId: 2150417517565600557636858ee145'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29a224db-979c-9404-8a3c-c87084d81263"}, traceId: 2150449a17565600573306564e82c6'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.66
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5177
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5177
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a41dc02-1068-93eb-a605-0a3e41ad74c4"}, traceId: 2150417517565600597316883ee145'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f084b88-5f05-98f1-b984-5812b4c69398"}, traceId: 2150449a17565600624676583e82c6'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"57cbdc4f-85c3-9223-aa08-eaed898d1b5e"}, traceId: 2150417517565600653036926ee145'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5263
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5263
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-30 09:21:26,841 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:27,000 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:28,224 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:28,237 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:28,237 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:28,261 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:28,261 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:28,261 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:28,347 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:28,352 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:29,036 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:29,641 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:30,100 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:30,272 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:30,794 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:30,915 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:31,952 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:32,077 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:32,232 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:33,157 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:33,805 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:34,467 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:34,594 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:34,755 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:34,780 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:35,850 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:36,472 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:36,484 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:36,484 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:36,511 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:36,511 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:36,511 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:36,679 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:36,797 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:37,312 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:37,643 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:37,672 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:37,907 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:38,562 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:39,184 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:39,184 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:39,964 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:39,979 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:39,979 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:40,004 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:40,004 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:40,004 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:40,107 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:40,525 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:41,805 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:42,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:42,743 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:42,853 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:43,172 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:43,507 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:43,518 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5227
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5227
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c775afa-a5b7-9760-916a-325b1407cab0"}, traceId: 215045a817565600673935897e7ecb'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fb14261c-4dea-9652-aaca-d6602bda2b66"}, traceId: 213e065e17565600676777750e8082'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13115
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13115
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe6dd5e2-349b-94dd-b2bd-b9d8652e3fb3"}, traceId: 215045a817565600706125915e7ecb'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f87b73fb-bdf6-9fd5-9bbd-562c6d96147d"}, traceId: 215045b717565600721156035e8037'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8eea3530-8343-9360-b237-f0d0b03ffc46"}, traceId: 215045b717565600749026058e8037'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a540cdf8-6ffe-9dcd-81b1-e19ed7beaca8"}, traceId: 215045a817565600755755942e7ecb'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8da10658-8da1-975f-8e33-c491e3facc36"}, traceId: 215045af17565600763007671e8130'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"55ea6a20-326f-9b90-ac4f-1ccc9ea59aa3"}, traceId: 215045b717565600769106070e8037'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c39c6c6d-7d6d-99f5-94e5-a7fa9ae83cab"}, traceId: 215041a817565600776797391e368d'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5199
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5199
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e58a98c-1e05-9943-af26-9e8a2e9232d3"}, traceId: 2150454417565600801794320e826b'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4bca9c82-1915-9f35-90df-f965752f68e1"}, traceId: 215045b717565600822176103e8037'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8d670ab-f6b8-9605-89e1-faa2160980a4"}, traceId: 215044eb17565600839367555e7f90'}2025-08-30 09:21:43,518 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:43,541 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:43,541 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:43,541 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:44,095 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:44,158 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:44,531 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:44,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:44,864 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:21:45,989 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:46,242 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:46,784 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:46,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:46,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:47,296 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:47,774 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:47,961 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:48,266 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:48,374 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:49,228 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:49,800 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:49,860 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:49,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:50,278 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:50,858 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:50,939 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:51,909 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ee881685-fc0e-9f7a-98fa-4b7505a3095f"}, traceId: 2150417517565600611247689ee187'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad28bf5a-fc41-9a8a-b3ee-5be219cd2274"}, traceId: 2150417917565600608975643eec5e'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bbc694af-0634-974a-aede-50622bf787e2"}, traceId: 213e007b17565600629036990eecee'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f5da51e8-9940-9729-8624-d0526a74dd75"}, traceId: 2150417917565600650935664eec5e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa259fb5-cb6e-9fec-88ff-5fe5b29df157"}, traceId: 213e004f17565600663462075ee698'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fcf94af5-7489-9c72-aa8e-00eb17bf20cc"}, traceId: 2150452b17565600665225558e7998'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10237f3d-e055-9161-b0bd-14c93baac953"}, traceId: 2150452b17565600686965569e7998'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4069e98d-a606-932a-afe8-9de31acbf60a"}, traceId: 2150452b17565600718155592e7998'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01a72fd1-336d-9e02-afa7-62e0e4e55809"}, traceId: 215045b417565600723382610e8170'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"155ed4a8-3791-9bbc-8660-0f5355014bf8"}, traceId: 2150452b17565600743105604e7998'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fd700d78-b4fd-94dd-8cac-f1e5ec4edfce"}, traceId: 2150455217565600755264681e8357'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b6db24c-d8df-99e7-82a1-eb7c3d7f5c48"}, traceId: 215041a817565600776514781e3439'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fced8fc5-d13b-96da-9fb3-a1b7fd9e3059"}, traceId: 2150409517565600819107988eec66'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b78a7fdf-8d05-9498-a92e-691fb8d39f26"}, traceId: 2150452b17565600824015644e7998'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5da0957d-77a4-96d3-b8d3-9dff256b726f"}, traceId: 2150452b17565600834825646e7998'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2cfc0a2-d1ff-990b-aca8-8212c36b3bee"}, traceId: 2150452b17565600855645655e7998'}2025-08-30 09:21:51,990 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:52,305 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:21:52,559 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:53,108 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:53,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:53,609 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:53,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:54,939 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:56,258 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:56,780 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:57,075 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:21:57,434 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:57,457 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:57,458 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:57,491 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:57,491 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:57,491 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:57,514 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b71e715-78c6-96f4-b136-35b11dfabde2"}, traceId: 213e03d917565600671514426e1e03'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"daf46dcb-da66-99cb-b152-e0bcb9de8cc9"}, traceId: 2150449a17565600677886602e82c6'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"84fdafe6-7fbb-9846-afd0-747379cd9da1"}, traceId: 2150458717565600686852810e8056'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9f25678f-9937-9b73-ac8d-419fe5e51278"}, traceId: 2150456317565600712933979e7fed'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7280aacf-3918-96bb-91ec-030e878df19b"}, traceId: 2150438d17565600709061883e2b93'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
Progress: 10/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13131
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13131
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88fe310c-a61a-9081-b738-d903b93dcb4a"}, traceId: 2150438d17565600738241896e2b93'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e3c60e80-96d2-9d7c-b1e2-e952de43e3ec"}, traceId: 2150436817565600748066481e1c73'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fea3d039-1ba3-9e77-b20e-24cbd81daabd"}, traceId: 2150438d17565600760871910e2b93'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a219c751-6208-9467-addb-25a570450078"}, traceId: 2150438d17565600785371925e2b93'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"569b3d5e-9ed9-9ba0-81dc-2fe46728e3f1"}, traceId: 2150455217565600796655252e816b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"46626340-8a9c-91b2-b1b6-89feed1a6539"}, traceId: 2150456117565600808343981e80a9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5213
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5213
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"553f812c-2f5b-9bfd-9d8b-2b57173b2d20"}, traceId: 2150456117565600834763995e80a9'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e850e03-7bd1-98a7-a290-3f4b38c8be28"}, traceId: 2150438d17565600862741955e2b93'}2025-08-30 09:21:57,601 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:58,621 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:58,634 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:21:58,634 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:21:58,658 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:21:58,659 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:21:58,659 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:21:58,858 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:21:59,700 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:21:59,786 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:00,323 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
Progress: 10/35 (Success: 0)
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6cc72bc-6ea6-91ea-b3c8-fc739f70d2dc"}, traceId: 215045b717565600865776125e8037'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b881fc6f-b5e9-9ee4-8bcb-4589b43b5c39"}, traceId: 2150448717565600875183742e7e18'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5127
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5127
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9e83970a-fef7-9895-94a2-76d5452b6907"}, traceId: 215045b717565600880956133e8037'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"744af1cb-822b-9fbe-b921-6ad293240606"}, traceId: 215045b717565600905296147e8037'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f45c8b46-6db0-9115-b7b8-23a7d1d5514d"}, traceId: 215045b817565600918394836e7f02'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e88ea303-5712-92e6-a8b5-65152ea69c2b"}, traceId: 215045b817565600941584843e7f02'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5353c9c8-c7e3-9ca6-9c20-146f780934bb"}, traceId: 215045b717565600965596167e8037'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dcabb603-fb2f-931d-8a7d-3e09bbd0b348"}, traceId: 215045b817565600973894856e7f02'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b08c7bc8-d175-92b4-a207-294922d39cbd"}, traceId: 215045b717565600983736175e8037'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"79692d53-2bd8-90ff-a65f-bac30361844b"}, traceId: 215045b817565601002784872e7f02'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b610b46-19c1-967d-a491-d2b22e689d36"}, traceId: 215045b717565601025226204e8037'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2b7ff05-6393-9077-bc02-8aeae3f046b0"}, traceId: 215045b817565601032624899e7f02'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13037
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13037
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)2025-08-30 09:22:00,455 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:00,556 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:00,556 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:00,580 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:00,580 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:00,580 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:01,476 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:01,492 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:01,492 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:01,517 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:01,517 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:01,517 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:01,592 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:01,625 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:01,625 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:01,652 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:01,652 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:01,652 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:02,120 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:02,405 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:02,871 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:03,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:03,166 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:04,017 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:04,075 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:04,460 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:04,942 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:05,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:05,399 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:06,490 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:06,743 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:06,954 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:06,985 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:07,118 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:08,611 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:09,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:09,578 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:09,578 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:09,605 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:09,605 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:09,605 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:10,089 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:10,107 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:10,107 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:10,132 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:10,132 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:10,132 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:11,031 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:11,100 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:11,101 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:11,635 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:11,840 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:12,780 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:13,126 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:14,249 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:14,284 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e4f5d00-7ad5-908f-8930-834a2bb9c6c3"}, traceId: 213e006e17565600852311285e15d4'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43902e39-996c-95ef-a280-f90dd3480c8c"}, traceId: 2150452b17565600881015669e7998'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59488602-6dfb-9970-a872-f4b17a25cb36"}, traceId: 213e007917565600894171476eebc2'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a4e1e0b-d187-908d-ad14-b72892d49b59"}, traceId: 2150421317565600920344277e34a2'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"410aad37-cd19-90a9-a067-d03919813ff2"}, traceId: 2150452b17565600945235696e7998'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b79efc39-7b84-9f0a-acba-18c6c3397245"}, traceId: 2150417917565600962755915eee4c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"709cc63f-e42e-95e1-8791-3e117065e60d"}, traceId: 2150452b17565600965535706e7998'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5cb8da23-c821-99d4-86ce-db4bb957da65"}, traceId: 2150409517565600976646448eeb5d'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"16fc9845-7425-943d-a630-148dc0b8b511"}, traceId: 2150452b17565600988855712e7998'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac25c727-2b2f-958a-ad2d-1332e9a3d79c"}, traceId: 2150409517565600998736457eeb5d'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5797b211-3753-9f33-947c-c07593a6752b"}, traceId: 2150452b17565601029475720e7998'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d8d8548a-39ad-9d39-951b-94f1e0e020cc"}, traceId: 2150409517565601034256468eeb5d'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1cd6e42a-3814-9f4c-a9e3-1125ef406cb6"}, traceId: 2150409517565601065556475eeb5d'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"607a734b-0ddb-92e8-8025-6d02acda83e1"}, traceId: 2150452b17565601075135736e7998'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6c8948a-41a9-99ac-936d-b53035670ddc"}, traceId: 2150452b17565601095475740e7998'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5f5117e2-2256-973a-af38-827e7252edac"}, traceId: 2150409517565601111326491eeb5d'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...2025-08-30 09:22:14,295 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:14,295 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:14,320 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:14,320 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:14,320 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:15,223 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:15,527 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:16,456 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:16,467 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:16,467 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:16,491 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:16,491 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:16,491 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:16,564 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:16,577 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:16,577 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:16,600 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:16,600 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:16,600 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:16,698 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:16,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:17,527 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:17,675 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:18,099 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:18,916 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:19,418 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns

[TURN 10/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e056d4b-afd8-98d9-99b2-4d56a7ea59fd"}, traceId: 215045b717565601065886224e8037'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7b0b05dc-450f-997c-828e-2a19d3cf3038"}, traceId: 215045b717565601080216229e8037'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"00349df5-6339-9536-bcac-755bc7247587"}, traceId: 215040be17565601085043676ee170'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ec93f17d-c453-9418-ad59-251add354781"}, traceId: 215045b717565601096346235e8037'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08ad5009-04c4-9a9f-9c44-e09c27b8ce19"}, traceId: 215040be17565601106293688ee170'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.62
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a03fb43b-c265-92ca-b580-0f8d109748f3"}, traceId: 215040be17565601123223696ee170'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d61716a-1c0a-98fb-8dba-5595839c43d8"}, traceId: 215045b717565601128726249e8037'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f37c2aa-0f3b-9371-bcce-e73a3d5b153c"}, traceId: 215040be17565601155073711ee170'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9fb03f43-15d4-9ee6-9d81-c40a8f22c964"}, traceId: 215045b717565601171926261e8037'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 4 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 22292
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=22292
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9244a20-9af8-92d6-8d4c-d283fee60092"}, traceId: 215040be17565601183733725ee170'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"deaa3c6f-7db4-9bc2-806c-6f13343a4a94"}, traceId: 215041d717565601181335744e3386'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4f4b4a7-b16b-93ba-a29a-0e21878ace7f"}, traceId: 2150436a17565601195923227e21a1'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed6c8387-ce30-968b-bed6-9514212682a7"}, traceId: 2150457117565601195826386e7add'}2025-08-30 09:22:20,101 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:20,221 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:20,349 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:20,365 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:20,365 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:20,402 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:20,402 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:20,402 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"756dee75-7568-9554-be98-db7de467a906"}, traceId: 2150456117565600888014028e80a9'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c715498-3c59-9488-af96-604324708ac3"}, traceId: 2150438d17565600899431968e2b93'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9b5200a5-eb61-938c-829f-3aa490789af5"}, traceId: 2150456117565600912084042e80a9'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ce2c471-4871-9dd7-a7ba-1d790067978f"}, traceId: 2150438d17565600929081976e2b93'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2741bbd9-b4be-9c2c-a816-c4b9374095c1"}, traceId: 2150456117565600943384051e80a9'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e188301-f44c-9cb1-b597-1a0f5208d36e"}, traceId: 2150438d17565600964371988e2b93'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"993b97f5-0af8-90d4-8035-22ee446aaa82"}, traceId: 2150456117565600983264066e80a9'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0f77ef19-94ad-9507-b683-935f34bbb7c6"}, traceId: 2150438d17565600997181996e2b93'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13488
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13488
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bdf09e3f-ac83-93e6-afb8-6400f7ecae13"}, traceId: 213e060b17565601012394053e897a'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4cf11edd-af4d-9d69-93ad-b99ef7623cf4"}, traceId: 2150456117565601044844090e80a9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa5d0b61-19a5-9a68-9a3a-f0e20a87039c"}, traceId: 213e06c817565601060526466e835f'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db67efd5-aa78-948d-abb7-4012e34d8b7b"}, traceId: 2150456117565601076274104e80a9'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eab1f8ff-7b2c-9d60-bbf9-175c6902793e"}, traceId: 213e06b717565601092281055e7712'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd00af9c-a76a-9d51-b2b3-95bf2307218c"}, traceId: 213e063817565601128663841e7f50'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b59073db-9f56-9d1b-be17-4bb607620c3c"}, traceId: 213e007c17565601172918337ef042'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...2025-08-30 09:22:20,991 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:21,028 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:22:22,154 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:22:22,586 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:22,652 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:23,114 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:23,504 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:23,505 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:24,204 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:24,744 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:25,063 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:25,295 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:25,317 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:25,317 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:25,344 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:25,344 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:25,344 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:25,574 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:26,317 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:27,174 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:27,282 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:28,426 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:28,446 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:28,447 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:28,471 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:28,471 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:28,471 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:28,556 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:28,856 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:29,409 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:29,902 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:29,926 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:30,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:31,014 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:31,885 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:32,000 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:32,011 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:32,012 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:32,036 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:32,037 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:32,037 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bdb8d96-625f-94bf-a06a-16f3b4a9c0d6"}, traceId: 2150452b17565601128715759e7998'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fb2b9fb7-b280-9ad5-95d2-f2fbedaabbe5"}, traceId: 2150409517565601133696503eeb5d'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"304d358a-7d60-9f4a-92d9-5c285e210321"}, traceId: 2150409517565601147126509eeb5d'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cde033fe-538e-969f-a96e-813b326ae3d4"}, traceId: 2150452b17565601160405775e7998'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d01c9d7-753b-956e-99bf-923a6511652b"}, traceId: 2150409517565601173506516eeb5d'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb40b446-c253-9d9e-9272-48008abfb788"}, traceId: 2150409517565601201846526eeb5d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5261842e-b07b-9010-b288-b8bdbe358abb"}, traceId: 2150452b17565601207395790e7998'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"02b88844-0810-9522-927c-8256c9ff1bdb"}, traceId: 215042f817565601213777218e26b4'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d03b9ce-e54c-93da-9d2a-82ec47c86d2f"}, traceId: 215040ed17565601228122741ebe85'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a93977c7-930e-9d6a-8e5e-fbe9323d02fa"}, traceId: 2150416417565601233486962e1325'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"915abe28-8c22-9ef0-995a-e1eec09c7fdb"}, traceId: 215040ed17565601247052751ebe85'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf3eb9ef-08b5-9e9d-99d2-2aec71ed1d0d"}, traceId: 213e007017565601262444576eead5'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a08ad2c6-f0d0-9f09-964a-fdb8a8afbaa9"}, traceId: 215040ed17565601267352760ebe85'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3350d3b6-8ab4-9ba7-9649-1ee2b7af3bc6"}, traceId: 215040ed17565601308592780ebe85'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"192e88cd-7a84-973b-b9cf-bc5a795883f0"}, traceId: 213e066017565601303731326e882d'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a020ee9-10cc-9a6a-bc38-61f6f9138587"}, traceId: 215040ed17565601335342789ebe85'}2025-08-30 09:22:32,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:33,119 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:33,368 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:33,927 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:34,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:34,982 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:22:35,892 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:35,915 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:35,933 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:35,933 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:35,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:35,962 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:35,962 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:35,962 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:36,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:36,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:22:36,981 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:38,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:38,046 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:38,826 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:39,443 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:39,447 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:39,456 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:39,466 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:39,467 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:39,490 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:39,490 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:39,490 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:39,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:40,142 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:40,920 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:40,920 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:41,440 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8b9105d-aa9b-942d-af6d-174b0657a4c5"}, traceId: 2150457117565601216656396e7add'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c57b2cc0-a60a-993d-981f-1f409e571457"}, traceId: 2150409b17565601221711719e082a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6a86eb8-36d1-9077-ab08-903c128254f0"}, traceId: 2150457117565601242256403e7add'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7936f01-579e-9562-a0cb-d1998850192b"}, traceId: 213e065917565601247525101e815b'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13313
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13313
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"07725f7d-406c-91b2-86d0-204ffd88707f"}, traceId: 2150457117565601262496412e7add'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e018acd-74e3-956f-9182-85c3c76b2752"}, traceId: 2150409b17565601288591604e087f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50d7c456-0be8-900d-9001-67ac62660b58"}, traceId: 2150457117565601293716425e7add'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"982317a0-d32d-9639-93be-2837e95f7fef"}, traceId: 2150460e17565601309353080e79de'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8350f8f0-31a0-940f-ad4e-98e6d83a01c0"}, traceId: 213e065917565601324914754e8032'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c2cbe41-50dc-9cd4-8279-0594efad424d"}, traceId: 2150415b17565601335528382ee55a'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a1674da-4e9c-99ab-b180-3f53ab0009d0"}, traceId: 213e065917565601344354761e8032'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98e1994a-a033-9869-815d-633cf2d38d7f"}, traceId: 213e011517565601364643942e920c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4b400128-371e-993a-ab00-d04f1410dce8"}, traceId: 213e065917565601362574770e8032'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5828
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5828
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"156edf33-e97d-95c2-9289-d00ed1546feb"}, traceId: 213e065917565601391704777e8032'}2025-08-30 09:22:42,246 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:42,274 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:42,363 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:42,379 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:42,804 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:43,843 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:22:43,869 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:44,257 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:44,319 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"027c2444-3bd1-97f6-93a2-3382aef05d8d"}, traceId: 2150456117565601189564169e80a9'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3362c31a-cd24-9799-a9cc-80739b85699a"}, traceId: 215042f917565601208703437e1aad'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13430
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13430
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f16c1335-4515-9349-a1ed-8b8e814ffe29"}, traceId: 2150456117565601223584178e80a9'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5a1ba77-23e7-9172-80b9-311a0de7a8ee"}, traceId: 215042f917565601237884443e1bdb'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"557bbb82-bb16-91dc-9ea2-d1a7777506e2"}, traceId: 2150456117565601265074190e80a9'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e40401c2-a417-9744-8ed3-892918fead7c"}, traceId: 215042f917565601263844455e1bdb'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"40ca8b54-e385-9cf5-b707-76eb5ae01f3a"}, traceId: 215042f917565601283534462e1bdb'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6e28259-13f4-9bf4-8f42-667ee02af07d"}, traceId: 2150456117565601307084203e80a9'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9b1df8af-8700-9e32-a2ad-f396ff241780"}, traceId: 215042f917565601323464481e1bdb'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0c29d10-53ef-9642-bec0-d98614bd2be6"}, traceId: 2150456117565601358184219e80a9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14114
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14114
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9e90804d-57ec-9aaf-8936-5b3ed26d83ea"}, traceId: 213e063717565601394783190e88ec'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9e54aa7-0cfb-9f0a-9446-e82f4748ca7c"}, traceId: 215042f917565601396144502e1bdb'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-30 09:22:45,012 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:45,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:45,852 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:46,545 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:46,556 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:46,556 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:46,582 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:46,582 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:46,582 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:47,002 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:47,271 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:47,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:47,831 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:47,893 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:48,255 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:48,613 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:48,779 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:49,053 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:49,838 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:22:50,453 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:50,461 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:50,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:50,489 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:50,490 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:50,513 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:50,513 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:50,513 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:50,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:51,153 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:51,465 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:51,484 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:52,448 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:53,372 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:54,022 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:54,079 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:54,456 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:55,694 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:55,952 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:56,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:57,166 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:57,184 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:57,184 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:57,209 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:22:57,217 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:57,217 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:57,217 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:22:58,215 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:58,228 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:22:58,228 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:22:58,253 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:22:58,253 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:22:58,253 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5319d6d3-4e0b-9d1d-b876-5d6089ddc07f"}, traceId: 213e060c17565601352806499e8a8c'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fc9a1d4d-7171-92a0-b254-23d918914885"}, traceId: 213e006a17565601357381851ee3a3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ec615c1-f2c4-9190-aa2b-9ff7f0ccb681"}, traceId: 213e060c17565601367626515e8a8c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"16fb4e19-855e-9033-828b-5b2abf50e6b3"}, traceId: 213e007517565601378633379eee8a'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"107b2f58-7f27-9977-918a-5a1502789b98"}, traceId: 213e06a117565601399047092e8bf0'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4176ec65-4dd2-97d1-b20a-77c671e785db"}, traceId: 213e060c17565601401886540e8a8c'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a23a2fb-f02c-9828-ab34-b4c8368edf64"}, traceId: 2150416717565601423821126eeceb'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86ebca16-5f23-9ea8-bff8-4e5a593ad80c"}, traceId: 213e060c17565601428656554e8a8c'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bc03bc5-6d58-9c29-b645-0571a98d9251"}, traceId: 2150456117565601456027497e80ca'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04a9b944-cdc1-93c0-8949-5179a5aec9e2"}, traceId: 213e060c17565601476666580e8a8c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b378682-d3b7-9125-a688-c45736826591"}, traceId: 213e06c317565601495815144e7c82'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cee1a860-d2b8-9035-af23-dec346e94cef"}, traceId: 213e007e17565601517488101eeed5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct2025-08-30 09:22:58,334 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:22:58,741 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:58,777 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:22:59,651 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:00,046 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:23:00,148 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:00,175 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:00,187 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:00,188 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:00,218 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:00,218 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:00,218 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:01,656 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:01,888 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:23:02,498 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:02,512 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:03,324 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:03,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:04,357 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:04,389 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af37a44a-196b-9aaf-b40d-ae8559f3b254"}, traceId: 2150409517565601419535266eea34'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"05a65656-97b0-956e-b810-2174cf0ecced"}, traceId: 213e042f17565601445408861e2474'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5848
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5848
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac6a7cdf-cf70-99f4-a164-6590776d189b"}, traceId: 213e065917565601445604804e8032'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1eb53360-4b77-95b3-aca1-9998736b6f7b"}, traceId: 213e081017565601465762814e0b6e'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"abaff66f-05a9-9cf0-9017-71181084aca6"}, traceId: 213e066d17565601483177253e8159'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0db0380-055f-938f-bfcc-016cebea34f2"}, traceId: 213e059717565601491914060e3864'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e14cf3e-043c-9783-9992-f6dc65a2f27a"}, traceId: 213e066d17565601496947257e8159'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5fd81899-fe25-9d0b-a0d5-8ffff3c75497"}, traceId: 213e066d17565601518317266e8159'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5848
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5848
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8104be25-2e03-9033-b9f8-f58ff86696d5"}, traceId: 213e066d17565601556767282e8159'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8fc07838-0921-9cfa-9493-a7e39fc288d2"}, traceId: 2150456617565601585268021e8203'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66272cb7-ec22-929e-9517-9a9aae01dbce"}, traceId: 213e066d17565601592197302e8159'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06640af0-190c-9f16-9b09-164efa9a08a5"}, traceId: 213e064d17565601605972125e8432'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6f50199f-461d-9b00-bb4f-31c13344421a"}, traceId: 2150421317565601612176973e3691'}2025-08-30 09:23:04,407 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:04,408 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:04,433 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:04,433 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:04,433 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:05,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:05,562 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bb27a784-1b69-9c3e-9ea8-cdc743626388"}, traceId: 215045c117565601427993018e7f86'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"364500fa-a066-9515-a2fa-82267a9d67be"}, traceId: 213e063717565601432813208e88ec'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5504
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5504
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b5992761-101e-921a-8ec9-3c81e1158939"}, traceId: 215040ed17565601453684365ebec5'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5be87266-009b-9b8c-95da-ea3f8819a7af"}, traceId: 213e063717565601464283218e88ec'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e5e7b24-823b-9617-83e5-be99869281a5"}, traceId: 213e043b17565601485917906e238b'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7e314ba-3ca8-9f34-94a2-82402c316ce4"}, traceId: 213e006817565601503112857ee5a2'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc4435d2-bf71-903b-b3db-8d160b68c0c5"}, traceId: 213e063717565601511463235e88ec'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8972e36d-79da-936e-b554-d87510ba7b6f"}, traceId: 2150416a17565601551712972ee040'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c3e976e-c5a3-9364-9e4c-b96aaaf4c53d"}, traceId: 213e063717565601556763249e88ec'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13474
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13474
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"55213e96-5fa4-96ed-bbd6-2c26bbde7b0f"}, traceId: 215045c117565601572803013e7f65'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43ed1b8f-5040-9a50-9db4-e5bde0c69739"}, traceId: 213e00cd17565601599492919e94c3'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6ada2a8-34e7-9282-85f0-121ec6d119ca"}, traceId: 213e007d17565601605917172ef086'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78999498-d02b-9f31-94a0-fb830e509b08"}, traceId: 213e007d17565601620037181ef086'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c997a540-1d16-9b3d-86fb-db7ee0494085"}, traceId: 2150435d17565601621642622e21f2'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3469a0bc-bb3c-97f1-823a-7fc1a071c056"}, traceId: 213e007d17565601640717192ef086'}2025-08-30 09:23:05,575 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:05,575 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:05,601 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:05,601 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:05,601 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:06,085 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:06,420 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:06,804 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:23:06,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:06,988 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:07,651 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:07,877 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:08,178 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:09,224 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:09,322 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:10,142 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:10,428 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:10,511 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:10,638 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:10,653 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:10,653 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:10,676 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:10,676 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:10,676 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:11,465 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:12,228 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:12,243 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:12,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:13,079 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:13,081 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193079970.json
2025-08-30 09:23:13,082 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193081848.json
2025-08-30 09:23:13,082 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193082230.json
2025-08-30 09:23:13,082 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193082505.json
2025-08-30 09:23:13,082 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193082766.json
2025-08-30 09:23:13,083 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193082989.json
2025-08-30 09:23:13,084 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193083341.json
2025-08-30 09:23:13,084 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193084138.json
2025-08-30 09:23:13,084 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193084400.json
2025-08-30 09:23:13,084 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193084661.json
2025-08-30 09:23:13,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193084904.json
2025-08-30 09:23:13,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193085158.json
2025-08-30 09:23:13,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193085401.json
2025-08-30 09:23:13,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193085603.json
2025-08-30 09:23:13,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193085827.json
2025-08-30 09:23:13,086 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193086019.json
2025-08-30 09:23:13,086 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193086488.json
2025-08-30 09:23:13,087 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193086764.json
2025-08-30 09:23:13,087 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193087067.json
2025-08-30 09:23:13,087 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560193087369.json
2025-08-30 09:23:13,537 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:13,549 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:13,550 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:13,574 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:13,574 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:13,574 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:13,944 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:14,155 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:14,156 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194156396.json
2025-08-30 09:23:14,157 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194156930.json
2025-08-30 09:23:14,157 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194157252.json
2025-08-30 09:23:14,157 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194157561.json
2025-08-30 09:23:14,158 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194157910.json
2025-08-30 09:23:14,158 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194158381.json
2025-08-30 09:23:14,158 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194158685.json
2025-08-30 09:23:14,159 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194159002.json
2025-08-30 09:23:14,159 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194159247.json
2025-08-30 09:23:14,159 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194159486.json
2025-08-30 09:23:14,159 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194159756.json
2025-08-30 09:23:14,160 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194160012.json
2025-08-30 09:23:14,160 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194160260.json
2025-08-30 09:23:14,160 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194160783.json
2025-08-30 09:23:14,161 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194161018.json
2025-08-30 09:23:14,161 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194161327.json
2025-08-30 09:23:14,161 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194161579.json
2025-08-30 09:23:14,162 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194161834.json
2025-08-30 09:23:14,162 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194162061.json
2025-08-30 09:23:14,162 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560194162294.json
2025-08-30 09:23:14,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:14,998 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:15,007 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:15,025 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:15,025 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:15,049 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:15,049 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:15,049 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:15,078 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:16,286 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:16,571 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:16,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:17,614 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:18,184 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:18,205 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:18,206 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:18,232 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:18,232 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:18,232 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:18,306 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:19,383 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:19,395 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:19,395 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:19,419 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:19,419 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:19,419 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:19,429 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"71dc4e6a-2379-96eb-9b43-235bdd24b1bb"}, traceId: 215042f917565601663373910e19a9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13172
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13172
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"078e07d1-9006-9516-abde-c70049ffaeb6"}, traceId: 213e007d17565601676307286ef086'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7df9c66b-da4c-95ad-8be4-500d09724f68"}, traceId: 213e006c17565601688235052e1198'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"74a27729-43fc-9d37-a11d-311091be473e"}, traceId: 213e007d17565601702307372ef086'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bdb3cb4a-58a8-9605-b1f0-06e8f9775087"}, traceId: 2150416a17565601709608715ede6f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b72c0572-3dfd-9c0f-be6b-dd81a755cdfa"}, traceId: 213e006c17565601712495125e1198'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8381ec5a-72d2-93e3-8567-ab2afe45016b"}, traceId: 215045be17565601726595519e82c3'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3926dea7-b5c3-9f95-97e8-3df886012109"}, traceId: 213e006c17565601738415221e1198'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61a1066f-512f-9668-9b01-c3e318d0ac1d"}, traceId: 2150443817565601752558766e89f1'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14013
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14013
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4f0e164-cdb8-9647-b1bb-212bf4e5ee20"}, traceId: 213e006c17565601780465357e1198'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c1a4db44-d4fe-92da-95e9-f3d83184d48d"}, traceId: 2150452b17565601823086029e7998'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73eb2610-d215-980d-bfc7-f1ec515dfe50"}, traceId: 215040c017565601841655635eddae'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"477979a0-6927-945a-8093-7f732d516393"}, traceId: 213e065417565601847628612e7e97'}2025-08-30 09:23:20,335 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:20,359 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:20,900 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:21,178 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7cafe5dc-1009-9c78-95bd-2e5cd4db8c79"}, traceId: 213e042f17565601528842869e255c'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0fdec22d-c8f0-99a3-ad6e-1ffae35bfdff"}, traceId: 213e06c317565601526125154e7c82'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3201761a-879b-9316-8fa3-0c0f7119349d"}, traceId: 213e042f17565601546542875e255c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c35f14b5-81ab-9e2b-90b4-769d2afdf71c"}, traceId: 213e06c317565601563955168e7c82'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5cd8991f-6e4e-90b6-bd87-6c7d2cacebfe"}, traceId: 213e042f17565601573122908e255c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"82a01f96-6372-97e8-992d-eb73cdea4074"}, traceId: 213e042f17565601591962919e255c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d3cc694-9ba5-9aaa-86cd-65afbb5e1f14"}, traceId: 213e06c317565601587205182e7c82'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6f12e9a6-505d-9bad-836d-cd9a9549adf7"}, traceId: 213e042f17565601635352938e255c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d0b51053-7569-9f21-b84e-3d46341548a1"}, traceId: 213e06c317565601656135243e7c82'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0be7d386-b73e-965e-98a6-fc4b6bb4adc8"}, traceId: 213e042f17565601675903020e255c'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf51bd58-7705-990f-839b-f009945ffecf"}, traceId: 213e06c317565601674345286e7c82'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73acb829-a27e-9b4d-9aaf-b9bdf3cb93ad"}, traceId: 213e042f17565601685423045e255c'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f94a7140-1368-96de-b790-27b44aff429b"}, traceId: 213e06c317565601702315371e7c82'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4d20ba4-bca0-9907-8a8c-9e46454a78c8"}, traceId: 213e042f17565601707083129e255c'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6b87ac2-7684-909e-9648-6b9cdd4b22b9"}, traceId: 213e06c317565601736945484e7c82'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70d6b5cb-1f03-9f42-8b99-b2d1576ff54b"}, traceId: 213e042f17565601754503285e255c'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9904ab91-f7b8-9044-be8f-b34bc1c071ed"}, traceId: 213e06c317565601774215603e7c82'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully2025-08-30 09:23:21,835 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:22,747 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:22,914 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:23:23,040 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:23,073 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:23,397 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:23,540 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:23,576 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"266af91b-7932-912f-8e09-d7723dbfffa3"}, traceId: 213e064d17565601620062130e8432'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5570
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5570
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99c9ee28-f374-9721-a160-9ab38a9b63cd"}, traceId: 213e066d17565601643087728e8239'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3170e600-735f-9a7e-940a-1635f8c14284"}, traceId: 213e064d17565601650832161e8432'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8877f8e1-18e4-96a6-8359-ef8ab94e36dd"}, traceId: 2150417d17565601671086505e13b1'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4b51e3f-2526-944f-8e78-46b9c0205a7a"}, traceId: 213e064d17565601702352319e8432'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb11b560-d767-948f-a37f-2b3667a157b0"}, traceId: 2150417517565601702451813ee05d'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04735d04-166b-9776-898c-6135a229649b"}, traceId: 213e064d17565601721742392e8432'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a047b5f7-133c-9792-81af-30ffa21dc74c"}, traceId: 215044eb17565601737972968e8225'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c707281c-9e77-94af-8995-560901b4c5b7"}, traceId: 213e064d17565601754662489e8432'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f5d37766-f964-9c6b-9459-cca6557f3dc1"}, traceId: 215041d717565601764234441e35b7'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14216
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14216
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"948257c7-c474-9cf3-a606-4cec9510ccca"}, traceId: 2150423617565601781447948e0b60'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66b504db-67ef-9e52-b2ab-786d62a19360"}, traceId: 213e064d17565601784282602e8432'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ee6322e-ca2e-9953-b380-0be6427c037c"}, traceId: 2150460817565601794491934e7a5a'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59fa6723-2aa0-9e6d-8dde-22a6a5988281"}, traceId: 2150458117565601831206560e81bb'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e76d53e6-6f93-9dc1-9871-851d34bbb62e"}, traceId: 213e064d17565601836602683e8432'}2025-08-30 09:23:23,781 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:24,603 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:25,024 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:25,252 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:26,004 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:26,527 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:27,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:27,151 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:27,151 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:27,174 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:27,174 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:27,174 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:27,261 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:27,676 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:28,382 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:28,623 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:28,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:28,636 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:28,636 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:28,660 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:28,660 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:28,660 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:29,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:30,196 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:30,259 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:31,062 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:31,324 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:31,336 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:31,337 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:31,360 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:31,360 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:31,360 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:31,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:31,805 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:32,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:32,007 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:32,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:32,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:33,615 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:34,046 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:34,758 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:35,306 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:35,317 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:35,331 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:35,870 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:36,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:36,395 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:36,539 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:36,551 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:36,552 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:36,579 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:36,579 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:36,579 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:37,054 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:37,540 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4829
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4829
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6a57f61-598c-970f-9aba-36309dc1a634"}, traceId: 213e043117565601868258122e2377'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"76681f24-dfe6-9a26-8ed3-0830fa5552d0"}, traceId: 2150417c17565601874515639ef1e5'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8cf8ddd-e356-9844-8a5c-236e664a4292"}, traceId: 2150449a17565601894331734e80b6'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b606f9d-5d0e-9fad-92d2-fadce4fd1b9b"}, traceId: 213e043117565601896838172e2377'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1e8a0ff2-fba7-95b8-92c1-000e62608170"}, traceId: 213e043117565601914848220e2377'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"769423ee-7b3f-917b-9a07-1f171882137a"}, traceId: 215041de17565601925586325e32e3'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/30 (Success: 0)
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"117e5992-dfd6-9c18-a33f-a4ec84b86659"}, traceId: 213e043117565601948198261e2377'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f4143622-57a3-9cd3-8cdc-e218754050e7"}, traceId: 213e065017565601958656202e7e45'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"966f724b-f48d-96bb-8da3-8e466cbd4c08"}, traceId: 213e043117565601978778282e2377'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4971
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4971
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"46f36624-469f-904c-85a3-34e82e1717d8"}, traceId: 213e064e17565601991734035e81ad'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7831b1f8-9b77-91fd-b3bf-37b2cf693716"}, traceId: 213e041717565601991914758e9774'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...2025-08-30 09:23:38,101 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:38,268 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:38,618 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:38,803 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:39,111 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:39,635 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:40,220 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:40,233 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:40,233 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:40,259 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:40,259 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:40,259 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:40,790 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:40,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:41,771 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:41,787 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:41,821 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:41,923 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:42,791 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:42,793 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13592
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13592
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c9085cdd-20f0-9365-b67a-357e8bc4cc39"}, traceId: 215045ee17565601862681474e7901'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"559e894b-98c9-93b3-81da-8022cd4f24c9"}, traceId: 213e007d17565601884077541ef12c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"69ef5e18-99f1-975b-9290-559759f09b17"}, traceId: 213e007d17565601902207552ef12c'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db5fd860-13f6-96b0-b8fc-119e17de31ca"}, traceId: 213e011517565601899412909e91ca'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef4e4b08-3d70-9056-ac42-5364f77b3e18"}, traceId: 213e03d917565601914986074e1fd0'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.75
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5848
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5848
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dfa3182b-db39-9136-83dc-0119d5d1ace7"}, traceId: 213e007d17565601934507574ef12c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9684ecae-1514-925a-a54d-005aac3415ff"}, traceId: 213e03d917565601942616089e1fd0'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ef7ba2e-3899-9d70-bedc-100b359bb7fc"}, traceId: 213e007d17565601963897586ef12c'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"67efc3c0-3d9d-9d11-9fb2-14f1cde0dec4"}, traceId: 213e03d917565601968646102e1fd0'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4162d649-4689-996c-a001-daaf211cb5bb"}, traceId: 213e03d917565602001146114e1fd0'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"728e9b87-eeeb-9466-9b52-0b6d1811c161"}, traceId: 213e03d917565602028176144e1fd0'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fab32ca6-7008-9463-812a-0c61f37bb8f9"}, traceId: 213e007d17565602033467625ef12c'}2025-08-30 09:23:42,815 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:42,815 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:42,840 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:42,840 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:42,840 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:43,365 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:43,827 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:43,829 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:43,829 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:44,495 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:44,775 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:45,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:45,715 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:45,806 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:45,812 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:46,566 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61ef2ccb-196f-99ac-a92c-fe93cb62c3c5"}, traceId: 2150449017565601794588319e7f0a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e40047d6-6936-9130-b79d-93f73c7d80a8"}, traceId: 213e042f17565601794313401e255c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8d74fb4-042b-91af-bbca-d7bc79392cc5"}, traceId: 213e063717565601814177312e8ba1'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a2251875-a30e-9a3c-b8d8-a60dbd3c5050"}, traceId: 215045ee17565601817993620e7af0'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a60fa64-eb5e-95d1-97d9-1a5063ec4f8c"}, traceId: 213e063717565601831027332e8ba1'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"869a963c-ae19-9906-8aa1-5bae16c5d51a"}, traceId: 2150413117565601846994788eeb2c'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d66cdd2e-46b8-9cee-b09f-fde58819da3f"}, traceId: 213e063717565601862497352e8ba1'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2239bd61-d20f-9568-8fdd-13752236bf88"}, traceId: 215045b417565601886302152e808a'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"35868fd4-305a-9c57-b5f3-6c20b7ce1f98"}, traceId: 213e063717565601901907370e8ba1'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e763e96-15aa-9734-815e-8c8c093844e1"}, traceId: 213e007d17565601928115531ef023'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1e05065f-9177-9943-a7dd-9a173bedce4a"}, traceId: 213e063717565601942577397e8ba1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98cd7a3c-067b-93e1-bb0b-9ff0e97b2fd7"}, traceId: 215045f517565601955876041e7f09'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f239680e-d6c9-9c8a-9903-6f73c5339b34"}, traceId: 2150436817565601976186598e1c30'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f87e27fa-5890-9b10-884b-7ec3f5ce78e3"}, traceId: 213e00cd17565602004363829e9761'}2025-08-30 09:23:46,991 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:47,358 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:47,807 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:48,304 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:48,699 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:49,324 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:49,342 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:49,342 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:49,367 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:49,367 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:49,367 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:50,120 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:50,248 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:50,667 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:51,168 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:23:51,214 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:51,693 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:52,216 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:52,268 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:52,907 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:52,974 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:23:53,468 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:53,955 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:53,969 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:54,484 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:55,382 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:55,388 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:55,558 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:23:56,107 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:57,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:57,083 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:57,083 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:57,106 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:57,106 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:57,106 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:57,612 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:57,628 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:57,645 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:23:57,645 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:23:57,671 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:23:57,671 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:23:57,671 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:23:58,394 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:23:58,641 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:59,110 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:59,454 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:23:59,893 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:00,082 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:00,913 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:24:01,353 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:01,958 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:02,328 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:02,357 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:02,435 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:02,899 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8d55f27-c853-9275-bcf4-cdd4701ae7c0"}, traceId: 213e065417565602001271094e7f7e'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86712ead-a776-9c0a-b9fd-0a0bb7e92489"}, traceId: 213e041717565602006484773e9774'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7cb7b342-1d46-9187-b1a9-8244f2086134"}, traceId: 213e041717565602023354782e9774'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1c19a30-fffe-9a3e-bec1-7fab27ffcf38"}, traceId: 213e065117565602035761237e81e7'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14363
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14363
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bff99931-dd5c-9efd-8422-18a451c12d7c"}, traceId: 215045c117565602052308517e825d'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af149b94-912d-9dce-aebe-a0c58b47c0f0"}, traceId: 213e041717565602062334802e9774'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4d0ff2e-5360-9e60-b6ea-0fade70b1277"}, traceId: 215040ed17565602078822601ebf6c'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2ffa14f0-49e1-9ed1-80bf-1aee05fb172b"}, traceId: 213e041717565602110984821e9774'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce2c817b-1d98-9a7e-935d-f2c3d8848166"}, traceId: 213e007017565602114937428eeb17'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.76
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4829
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4829
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70e52f00-5a0a-9c35-8263-93fccc54b57d"}, traceId: 213e059617565602125015597e3c12'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e9db95bc-16ae-9ce2-9cb9-2089e853d7b6"}, traceId: 213e059617565602145955607e3c12'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9e88e89-4401-9e1c-9370-82b98cc1461f"}, traceId: 213e066e17565602163406895e8175'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13971
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13971
  - task_model=qwen2.5-72b-instruct2025-08-30 09:24:03,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:04,453 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:04,542 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e97f77d7-5c85-9718-b803-6ea8510bde39"}, traceId: 213e007d17565602045077633ef12c'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88199ccb-1520-9f44-a4b7-b325526fa0fe"}, traceId: 213e03d917565602063996155e1fd0'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14431
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14431
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e527836f-5505-90b8-a644-dfe08cc067f5"}, traceId: 213e007d17565602069387640ef12c'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe78a82c-1f49-9b74-a2b4-3da4ebaff5ff"}, traceId: 213e043a17565602076814186e1d33'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c5aff1f-aebe-9bc1-955b-635db048d309"}, traceId: 213e059617565602094297105e3e9d'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5274384b-7b59-930d-84e4-88d382340ab7"}, traceId: 213e007e17565602117818142eec83'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77409e44-d1b9-9203-a130-c9af74edb3bb"}, traceId: 213e007d17565602112747654ef12c'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cbc29f1f-34b8-941b-810a-148a80515687"}, traceId: 213e007d17565602133157660ef12c'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5564752-4b90-9e41-8992-99dcd2b5ee24"}, traceId: 213e041717565602145895719e9900'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"23b8dcfd-457d-926b-9630-5cd878a0a770"}, traceId: 213e007d17565602158487673ef12c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c96b6eeb-1d66-91b8-a6dd-387a9fa0e5ec"}, traceId: 213e007d17565602178777677ef12c'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29e8c94a-fe28-92c2-b561-3ab462226338"}, traceId: 213e007617565602195205808e139f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4889
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4889
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99610943-9e40-9a7c-a663-3bc35f7f005e"}, traceId: 213e007b17565602211867762eecac'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6c9a26e-f842-97d8-b8ff-485fac61c7a6"}, traceId: 213e007d17565602225637692ef12c'}2025-08-30 09:24:04,878 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:05,408 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:05,423 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:05,438 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:05,439 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:05,466 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:05,466 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:05,466 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:06,163 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:06,245 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:07,186 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:07,188 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:07,203 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:08,170 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:08,687 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:08,695 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:08,995 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:09,023 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:09,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:10,782 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:11,616 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:11,789 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:11,969 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:12,170 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:12,265 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:12,292 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac974713-ac6f-9372-9bcc-8578e56bfa9a"}, traceId: 213e064d17565602011331750e8097'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c775795-844c-9f84-8392-333fba2bd1ea"}, traceId: 213e00cd17565602026603841e9761'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"686864c7-c7e0-9950-b423-fc7bc5e843f1"}, traceId: 213e066017565602038434941e8914'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df578974-3ca4-95e2-a0a5-ea6ca7045cc4"}, traceId: 213e00cd17565602065233863e9761'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1022f870-3ab3-9779-95ee-73982b9d728c"}, traceId: 213e059d17565602084127542e3455'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"15c9860a-4731-90d0-a702-2961a5696b5d"}, traceId: 213e00cd17565602097553875e9761'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed254cab-166a-9d2c-bebf-aa73b8b9a80b"}, traceId: 213e007b17565602095305426eee7a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"517336f2-0e77-914c-9c4c-61157ece0a8f"}, traceId: 213e007b17565602122595437eee7a'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"adc0d533-0a72-90b2-8606-c1f152a69709"}, traceId: 213e00cd17565602145933902e9761'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f137320-72cc-9b12-b9ee-65489c411c89"}, traceId: 213e007b17565602163185454eee7a'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1af177e6-c4b9-94df-b564-cf7c4449152d"}, traceId: 213e00cd17565602175403925e9761'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4d6e563-05e6-90f0-b14b-61b3c733fbd4"}, traceId: 213e007b17565602183525460eee7a'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8c68fc2-c54d-9e24-9de2-533b6ec87bd0"}, traceId: 213e00cd17565602226093964e9761'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"72d30278-a5be-996b-b8a1-f0b468a0b897"}, traceId: 213e007b17565602250435488eee7a'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f692858-1bbf-92a1-a4aa-bc63770ba1a8"}, traceId: 213e00cd17565602258283980e9761'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...2025-08-30 09:24:12,947 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:24:13,293 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:13,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:14,900 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:15,415 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:15,528 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:15,542 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:15,542 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:15,567 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:15,567 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:15,567 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:15,914 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:15,944 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:16,414 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:17,122 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:18,431 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:18,543 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:18,592 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:18,954 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:20,595 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:20,622 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:20,622 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:20,648 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:20,648 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:20,648 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:21,053 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:21,577 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:21,598 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:21,599 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:21,633 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:21,633 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:21,633 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:22,183 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:24:22,522 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:22,625 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:22,771 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:23,152 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b238768c-53b7-9fca-ad4a-2b8f1050c55e"}, traceId: 213e059617565602178695623e3c12'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e296134d-0bae-9153-991e-f0c5a5798b3d"}, traceId: 213e041717565602215177982e985b'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b291ca5e-3edf-974d-b9b9-c6fd1d55c167"}, traceId: 213e059617565602210405647e3c12'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2f66463-8769-91a4-9a68-ae641d2e524d"}, traceId: 213e041717565602235467986e985b'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8fed88d-fb69-9948-836f-7b685e900d78"}, traceId: 213e041717565602255717993e985b'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7655a831-fa1a-94a1-a15f-bc4febebb7ae"}, traceId: 213e041717565602284298010e985b'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68f1be90-be1c-976e-80df-d36128d52083"}, traceId: 213e06a217565602285911669e8302'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5874
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5874
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"386c6b86-f988-940e-93b9-2d6909825025"}, traceId: 213e065e17565602315074107e81a0'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98fba30f-a87e-970b-a82c-5253de37b202"}, traceId: 213e041717565602332198022e985b'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a5d6c684-5d7d-91f6-a45a-59e57a17054d"}, traceId: 213e060917565602346768360e7090'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=max_turns_errors, confidence=0.7
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e837bb4f-d8d4-96bf-88c4-413981169350"}, traceId: 213e041717565602353768033e985b'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b6a0e483-e823-9fbf-9cab-85f1b5541d2d"}, traceId: 213e06c817565602373758240e83e3'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08079727-49a8-98d3-85fa-d1e30a1a957a"}, traceId: 213e041717565602383628044e985b'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d523c2f8-3fe8-96e9-8aa6-5132efb9dcfd"}, traceId: 213e00cd17565602398281388e95aa'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6a5de5eb-6b69-9a6e-acb4-c0a29383216b"}, traceId: 213e041717565602426398052e985b'}2025-08-30 09:24:23,766 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:24,200 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:24,214 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:24,215 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:24,239 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:24,239 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:24,239 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:24,614 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:24,636 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:24,636 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:24,663 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:24,663 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:24,663 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:24,724 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:24:25,155 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:25,247 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:25,771 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:25,927 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:26,380 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:27,230 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:27,759 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:27,869 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:27,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:28,009 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:28,009 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:28,033 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:28,033 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:28,033 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:28,440 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c1a4a958-457d-91d2-abb0-ca88ecd181f6"}, traceId: 213e007b17565602235387770eecac'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5054db2d-ffe2-93fd-b127-e8f284c30c51"}, traceId: 213e007d17565602237533038ef2d8'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14263
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14263
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4ac41803-3fd0-9621-a381-396511985b0e"}, traceId: 213e007b17565602266137792eecac'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e2e286b1-017f-97ec-a18a-2f0b2aac8b73"}, traceId: 213e007d17565602275903053ef2d8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93383f19-5011-97fb-aa40-7f0120e1d0c3"}, traceId: 213e007d17565602294763065ef2d8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bef97153-d7be-9b33-b807-22e8eab43a86"}, traceId: 213e007b17565602309617818eecac'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"72e3ff91-e167-9bbd-ae81-e0693da2d421"}, traceId: 213e007d17565602315013075ef2d8'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f17e800a-8d34-9d68-ae93-50f762b16fb4"}, traceId: 213e007d17565602337573083ef2d8'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70388437-c3d3-92bc-9864-50c61f3bc4a7"}, traceId: 213e007b17565602363327845eecac'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4773
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4773
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8080c160-6e0a-9833-944f-e09f7f3b27c4"}, traceId: 213e007b17565602376793085eee59'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe08a8a1-edf9-9aaa-9889-beccdd9dd48f"}, traceId: 213e007d17565602406163107ef2d8'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01d421a0-b024-9d2e-98ff-533e24da0953"}, traceId: 213e007617565602416162017e1520'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.822025-08-30 09:24:28,741 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:28,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:29,872 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:30,042 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:30,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:30,381 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:30,888 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:31,081 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:31,870 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:32,343 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:32,492 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:32,977 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:33,923 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:34,420 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:34,492 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:34,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:35,448 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:35,474 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c7e9c1c-8fba-98a0-b562-a9d23aeaeda9"}, traceId: 213e007b17565602275555505eee7a'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c0e4e1f-934f-9b6d-99d7-db2ab25f4b44"}, traceId: 213e007b17565602299415511eee7a'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff69bcd4-d35f-9a0e-837d-36c6b2265747"}, traceId: 213e00cd17565602304933996e9761'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a578858-f84d-9e0e-9aba-fc647e388ff2"}, traceId: 213e00cd17565602327354005e9761'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aed2ddf5-01e1-9697-9b1f-3be13bb6abf3"}, traceId: 213e007b17565602332155522eee7a'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ac7361c-75a0-9f1f-9095-c523eb598bf6"}, traceId: 213e00cd17565602346514013e9761'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"35352d8a-8e2c-9b10-9759-0a6ddc4da088"}, traceId: 213e007b17565602373565540eee7a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3d4ad8dc-0525-9046-98ed-35554e03fff6"}, traceId: 213e00cd17565602383964026e9761'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"458803bb-c5fc-9e7d-ada8-6200d695d5a6"}, traceId: 213e066c17565602387192283e79f3'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ef40bfd-ea06-9dde-8f9c-2fe1817e1dda"}, traceId: 213e066c17565602416252291e79f3'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7164652c-a16b-9e50-bb78-961e0919b3df"}, traceId: 213e00cd17565602421624038e9761'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc94fc4f-4844-9357-834f-15d73536473d"}, traceId: 213e00cd17565602436674041e9761'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"38dcdfc8-aa82-9ec3-8489-8c4edd685c38"}, traceId: 213e066c17565602446782302e79f3'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9d16b2bb-20d0-9a4f-abca-f93e3bfc9abe"}, traceId: 213e00cd17565602469504055e9761'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea5a21bb-1ac9-9d71-96d6-f50b18549380"}, traceId: 213e066c17565602491982319e79f3'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"42895d0b-0269-9a22-bd66-e95cf689dc92"}, traceId: 213e00cd17565602514454070e9761'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fca8a991-d7b9-9e8b-8dfe-b56710198c0e"}, traceId: 213e066c17565602515402327e79f3'}2025-08-30 09:24:37,323 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:37,747 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:38,760 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:38,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:38,907 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:38,907 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:38,932 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:38,932 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:38,932 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:39,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:39,104 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:39,104 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:39,129 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:39,129 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:39,129 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:39,291 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:39,940 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:40,039 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:40,514 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:40,779 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:40,863 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:40,875 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:40,875 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:40,899 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:40,899 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:40,899 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:42,038 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:42,561 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:42,703 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:24:42,900 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:42,904 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:43,347 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:43,843 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:43,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:44,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:45,257 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:45,816 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:46,233 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:46,506 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:46,914 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:47,425 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:48,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:49,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:49,903 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:49,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c79fe53-0749-961d-983c-034939e6781c"}, traceId: 215045a817565602441774232e7f4f'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6c88fa5-f287-9ac4-bb25-ad7f9d8cf8c1"}, traceId: 213e007d17565602459103127ef2d8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2463597b-b7ba-99f8-bd51-7ed909be1849"}, traceId: 213e06b617565602474632004e8126'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d18e280a-468f-9dfc-829d-0b2407ff2502"}, traceId: 213e007d17565602482923138ef2d8'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8ce9410-c443-913a-af5c-cabb0390d970"}, traceId: 213e007d17565602515473148ef2d8'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2fe2f8ef-b8dc-97d4-a4a3-c5ac2f8467f9"}, traceId: 2150430d17565602533894858e975d'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ec2a22b0-1f3c-9d5c-b79b-b9a0ee4ccbe0"}, traceId: 213e007d17565602546763158ef2d8'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8296ce52-edae-9326-9482-edfb2bf9d3b5"}, traceId: 213e007f17565602557216424eea45'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a75135ad-a773-9b88-a208-44d71b1d97df"}, traceId: 2150439017565602583932792e2589'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c32daa3e-73d3-9256-bba1-284f26b6daf6"}, traceId: 213e007d17565602598383176ef2d8'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14340
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14340
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"541e23b0-14ea-9c9e-802f-de934bc3328e"}, traceId: 215040aa17565602623266470ee640'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c802cc49-4d53-9c7b-885d-4f3c81af1f96"}, traceId: 213e06a117565602649074779e8897'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"57402972-53ef-98a4-a473-96baa5d04349"}, traceId: 213e007d17565602672801823ef234'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"109c9d32-c292-9b74-870a-df6b99a86859"}, traceId: 213e06a117565602682084792e8897'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...2025-08-30 09:24:50,100 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:50,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:51,600 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:52,000 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:52,015 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:52,015 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:52,040 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:52,040 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:52,040 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:52,524 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:52,958 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:54,097 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:54,965 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:24:55,368 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:56,090 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:24:56,104 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:56,104 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:56,128 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:56,128 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:56,128 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:56,382 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:57,090 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:57,660 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"917f6c4f-7be8-95a3-a166-fb9064a7dcb7"}, traceId: 213e066c17565602546712334e79f3'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"838df1cd-065a-9a39-825e-367cbd5c4162"}, traceId: 213e00cd17565602547904087e9761'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c7953ca-5abc-9403-bd14-4c6e7d0cc3f0"}, traceId: 215045ee17565602564295404e7aef'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"505a1faf-93c8-99b6-9323-fd4a7302ef21"}, traceId: 213e066c17565602577992351e79f3'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34523c93-117d-91e6-b595-95d2d8de86da"}, traceId: 2150435d17565602586644345e1e99'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6eec34ee-f510-99ac-931b-5c2f57500c1e"}, traceId: 215041e117565602623787373e32d1'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d380c84b-bcc9-9e72-a6da-16aa47f82e38"}, traceId: 213e066c17565602638662385e79f3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8919d004-5485-941d-8977-68d95c5d6443"}, traceId: 2150416017565602655144964ef0c5'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e212b93-e80f-9a19-86c9-8a2b81b566f1"}, traceId: 213e065017565602656394395e8035'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1076ea73-97c6-9a81-9ff8-99ed3bdccf45"}, traceId: 213e065417565602665218759e816c'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a844654a-b9e1-9bbe-8305-4d0f2dc7bc0d"}, traceId: 213e065017565602684764402e8035'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5df4bd18-7395-91ac-bb4e-33f6808e4047"}, traceId: 213e006917565602696443605ee11b'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"05cb0bbd-dd4d-9fdb-a990-d83846fa8323"}, traceId: 213e065017565602711294411e8035'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"376de6f3-31f4-9842-96c7-1fdbdc8f20fc"}, traceId: 213e065517565602737227091e7fa4'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a8c6a71f-f307-9fcf-82f0-a5c85a97aa93"}, traceId: 213e065017565602747404419e8035'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...2025-08-30 09:24:57,670 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:24:57,670 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:24:57,694 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:24:57,694 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:24:57,694 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:24:57,766 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:57,856 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:24:57,858 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297857919.json
2025-08-30 09:24:57,859 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297858754.json
2025-08-30 09:24:57,859 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297859501.json
2025-08-30 09:24:57,860 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297859781.json
2025-08-30 09:24:57,860 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297860202.json
2025-08-30 09:24:57,861 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297860717.json
2025-08-30 09:24:57,861 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297861198.json
2025-08-30 09:24:57,861 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297861498.json
2025-08-30 09:24:57,862 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297862096.json
2025-08-30 09:24:57,862 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297862705.json
2025-08-30 09:24:57,863 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-72b-instruct:30)
2025-08-30 09:24:57,864 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 30 个结果到收集器: qwen2.5-72b-instruct_79843_1756560297863238.json
2025-08-30 09:24:57,864 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)

[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d5c9c18-5aca-9314-be52-31f9e9b1dbc5"}, traceId: 2150456117565602447136803e812c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13780
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13780
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b282471d-4a86-9d4e-b661-983a6e608861"}, traceId: 213e041717565602464218067e985b'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1b7dbbd1-cace-9adc-b47c-9af367f15ca3"}, traceId: 213e064e17565602464524832e7fb2'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4bb856a1-0602-9501-9a7c-e5b8f4dc01ea"}, traceId: 213e041717565602479428072e985b'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"62deca82-c885-9e5f-85b9-b871e155e94c"}, traceId: 213e064e17565602484574843e7fb2'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6a91713b-33b5-94e0-b82d-94f0008c3cf0"}, traceId: 213e041717565602515188080e985b'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1362359-5c2f-950e-85e2-84e30ecf4058"}, traceId: 213e064e17565602525394872e7fb2'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"25e48192-3f00-91c9-a5fd-dae9d2ab556e"}, traceId: 213e041717565602551608091e985b'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe6a33ad-4d09-9724-9d48-0ac10f61c936"}, traceId: 213e064e17565602556734900e7fb2'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"714d2254-3831-9b18-908a-7524b2b73cb0"}, traceId: 213e064e17565602576244918e7fb2'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47d580bc-d7d0-93dd-a873-829ded4c6b9f"}, traceId: 213e064e17565602603154941e7fb2'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0033c004-4f21-965a-b2fc-aff9e9e403b0"}, traceId: 213e041717565602608218113e985b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14036
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14036
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df5a1cdc-9d40-9c39-97ed-104c06a69ef3"}, traceId: 213e042f17565602624201717e232a'}2025-08-30 09:24:57,897 - batch_test_runner - INFO - Database saved successfully
2025-08-30 09:24:57,897 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 09:24:57,897 - batch_test_runner - INFO - ============================================================
2025-08-30 09:24:57,897 - batch_test_runner - INFO - Batch test completed at 2025-08-30T09:24:57.897750
2025-08-30 09:24:57,897 - batch_test_runner - INFO - Summary:
2025-08-30 09:24:57,897 - batch_test_runner - INFO -   - Total tests: 30
2025-08-30 09:24:57,897 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 09:24:57,897 - batch_test_runner - INFO -   - Failed: 30
2025-08-30 09:24:57,897 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 09:24:57,898 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_091927.log
2025-08-30 09:24:57,898 - batch_test_runner - INFO - ============================================================
2025-08-30 09:24:57,898 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 09:24:57,898 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 09:24:57,898 - result_merger - INFO - 发现51个新的结果文件
2025-08-30 09:24:57,935 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:24:57,935 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 09:24:59,199 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:59,337 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:59,634 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:24:59,644 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:01,301 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:01,960 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:02,233 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:02,339 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:02,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:02,881 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:03,396 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:04,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:04,196 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any required data pipeline tool; no tool was used, indicating a tool selection/omission error that blocked progr
2025-08-30 09:25:04,472 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:04,989 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:05,010 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:05,010 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:05,035 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:05,035 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:05,035 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:05,499 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:06,552 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8e40ecf7-e731-9cb1-b2de-f3a72eac2dd5"}, traceId: 213e043517565602691401231e2ee9'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99f5ebbf-2efb-9516-be7e-52e42af1dce9"}, traceId: 213e043517565602706701242e2ee9'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14183
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14183
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"220cdba4-8f92-9906-8dcf-f93187b736ca"}, traceId: 213e06a117565602717574804e8897'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea284942-07b1-96b1-8903-59140809ce75"}, traceId: 213e043517565602731841254e2ee9'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"995e76ed-9731-9972-b6a5-a9422dd18236"}, traceId: 213e06a117565602742504815e8897'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7407ca7-aa88-91ee-9cd6-371ec9d1e62f"}, traceId: 213e043517565602774961266e2ee9'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e788ad46-afa6-9310-a884-42c72958bea2"}, traceId: 213e06a117565602785604831e8897'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b1c041e-0380-999f-a59a-1393fca97516"}, traceId: 2150416417565602798386673e1116'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"574dac56-863d-9931-bd2e-03ea9179c39a"}, traceId: 213e043517565602805421280e2ee9'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14177
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14177
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de13d226-10c7-9c8d-8620-aae7796c5c42"}, traceId: 2150460e17565602818451231e7a3f'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86086261-2eab-96cb-bf66-b73e4c59a0fd"}, traceId: 213e043517565602831021288e2ee9'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"151fd9c2-5806-9486-90ef-9f2c72a74eaa"}, traceId: 215040be17565602862134729ee089'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"afdd349c-3f8f-9cf6-b3d4-80b6b15365b3"}, traceId: 213e043517565602866771299e2ee9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b1bc46e-10fd-927f-b96e-24e67b113551"}, traceId: 213e043517565602891791312e2ee9'}2025-08-30 09:25:06,688 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:07,631 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:07,644 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:07,644 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:07,670 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:07,670 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:07,670 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:07,728 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:08,800 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:08,882 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:09,301 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:09,301 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or engage any tool for the multi-stage task (tool selection step failed to initialize tooling). This left required toolin
2025-08-30 09:25:10,202 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:10,350 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:10,757 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:25:11,172 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:11,184 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:11,184 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:11,207 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:11,207 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:11,207 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:11,922 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:12,184 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:12,717 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:12,859 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:14,437 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:14,951 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:15,347 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:15,370 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:15,392 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:15,393 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:15,418 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:15,419 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:15,419 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:16,547 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:17,368 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c38ed8a8-6556-9640-b3a0-b088c133ccf0"}, traceId: 213e065017565602783604430e8035'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9a26453c-93a1-98c9-aec5-371d22db64a6"}, traceId: 213e006a17565602802746696ee04b'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"25dc20a5-db2c-9edb-b079-0882e55a101e"}, traceId: 2150415c17565602806637548eeb69'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b986ff1c-351c-961b-9db9-6eef35c8d859"}, traceId: 213e006a17565602825966704ee04b'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f01111b2-4f07-9af9-b6f7-43b64e8dba8e"}, traceId: 215045ee17565602838207013e7775'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63071372-cbf7-9391-8488-26118cedbb5d"}, traceId: 213e006a17565602844726710ee04b'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"beec57b8-e2e8-9534-aab3-ca32ef092e71"}, traceId: 2150454417565602854661861e809c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a8c0f206-1410-903a-928c-30dd4662f7f8"}, traceId: 213e006a17565602874446725ee04b'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2322f10f-390a-911d-8c49-6d7e58b8c66f"}, traceId: 215044fd17565602888681163e7e81'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4f065fa0-5e92-9ca3-923a-1bcc42b04906"}, traceId: 213e006a17565602917326744ee04b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d3d602f-23c5-9c2b-95b8-05a5816692ed"}, traceId: 2150429e17565602922644252e2252'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d55e7f7-6e70-9c8d-ae70-48b2b1094283"}, traceId: 213e060c17565602938294478e885b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e4d6f56d-3ea6-938a-b4d6-28241242ce25"}, traceId: 213e060c17565602956514487e885b'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47d756c0-d43f-9ca1-b12e-9eff44fa48f6"}, traceId: 2150457117565602974404077e7b1f'}2025-08-30 09:25:17,440 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:17,909 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:18,446 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:18,447 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were chosen or executed; the error context provides no evidence of an incorrect tool selection, parameter usage, sequence, or dependencie
2025-08-30 09:25:18,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:19,871 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:20,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:20,854 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:21,495 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:22,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:22,044 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:22,251 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:22,257 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required data_pipeline tools; effectively chose no tool or failed to choose the appropriate tool for the ta
2025-08-30 09:25:23,713 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:25:24,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:24,910 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:24,928 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:24,928 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:24,954 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:24,954 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:24,954 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:25,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:26,501 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:26,843 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:26,999 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:27,016 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:27,017 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:27,041 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:27,041 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:27,041 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:27,172 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:27,173 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tools appropriate for the multi_stage_pipeline task; no tools were executed, indicating a failure to choose
2025-08-30 09:25:27,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:25:28,073 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:28,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"465e1986-6852-9af7-b276-39e047d2b66c"}, traceId: 2150417c17565602893851800eee8b'}
[RETRY] 400 error detected, waiting 5.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91d471e8-5a79-9597-9c3b-af3c27eb8b2d"}, traceId: 213e043517565602922381330e2ee9'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8e287fca-f976-9874-baa5-e0c788a55fc6"}, traceId: 213e043517565602951371347e2ee9'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"72fe4b09-ba27-9733-96e9-5c3d07fa9dcd"}, traceId: 215045f517565602958982187e80f7'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 6063
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=6063
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73a40f64-1fcc-947c-beeb-d9122c7ce1c2"}, traceId: 213e043517565602963601353e2ee9'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5c1a8382-f6fd-99a9-b850-3e30d33e349c"}, traceId: 213e059717565602974751665e34a4'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"95ea806d-bf1c-9924-9d37-26517be777f9"}, traceId: 213e059717565602988911678e34a4'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"36897fc6-ce2d-93ee-8637-c872c25eedfd"}, traceId: 213e043517565602993941362e2ee9'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d5100d8-15bc-923b-8fbb-9746676b0237"}, traceId: 213e043517565603016031373e2ee9'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f66bbd7-1f04-9e2c-b3d1-2d0ca8eb5443"}, traceId: 213e059717565603026561700e34a4'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ac520f4-e548-9b58-a443-a30a98abc5e9"}, traceId: 213e059717565603042261709e34a4'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"64c75cbc-37e9-9bb5-ba1f-039e67388bdb"}, traceId: 213e043517565603047541388e2ee9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 19114
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=19114
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20033854-9c0a-9d38-8622-a67a061fb571"}, traceId: 213e059717565603063231715e34a4'}2025-08-30 09:25:28,084 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328083657.json
2025-08-30 09:25:28,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328084697.json
2025-08-30 09:25:28,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328085068.json
2025-08-30 09:25:28,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328085482.json
2025-08-30 09:25:28,085 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328085734.json
2025-08-30 09:25:28,086 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328086006.json
2025-08-30 09:25:28,086 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328086380.json
2025-08-30 09:25:28,086 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328086635.json
2025-08-30 09:25:28,086 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328086835.json
2025-08-30 09:25:28,087 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328087025.json
2025-08-30 09:25:28,087 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560328087204.json
2025-08-30 09:25:28,929 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:29,067 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:29,829 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:29,902 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:30,361 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:30,922 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:31,366 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:31,573 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:31,922 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:32,781 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:34,052 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:34,053 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tool/action for a basic_task, representing a wrong tool decision by omission. No tools were executed and no ou
2025-08-30 09:25:34,579 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:34,795 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 09:25:34,901 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:35,385 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:35,928 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:35,950 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:35,951 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:35,978 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:35,978 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:35,978 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:37,616 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:38,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:38,515 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:38,547 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"317eee41-521b-972a-9196-8555230c657f"}, traceId: 213e060c17565602984644495e885b'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c968198f-c5dc-91e3-b371-f6cec70ffcfd"}, traceId: 213e007317565602985071944ee3d8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dbc794b0-8bd6-9904-bcbb-45bb28636036"}, traceId: 213e007317565603005501948ee3d8'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f926930-f99f-9719-88db-b4137fa25bf3"}, traceId: 213e060c17565603021354510e885b'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"72d46dc4-8181-9468-8fa8-19d9657777fb"}, traceId: 213e007317565603026491955ee3d8'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"76392645-e9a3-9117-baf0-babf38479802"}, traceId: 213e007317565603052671960ee3d8'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9062ad95-71e4-9315-b892-f51ceb8cb2ad"}, traceId: 213e060c17565603073774532e885b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8efbd197-cc7e-9a6a-bc1f-5eea497b1626"}, traceId: 213e006817565603081676738ee437'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b1426d57-86c7-97ca-b2b6-bc2dff162635"}, traceId: 213e007317565603104121980ee3d8'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5ae0798c-c65a-9f4e-8543-98ae14d932bb"}, traceId: 2150455f17565603114585668e81a9'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f3e3b76-62e1-9cac-a6ed-97bd82b28440"}, traceId: 213e064717565603126203424e8810'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"56034208-bffe-9b9a-af40-3a81ed5f2037"}, traceId: 2150455217565603137214250e8292'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cceb7205-44d1-984d-9417-ac9b1e1ca1da"}, traceId: 213e064717565603146193431e8810'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d31c57cb-6722-9655-a3f1-faede7922051"}, traceId: 2150429e17565603166694350e2252'}2025-08-30 09:25:39,820 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:40,016 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:40,871 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:40,953 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:40,954 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error: required tools coverage is 0% (0/0) and no tools were executed. The error message provides no actionable context to ass
2025-08-30 09:25:41,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:42,855 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:43,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:43,536 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:43,536 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:43,561 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:43,561 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:43,561 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:43,765 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:45,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:45,312 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:45,313 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected or executed and the error message is unspecified (Unknown error). There is no evidence of a wrong tool choice, incorrect parameters, s
2025-08-30 09:25:45,487 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:45,539 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:46,049 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:47,632 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:47,663 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:47,780 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:48,995 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:49,968 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91690045-e0e6-951a-a69c-e90d202799fb"}, traceId: 213e007f17565603069001162eeac9'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1231dc22-7b17-94de-b3d1-0490efdb3b66"}, traceId: 213e007f17565603085611168eeac9'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54c4b457-b3cb-9426-9a4a-1dbc537b2ca6"}, traceId: 213e059717565603094691739e34a4'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
Progress: 30/35 (Success: 0)
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef978b7f-bc90-9362-a415-9607f82eaf69"}, traceId: 213e007f17565603124821205eeac9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d17775fc-aabe-98c1-b61d-35188fdd7f33"}, traceId: 213e007f17565603142131223eeac9'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af9f117c-6dba-9292-abb5-358bb74a9c0d"}, traceId: 213e059717565603146191774e34a4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13644
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13644
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bbc0a7bd-95d2-9e7b-9dc0-db96525653fd"}, traceId: 2150457117565603158492996e79d5'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c8a42d7-aa6b-9c22-ad13-a60884f85884"}, traceId: 213e007f17565603171971238eeac9'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c4c909f-73f9-90b0-a4e1-a29cd44b100f"}, traceId: 213e007217565603182024585eeb41'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9235593f-c410-9677-b5c1-72ef9dbd5e5e"}, traceId: 213e06bc17565603207861071e8311'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7519279-7695-99f8-aca2-9f52e22dad6a"}, traceId: 213e007f17565603213061258eeac9'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88285500-6a82-958d-8dd7-d4dbd79595b9"}, traceId: 213e007f17565603236551263eeac9'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"645988fb-2401-9c7f-96bc-a52a685dc8cd"}, traceId: 213e007c17565603248488505ef284'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1679172-07a2-9fd2-99a4-83a835fd3661"}, traceId: 213e007f17565603266081276eeac9'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.64
💾 智能Checkpoint: 保存11个结果...
   触发原因: 数量=11, 时间=133.9s, 强制=False2025-08-30 09:25:50,368 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 09:25:50,381 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:50,382 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:50,408 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:50,408 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:50,408 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:50,620 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:51,625 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:51,626 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for the (unknown) task, effectively making no tooling decision. This indicates a misstep in choosing 
2025-08-30 09:25:51,901 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:52,291 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:53,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:54,974 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 09:25:55,317 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:55,317 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initiate the necessary data_pipeline tools (no tools were executed). This indicates a wrong or missing tool choice for 
2025-08-30 09:25:55,437 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:55,452 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 09:25:55,452 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 09:25:55,477 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 09:25:55,477 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 09:25:55,477 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 09:25:55,965 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:56,392 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:57,259 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:25:58,075 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:58,235 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:58,479 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:25:59,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:26:00,451 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:26:02,069 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:02,071 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select and execute the required API integration tool (no API/HTTP/API client tool was chosen). There were no tools attempted, re
2025-08-30 09:26:02,479 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04809e08-fe2f-9187-97b1-0469de95b96b"}, traceId: 213e064717565603176753441e8810'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"066e906b-d7fe-92e5-a74b-4ab8a2385626"}, traceId: 2150421317565603198074173e33db'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6379ab89-0903-9ae3-8658-82bf602924e6"}, traceId: 213e064717565603217843456e8810'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fbeeddbd-019b-9283-bd05-292f37e029ca"}, traceId: 213e064717565603246753465e8810'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"00b1f63c-cb25-98c5-aad2-20f3defa414d"}, traceId: 213e062917565603257708961e810e'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c328eea9-3ff3-9e00-90c4-0835783080e2"}, traceId: 2150449017565603262665113e8126'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ebf4289-5255-9b8a-9fd4-8b7d3a62a5e0"}, traceId: 2150456317565603278588691e802f'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce22668c-f312-9a62-bf96-ef3266dee8db"}, traceId: 213e066e17565603296321860e8112'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7bb73bd9-a76a-9859-b26f-92a61de8d671"}, traceId: 213e062917565603311388978e810e'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1be5c9cb-c9e4-958a-a46c-d1f657655391"}, traceId: 213e065a17565603317286839e8355'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"65fc108d-ab58-939d-9fbc-25ea6926e478"}, traceId: 213e062917565603325358980e810e'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"294867e9-044e-9fa7-b111-561426578ca9"}, traceId: 213e062917565603346608987e810e'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6df67054-141f-9439-b357-1ccdf85ba955"}, traceId: 2150454417565603351873575e8249'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c55fd10-55d4-940f-94b1-b032d28af4c6"}, traceId: 213e043517565603374586412e2e12'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fd71dbe3-c269-91fc-aa62-b1928690e18d"}, traceId: 213e062917565603383028993e810e'}2025-08-30 09:26:04,103 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:26:06,198 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:26:07,961 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:26:08,317 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:08,319 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The simple_task requires no tools; selecting or relying on tooling would be an unnecessary wrong decision for this task. The agent failed to align
2025-08-30 09:26:10,311 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:10,568 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 09:26:13,311 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:13,313 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a wrong agent decision (tool selection, parameter config, sequence, or dependencies). The error message is ambiguous ('Unknown erro
2025-08-30 09:26:18,786 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:18,788 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560378787610.json
2025-08-30 09:26:18,789 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560378788638.json
2025-08-30 09:26:18,789 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560378789147.json
2025-08-30 09:26:18,789 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79842_1756560378789471.json
2025-08-30 09:26:18,789 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
2025-08-30 09:26:18,792 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 35 个结果到收集器: qwen2.5-72b-instruct_79842_1756560378790310.json
2025-08-30 09:26:18,792 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
2025-08-30 09:26:18,842 - batch_test_runner - INFO - Database saved successfully
2025-08-30 09:26:18,843 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 09:26:18,843 - batch_test_runner - INFO - ============================================================
2025-08-30 09:26:18,843 - batch_test_runner - INFO - Batch test completed at 2025-08-30T09:26:18.843137
2025-08-30 09:26:18,843 - batch_test_runner - INFO - Summary:
2025-08-30 09:26:18,843 - batch_test_runner - INFO -   - Total tests: 35
2025-08-30 09:26:18,843 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 09:26:18,843 - batch_test_runner - INFO -   - Failed: 35
2025-08-30 09:26:18,843 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 09:26:18,843 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_091927.log
2025-08-30 09:26:18,843 - batch_test_runner - INFO - ============================================================
2025-08-30 09:26:18,843 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 09:26:18,843 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 09:26:18,844 - result_merger - INFO - 发现16个新的结果文件
2025-08-30 09:26:18,863 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:26:18,863 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 09:26:20,128 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:20,136 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure is described as an Unknown error with no tool executions or task details, making it impossible to attribute to a specific agent decision (tool 
2025-08-30 09:26:26,724 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:26,726 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient task context and an 'Unknown error' message; no evidence of a wrong agent decision (tool selection, parameter config, sequence, or dependencie
2025-08-30 09:26:28,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:28,901 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task, indicating a failure in the tool selection step. Without a chosen tool, the task ca
2025-08-30 09:26:31,658 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:31,659 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and engage any appropriate tool for the data_pipeline task (effectively chose 'no tool' or an inappropriate approach). With
2025-08-30 09:26:33,792 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:33,792 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool for the api_integration task, resulting in zero tool usage and inability to progress. This indicat
2025-08-30 09:26:35,327 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:35,327 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool to perform the multi_stage_pipeline; no tool was chosen, leading to no execution steps and complete fa
2025-08-30 09:26:38,235 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:38,235 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent-specific decision errors (no tool usage or parameter choices available). The failure is reported as Unknown error, indicating a system
2025-08-30 09:26:44,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:44,254 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for a data_pipeline task. For data ingestion/processing, the agent should pick and run at least the appropriate
2025-08-30 09:26:44,462 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:44,465 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool for a data_pipeline task (no tools executed), effectively choosing an insufficient toolset/omitting requir
2025-08-30 09:26:48,958 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:48,959 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool suitable for an api_integration task (no tools were chosen or executed). This represents a wrong tool 
2025-08-30 09:26:54,870 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:54,888 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for an unknown task; the agent failed to choose the appropriate tool (tool selection error). Data shows Require
2025-08-30 09:26:56,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:26:56,529 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or engage any tools for the multi_stage_pipeline task, resulting in no progress. In a multi-stage workflow, the agent sho
2025-08-30 09:27:00,755 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:00,756 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error. No tools were executed and the error is described as Unknown error, so the failure ca
2025-08-30 09:27:01,852 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:01,854 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Primary agent decision error: no tools were selected or instantiated for the (unknown) multi-stage task, resulting in 0% tool coverage. The agent 
2025-08-30 09:27:06,765 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:06,766 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown system/tool failure prevented task progress; no tools were executed (0% coverage) and no identifiable agent misdecision (tool selection, parameters
2025-08-30 09:27:09,138 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:09,140 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task defined no required tools, yet the agent did not select any tool or propose a course of action and instead returned an 'Unknown error.' T
2025-08-30 09:27:11,456 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:11,456 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or initiate any tool for the api_integration task, effectively making no tool choice at all. This constitutes a tool se
2025-08-30 09:27:17,892 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:17,893 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "This task (basic_task) requires no tools (0/0 coverage). With no tool usage or dependencies to manage, there is insufficient evidence to attribute the
2025-08-30 09:27:18,697 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:18,698 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate any stages or establish a workflow sequence for the multi_stage_pipeline, effectively ignoring the required execution o
2025-08-30 09:27:21,555 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:21,556 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were invoked for a task that requires tooling; the agent failed to select or initialize an appropriate tool, preventing any execution pat
2025-08-30 09:27:23,495 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:23,495 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to execute or follow the required multi-stage pipeline in the correct order (no stages were performed), indicating a sequence/ord
2025-08-30 09:27:27,363 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:27,364 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent attempted to use tooling for a task that required no tools, effectively making an incorrect tool decision by selecting (or assuming) a t
2025-08-30 09:27:28,690 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:28,691 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or invoke any tool suitable for an api_integration task; no tools were executed (no HTTP client or API wrapper used). This 
2025-08-30 09:27:36,587 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:36,589 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected because the task is Unknown; there was no actionable objective to drive tool choice, indicating a lack of an appropriate agen
2025-08-30 09:27:37,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:37,212 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision error can be identified because there are no tools executed and no observable agent decisions (tool choice, parameters, sequence, o
2025-08-30 09:27:41,133 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:41,133 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error: there were no tools executed and the error is reported as Unknown error. Without tool usage data, there is no basis to 
2025-08-30 09:27:42,531 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:42,532 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision error can be identified: there were no tool selections, parameter specifications, or sequence dependencies to critique, and the err
2025-08-30 09:27:47,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:47,529 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No clear agent decision error can be identified. Unknown error with zero required tools and no executed actions suggests a system/unknown failure rather th
2025-08-30 09:27:48,045 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:48,045 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle TOOL DEPENDENCIES: there were no tools executed and no plan established due to the unknown task, indicating a breakdown in reco
2025-08-30 09:27:52,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:52,411 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select and initialize any of the required tools for the API integration task; no tools were used or executed, indicating a fault
2025-08-30 09:27:56,737 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:56,798 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task is a basic_task with no required tools, yet the agent did not select or execute any tool action. This inaction constitutes a wrong decisi
2025-08-30 09:27:59,581 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:27:59,584 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tools for a multi_stage_pipeline task where tool usage is required; effectively choosing an invalid/absent tool
2025-08-30 09:28:02,774 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:02,775 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tool executions; there is no evidence of a wrong tool choice, incorrect parameters, improper execution order, or unmet dep
2025-08-30 09:28:03,399 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:03,399 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or specify any tools or a execution plan for the multi_stage_pipeline task, effectively failing to define the necessary w
2025-08-30 09:28:07,445 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:07,448 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or configured for the data_pipeline task; there was 0% tool coverage and no tools executed, indicating a decision to omit o
2025-08-30 09:28:12,505 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:12,508 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the api_integration task; the agent did not choose/initialize any tool (empty Executed Tools and empty Requ

✅ Checkpoint完成: 成功保存 11/11 个结果
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"26a177a9-0380-951e-98f9-fdbae8953b11"}, traceId: 215045c117565603283661968e804c'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4122de8-3697-9fe9-9415-881e3ace76b4"}, traceId: 213e007f17565603296381287eeac9'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"25e40d17-6c12-934b-b673-2b1f74f8ebb3"}, traceId: 2150411617565603313476579ee723'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"33829ed4-4cba-9dbc-bf7f-050ee8e93193"}, traceId: 2150411617565603343575920eea10'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3cb1300b-6480-95ed-81c2-ff9435433f12"}, traceId: 213e007f17565603351921304eeac9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13970
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13970
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e2280c8-df22-99ee-9e0d-f13dc7c02113"}, traceId: 213e06c017565603368878011e7fd5'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5cb173de-213f-909a-8886-c21750659916"}, traceId: 213e01f617565603378087531e1463'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"49a5b690-444d-9ff6-8b5c-e352731c65ce"}, traceId: 213e06c017565603424078042e7fd5'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4460770048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"57c0112c-0904-9ef4-9917-d90bb09090cc"}, traceId: 213e081017565603447647661e0a00'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"200382cf-8a41-9dbc-a0ab-a6360ffdab8c"}, traceId: 213e06c017565603448028053e7fd5'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cab98626-8fba-9056-ada0-0d6362f383fe"}, traceId: 213e06c017565603468918060e7fd5'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"902fe1ee-3f1e-9a91-b069-6ad65d9b36ba"}, traceId: 213e081017565603474257675e0a00'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13974
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13974
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50bb4846-6a5d-9065-9a6e-97486d74a6ce"}, traceId: 213e081017565603492357686e0a00'}2025-08-30 09:28:15,400 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:15,403 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there were no required tools, no tool usage occurred, and the error message is Unknown. The failure appears to be environ
2025-08-30 09:28:16,489 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:16,489 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke the required API integration tool; no tools were used and no steps executed, indicating an incorrect tool choice

[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83cd657e-d4a1-95e8-9126-d8b81eda187e"}, traceId: 213e06c017565603503758073e7fd5'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"442280d2-b74d-9103-a148-af1a66f4b746"}, traceId: 213e081017565603535377698e0a00'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b1bd13e-aea2-9797-ab62-385fcf5e6d75"}, traceId: 213e06c017565603556598100e7fd5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14460
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14460
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7ada1682-9078-90ca-a2d3-60381cb4ce19"}, traceId: 213e081017565603582527710e0a00'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=max_turns_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 6014
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=6014
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
💾 智能Checkpoint: 保存4个结果...
   触发原因: 数量=4, 时间=50.7s, 强制=True
✅ Checkpoint完成: 成功保存 4/4 个结果

[INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_092618.json
[SAVE_ENHANCED] 开始增强保存，时间: 09:26:18
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-72b-instruct的新prompt_type: flawed_redundant_operations
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.65) - No tools were selected or executed for the data_pi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72) - The agent did not select or initialize any tool fo
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - No evidence of agent-specific decision errors (no 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - Primary agent decision error: no tools were select
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - Unknown system/tool failure prevented task progres
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.60) - The agent failed to select or initiate any tool fo
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.70) - No agent-level decision error can be identified be
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.70) - No observable agent decision error: there were no 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.55) - No clear agent decision error can be identified. U
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62) - No tools were selected or executed for the api_int
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors2025-08-30 09:28:22,104 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:22,105 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error prevented any agent decision or tool usage; there is no evidence of tool selection, parameter, sequence, or dependency mistakes. The failure 
2025-08-30 09:28:24,356 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:24,358 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized to begin the multi-stage pipeline; progress halted immediately. In a structured workflow, the agent should c
2025-08-30 09:28:29,301 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:29,302 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no steps were carried out, indicating the agent did not follow the expected data_pipeline sequence (A→B→C). The agent e

[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"673a702a-8daf-9cb2-b611-60be951d04fc"}, traceId: 213e064e17565602634554968e7fb2'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5381896032)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f387fbd-24f1-9aec-a582-f453055943eb"}, traceId: 213e042f17565602644661725e232a'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"31348bb4-882c-90d0-b0bb-1505dc68f8c4"}, traceId: 215045a817565602652301951e7e46'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1a5410f-61b4-965b-a62c-a21cd5c8c5f2"}, traceId: 215044fd17565602675521183e804f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8291061-06a9-9db7-baf1-a3bea185844c"}, traceId: 215045b017565602693508960e8413'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac603e73-9360-9450-8ca8-b275052247de"}, traceId: 213e042f17565602696241840e232a'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54030262-8546-9e6d-bce6-b98652b7c4bd"}, traceId: 213e042f17565602716051871e232a'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14272
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14272
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9dda7abd-019b-960d-ab2a-529b0a2f90db"}, traceId: 213e057b17565602741772555e3dc9'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ace056e9-6231-9b20-bb88-b9188089b949"}, traceId: 213e042f17565602747111899e232a'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8a5844db-875f-9112-9bbe-c2f3d443cea6"}, traceId: 213e042f17565602780121912e232a'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0057a815-f937-9c7d-a35d-db8c634cddbe"}, traceId: 215042f917565602790804027e1c3e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5655
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5655
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4883432c-c315-9b96-ae2e-4899f736327c"}, traceId: 213e042f17565602836201933e232a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13940
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13940
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.74
Progress: 30/30 (Success: 0)
💾 智能Checkpoint: 保存10个结果...
   触发原因: 数量=10, 时间=104.8s, 强制=True
✅ Checkpoint完成: 成功保存 10/10 个结果

[INFO] Batch writing 30 records to database (qwen2.5-72b-instruct:30)
[INFO] Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_092457.json2025-08-30 09:28:33,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:33,113 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were executed and the error is a generic 'Unknown error', which suggests the agent failed to satisfy prerequisite dependencies or workflow fl
2025-08-30 09:28:37,952 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:37,953 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API integration tool was selected or initialized for the task; required tools were not invoked (0% coverage). This omission indicates an incorr
2025-08-30 09:28:39,092 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:39,092 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required (Required Tools: 0) and no tools were executed; there is no observable agent decision (no tool selection, parameterization, or seque
2025-08-30 09:28:43,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:43,855 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute or establish the required multi-stage pipeline sequence (loading -> processing -> aggregating/etc.), resulting in no ste

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors2025-08-30 09:28:49,595 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:49,596 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the api_integration task. This indicates a failure at the tool-selection stage (identifying and choosing the
2025-08-30 09:28:50,590 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:50,591 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "There were no tools required to complete the task (0/0). The agent did not select any tool, which is effectively the correct behavior given the ta
2025-08-30 09:28:54,267 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:54,268 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or configured for the data_pipeline task (0% tool coverage). The agent failed to choose the appropriate data_pipeline tools
2025-08-30 09:28:54,405 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:54,406 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any API/integration tool to perform the api_integration task; no tools were used, indicating a tool selection decis
2025-08-30 09:28:59,507 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:59,507 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed; the agent failed to choose an appropriate initiating tool for the data_pipeline task given the unknown task co
2025-08-30 09:28:59,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:28:59,912 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or the selected tooling was inappropriate for a multi-stage pipeline (0% coverage). The agent failed at the planning stage 
2025-08-30 09:29:05,393 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:05,393 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). There were zero required tools to execute (0/0 coverage) and th
2025-08-30 09:29:05,394 - result_merger - INFO - 模型qwen2.5-72b-instruct保存50/50条记录
2025-08-30 09:29:05,398 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-30 09:29:05,399 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 09:29:05,399 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 12)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 22)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: max_turns_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 22)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'max_turns_errors' -> 'max_turns_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: max_turns_errors -> max_turns_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.68) - No tools were selected or initialized to begin the
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: dependency_errors (confidence: 0.65) - No tools were executed and the error is a generic 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85) - No API integration tool was selected or initialize
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 26)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75) - No tools were selected or the selected tooling was
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.75) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 29)
[INFO] 最终合并完成: 16 个文件
2025-08-30 09:29:05,535 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 09:29:05,535 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-30 09:29:10,695 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:10,696 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision error can be identified: there were zero required tools (Coverage 0%), and there is no record of tool usage, parameterization,
2025-08-30 09:29:18,262 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:18,262 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or agent decision evidence is available. The error message is unknown and there is no indication of a wrong tool choice, incorrect parameters
2025-08-30 09:29:22,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:22,829 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required data processing tool for the data_pipeline task, effectively choosing no tool (or a non-applicable
2025-08-30 09:29:27,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:27,114 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate or complete the required workflow steps (no tools invoked), effectively omitting the expected sequence and thus failing
2025-08-30 09:29:35,639 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:35,640 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Primary agent decision error: the task required no explicit tools, yet the agent produced a complete failure by taking no action and generating no output. 
2025-08-30 09:29:45,744 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:45,746 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed (Required Tools Coverage: 0%), and there is an 'Unknown error' with no tool activity. This indicates the agent 
2025-08-30 09:29:51,291 - openai._base_client - INFO - Retrying request to /chat/completions in 0.455843 seconds
2025-08-30 09:29:51,811 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:51,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select an appropriate tool (or request clarification) for an unknown task; no tool was chosen or executed, representing a tool-sel
2025-08-30 09:29:57,580 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:29:57,580 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be evaluated because there were no tools executed and the error is unspecified ('Unknown error'). Consequently, it's not possible to 
2025-08-30 09:30:01,146 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:04,096 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:04,096 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were selected or executed; no logical workflow sequence was followed (the task required at least some action, but the agent did not initi
2025-08-30 09:30:09,668 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:09,669 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error identifiable. The task required no tools (Required Tools Coverage: 0%), and there were no executed tools or parameter/sequ
2025-08-30 09:30:12,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:16,505 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:16,506 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate or select any tools, effectively skipping the required workflow steps for the API integration. This breaks the intended
2025-08-30 09:30:21,336 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:23,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:23,170 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed, so there is no evidence of tool_selection_errors, parameter_config_errors, sequence_order_errors, or dependency_errors.
2025-08-30 09:30:28,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:29,741 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:29,742 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for the given unknown/simple task, effectively failing to choose an appropriate tool or approach. Thi
2025-08-30 09:30:39,657 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:40,780 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:40,780 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or configure any tool to perform the simple_task. No tools were invoked (0% coverage), indicating a tool selection decisi
2025-08-30 09:30:48,388 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:48,389 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error detected. The task lists no required tools and no tools were executed, so there is no evidence of wrong tool choice, misco
2025-08-30 09:30:52,698 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:55,566 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:30:55,566 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for a task that requires an active action; this omission indicates a wrong tool decision/omission (to
2025-08-30 09:31:01,839 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:03,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:03,800 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required or executed; therefore there is no agent decision error (no wrong tool, parameter, or sequence). The failure appears to be due to in

[SAVE_ENHANCED] 开始增强保存，时间: 09:24:57
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.72) - Agent failed to select and invoke any required dat
[V3_UPDATE] 创建新prompt类型结构: qwen2.5-72b-instruct -> flawed_redundant_operations
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - The agent did not select or engage any tool for th
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65) - No tools were chosen or executed; the error contex
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60) - No observable agent decision error: required tools
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No tool was selected or executed and the error mes
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.65) - The agent did not select or execute any tool for t
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_redundant_operations -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - There is no evidence of a wrong agent decision (to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - The failure is described as an Unknown error with 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60) - Insufficient task context and an 'Unknown error' m
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 6)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55) - No tools were selected or executed for an unknown 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - Insufficient information to identify a specific ag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 4)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.40) - The task defined no required tools, yet the agent 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: dependency_errors (confidence: 0.42)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60) - No tool was selected because the task is Unknown; 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No agent-level decision error can be identified: t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.58) - Agent failed to handle TOOL DEPENDENCIES: there we
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.75) - No agent decision error detected: there were no re
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.80) - Unknown error prevented any agent decision or tool
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.85) - No tools were executed and no steps were carried o
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.72) - No tools were selected or executed; the agent fail
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.60) - No actionable agent decision error can be identifi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.70) - No tool usage or agent decision evidence is availa
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.62) - No tools were selected or executed (Required Tools
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.72) - Agent failed to select an appropriate tool (or req
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No agent decision can be evaluated because there w
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No tools were selected or executed, so there is no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.78) - The agent did not select or execute any tool for t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60) - The agent did not select or configure any tool to 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 20)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 26)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...2025-08-30 09:31:09,162 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:09,163 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified: there are no tool selections, executions, or parameters to evaluate, and the error message is Unknown/unknown-system-le
2025-08-30 09:31:09,669 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:18,218 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:18,218 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for an api_integration task; no tools were chosen despite the task requiring tool interaction, indica
2025-08-30 09:31:18,255 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:23,094 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:23,094 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tool for an api_integration task, effectively choosing no tool; this is a tool selection error that pr
2025-08-30 09:31:28,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:30,486 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:30,487 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent proceeded with downstream stages without the required outputs from upstream stages, violating dependencies and causing complete failure even
2025-08-30 09:31:35,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:35,211 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize the required API integration tool(s); no tools were executed (0% coverage). This indicates a tool-choice/in
2025-08-30 09:31:36,568 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:39,614 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:39,615 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select/use the appropriate toolchain for an API integration task (no tools chosen or incorrect tool), preventing progress toward c
2025-08-30 09:31:43,909 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:44,957 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:44,957 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision errors can be identified. There were no tool selections, parameter configurations, sequence decisions, or dependency handling to evaluate
2025-08-30 09:31:51,820 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:52,945 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:52,945 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no required tools for the task (coverage 0/0), and no agent actions were performed. The error message (Unknown error) does not indicate a wrong 
2025-08-30 09:31:57,876 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bb3e2ffc-52fa-9b8d-a6f2-77837aef3d7f"}, traceId: 2150409b17565603398018283e0926'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3503ce6d-3497-9a19-b7c8-ec35536a928c"}, traceId: 213e062917565603430271008e810e'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7918e54e-c128-97e8-9518-e2eb65cbdd7c"}, traceId: 2150416017565603443255556ef0a4'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"744d5750-257a-97f6-b959-4d4d1737ac22"}, traceId: 213e062917565603453091020e810e'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b81b9f79-6ace-9345-8347-759e70431b5b"}, traceId: 213e062917565603482641034e810e'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"526a1c71-01ca-96d1-9a16-bf0662a5eeb4"}, traceId: 213e06c017565603496724011e8343'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df426f8a-2b62-9b3b-a6e9-180932a25c9b"}, traceId: 213e062917565603516561050e810e'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c501224a-887d-9477-b84d-d0f706705856"}, traceId: 213e060a17565603515422070e8c8c'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c58eec03-8ae1-9dcc-8320-0096a584031d"}, traceId: 213e062917565603546321060e810e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_redundant_operations for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4954960112)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a121b1a5-451e-96a3-accf-0f8ad37d0eca"}, traceId: 213e060a17565603551672080e8c8c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df1d5e25-9eca-9720-93c7-adb345e42bbc"}, traceId: 2150455217565603573406199e8148'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b58f0d59-6e75-9610-b2d0-dd5684488b59"}, traceId: 213e060a17565603574872086e8c8c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea111a43-e778-960f-95c6-057a6a7687fd"}, traceId: 2150455217565603587706206e8148'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78651925-17a4-932c-8c0e-02518cf19690"}, traceId: 213e060a17565603602102102e8c8c'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1688abb2-2e69-963d-ad4f-87c2b34e92d7"}, traceId: 2150455217565603617116220e8148'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...2025-08-30 09:31:59,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:31:59,212 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent tool-choice/parameterization/sequence decisions were observable because no tools were executed (executed tools: none). The error message 'Unknown 
2025-08-30 09:32:03,829 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:03,830 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any appropriate data-pipeline tool (e.g., data_loader/pdf_reader) for the task; no tools were executed, indi
2025-08-30 09:32:07,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:10,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:10,178 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (no tools selected or executed, no parameters provided, and no sequence defined). The task shows required tools cover
2025-08-30 09:32:15,183 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:15,183 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or propose any tool to perform the 'simple_task' and did not provide an actionable plan, effectively making a wrong tool 
2025-08-30 09:32:17,198 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:20,085 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:20,087 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identifiable: no tools were selected or executed and the error is labeled Unknown error. This does not indicate a tool selection, p
2025-08-30 09:32:25,102 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:25,103 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision was observable: no tools were selected or executed and the error is reported as unknown. Therefore there is no evidence of tool selection
2025-08-30 09:32:26,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:29,555 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:29,555 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of incorrect agent decisions given; error message 'Unknown error' suggests a system-level/unknown failure rather than a mischoice of tool, wron
2025-08-30 09:32:32,481 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:33,760 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:33,761 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Primary agent decision error: The agent did not select or invoke any of the required tools for the multi_stage_pipeline task, resulting in 0% tool
2025-08-30 09:32:39,917 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:40,694 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:40,695 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tool appropriate for the task; no tools were used (0/0 coverage). This indicates a missing or incorrect tool d
2025-08-30 09:32:46,821 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:46,823 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766822519.json
2025-08-30 09:32:46,823 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766823268.json
2025-08-30 09:32:46,824 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766824048.json
2025-08-30 09:32:46,824 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766824387.json
2025-08-30 09:32:46,824 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766824712.json
2025-08-30 09:32:46,825 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766825013.json
2025-08-30 09:32:46,825 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766825344.json
2025-08-30 09:32:46,825 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766825634.json
2025-08-30 09:32:46,826 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766826033.json
2025-08-30 09:32:46,828 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766826283.json
2025-08-30 09:32:46,828 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766828677.json
2025-08-30 09:32:46,829 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766828971.json
2025-08-30 09:32:46,829 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766829199.json
2025-08-30 09:32:46,829 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766829430.json
2025-08-30 09:32:46,829 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766829656.json
2025-08-30 09:32:46,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766829882.json
2025-08-30 09:32:46,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766830082.json
2025-08-30 09:32:46,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766830282.json
2025-08-30 09:32:46,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766830563.json
2025-08-30 09:32:46,831 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560766830862.json
2025-08-30 09:32:52,305 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:52,306 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Insufficient information to identify a concrete agent decision error. No tools were executed and there is no explicit indication of what a correct
2025-08-30 09:32:55,547 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:58,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:32:58,130 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision can be identified: no tools were selected/executed and no parameters/sequence were provided. The error message is 'Unknown err
2025-08-30 09:33:04,551 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:05,173 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:05,174 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient evidence of any agent-level decision error: no tools were executed and the error is a generic 'Unknown error'. This suggests a system/tool-lev
2025-08-30 09:33:10,000 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:10,001 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent tool decisions or workflow steps; the task failed due to an unknown/undefined error rather than a mischosen tool, wrong parameters, mi
2025-08-30 09:33:13,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:16,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:16,778 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tool for the api_integration task, effectively skipping tool usage and halting progression. This repre
2025-08-30 09:33:21,212 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:28,499 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:28,499 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were required or executed for this basic_task task; therefore there was no tool selection decision by the agent. There is no evidence of 
2025-08-30 09:33:29,659 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:34,251 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:34,252 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not perform any steps or execute the expected workflow for the simple_task, effectively halting before progressing through the intended 
2025-08-30 09:33:37,841 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:43,089 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:43,091 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error could be identified: there were no tools selected or executed, and there is no evidence of wrong tool choice, incorrect parameters,
2025-08-30 09:33:45,650 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:49,890 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:49,891 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected or configured and there is no evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The failure app
2025-08-30 09:33:54,765 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:58,530 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:33:58,531 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task (Required Tools Coverage: 0%), indicating the agent failed to initiate or choose an 
2025-08-30 09:34:03,088 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:06,581 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:06,581 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or invoke any tool to perform the simple_task; no tool usage indicates a poor tool choice/decision leading to no output.",

2025-08-30 09:34:10,183 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d011b20-50c0-9b7e-90e8-2dd21c9b04e9"}, traceId: 213e060a17565603633552118e8c8c'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2cfabb2a-e107-9b0d-9ef6-1ddf7b826d2a"}, traceId: 2150455217565603654616231e8148'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b583917-fde0-94bf-a1e5-7a342cc43f67"}, traceId: 213e060a17565603672352128e8c8c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9f8226a7-82df-99ae-b62e-8a8bd5d5121f"}, traceId: 2150455217565603698416249e8148'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12409
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12409
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5073
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5073
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15201
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15201
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5073
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5073
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17350
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17350
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13160
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13160
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5233
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5233
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13786
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13786
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13519
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13519
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13381
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13381
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5232
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5232
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5207
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5207
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5223
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5223
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.782025-08-30 09:34:14,564 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:14,565 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and execute the necessary data processing tools (no tools were invoked for a data_pipeline task). This indicates a wrong to
2025-08-30 09:34:19,781 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:19,782 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision errors: there were no tools invoked and no error messages; unable to attribute failure to a specific agent decision (tool sele
2025-08-30 09:34:20,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:25,431 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:25,434 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient task and tool execution context to identify a concrete agent decision error. The task is unknown, no tools were executed, and the error is lab
2025-08-30 09:34:28,567 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:33,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:33,855 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to perform the data_pipeline task, effectively halting before any processing. This indicates a wrong/tooll
2025-08-30 09:34:40,263 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:40,764 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:40,764 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no agent decision to critique: the task required no tools, no parameters were set, and no execution sequence occurred. The error message 'Unknown 

[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 20)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 21)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 22)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: max_turns_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 6)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'max_turns_errors' -> 'max_turns_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: max_turns_errors -> max_turns_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors2025-08-30 09:34:47,815 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:47,817 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887816432.json
2025-08-30 09:34:47,817 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887817189.json
2025-08-30 09:34:47,817 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887817486.json
2025-08-30 09:34:47,817 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887817792.json
2025-08-30 09:34:47,818 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887818035.json
2025-08-30 09:34:47,819 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887818936.json
2025-08-30 09:34:47,819 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887819482.json
2025-08-30 09:34:47,820 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887819796.json
2025-08-30 09:34:47,821 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887820719.json
2025-08-30 09:34:47,821 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887821117.json
2025-08-30 09:34:47,821 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887821459.json
2025-08-30 09:34:47,822 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887821702.json
2025-08-30 09:34:47,822 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887822138.json
2025-08-30 09:34:47,822 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560887822391.json
2025-08-30 09:34:49,595 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:49,595 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or engage any tool to perform the basic_task (no tools were executed), effectively choosing a non-action path. Because no
2025-08-30 09:34:55,533 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:55,534 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_79841_1756560895533846.json
2025-08-30 09:34:55,534 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
2025-08-30 09:34:55,540 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 35 个结果到收集器: qwen2.5-72b-instruct_79841_1756560895537351.json
2025-08-30 09:34:55,540 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
2025-08-30 09:34:55,594 - batch_test_runner - INFO - Database saved successfully
2025-08-30 09:34:55,594 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 09:34:55,594 - batch_test_runner - INFO - ============================================================
2025-08-30 09:34:55,594 - batch_test_runner - INFO - Batch test completed at 2025-08-30T09:34:55.594672
2025-08-30 09:34:55,594 - batch_test_runner - INFO - Summary:
2025-08-30 09:34:55,594 - batch_test_runner - INFO -   - Total tests: 35
2025-08-30 09:34:55,594 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 09:34:55,594 - batch_test_runner - INFO -   - Failed: 35
2025-08-30 09:34:55,594 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 09:34:55,594 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_091927.log
2025-08-30 09:34:55,594 - batch_test_runner - INFO - ============================================================
2025-08-30 09:34:55,594 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 09:34:55,595 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 09:34:55,595 - result_merger - INFO - 发现36个新的结果文件
2025-08-30 09:34:55,617 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 09:34:55,617 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 09:34:55,802 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:55,803 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for a data_pipeline task. The agent did not choose a necessary tool (e.g., a data_loader or processing step) an
2025-08-30 09:34:59,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:34:59,202 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent making a decision error: no tools were executed and the error message is generic 'Unknown error'. Without tool usage, parameters, or s
2025-08-30 09:35:03,136 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:03,136 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or tools, effectively failing to establish or follow the required execution sequence for the task. This omissi
2025-08-30 09:35:04,186 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:04,186 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision errors detected: there were no tool selections, parameter configurations, sequence steps, or dependencies to evaluate. The reported failu
2025-08-30 09:35:09,430 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:09,431 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute the failure to a specific agent decision. The error shows as an unknown/system-level issue with no tools executed or 
2025-08-30 09:35:11,555 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:11,558 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked by the agent; there is no evidence of a wrong tool choice or any tool parameters. The failure appears to be due 
2025-08-30 09:35:16,280 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:16,280 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision (tool selection, parameter configuration, sequence, or dependencies) since there were no tools executed and the er
2025-08-30 09:35:16,966 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:16,966 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute the mandated multi-stage pipeline steps (A→B→C) and effectively produced no output; this indicates a failure to follow t
2025-08-30 09:35:21,882 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:21,882 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tool due to an unclear task, effectively making a tool selection/decision error by choosing not to initiate wi
2025-08-30 09:35:22,011 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:22,011 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the multi_stage_pipeline task. The agent failed to initialize or choose the required tools, resulting in zer
2025-08-30 09:35:26,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:26,905 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select/initialize any tool(s) for the multi_stage_pipeline and produced no tool executions, effectively abandoning the required 
2025-08-30 09:35:27,043 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:27,044 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required performing a data_pipeline operation, but no tools were selected or executed. This implies the agent failed at the initial decis
2025-08-30 09:35:32,498 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:32,501 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle workflow prerequisites by not performing any steps to complete the basic_task; no actions were taken, effectively ignoring nece
2025-08-30 09:35:32,642 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:32,646 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and there is no observable agent decision path (tool choice, parameter settings, execution sequence, or dependencies) to
2025-08-30 09:35:37,449 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:37,450 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there is no tool usage or parameter configuration to analyze. The failure is reported as an unknown error with 0/0 tool c
2025-08-30 09:35:37,818 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:37,819 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tools to run the multi_stage_pipeline (no tools executed). This constitutes a tool selection error, as 
2025-08-30 09:35:42,145 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:42,146 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error. No tools were selected or executed, and the error message is generic ('Unknown error'
2025-08-30 09:35:42,695 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:42,696 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error with zero tools executed prevents evaluation of any agent decision. There is no evidence of wrong tool selection, incorrect parameters, incor
2025-08-30 09:35:47,817 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:47,818 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions or tool usage were made (no tools executed). The failure appears to be due to an unknown task/context, not a mischoice of tool/parameter
2025-08-30 09:35:47,819 - result_merger - INFO - 模型qwen2.5-72b-instruct保存80/80条记录
2025-08-30 09:35:47,820 - result_merger - INFO - 合并完成，共处理51个文件，保存80条记录
2025-08-30 09:35:47,821 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 09:35:47,822 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No agent decision error identified: there are no t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.50) - The agent did not select or execute any tool for a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85) - Agent did not select or invoke any required tool f
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 20)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.66)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent decision errors can be identified. There 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - There were no required tools for the task (coverag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.75) - No agent tool-choice/parameterization/sequence dec
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 32)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - No agent decision error identifiable: no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.80) - No agent decision was observable: no tools were se
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - No evidence of incorrect agent decisions given; er
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 26)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.40)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.60) - No actionable agent decision can be identified: no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.66) - Insufficient evidence of any agent-level decision 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No evidence of agent tool decisions or workflow st
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error could be identified: there
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No tool was selected or configured and there is no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.62) - No tools were selected or executed for the data_pi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 30)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.65) - Insufficient task and tool execution context to id
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85) - Agent did not select or invoke any tool to perform
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 33)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60) - There is no agent decision to critique: the task r
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 32)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.55) - No tools were selected or invoked by the agent; th
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - No evidence of a specific agent decision (tool sel
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60) - Agent did not select or execute any tool due to an
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: dependency_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - Unknown error with zero tools executed prevents ev
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60) - No agent decisions or tool usage were made (no too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 37)
[INFO] 最终合并完成: 51 个文件
2025-08-30 09:35:47,931 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 09:35:47,931 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-30 09:35:50,395 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:50,396 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools, yet the agent did not perform any action or tool invocation to complete it. This indicates a misdecision in tool usage
2025-08-30 09:35:57,710 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:35:57,711 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions or tools were executed, effectively breaking the intended execution sequence for the task. The agent omitted the required steps and did
2025-08-30 09:36:09,217 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:09,217 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task had no required tools (required_tools coverage = 0), yet the agent did not select or execute any tool to progress the task. This represen
2025-08-30 09:36:16,625 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:16,625 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error is 'Unknown error'; there is no evidence of a wrong tool choice, misconfigured parameters, incorrect seque
2025-08-30 09:36:24,140 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:24,141 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or initiate any appropriate tool to handle the unknown basic task; no tools were executed, indicating a tool-selection 
2025-08-30 09:36:32,848 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:32,849 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision path can be identified from the provided data. There were no tool selections, parameter configurations, or execution sequences to evaluat
2025-08-30 09:36:42,227 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:42,228 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "There were no required tools to perform the task (0/0), yet the agent did not select or invoke any tool to execute the task. This represents a fau
2025-08-30 09:36:50,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:50,090 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed and no workflow steps were carried out. The task remained incomplete, indicating a failure to initiate/follow the require
2025-08-30 09:36:56,490 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:36:56,491 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initiate any tool to start the api_integration task; no tools were executed and no starting action was chosen, indicatin
2025-08-30 09:37:02,675 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:02,675 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision data available: error logged as Unknown error with no tool usage, parameters, or sequence supplied. Cannot attribute failure to a wrong t
2025-08-30 09:37:06,869 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:06,869 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were invoked and no tool selections were made for the multi-stage pipeline, indicating a misstep in tool selection/omission (the agent fa
2025-08-30 09:37:13,261 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:13,262 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tooling to perform the data_pipeline task (no tools executed). This represents a tool-selection mistake
2025-08-30 09:37:18,759 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:18,760 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API interaction tool was selected or initialized for the api_integration task, so no actions were performed. This indicates a wrong or missing 
2025-08-30 09:37:23,739 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:23,739 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any required tools for the multi_stage_pipeline (no tools executed). This implies a failure in the tool sel
2025-08-30 09:37:28,699 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:28,700 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tools to perform the data_pipeline task; no tools were executed, indicating a misstep in tool selection/i

[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5848
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5848
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13778
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13778
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13840
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13840
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5538
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5538
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5538
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5538
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5505
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5505
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.85
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16586
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16586
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14306
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14306
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13859
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13859
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4793
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4793
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14099
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14099
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5043
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5043
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14155
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14155
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4889
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4889
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5744
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5744
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5654
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5654
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 136882025-08-30 09:37:33,949 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:33,950 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or initialized to perform the required basic_task; the agent proceeded without choosing the appropriate tooling, leading to a
2025-08-30 09:37:44,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:44,617 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision error (no tools were required or invoked). The error message 'Unknown error' cannot be traced to a wrong tool se
2025-08-30 09:37:51,845 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:37:51,846 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "no_agent_error",
  "reason": "No evidence of a wrong agent decision (tool selection, parameter config, sequence, or dependencies). The failure appears external/unknown with zero tools
2025-08-30 09:37:51,846 - focused_ai_classifier - WARNING - Unknown category from AI: no_agent_error, defaulting to OTHER
2025-08-30 09:38:00,676 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:00,676 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No steps/tools were executed and no workflow sequence was established or followed. The task requires at least some action in a defined order (even
2025-08-30 09:38:08,473 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:08,474 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed; there is no evidence of a wrong tool choice, incorrect parameters, wrong sequence, or unmet dependencies. The failure a
2025-08-30 09:38:12,315 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:12,316 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke the required integration tool(s) for the API integration task; no tools were used, indicating a tool_selection_e
2025-08-30 09:38:16,365 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:16,365 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure cannot be attributed to a specific agent decision (tool choice, parameters, sequence, or dependencies). No tools were executed and the error re
2025-08-30 09:38:19,884 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:19,885 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision or tool usage to indicate a wrong tool choice, incorrect parameters, wrong sequence, or missing dependencies. The failure appe
2025-08-30 09:38:24,462 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:24,463 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any appropriate tool for the api_integration task; no tools were invoked, indicating an incorrect or missing tool choice.",
 
2025-08-30 09:38:28,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:28,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the multi-stage pipeline, indicating a failure to choose the required tooling (the agent did not pick an
2025-08-30 09:38:35,361 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:35,362 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There was no agent decision error: the task requires no tools and no steps were executed. The failure stems from a lack of action/undefined workflow rather
2025-08-30 09:38:40,191 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:40,191 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tool(s) for the api_integration task, effectively failing to establish the required tool workflow (no 
2025-08-30 09:38:46,253 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:46,253 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent tool selection, parameter configuration, sequence ordering, or dependency handling decisions could have caused the failure because no tools were s
2025-08-30 09:38:53,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:38:53,301 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any concrete agent decision (no tool selection, parameter configuration, or sequence execution) and the error is reported as unknow
2025-08-30 09:39:00,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:00,641 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error: no tools were selected or executed, and there is an 'Unknown error' with 0% tool coverage. The available data does no
2025-08-30 09:39:07,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:07,083 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was chosen or executed for a task that requires producing a result; the agent failed to select the appropriate action/tool, resulting in n
2025-08-30 09:39:14,794 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:14,794 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task; the agent failed to pick an appropriate tool (e.g., data_loader or pipeline process
2025-08-30 09:39:21,890 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:21,890 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a wrong tool choice, incorrect parameters, faulty execution order, or unmet dependencies. The task metadata shows no required tools
2025-08-30 09:39:29,722 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:29,723 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "System-level unknown error occurred with no tools selected or executed, so there is no agent decision error (no tool selection, parameter config, sequence 
2025-08-30 09:39:36,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:36,636 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool actions were executed and the error is generic ('Unknown error'), providing no evidence of a wrong agent decision (no incorrect tool selection, par
2025-08-30 09:39:43,478 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:43,479 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision evidence available: the task context indicates an Unknown task, with no tools executed and an 'Unknown error' message. This appears to be
2025-08-30 09:39:48,024 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:48,025 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the basic_task. There was no tool execution and no parameters provided, effectively an inac
2025-08-30 09:39:52,655 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:52,655 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or deploy any of the required data_pipeline tools (no tool execution occurred), effectively bypassing the toolchain. This
2025-08-30 09:39:58,204 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:39:58,204 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any tools to perform the multi-stage pipeline, resulting in zero tool usage and a complete halt in progress. 

[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13688
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13564
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13564
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.58
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14176
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14176
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13642
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13642
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
💾 智能Checkpoint: 保存14个结果...
   触发原因: 数量=14, 时间=121.0s, 强制=False
✅ Checkpoint完成: 成功保存 14/14 个结果
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 6063
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=6063
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
💾 智能Checkpoint: 保存1个结果...
   触发原因: 数量=1, 时间=7.7s, 强制=True
✅ Checkpoint完成: 成功保存 1/1 个结果

[INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_093455.json
[SAVE_ENHANCED] 开始增强保存，时间: 09:34:55
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-72b-instruct的新prompt_type: flawed_redundant_operations
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No evidence of agent making a decision error: no t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No agent decision errors detected: there were no t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.70) - Insufficient information to attribute the failure 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.60) - No tools were selected or executed and there is no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error detected: there is no tool
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 40)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - Insufficient information to identify a specific ag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.70)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.70)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.70) - No tools were selected or executed and the error i
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.62) - The agent failed to select or initiate any appropr
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 32)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.60) - No agent decision path can be identified from the 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No agent decision data available: error logged as 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - No tools were invoked and no tool selections were 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.78) - The agent did not select or initialize any tooling
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65) - No tool was selected or initialized to perform the
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - There is no evidence of any agent decision error (
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.20) - No evidence of a wrong agent decision (tool select
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 29)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - The failure cannot be attributed to a specific age
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - No observable agent decision or tool usage to indi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.68) - Agent did not select any appropriate tool for the 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.68)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.78) - No agent tool selection, parameter configuration, 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.62) - There is no evidence of any concrete agent decisio
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65) - No identifiable agent decision error: no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 48)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.66)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.75) - System-level unknown error occurred with no tools 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60) - No tool actions were executed and the error is gen
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No agent decision evidence available: the task con
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 51)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 52)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 53)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 57)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 58)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 59)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 63)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 41)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors2025-08-30 09:40:04,333 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:04,334 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be identified: no tools were selected/executed and the error is described as Unknown error. This appears to be a system-level/unknown
2025-08-30 09:40:09,367 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:09,368 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle tool dependencies in the multi_stage_pipeline: it attempted to proceed without ensuring that prerequisites/inputs for subsequen
2025-08-30 09:40:19,620 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:19,623 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked, resulting in zero tool coverage. With an unknown task and no executed tooling, the agent’s decision to abstain 
2025-08-30 09:40:26,718 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:26,719 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (no tools selected or executed; task details are unknown). The error message 'Unknown error' provides insuff
2025-08-30 09:40:35,410 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:35,410 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tools due to an Unknown error, indicating a failed initial tool-selection/initialization decision at the start
2025-08-30 09:40:45,580 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:45,580 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task had no required tools or steps (0 tools required), yet the agent elected to perform no actions at all. This represents an improper sequen
2025-08-30 09:40:51,790 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:51,791 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed. The agent did not choose or initialize the necessary API integration tool, effectively skipping the required t
2025-08-30 09:40:56,188 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:40:56,188 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any data processing tools or selected an inappropriate tool for a data_pipeline task, resulting in 0% coverage and no valid e
2025-08-30 09:41:01,789 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:01,790 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error. There were no tools executed and no task details to indicate a wrong tool choice, incorrect parameters, imp
2025-08-30 09:41:06,263 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:06,264 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent actions or decision points are available to attribute the failure. The error is unknown, and no tools were executed, so it cannot be classified as
2025-08-30 09:41:12,868 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:12,869 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to determine any specific agent decision error. No tools were executed (Executed Tools: none) and the error message is Unknown err
2025-08-30 09:41:18,743 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:18,744 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to follow the required data_pipeline sequence (no tools activated and no data flow established), effectively ignoring workflow de
2025-08-30 09:41:26,077 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:26,077 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision error: no tools were used, no parameters set, and the task indicates 0 required tools. The complete failure appe
2025-08-30 09:41:33,573 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:33,574 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent produced an empty action plan and did not execute any steps, effectively failing to follow a required processing sequence for the data_p
2025-08-30 09:41:38,431 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:38,431 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The failure appears to be an unknown/system-level error rather 
2025-08-30 09:41:42,501 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:42,502 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool selection, parameter config, sequence, or dependencies). The error is reported as Unknown error with 0% tool co
2025-08-30 09:41:47,861 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:47,862 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision can be identified since no tools were selected or executed and the error message is unknown. This appears to be a non-agent/system-
2025-08-30 09:41:53,441 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:53,442 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select and invoke the required API/tool for an api_integration task; no tools were used, resulting in a complete failure despite
2025-08-30 09:41:59,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:41:59,245 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any required tool(s) for the api_integration task; no tools were invoked, resulting in zero progress. This i

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 42)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 46)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 47)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 51)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 52)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 41)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 42)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 43)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 47)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 48)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 51)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 36)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 39)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 40)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...2025-08-30 09:42:05,261 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:42:05,262 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task, indicating the agent failed to choose and start the necessary tool(s) (i.e., missing
2025-08-30 09:42:12,692 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 09:42:12,694 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "There is insufficient information to determine the agent's tool choice decisions. The task details are unknown, no tools were listed as executed, 
2025-08-30 09:42:12,694 - result_merger - INFO - 模型qwen2.5-72b-instruct保存70/70条记录
2025-08-30 09:42:12,696 - result_merger - INFO - 合并完成，共处理36个文件，保存70条记录
2025-08-30 09:42:12,698 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 09:42:12,700 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 34)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 38)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 43)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 44)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No agent decision can be identified: no tools were
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> multi_stage_pipeline (total: 45)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.55) - No tools were selected or invoked, resulting in ze
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> simple_task (total: 65)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.64) - No evidence of a specific agent decision error (no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.60) - Agent did not select or execute any tools due to a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 53)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60) - No evidence of a specific agent decision error. Th
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 55)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - No agent actions or decision points are available 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 55)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.65) - Insufficient information to determine any specific
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 56)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 49)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of a wrong agent decision (tool select
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> api_integration (total: 50)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent-level decision can be identified since no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> data_pipeline (total: 59)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60) - There is insufficient information to determine the
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_redundant_operations -> basic_task (total: 57)
[INFO] 最终合并完成: 36 个文件
2025-08-30 09:42:12,817 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 09:42:12,817 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片1完成
INFO:__main__:等待分片2完成（20实例×50workers，最多等待50分钟）...
INFO:__main__:✅ 分片2完成
INFO:__main__:等待分片3完成（20实例×50workers，最多等待50分钟）...
INFO:__main__:✅ 分片3完成
INFO:__main__:📊 并发执行结果: 3/3 分片成功
INFO:__main__:✅ Key0: 完成 qwen2.5-72b-instruct-easy
INFO:__main__:最终利用率: 1.1%
=== 测试结束时间: 2025年 8月30日 星期六 09时42分14秒 EDT ===
=== 退出码: 0 ===
