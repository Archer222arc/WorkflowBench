===== 分片 qwen2.5-72b-instruct_easy_key1 =====
时间: 2025-08-20T02:01:49.849086
模型: qwen2.5-72b-instruct
实例: qwen-key1
命令: python -u smart_batch_runner.py --model qwen2.5-72b-instruct --deployment qwen-key1 --prompt-types optimal --difficulty easy --task-types all --num-instances 7 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[02:01:51.617] 2025-08-20 02:01:51,617 - faiss.loader - INFO - Loading faiss.
[02:01:51.631] 2025-08-20 02:01:51,631 - faiss.loader - INFO - Successfully loaded faiss.
[02:01:52.485] [INFO] 使用Parquet存储格式
[02:01:52.870] [INFO] 使用Parquet存储格式
[02:01:52.873] [INFO] 使用PARQUET存储格式
[02:01:52.873] 
[02:01:52.873] ============================================================
[02:01:52.873] 智能批测试: qwen2.5-72b-instruct (idealab)
[02:01:52.873] Prompt types: ['optimal']
[02:01:52.873] 难度: easy
[02:01:52.873] 目标: 每种配置 7 个实例
[02:01:52.873] ============================================================
[02:01:52.904] ○ simple_task         :   0/  7 已完成 (需要补充 7 个)
[02:01:52.909] ○ basic_task          :   0/  7 已完成 (需要补充 7 个)
[02:01:52.914] ○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
[02:01:52.918] ○ api_integration     :   0/  7 已完成 (需要补充 7 个)
[02:01:52.923] ○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)
[02:01:52.923] 
[02:01:52.923] ⏳ 需要运行 35 个新测试
[02:01:52.923] 
[02:01:52.923] ▶ 准备 simple_task (7 个实例)...
[02:01:52.923] 
[02:01:52.923] ▶ 准备 basic_task (7 个实例)...
[02:01:52.923] 
[02:01:52.923] ▶ 准备 data_pipeline (7 个实例)...
[02:01:52.923] 
[02:01:52.923] ▶ 准备 api_integration (7 个实例)...
[02:01:52.923] 
[02:01:52.923] ▶ 准备 multi_stage_pipeline (7 个实例)...
[02:01:52.923] 
[02:01:52.923] ▶ 开始执行 35 个测试...
[02:01:52.923] 📦 批量提交模式：每20个测试保存一次
[02:01:52.923] ⚠️  检测到idealab API，调整并发: workers=3, qps=5.0
[02:01:52.925] 2025-08-20 02:01:52,925 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[02:01:52.970] 2025-08-20 02:01:52,970 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[02:01:52.970] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x169fd48f0>
[02:01:52.970] 2025-08-20 02:01:52,970 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[02:01:52.970] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - ============================================================
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - Batch test runner initialized
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_020152.log
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - ============================================================
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - Running 35 tests with 3 workers, QPS limit: 5.0
[02:01:52.971] 2025-08-20 02:01:52,971 - batch_test_runner - INFO - Initializing test components...
[02:01:53.307] 2025-08-20 02:01:53,307 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[02:01:53.307] 2025-08-20 02:01:53,307 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[02:01:53.307] 2025-08-20 02:01:53,307 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[02:01:53.307] [DEBUG] Creating new ToolCapabilityManager instance
[02:01:53.307] [OperationEmbeddingIndex] Initializing with unified API client manager
[02:01:53.307] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[02:01:53.309] 2025-08-20 02:01:53,308 - api_client_manager - INFO - Loaded configuration from config/config.json
[02:01:53.326] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[02:01:53.326] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[02:01:53.326] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[02:01:54.250] 2025-08-20 02:01:54,250 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[02:01:54.252] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[02:01:54.299] [INFO] Loaded 4150 embeddings from persistent cache
[02:01:54.299] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[02:01:54.300] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[02:01:54.300] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[02:01:54.300] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[02:01:54.304] [INFO] Successfully loaded FAISS index with dimension 3072
[02:01:54.304] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[02:01:54.304] [INFO] Loaded 15 operations with dimension 3072
[02:01:54.304] [INFO] Successfully loaded cached index
[02:01:54.304] [INFO] Operation semantic index initialized
[02:01:54.304] [INFO] Using device: cpu
[02:01:54.305] [INFO] Initialized tool success tracking attributes
[02:01:54.305] [INFO] Initializing embedding manager for enhanced tool selection
[02:01:54.305] [MCPEmbeddingManager] Creating new singleton instance
[02:01:54.305] [MCPEmbeddingManager] Initializing with unified API client manager
[02:01:54.311] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[02:01:54.311] [MCPEmbeddingManager] Client initialized successfully
[02:01:54.311] 2025-08-20 02:01:54,311 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[02:01:54.461] 2025-08-20 02:01:54,461 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[02:01:54.705] 2025-08-20 02:01:54,705 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[02:01:54.705] 2025-08-20 02:01:54,705 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[02:01:54.728] 2025-08-20 02:01:54,728 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[02:01:54.807] 2025-08-20 02:01:54,807 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[02:01:55.159] 2025-08-20 02:01:55,159 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[02:01:55.159] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[02:01:55.159] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[02:01:55.159] 2025-08-20 02:01:55,159 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:01:55.541] 2025-08-20 02:01:55,541 - mcp_embedding_manager - INFO - FAISS index loaded
[02:01:55.541] 2025-08-20 02:01:55,541 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:01:55.541] 2025-08-20 02:01:55,541 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:01:55.543] [SUCCESS] Loaded 30 tool embeddings
[02:01:55.543] 2025-08-20 02:01:55,543 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[02:01:55.543] [SUCCESS] Embedding manager initialized with 30 tools
[02:01:55.543] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[02:01:55.543] [INFO] Loading full MCP protocol registry...
[02:01:55.544] 2025-08-20 02:01:55,544 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:01:55.544] [INFO] Loaded full tool registry with 30 tools
[02:01:55.544] 2025-08-20 02:01:55,544 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[02:01:55.544] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[02:01:55.545] [INFO] Embedding manager ready with 30 tools
[02:01:55.545] [WARNING] Embedding manager exists but has no embeddings
[02:01:55.545] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[02:01:55.545] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[02:01:55.545] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[02:01:55.545] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:01:55.545] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[02:01:55.545] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[02:01:55.545] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:01:55.545] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:01:55.545] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:01:55.545] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:01:55.545] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[02:01:55.545] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:01:55.545] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:01:55.545] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[02:01:55.545] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[02:01:55.545] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[02:01:55.545] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:01:55.545] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:01:55.545] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:01:55.545] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[02:01:55.545] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[02:01:55.545] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[02:01:55.545] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[02:01:55.545] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[02:01:55.545] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[02:01:55.545] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[02:01:55.545] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[02:01:55.545] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[02:01:55.545] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[02:01:55.545] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[02:01:55.545] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[02:01:55.546] 2025-08-20 02:01:55,545 - mdp_workflow_generator - INFO - Loaded 30 tools
[02:01:55.546] [INFO] Setting default state_dim based on loaded tools
[02:01:55.546] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[02:01:55.546] 2025-08-20 02:01:55,546 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[02:01:55.546] [INFO] Setting default action_dim based on loaded tools
[02:01:55.546] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[02:01:55.546] 2025-08-20 02:01:55,546 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[02:01:55.546] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[02:01:55.546] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[02:01:55.546] [INFO] ⚡ Will use pre-generated workflows or random policy
[02:01:55.546] 2025-08-20 02:01:55,546 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[02:01:55.546] [INFO] Initializing TaskManager...
[02:01:56.790] 2025-08-20 02:01:56,790 - unified_training_manager - INFO - Using device: cpu
[02:01:56.954] 2025-08-20 02:01:56,953 - unified_training_manager - INFO - Task filtering results:
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO -   Total: 5040 -> 5040
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO -   simple_task: 320 -> 320
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[02:01:56.954] 2025-08-20 02:01:56,954 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[02:01:56.957] 2025-08-20 02:01:56,957 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[02:01:56.957] [TaskManager] Difficulty level 'easy': 1096 tasks
[02:01:56.957] [TaskManager] Difficulty level 'very_easy': 856 tasks
[02:01:56.957] [TaskManager] Difficulty level 'medium': 1136 tasks
[02:01:56.957] [TaskManager] Difficulty level 'hard': 1096 tasks
[02:01:56.957] [TaskManager] Difficulty level 'very_hard': 856 tasks
[02:01:56.962] [INFO] TaskManager initialized with 5040 tasks
[02:01:56.962] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[02:01:56.962] [INFO] Initializing ToolCallVerifier...
[02:01:56.967] [INFO] ToolCallVerifier initialized with 30 tools
[02:01:56.967] [INFO] Output tools identified: 1
[02:01:56.967] [INFO] Component initialization status:
[02:01:56.967]   - embedding_manager: initialized
[02:01:56.967]   - task_manager: initialized
[02:01:56.967]   - output_verifier: initialized
[02:01:56.967]   - tool_capability_manager: initialized
[02:01:56.967]   - tool_success_rates: initialized with 0 entries
[02:01:56.967] [INFO] MDPWorkflowGenerator initialization complete
[02:01:56.967] 2025-08-20 02:01:56,967 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[02:01:56.967] 2025-08-20 02:01:56,967 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[02:01:56.967] 2025-08-20 02:01:56,967 - batch_test_runner - INFO -   - task_manager: ✓
[02:01:56.968] 2025-08-20 02:01:56,967 - batch_test_runner - INFO -   - output_verifier: ✓
[02:01:56.968] 2025-08-20 02:01:56,967 - batch_test_runner - INFO -   - embedding_manager: ✓
[02:01:56.968] 2025-08-20 02:01:56,967 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[02:01:56.968] 2025-08-20 02:01:56,968 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[02:01:56.968] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:56.968] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:56.968] [FlawedWorkflowGenerator] Initialized with 30 tools
[02:01:56.968] [FlawedWorkflowGenerator] RAG support: disabled
[02:01:56.969] DEBUG: Checking generator attributes
[02:01:56.969]   - has tool_capabilities: True
[02:01:56.970]   - has tool_capability_manager: True
[02:01:56.970]   - has task_manager: True
[02:01:56.970] [INFO] Loaded 30 tools from generator
[02:01:56.970] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[02:01:56.970] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:56.970] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:56.970] [INFO] Initializing LLM client using APIClientManager
[02:01:56.980] [INFO] Using Azure OpenAI client
[02:01:56.980] [DEBUG] Checking if generator has tool_capability_manager attribute
[02:01:56.980] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[02:01:56.980] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:56.980] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:56.980] [FlawedWorkflowGenerator] Initialized with 30 tools
[02:01:56.980] [FlawedWorkflowGenerator] RAG support: enabled
[02:01:56.980] [INFO] FlawedWorkflowGenerator initialized successfully
[02:01:56.980] [INFO] Initializing StableScorer for Phase 2 scoring
[02:01:56.980] <tool_capability_manager.ToolCapabilityManager object at 0x309acba40>
[02:01:56.980] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:56.980] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:56.980] [INFO] Loaded tool success history for 0 tools
[02:01:56.980] [INFO] StableScorer initialized with semantic capability
[02:01:56.980] [INFO] StableScorer initialized successfully
[02:01:56.981] [INFO] Loading task instances...
[02:01:56.981] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[02:01:56.990] [INFO] Loaded 630 task instances
[02:01:56.990] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[02:01:56.990] 2025-08-20 02:01:56,990 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[02:01:56.990] 2025-08-20 02:01:56,990 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[02:01:57.343] 2025-08-20 02:01:57,343 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[02:01:57.343] 2025-08-20 02:01:57,343 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[02:01:57.359] 2025-08-20 02:01:57,359 - batch_test_runner - INFO - Initialization complete
[02:01:57.422] 2025-08-20 02:01:57,422 - batch_test_runner - INFO - Starting batch test with 35 tasks, 3 workers
[02:01:57.422] 2025-08-20 02:01:57,422 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[02:01:57.422] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:01:57.423] 2025-08-20 02:01:57,423 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
[02:01:57.430] 2025-08-20 02:01:57,430 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:01:57.430] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:01:57.430] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:01:57.431] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:01:57.431] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:57.431] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:57.431] 2025-08-20 02:01:57,431 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:01:57.734] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:01:57.735] 2025-08-20 02:01:57,734 - mcp_embedding_manager - INFO - FAISS index loaded
[02:01:57.735] 2025-08-20 02:01:57,735 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:01:57.735] 2025-08-20 02:01:57,735 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:01:57.737] [INFO] Tool embedding index loaded successfully
[02:01:57.738] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:01:57.738] [INFO] Operation semantic index initialized
[02:01:57.738] 
[02:01:57.738] [TURN 1/10]
[02:01:57.738] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:01:57.744] 2025-08-20 02:01:57,744 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:01:57.744] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:01:57.744] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:01:57.745] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:01:57.745] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:57.745] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:57.745] 2025-08-20 02:01:57,745 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:01:57.762] 2025-08-20 02:01:57,762 - mcp_embedding_manager - INFO - FAISS index loaded
[02:01:57.762] 2025-08-20 02:01:57,762 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:01:57.762] 2025-08-20 02:01:57,762 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:01:57.764] [INFO] Tool embedding index loaded successfully
[02:01:57.765] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:01:57.765] [INFO] Operation semantic index initialized
[02:01:57.765] 
[02:01:57.765] [TURN 1/10]
[02:01:57.765] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:01:57.924] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:01:57.931] 2025-08-20 02:01:57,931 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:01:57.931] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:01:57.931] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:01:57.932] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:01:57.932] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:01:57.932] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:01:57.932] 2025-08-20 02:01:57,932 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:01:57.955] 2025-08-20 02:01:57,955 - mcp_embedding_manager - INFO - FAISS index loaded
[02:01:57.955] 2025-08-20 02:01:57,955 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:01:57.956] 2025-08-20 02:01:57,955 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:01:57.959] [INFO] Tool embedding index loaded successfully
[02:01:57.960] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:01:57.960] [INFO] Operation semantic index initialized
[02:01:57.960] 
[02:01:57.960] [TURN 1/10]
[02:01:57.961] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:01:58.534] 2025-08-20 02:01:58,534 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:01:58.536] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c649e47-a6f6-99ac-b8fa-0bbc659f7729"}, traceId: 213e066317556805184091627e827f'}
[02:01:58.536] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:01:58.554] 2025-08-20 02:01:58,554 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:01:58.555] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f51452c0-f9ec-9cce-b712-d0bc740311fc"}, traceId: 213e042b17556805184337859e1cfd'}
[02:01:58.555] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:01:58.787] 2025-08-20 02:01:58,787 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:01:58.787] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7155b1e-6833-95c5-868e-969c53e11d11"}, traceId: 213e06ba17556805186161141e8871'}
[02:01:58.788] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:01:59.718] 2025-08-20 02:01:59,718 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:01:59.719] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29942676-925f-9e72-ac32-447db5b384f4"}, traceId: 213e066317556805196071633e827f'}
[02:01:59.719] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:01:59.793] 2025-08-20 02:01:59,793 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:01:59.794] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d0664776-54de-9208-bac2-97e899838cc1"}, traceId: 213e06ba17556805196851144e8871'}
[02:01:59.794] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:00.825] 2025-08-20 02:02:00,825 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:00.828]   [SEARCH] Query: data validation parser
[02:02:00.829] 
[02:02:00.829] [TURN 2/10]
[02:02:00.830] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:01.350] 2025-08-20 02:02:01,350 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:01.351] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4afe7d2-8dc1-95db-ae69-b0e20228a3f3"}, traceId: 213e06ba17556805211851149e8871'}
[02:02:01.351] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:02:01.462] 2025-08-20 02:02:01,462 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:01.463] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f991f370-6580-9743-be0e-e51f94cad98d"}, traceId: 213e066317556805213031649e827f'}
[02:02:01.463] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[02:02:02.187] 2025-08-20 02:02:02,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:02.189]   [INFO] Tool info request: data_processing_validator
[02:02:02.189] 
[02:02:02.189] [TURN 3/10]
[02:02:02.189] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:02.531] 2025-08-20 02:02:02,531 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:02.532] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77e7629d-5b62-982d-baf1-506f89293bb9"}, traceId: 213e042b17556805224137877e1cfd'}
[02:02:02.532] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:03.722] 2025-08-20 02:02:03,722 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:03.723] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7c8e7526-2815-978a-a9bb-ccb42e2e6b05"}, traceId: 213e06ba17556805235591164e8871'}
[02:02:03.723] [RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[02:02:04.715] 2025-08-20 02:02:04,714 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:04.715] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6865d195-e19b-9c82-afd2-17bb1cd849ca"}, traceId: 213e066317556805245851666e827f'}
[02:02:04.715] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:04.913] 2025-08-20 02:02:04,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:04.915]   [INFO] Tool info request: data_processing_parser
[02:02:04.915] 
[02:02:04.915] [TURN 4/10]
[02:02:04.916] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:05.300] 2025-08-20 02:02:05,300 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:05.300] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86354f95-b398-93ea-9e5a-104a6c9ae642"}, traceId: 213e042b17556805251487889e1cfd'}
[02:02:05.300] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:02:06.339] 2025-08-20 02:02:06,339 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:06.340] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"85fd8235-4115-90b4-9bd9-85e92abe2f61"}, traceId: 213e042b17556805261987891e1cfd'}
[02:02:06.340] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:07.824] 2025-08-20 02:02:07,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:07.825]   [SEARCH] Query: data validation parser
[02:02:07.825] 
[02:02:07.825] [TURN 2/10]
[02:02:07.826] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:07.909] 2025-08-20 02:02:07,909 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:07.910] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e251e26c-6012-9428-b696-639c795a6711"}, traceId: 213e042b17556805277367898e1cfd'}
[02:02:07.910] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:08.828] 2025-08-20 02:02:08,827 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:08.829]   [INFO] Tool info request: data_processing_validator
[02:02:08.829] 
[02:02:08.829] [TURN 3/10]
[02:02:08.830] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:09.534] 2025-08-20 02:02:09,533 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:09.536] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"274520a4-05d5-968e-905d-d8dbdf627e9f"}, traceId: 213e065417556805294254742e8211'}
[02:02:09.536] [ERROR] Max retries reached after 5 attempts
[02:02:09.536] [API_FAILURE] All retries exhausted
[02:02:09.536]   [API_FAILURE] API failed (timeout or max retries)
[02:02:09.538] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:09.538] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:09.538] [AI_DEBUG] 生成的txt_content长度: 4242
[02:02:09.538] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:09.538]   - use_ai_classification=True
[02:02:09.538]   - ai_classifier=True
[02:02:09.538]   - txt_content_len=4242
[02:02:09.538]   - task_model=qwen2.5-72b-instruct
[02:02:09.540] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:09.555] 2025-08-20 02:02:09,555 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:09.555] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:09.555] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:09.555] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:09.555] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:09.555] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:09.555] 2025-08-20 02:02:09,555 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:09.588] 2025-08-20 02:02:09,588 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:09.589] 2025-08-20 02:02:09,588 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:09.589] 2025-08-20 02:02:09,588 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:09.592] [INFO] Tool embedding index loaded successfully
[02:02:09.593] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:09.594] [INFO] Operation semantic index initialized
[02:02:09.594] 
[02:02:09.594] [TURN 1/10]
[02:02:09.594] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:09.891] 2025-08-20 02:02:09,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:09.893]   [INFO] Tool info request: data_processing_parser
[02:02:09.893] 
[02:02:09.893] [TURN 4/10]
[02:02:09.893] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:10.017] 2025-08-20 02:02:10,017 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:10.017] 2025-08-20 02:02:10,017 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:10.017] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:02:10.370] 2025-08-20 02:02:10,370 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:10.370] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"895600b5-639f-99d7-8f1e-4471670ba0d4"}, traceId: 213e06bc17556805302537377e801e'}
[02:02:10.371] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:02:10.792] 2025-08-20 02:02:10,792 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:10.794]   [EARLY_EXIT] No actions taken, continuing...
[02:02:10.794] 
[02:02:10.794] [TURN 5/10]
[02:02:10.795] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:10.994] 2025-08-20 02:02:10,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:11.007]   [EARLY_EXIT] No actions taken, continuing...
[02:02:11.007] 
[02:02:11.007] [TURN 5/10]
[02:02:11.007] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:11.403] 2025-08-20 02:02:11,403 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:11.408] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"abc5391c-d8dd-9118-862c-8fd8ca118c0a"}, traceId: 213e066317556805312291694e827f'}
[02:02:11.408] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:02:11.559] 2025-08-20 02:02:11,559 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:11.559]   [EARLY_EXIT] No actions taken, continuing...
[02:02:11.559] 
[02:02:11.559] [TURN 6/10]
[02:02:11.560] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:11.894] 2025-08-20 02:02:11,894 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:11.895] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"be759648-fa06-9596-9753-d8de1ca3708a"}, traceId: 213e042b17556805317837912e1cfd'}
[02:02:11.895] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:02:12.131] 2025-08-20 02:02:12,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:12.133]   [SEARCH] Query: data processing parser
[02:02:12.133] 
[02:02:12.133] [TURN 2/10]
[02:02:12.133] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:13.098] 2025-08-20 02:02:13,097 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:13.098]   [EARLY_EXIT] No actions taken, continuing...
[02:02:13.098] 
[02:02:13.098] [TURN 6/10]
[02:02:13.099] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:13.105] 2025-08-20 02:02:13,105 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:13.105]   [EARLY_EXIT] No actions taken, continuing...
[02:02:13.106] 
[02:02:13.106] [TURN 3/10]
[02:02:13.106] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:13.329] 2025-08-20 02:02:13,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:13.330] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"11162f93-b082-96ae-b009-6ece6410ff8a"}, traceId: 213e042b17556805331647916e1cfd'}
[02:02:13.330] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:02:13.471] 2025-08-20 02:02:13,471 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:13.472] 2025-08-20 02:02:13,471 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:13.472] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"17e84731-812c-98a3-af4a-4f58f3da8754"}, traceId: 213e06bc17556805333287395e801e'}
[02:02:13.472] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:02:13.472] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd75ce49-6dfa-9768-a162-4107ae69a253"}, traceId: 213e066317556805333201703e827f'}
[02:02:13.472] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:14.986] 2025-08-20 02:02:14,985 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:14.990] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d7f5ebd-0545-9279-b5ed-97c0e2e65dfe"}, traceId: 213e066317556805347711708e827f'}
[02:02:14.990] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:02:15.346] 2025-08-20 02:02:15,346 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:15.347] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b206722-d415-90a7-ba9c-999c2834e7ff"}, traceId: 213e06bc17556805352067428e801e'}
[02:02:15.347] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:15.687] 2025-08-20 02:02:15,687 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:15.689]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:02:15.689] 
[02:02:15.689] [TURN 7/10]
[02:02:15.689] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:16.074] 2025-08-20 02:02:16,074 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:16.074] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9644d42a-19f7-9c97-8c45-41f3fa0aab1c"}, traceId: 213e042b17556805359147922e1cfd'}
[02:02:16.074] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:16.723] 2025-08-20 02:02:16,723 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:16.724] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01a2aee1-80d0-9a1a-b226-02d7e0aa8070"}, traceId: 213e066317556805365041723e827f'}
[02:02:16.724] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:02:16.934] 2025-08-20 02:02:16,934 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:16.935] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca84beb2-e7ed-9185-8225-cfa8d9d0014b"}, traceId: 213e06bc17556805368137469e801e'}
[02:02:16.935] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:18.130] 2025-08-20 02:02:18,130 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:18.136]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:02:18.136] 
[02:02:18.136] [TURN 8/10]
[02:02:18.136] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:19.196] 2025-08-20 02:02:19,196 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:19.198]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:02:19.198] 
[02:02:19.198] [TURN 9/10]
[02:02:19.199] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:19.340] 2025-08-20 02:02:19,340 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:19.342] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"933cd3eb-484b-93f5-a233-e29b60281856"}, traceId: 213e06bc17556805392257488e801e'}
[02:02:19.342] [RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[02:02:19.559] 2025-08-20 02:02:19,559 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:19.564] 2025-08-20 02:02:19,564 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:19.567] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88fd177f-def7-9315-877d-ac5f243fd888"}, traceId: 213e066317556805394081736e827f'}
[02:02:19.567] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:19.567] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe95aea0-03ae-9020-a8c0-636242e425ef"}, traceId: 213e042b17556805394257932e1cfd'}
[02:02:19.567] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:02:20.881] 2025-08-20 02:02:20,881 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:20.884] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"016a4b96-7f48-9e6a-a9e1-b1b7e0cc124b"}, traceId: 213e042b17556805406687936e1cfd'}
[02:02:20.884] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:02:21.759] 2025-08-20 02:02:21,758 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:21.763] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"697c0ac5-8a42-9bbe-a3b5-86055a5c4684"}, traceId: 213e066317556805416391742e827f'}
[02:02:21.763] [ERROR] Max retries reached after 5 attempts
[02:02:21.763] [API_FAILURE] All retries exhausted
[02:02:21.763]   [API_FAILURE] API failed (timeout or max retries)
[02:02:21.765] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:21.765] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:21.765] [AI_DEBUG] 生成的txt_content长度: 10993
[02:02:21.765] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:21.766]   - use_ai_classification=True
[02:02:21.766]   - ai_classifier=True
[02:02:21.766]   - txt_content_len=10993
[02:02:21.766]   - task_model=qwen2.5-72b-instruct[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:21.766] 
[02:02:21.766] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:21.774] 2025-08-20 02:02:21,774 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:21.774] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:21.774] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:21.775] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:21.775] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:21.775] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:21.775] 2025-08-20 02:02:21,775 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:21.819] 2025-08-20 02:02:21,819 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:21.819] 2025-08-20 02:02:21,819 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:21.819] 2025-08-20 02:02:21,819 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:21.822] [INFO] Tool embedding index loaded successfully
[02:02:21.822] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:21.822] [INFO] Operation semantic index initialized
[02:02:21.823] 
[02:02:21.823] [TURN 1/10]
[02:02:21.823] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:22.947] 2025-08-20 02:02:22,947 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:22.948] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"00bfe239-ac45-9f21-b1eb-2d6312a5a4e8"}, traceId: 213e042b17556805427507950e1cfd'}
[02:02:22.948] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:23.134] 2025-08-20 02:02:23,134 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:23.135]   [SEARCH] Query: data validation parser
[02:02:23.135] 
[02:02:23.135] [TURN 2/10]
[02:02:23.138] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:23.508] 2025-08-20 02:02:23,507 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:23.509] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e234cd49-587f-9b3f-9e77-37656adff315"}, traceId: 213e043517556805433593411e2e12'}
[02:02:23.509] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:02:24.634] 2025-08-20 02:02:24,634 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:24.635]   [EARLY_EXIT] No actions taken, continuing...
[02:02:24.635] 
[02:02:24.635] [TURN 4/10]
[02:02:24.635] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:24.704] 2025-08-20 02:02:24,704 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:24.704] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"368d3380-b19a-954d-948e-132a48fd49f4"}, traceId: 213e043517556805445853415e2e12'}
[02:02:24.704] [RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[02:02:25.026] 2025-08-20 02:02:25,026 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:25.027] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8397b40c-0932-996e-8a17-5e6643b2c703"}, traceId: 213e06bc17556805448587544e801e'}
[02:02:25.027] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:25.393] 2025-08-20 02:02:25,393 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:25.394] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c78af515-fe59-9cef-a529-511a210c31bf"}, traceId: 213e042b17556805452727963e1cfd'}
[02:02:25.394] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:02:26.769] 2025-08-20 02:02:26,769 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:26.770] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bfba0ef9-3900-9b37-bea4-7b92303b6161"}, traceId: 213e043517556805466373421e2e12'}
[02:02:26.770] [RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[02:02:27.147] 2025-08-20 02:02:27,147 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:27.148]   [EARLY_EXIT] No actions taken, continuing...
[02:02:27.148] 
[02:02:27.148] [TURN 5/10]
[02:02:27.149] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:27.504] 2025-08-20 02:02:27,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:27.505] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8614af41-54fd-9c3a-a1c2-620995ffd9b7"}, traceId: 213e06bc17556805473727561e801e'}
[02:02:27.505] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:02:28.482] 2025-08-20 02:02:28,482 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:28.483] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f53b3800-ddf5-9e03-9c17-dac052bfaab0"}, traceId: 213e042b17556805482967980e1cfd'}
[02:02:28.483] [ERROR] Max retries reached after 5 attempts
[02:02:28.483] [API_FAILURE] All retries exhausted
[02:02:28.483]   [API_FAILURE] API failed (timeout or max retries)
[02:02:28.483] [ASSISTED] Task received 3 format helps, final result: failure
[02:02:28.485] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:28.486] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:28.486] [AI_DEBUG] 生成的txt_content长度: 14239
[02:02:28.486] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:28.486]   - use_ai_classification=True
[02:02:28.486]   - ai_classifier=True
[02:02:28.486]   - txt_content_len=14239
[02:02:28.486]   - task_model=qwen2.5-72b-instruct
[02:02:28.486] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:28.486] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:28.499] 2025-08-20 02:02:28,498 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:28.499] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:28.499] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:28.499] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:28.499] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:28.499] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:28.499] 2025-08-20 02:02:28,499 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:28.523] 2025-08-20 02:02:28,523 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:28.523] 2025-08-20 02:02:28,523 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:28.523] 2025-08-20 02:02:28,523 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:28.526] [INFO] Tool embedding index loaded successfully
[02:02:28.527] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:28.527] [INFO] Operation semantic index initialized
[02:02:28.527] 
[02:02:28.527] [TURN 1/10]
[02:02:28.527] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:28.810] 2025-08-20 02:02:28,809 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:28.810] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"39cbeb47-bfcf-9585-9b29-c9d39562b0ab"}, traceId: 213e06bc17556805486327567e801e'}
[02:02:28.810] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:29.294] 2025-08-20 02:02:29,293 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:29.295] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"17d246d9-6cff-9053-b64f-debcfc27dd7d"}, traceId: 213e065917556805491824029e7f4b'}
[02:02:29.295] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:02:30.942] 2025-08-20 02:02:30,942 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:30.943] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8dbd0e1b-eda9-932c-95ca-983b0f60c663"}, traceId: 213e06bc17556805508347572e801e'}
[02:02:30.943] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:02:31.535] 2025-08-20 02:02:31,524 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:31.609]   [INFO] Tool info request: data_processing_validator
[02:02:31.609] 
[02:02:31.610] [TURN 3/10]
[02:02:31.627] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:31.639] 2025-08-20 02:02:31,639 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:31.646]   [SEARCH] Query: data validation parser
[02:02:31.646] 
[02:02:31.646] [TURN 2/10]
[02:02:31.689] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:31.985] 2025-08-20 02:02:31,985 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:31.986] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df5e922e-7750-9385-abff-2f682c422256"}, traceId: 213e043517556805518493440e2e12'}
[02:02:31.986] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:02:32.089] 2025-08-20 02:02:32,089 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:32.089] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"928f660c-c53a-9d3d-b7fe-68cfbfaf2dbb"}, traceId: 213e065917556805519094045e7f4b'}
[02:02:32.090] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:33.649] 2025-08-20 02:02:33,649 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:33.649] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"155cdb2f-e68a-9b39-bc18-812a1d8f8b8e"}, traceId: 213e065917556805535384047e7f4b'}
[02:02:33.649] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:33.990] 2025-08-20 02:02:33,989 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:33.990] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"60a959e0-59af-962f-b6b6-d32dcaf86995"}, traceId: 213e06bc17556805537497590e801e'}
[02:02:33.990] [RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[02:02:34.065] 2025-08-20 02:02:34,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:34.066]   [INFO] Tool info request: data_processing_parser
[02:02:34.066] 
[02:02:34.066] [TURN 4/10]
[02:02:34.072] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:35.175] 2025-08-20 02:02:35,175 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:35.177]   [EARLY_EXIT] No actions taken, continuing...
[02:02:35.177] 
[02:02:35.177] [TURN 5/10]
[02:02:35.177] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:36.025] 2025-08-20 02:02:36,025 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:36.026]   [INFO] Tool info request: data_processing_validator
[02:02:36.026] 
[02:02:36.026] [TURN 3/10]
[02:02:36.027] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:36.132] 2025-08-20 02:02:36,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:36.133]   [EARLY_EXIT] No actions taken, continuing...
[02:02:36.133] 
[02:02:36.133] [TURN 6/10]
[02:02:36.133] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:36.364] 2025-08-20 02:02:36,364 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:36.366] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4f543e2-83d2-9967-8f3e-8e4e926aff87"}, traceId: 213e065917556805561784055e7f4b'}
[02:02:36.366] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:02:36.469] 2025-08-20 02:02:36,469 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:36.470] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"097ca153-3c2f-997d-b471-ae680ea4b53c"}, traceId: 213e043517556805562823468e2e12'}
[02:02:36.470] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:02:37.692] 2025-08-20 02:02:37,692 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:37.692] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef8cbfa6-62a8-9419-af07-254d20ce1ca4"}, traceId: 213e043517556805574433490e2e12'}
[02:02:37.692] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:02:37.987] 2025-08-20 02:02:37,987 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:37.989]   [INFO] Tool info request: data_processing_parser
[02:02:37.989] 
[02:02:37.989] [TURN 4/10]
[02:02:37.990] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:38.715] 2025-08-20 02:02:38,715 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:38.717]   [EARLY_EXIT] No actions taken, continuing...
[02:02:38.717] 
[02:02:38.717] [TURN 5/10]
[02:02:38.718] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:38.851] 2025-08-20 02:02:38,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:38.852] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc94322b-82a9-98c1-93a1-9493104f8048"}, traceId: 213e06bc17556805586017644e801e'}
[02:02:38.852] [ERROR] Max retries reached after 5 attempts
[02:02:38.852] [API_FAILURE] All retries exhausted
[02:02:38.852]   [API_FAILURE] API failed (timeout or max retries)
[02:02:38.856] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:38.856] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:38.856] [AI_DEBUG] 生成的txt_content长度: 8612
[02:02:38.856] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:38.856]   - use_ai_classification=True
[02:02:38.856]   - ai_classifier=True
[02:02:38.856]   - txt_content_len=8612
[02:02:38.856]   - task_model=qwen2.5-72b-instruct
[02:02:38.856] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:38.857] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:38.866] 2025-08-20 02:02:38,866 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:38.866] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:38.866] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:38.866] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:38.866] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:38.866] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:38.866] 2025-08-20 02:02:38,866 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:38.900] 2025-08-20 02:02:38,900 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:38.900] 2025-08-20 02:02:38,900 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:38.900] 2025-08-20 02:02:38,900 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:38.903] [INFO] Tool embedding index loaded successfully
[02:02:38.904] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:38.904] [INFO] Operation semantic index initialized
[02:02:38.904] 
[02:02:38.904] [TURN 1/10]
[02:02:38.905] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:39.005] 2025-08-20 02:02:39,005 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:39.005] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4db96152-fa92-96f4-8d2a-d6a0148dd914"}, traceId: 213e043517556805587543508e2e12'}
[02:02:39.005] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:39.118] 2025-08-20 02:02:39,118 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:39.118] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d566ecf6-8283-9956-853a-ef993c9d77ad"}, traceId: 213e065917556805588694074e7f4b'}
[02:02:39.118] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:02:39.736] 2025-08-20 02:02:39,736 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:39.737] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aacb268e-76ee-91d0-98fa-a49cc05039be"}, traceId: 213e006a17556805595056769ee218'}
[02:02:39.737] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:02:40.118] 2025-08-20 02:02:40,118 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:40.120] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d6d99a2-fd71-9f74-9983-2f5c858e89ad"}, traceId: 213e065917556805599004081e7f4b'}
[02:02:40.120] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:40.874] 2025-08-20 02:02:40,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:40.877] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dc26471c-50b7-91f4-a26d-ba9c9f0aeb08"}, traceId: 213e006a17556805606856773ee218'}
[02:02:40.877] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:02:41.544] 2025-08-20 02:02:41,544 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:41.546] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef27424d-7726-9c3a-8602-b97bc38ac34a"}, traceId: 213e065917556805613644089e7f4b'}
[02:02:41.546] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:02:42.210] 2025-08-20 02:02:42,210 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:42.211]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:02:42.211] 
[02:02:42.211] [TURN 7/10]
[02:02:42.211] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:42.542] 2025-08-20 02:02:42,541 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:42.543] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f9015ba6-aab9-9729-9489-b6c6879a41e3"}, traceId: 213e006a17556805623426777ee218'}
[02:02:42.543] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:02:42.547] 2025-08-20 02:02:42,546 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:42.547] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ca5af16-29a1-90d4-811b-1ed1a61ef60f"}, traceId: 213e043517556805623603571e2e12'}
[02:02:42.547] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:43.482] 2025-08-20 02:02:43,481 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:43.482] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01c3cf07-3e6d-9132-9711-1d3c310040c5"}, traceId: 213e065917556805632864100e7f4b'}
[02:02:43.482] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:44.066] 2025-08-20 02:02:44,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:44.069] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"075c5f37-74e1-9308-8300-cde2e7dfdca0"}, traceId: 213e043517556805638253599e2e12'}
[02:02:44.069] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:44.541] 2025-08-20 02:02:44,541 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:44.542] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8fbd90e4-34f6-9d29-af03-ccb9f59cba20"}, traceId: 213e006a17556805643216791ee218'}
[02:02:44.542] [RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[02:02:45.618] 2025-08-20 02:02:45,617 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:45.620] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"75d7f4e3-a479-9729-8029-c7057a452886"}, traceId: 213e065917556805653904111e7f4b'}
[02:02:45.620] [ERROR] Max retries reached after 5 attempts
[02:02:45.620] [API_FAILURE] All retries exhausted
[02:02:45.621]   [API_FAILURE] API failed (timeout or max retries)
[02:02:45.623] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:45.623] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:45.623] [AI_DEBUG] 生成的txt_content长度: 10874
[02:02:45.623] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:45.623]   - use_ai_classification=True
[02:02:45.623]   - ai_classifier=True
[02:02:45.623]   - txt_content_len=10874
[02:02:45.623]   - task_model=qwen2.5-72b-instruct
[02:02:45.623] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:45.623] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:45.632] 2025-08-20 02:02:45,632 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:45.632] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:45.632] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:45.632] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:45.632] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:45.632] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:45.632] 2025-08-20 02:02:45,632 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:45.651] 2025-08-20 02:02:45,651 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:45.651] 2025-08-20 02:02:45,651 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:45.651] 2025-08-20 02:02:45,651 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:45.654] [INFO] Tool embedding index loaded successfully
[02:02:45.655] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:45.655] [INFO] Operation semantic index initialized
[02:02:45.655] 
[02:02:45.655] [TURN 1/10]
[02:02:45.656] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:45.720] 2025-08-20 02:02:45,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:45.720] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5fecb4e-ec49-98c9-be6e-033a1d6b62f7"}, traceId: 213e043517556805654763609e2e12'}
[02:02:45.720] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:02:46.498] 2025-08-20 02:02:46,497 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:46.502] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b8787b9-f794-9d72-8be8-dda3f1dc6933"}, traceId: 213e064717556805662746060e8939'}
[02:02:46.502] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:02:47.747] 2025-08-20 02:02:47,746 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:47.758] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7e087e1-f4c0-92b3-9c49-f712805735ee"}, traceId: 213e064717556805674646066e8939'}
[02:02:47.758] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:02:48.511] 2025-08-20 02:02:48,510 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:48.511] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dfeedd13-2057-9c4e-b609-849141295c29"}, traceId: 213e043517556805683293617e2e12'}
[02:02:48.511] [RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[02:02:49.206] 2025-08-20 02:02:49,206 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:49.235] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b436aa3-05ce-93bf-be33-cfb613a0f7a1"}, traceId: 213e006a17556805689636820ee218'}
[02:02:49.242] [ERROR] Max retries reached after 5 attempts
[02:02:49.242] [API_FAILURE] All retries exhausted
[02:02:49.242]   [API_FAILURE] API failed (timeout or max retries)
[02:02:49.274] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:49.274] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:49.274] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:49.274] [AI_DEBUG] 生成的txt_content长度: 4221
[02:02:49.274] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:49.274]   - use_ai_classification=True
[02:02:49.274]   - ai_classifier=True
[02:02:49.274]   - txt_content_len=4221
[02:02:49.274]   - task_model=qwen2.5-72b-instruct
[02:02:49.535] 2025-08-20 02:02:49,534 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:49.535] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:49.535] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:49.552] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:49.552] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:49.552] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:49.552] 2025-08-20 02:02:49,552 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:49.653] 2025-08-20 02:02:49,651 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:49.654] 2025-08-20 02:02:49,654 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:49.654] 2025-08-20 02:02:49,654 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:49.654] 2025-08-20 02:02:49,654 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:49.661] [INFO] Tool embedding index loaded successfully[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eafa5d3c-bb11-9de7-9eb0-2f2ebdb7aee0"}, traceId: 213e064717556805694016077e8939'}
[02:02:49.661] [RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[02:02:49.661] 
[02:02:49.675] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:49.687] [INFO] Operation semantic index initialized
[02:02:49.689] 
[02:02:49.689] [TURN 1/10]
[02:02:49.690] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:49.783] 2025-08-20 02:02:49,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:49.783] 2025-08-20 02:02:49,783 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:49.784] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:02:50.567] 2025-08-20 02:02:50,566 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:50.567] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8950240c-8fc6-9d62-adbc-fb720a317480"}, traceId: 213e065e17556805703216007e8058'}
[02:02:50.567] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:02:51.705] 2025-08-20 02:02:51,704 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:51.710] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06f39821-ac4a-98d6-adb1-1201fabeb076"}, traceId: 213e064717556805715096087e8939'}
[02:02:51.710] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:02:51.836] 2025-08-20 02:02:51,836 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:51.836] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"30401680-32b0-9d9b-8343-0e6957a0d0bc"}, traceId: 213e065e17556805716336013e8058'}
[02:02:51.836] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:53.720] 2025-08-20 02:02:53,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:53.721] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a890ccf0-93ea-97cd-88c0-75b3e11a2dc1"}, traceId: 213e043517556805734833639e2e12'}
[02:02:53.721] [ERROR] Max retries reached after 5 attempts
[02:02:53.721] [API_FAILURE] All retries exhausted
[02:02:53.721]   [API_FAILURE] API failed (timeout or max retries)
[02:02:53.721] [ASSISTED] Task received 1 format helps, final result: failure
[02:02:53.724] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:53.724] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:53.724] [AI_DEBUG] 生成的txt_content长度: 12043
[02:02:53.724] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:53.724]   - use_ai_classification=True
[02:02:53.724]   - ai_classifier=True
[02:02:53.724]   - txt_content_len=12043
[02:02:53.724]   - task_model=qwen2.5-72b-instruct
[02:02:53.724] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:53.724] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:53.737] 2025-08-20 02:02:53,737 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:53.737] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:53.737] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:53.739] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:53.739] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:53.739] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:53.739] 2025-08-20 02:02:53,739 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:53.776] 2025-08-20 02:02:53,776 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:53.776] 2025-08-20 02:02:53,776 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:53.777] 2025-08-20 02:02:53,776 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:53.779] [INFO] Tool embedding index loaded successfully
[02:02:53.780] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:53.780] [INFO] Operation semantic index initialized
[02:02:53.780] 
[02:02:53.780] [TURN 1/10]
[02:02:53.780] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:54.583] 2025-08-20 02:02:54,583 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:54.584] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44c228b2-2ec2-9a16-a858-5ac3ab448a1f"}, traceId: 213e06c817556805743576725e83e4'}
[02:02:54.584] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:02:54.612] 2025-08-20 02:02:54,612 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:54.616] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ae5f046f-fcad-9d1c-9760-3a497a1f89d2"}, traceId: 213e064717556805744326098e8939'}
[02:02:54.617] [ERROR] Max retries reached after 5 attempts
[02:02:54.617] [API_FAILURE] All retries exhausted
[02:02:54.617]   [API_FAILURE] API failed (timeout or max retries)
[02:02:54.617] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:54.618] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:54.618] [AI_DEBUG] 生成的txt_content长度: 4441
[02:02:54.618] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:54.618]   - use_ai_classification=True
[02:02:54.618]   - ai_classifier=True
[02:02:54.618]   - txt_content_len=4441
[02:02:54.618]   - task_model=qwen2.5-72b-instruct
[02:02:54.620] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:54.632] 2025-08-20 02:02:54,632 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:54.632] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:54.632] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:54.632] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:54.632] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:02:54.632] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:54.633] 2025-08-20 02:02:54,632 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:54.656] 2025-08-20 02:02:54,656 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:54.656] 2025-08-20 02:02:54,656 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:54.656] 2025-08-20 02:02:54,656 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:54.659] [INFO] Tool embedding index loaded successfully
[02:02:54.660] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:54.660] [INFO] Operation semantic index initialized
[02:02:54.660] 
[02:02:54.660] [TURN 1/10]
[02:02:54.660] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:54.735] 2025-08-20 02:02:54,735 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:54.736] 2025-08-20 02:02:54,735 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:54.736] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:02:54.803] 2025-08-20 02:02:54,803 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:54.804]   [SEARCH] Query: file reader
[02:02:54.805] 
[02:02:54.805] [TURN 2/10]
[02:02:54.805] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:55.547] 2025-08-20 02:02:55,547 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:55.548] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"530f7a69-9ebd-952c-906e-23fadc5cfb44"}, traceId: 213e058a17556805752897571e33ca'}
[02:02:55.548] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:02:55.698] 2025-08-20 02:02:55,698 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:55.698]   [EARLY_EXIT] No actions taken, continuing...
[02:02:55.698] 
[02:02:55.698] [TURN 3/10]
[02:02:55.699] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:55.816] 2025-08-20 02:02:55,816 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:55.817] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db7ead59-69a4-9fb2-8439-153482f178f3"}, traceId: 213e06c817556805755836730e83e4'}
[02:02:55.817] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:02:56.156] 2025-08-20 02:02:56,156 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:56.156] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f1338ce5-062a-9135-aa1d-7503e8fc42b4"}, traceId: 213e065e17556805758506032e8058'}
[02:02:56.157] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:56.590] 2025-08-20 02:02:56,590 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:56.594] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b6bb95a-8aad-9b7f-a2d5-d5abd247477d"}, traceId: 213e058a17556805763977575e33ca'}
[02:02:56.594] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:02:57.591] 2025-08-20 02:02:57,591 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:57.592] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2d4e4596-7070-90f8-aa5b-1bada1706a94"}, traceId: 213e06c817556805773576734e83e4'}
[02:02:57.592] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:02:57.782] 2025-08-20 02:02:57,781 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:57.782] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"042ab520-38b9-9afa-a20b-833224df2d90"}, traceId: 213e065e17556805775356041e8058'}
[02:02:57.782] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:58.494] 2025-08-20 02:02:58,494 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:58.498] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61f720f0-4b05-9efe-95cb-47190ce81bce"}, traceId: 213e058a17556805783077580e33ca'}
[02:02:58.499] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:03:00.769] 2025-08-20 02:03:00,769 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:00.770]   [EARLY_EXIT] No actions taken, continuing...
[02:03:00.770] 
[02:03:00.770] [TURN 4/10]
[02:03:00.771] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:00.879] 2025-08-20 02:03:00,879 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:00.886] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cca7981b-c700-97d9-8de1-46442571c68d"}, traceId: 213e058a17556805806467586e33ca'}
[02:03:00.886] [RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[02:03:01.012] 2025-08-20 02:03:01,011 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:01.018] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51e68a70-fe0a-9960-ae31-7d18c1082d1c"}, traceId: 213e06c817556805807706746e83e4'}
[02:03:01.018] [RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[02:03:01.179] 2025-08-20 02:03:01,178 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:01.179] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c847bd3d-c847-90d5-ba25-71e781e1d5af"}, traceId: 213e065e17556805809226059e8058'}
[02:03:01.179] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:03:02.869] 2025-08-20 02:03:02,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:02.870] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3e88d051-846b-9c87-85bf-ecf3cd5c2c68"}, traceId: 213e065e17556805825976066e8058'}
[02:03:02.870] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:04.617] 2025-08-20 02:03:04,617 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:04.618] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"018b8a84-d67b-9cf8-8d89-48d5122f8a33"}, traceId: 213e065e17556805844146069e8058'}
[02:03:04.619] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:03:05.805] 2025-08-20 02:03:05,805 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:05.809] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"756b1f19-9797-9a5e-a8dc-ea689d0ce9d4"}, traceId: 213e058a17556805855617608e33ca'}
[02:03:05.809] [ERROR] Max retries reached after 5 attempts
[02:03:05.809] [API_FAILURE] All retries exhausted
[02:03:05.809]   [API_FAILURE] API failed (timeout or max retries)
[02:03:05.811] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:05.812] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:05.812] [AI_DEBUG] 生成的txt_content长度: 4405
[02:03:05.812] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:05.812]   - use_ai_classification=True
[02:03:05.812]   - ai_classifier=True[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:05.812] 
[02:03:05.812]   - txt_content_len=4405
[02:03:05.813]   - task_model=qwen2.5-72b-instruct
[02:03:05.824] 2025-08-20 02:03:05,824 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:05.824] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:05.824] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:05.824] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:05.824] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:05.824] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:05.825] 2025-08-20 02:03:05,825 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:05.852] 2025-08-20 02:03:05,852 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:05.852] 2025-08-20 02:03:05,852 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:05.852] 2025-08-20 02:03:05,852 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:05.855] [INFO] Tool embedding index loaded successfully
[02:03:05.856] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:05.856] [INFO] Operation semantic index initialized
[02:03:05.856] 
[02:03:05.856] [TURN 1/10]
[02:03:05.857] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:05.930] 2025-08-20 02:03:05,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:05.931] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc4f6e57-11d2-90cd-91ea-c6cac7cf2cfb"}, traceId: 213e06c817556805856986762e83e4'}
[02:03:05.931] [ERROR] Max retries reached after 5 attempts
[02:03:05.931] [API_FAILURE] All retries exhausted
[02:03:05.931]   [API_FAILURE] API failed (timeout or max retries)
[02:03:05.931] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:05.939] 2025-08-20 02:03:05,939 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:05.939] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:05.939] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:05.939] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:05.940] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:05.940] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:05.940] 2025-08-20 02:03:05,940 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:05.960] 2025-08-20 02:03:05,960 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:05.960] 2025-08-20 02:03:05,960 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:05.960] 2025-08-20 02:03:05,960 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:05.962] [INFO] Tool embedding index loaded successfully
[02:03:05.964] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:05.964] [INFO] Operation semantic index initialized
[02:03:05.965] 
[02:03:05.965] [TURN 1/10]
[02:03:05.965] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:06.267] 2025-08-20 02:03:06,267 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:06.268] 2025-08-20 02:03:06,268 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:06.268] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:06.271] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:06.271] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:06.271] [AI_DEBUG] 生成的txt_content长度: 4546
[02:03:06.271] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:06.271]   - use_ai_classification=True
[02:03:06.271]   - ai_classifier=True
[02:03:06.271]   - txt_content_len=4546
[02:03:06.271]   - task_model=qwen2.5-72b-instruct
[02:03:06.480] 2025-08-20 02:03:06,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:06.480] 2025-08-20 02:03:06,480 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:06.480] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:06.483] Progress: 10/35 (Success: 0)
[02:03:06.705] 2025-08-20 02:03:06,705 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:06.706] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e297e1a9-c912-9636-87cf-126f55b215f1"}, traceId: 213e00cd17556805864753751e95ec'}
[02:03:06.706] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:06.851] 2025-08-20 02:03:06,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:06.851] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2e02753-7dc3-9fb5-8128-c0eb2989504c"}, traceId: 213e065e17556805865466078e8058'}
[02:03:06.851] [RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[02:03:06.964] 2025-08-20 02:03:06,964 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:06.965] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"646f2c89-ebf1-9b68-b27a-9cb98be65ece"}, traceId: 213e065a17556805866681098e8148'}
[02:03:06.965] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:07.891] 2025-08-20 02:03:07,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:07.891] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1781db35-3106-9761-b6b4-a2c145324187"}, traceId: 213e00cd17556805877163755e95ec'}
[02:03:07.891] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:03:08.436] 2025-08-20 02:03:08,435 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:08.438] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5ec72163-eb43-9b7c-9dff-e377df89531f"}, traceId: 213e065a17556805881901104e8148'}
[02:03:08.438] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:03:09.699] 2025-08-20 02:03:09,698 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:09.700] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"628206f4-3831-95f5-83ca-a51af37f1c13"}, traceId: 213e00cd17556805894993763e95ec'}
[02:03:09.700] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:03:10.987] 2025-08-20 02:03:10,984 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:11.000] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c7acd2d-d21b-9e20-a4d5-858ad5933221"}, traceId: 213e065a17556805907171126e8148'}
[02:03:11.002] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:11.845] 2025-08-20 02:03:11,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:11.855]   [EARLY_EXIT] No actions taken, continuing...
[02:03:11.855] 
[02:03:11.855] [TURN 5/10]
[02:03:11.859] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:12.818] 2025-08-20 02:03:12,818 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:12.819]   [EARLY_EXIT] No actions taken, continuing...
[02:03:12.819] 
[02:03:12.819] [TURN 6/10]
[02:03:12.820] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:12.956] 2025-08-20 02:03:12,956 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:12.959] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c27d52e2-9089-9f7a-a367-1e62bb4da710"}, traceId: 213e065a17556805927121134e8148'}
[02:03:12.959] [RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[02:03:13.034] 2025-08-20 02:03:13,034 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:13.035] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6ee5b3f-874f-9863-a3df-68a8802c7897"}, traceId: 213e00cd17556805928003773e95ec'}
[02:03:13.035] [RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[02:03:13.720] 2025-08-20 02:03:13,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:13.733]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:03:13.734] 
[02:03:13.734] [TURN 7/10]
[02:03:13.735] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:14.125] 2025-08-20 02:03:14,125 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:14.125] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"da6c2154-a498-9ef7-80ba-1dce5c93be6b"}, traceId: 213e065e17556805938866110e8058'}
[02:03:14.125] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:15.920] 2025-08-20 02:03:15,920 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:15.921] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e579ad3f-0fd4-9d31-87c8-f157979eaa2b"}, traceId: 213e065e17556805956666122e8058'}
[02:03:15.921] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:16.930] 2025-08-20 02:03:16,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:16.933] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e929d0d9-976f-9272-ae21-e26fb8cc3894"}, traceId: 213e065a17556805966931149e8148'}
[02:03:16.933] [ERROR] Max retries reached after 5 attempts
[02:03:16.933] [API_FAILURE] All retries exhausted
[02:03:16.933]   [API_FAILURE] API failed (timeout or max retries)
[02:03:16.935] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:16.935] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:16.935] [AI_DEBUG] 生成的txt_content长度: 4431
[02:03:16.936] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:16.936]   - use_ai_classification=True
[02:03:16.936]   - ai_classifier=True
[02:03:16.936]   - txt_content_len=4431
[02:03:16.936]   - task_model=qwen2.5-72b-instruct
[02:03:16.938] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:16.952] 2025-08-20 02:03:16,952 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:16.952] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:16.952] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:16.952] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:16.953] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:16.953] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:16.953] 2025-08-20 02:03:16,953 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:16.985] 2025-08-20 02:03:16,985 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:16.985] 2025-08-20 02:03:16,985 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:16.985] 2025-08-20 02:03:16,985 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:16.987] [INFO] Tool embedding index loaded successfully
[02:03:16.988] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:16.988] [INFO] Operation semantic index initialized
[02:03:16.989] 
[02:03:16.989] [TURN 1/10]
[02:03:16.989] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:17.182] 2025-08-20 02:03:17,182 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:17.184] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d5c3c57a-690b-93bc-bdb2-55962353ad2d"}, traceId: 213e065e17556805969356127e8058'}
[02:03:17.184] [RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[02:03:17.440] 2025-08-20 02:03:17,440 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:17.442] 2025-08-20 02:03:17,441 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:17.443] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:17.814] 2025-08-20 02:03:17,814 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:17.815] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b0e082a-47a7-960f-b034-c516cf670a29"}, traceId: 213e042b17556805975698069e1e24'}
[02:03:17.815] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:18.355] 2025-08-20 02:03:18,355 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:18.370] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8eb00a4d-4cdd-95f5-88b7-b143f609e8e5"}, traceId: 213e00cd17556805981763808e95ec'}
[02:03:18.372] [ERROR] Max retries reached after 5 attempts
[02:03:18.372] [API_FAILURE] All retries exhausted
[02:03:18.372]   [API_FAILURE] API failed (timeout or max retries)
[02:03:18.375] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:18.375] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:18.375] [AI_DEBUG] 生成的txt_content长度: 4415
[02:03:18.375] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:18.375]   - use_ai_classification=True
[02:03:18.375]   - ai_classifier=True
[02:03:18.375]   - txt_content_len=4415
[02:03:18.375]   - task_model=qwen2.5-72b-instruct
[02:03:18.377] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:18.391] 2025-08-20 02:03:18,391 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:18.391] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:18.391] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:18.392] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:18.392] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:18.392] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:18.392] 2025-08-20 02:03:18,392 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:18.419] 2025-08-20 02:03:18,419 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:18.419] 2025-08-20 02:03:18,419 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:18.419] 2025-08-20 02:03:18,419 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:18.421] [INFO] Tool embedding index loaded successfully
[02:03:18.422] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:18.422] [INFO] Operation semantic index initialized
[02:03:18.422] 
[02:03:18.422] [TURN 1/10]
[02:03:18.423] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:18.503] 2025-08-20 02:03:18,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:18.503] 2025-08-20 02:03:18,503 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:18.503] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:19.453] 2025-08-20 02:03:19,452 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:19.455] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"181777ea-71cf-9b46-b8ab-575d20a9da52"}, traceId: 213e06b617556805992595689e8148'}
[02:03:19.455] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:20.015] 2025-08-20 02:03:20,015 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:20.028]   [SEARCH] Query: file reader
[02:03:20.030] 
[02:03:20.030] [TURN 2/10]
[02:03:20.032] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:20.668] 2025-08-20 02:03:20,668 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:20.669] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f3ce249-b55e-962e-9634-3b4bf44ca737"}, traceId: 213e042b17556806001868085e1e24'}
[02:03:20.669] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:03:20.774] 2025-08-20 02:03:20,774 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:20.775] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"07cf1eff-93c3-9517-9939-6c7d781bf237"}, traceId: 213e065e17556806003896140e8058'}
[02:03:20.775] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:03:20.994] 2025-08-20 02:03:20,993 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:20.994] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20641e3e-fb4a-911d-88b2-d0ed8d7ed2e3"}, traceId: 213e06b617556806007245698e8148'}
[02:03:20.994] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:21.643] 2025-08-20 02:03:21,642 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:21.643] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"96136c5c-433c-9906-96ce-75493ed10b46"}, traceId: 213e042b17556806014108089e1e24'}
[02:03:21.643] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:03:22.483] 2025-08-20 02:03:22,479 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:22.484] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91a8a1e7-8d80-9622-88f5-a8e8100c3828"}, traceId: 213e06b617556806022745703e8148'}
[02:03:22.484] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:03:23.963] 2025-08-20 02:03:23,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:23.964] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"79c6fb6b-1d10-9c3d-ac70-adf7e5c9625c"}, traceId: 213e042b17556806037078097e1e24'}
[02:03:23.964] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:23.995] 2025-08-20 02:03:23,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:23.995] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"865f71be-ef77-99ed-b136-ddfe9edcbeb7"}, traceId: 213e065e17556806037536149e8058'}
[02:03:23.995] [ERROR] Max retries reached after 5 attempts
[02:03:23.995] [API_FAILURE] All retries exhausted
[02:03:23.995]   [API_FAILURE] API failed (timeout or max retries)
[02:03:23.996] [ASSISTED] Task received 1 format helps, final result: failure
[02:03:23.999] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:23.999] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:23.999] [AI_DEBUG] 生成的txt_content长度: 10271
[02:03:23.999] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:23.999]   - use_ai_classification=True
[02:03:23.999]   - ai_classifier=True
[02:03:23.999]   - txt_content_len=10271
[02:03:23.999]   - task_model=qwen2.5-72b-instruct
[02:03:23.999] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:24.000] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:24.011] 2025-08-20 02:03:24,010 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:24.011] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:24.011] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:24.011] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:24.011] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:24.011] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:24.011] 2025-08-20 02:03:24,011 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:24.038] 2025-08-20 02:03:24,038 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:24.038] 2025-08-20 02:03:24,038 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:24.038] 2025-08-20 02:03:24,038 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:24.041] [INFO] Tool embedding index loaded successfully
[02:03:24.042] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:24.042] [INFO] Operation semantic index initialized
[02:03:24.043] 
[02:03:24.043] [TURN 1/10]
[02:03:24.043] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:24.992] 2025-08-20 02:03:24,992 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:24.993] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8824624-3363-9e4f-956b-ad99f4ecf54a"}, traceId: 213e01f617556806047193401e139e'}
[02:03:24.993] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:25.591] 2025-08-20 02:03:25,591 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:25.591] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8cf4c7a-4d34-93ba-89e8-0bfae3c6019e"}, traceId: 213e06b617556806053465721e8148'}
[02:03:25.591] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:03:25.914] 2025-08-20 02:03:25,914 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:25.915] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73da42ec-ff57-97dc-90ce-73f24dc3feb2"}, traceId: 213e042b17556806056678101e1e24'}
[02:03:25.915] [RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[02:03:26.736] 2025-08-20 02:03:26,736 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:26.736] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efe4fd23-550c-9c59-8a62-fc19d39be884"}, traceId: 213e01f617556806065383423e139e'}
[02:03:26.736] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:03:28.601] 2025-08-20 02:03:28,601 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:28.603] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"17a7190d-09ec-9960-aaee-abac4c2c156a"}, traceId: 213e06b617556806083585727e8148'}
[02:03:28.603] [ERROR] Max retries reached after 5 attempts
[02:03:28.603] [API_FAILURE] All retries exhausted
[02:03:28.604]   [API_FAILURE] API failed (timeout or max retries)
[02:03:28.606] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:28.606] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:28.606] [AI_DEBUG] 生成的txt_content长度: 4790
[02:03:28.606] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:28.606]   - use_ai_classification=True
[02:03:28.606]   - ai_classifier=True
[02:03:28.606]   - txt_content_len=4790
[02:03:28.606]   - task_model=qwen2.5-72b-instruct
[02:03:28.611] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:28.624] 2025-08-20 02:03:28,624 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:28.625] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:28.625] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:28.625] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:28.625] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:28.625] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:28.626] 2025-08-20 02:03:28,626 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:28.684] 2025-08-20 02:03:28,684 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:28.684] 2025-08-20 02:03:28,684 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:28.684] 2025-08-20 02:03:28,684 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:28.687] [INFO] Tool embedding index loaded successfully
[02:03:28.688] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:28.688] [INFO] Operation semantic index initialized
[02:03:28.688] 
[02:03:28.688] [TURN 1/10]
[02:03:28.688] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:28.984] 2025-08-20 02:03:28,984 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:28.984] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70f866eb-a77f-990e-90e5-d32fc014a105"}, traceId: 213e01f617556806087323435e139e'}
[02:03:28.984] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:03:29.014] 2025-08-20 02:03:29,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:29.014] 2025-08-20 02:03:29,014 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:29.015] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:29.545] 2025-08-20 02:03:29,545 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:29.546] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1dabb86f-e9c7-9d7e-b6d7-beb166621f40"}, traceId: 213e006c17556806093038602e123d'}
[02:03:29.546] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:03:30.588] 2025-08-20 02:03:30,588 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:30.595] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9f29ff68-cbc6-9f2f-842f-568fd7d42769"}, traceId: 213e006c17556806103458612e123d'}
[02:03:30.595] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:30.912] 2025-08-20 02:03:30,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:30.912] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cd7a859e-c93b-9a9e-a0f9-b9ca3328da0b"}, traceId: 213e01f617556806106603450e139e'}
[02:03:30.912] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:03:31.185] 2025-08-20 02:03:31,185 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:31.187] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"faea5dcb-60f5-9566-a510-a5eccd58a960"}, traceId: 213e042b17556806109448112e1e24'}
[02:03:31.187] [ERROR] Max retries reached after 5 attempts
[02:03:31.187] [API_FAILURE] All retries exhausted
[02:03:31.187]   [API_FAILURE] API failed (timeout or max retries)
[02:03:31.188] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:31.189] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:31.189] [AI_DEBUG] 生成的txt_content长度: 8719
[02:03:31.189] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:31.189]   - use_ai_classification=True
[02:03:31.189]   - ai_classifier=True
[02:03:31.189]   - txt_content_len=8719
[02:03:31.189]   - task_model=qwen2.5-72b-instruct
[02:03:31.189] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:31.189] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:31.203] 2025-08-20 02:03:31,203 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:31.203] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:31.203] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:31.203] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:31.203] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:31.203] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:31.203] 2025-08-20 02:03:31,203 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:31.231] 2025-08-20 02:03:31,230 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:31.231] 2025-08-20 02:03:31,231 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:31.231] 2025-08-20 02:03:31,231 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:31.234] [INFO] Tool embedding index loaded successfully
[02:03:31.238] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:31.238] [INFO] Operation semantic index initialized
[02:03:31.239] 
[02:03:31.239] [TURN 1/10]
[02:03:31.239] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:31.998] 2025-08-20 02:03:31,998 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:32.003] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a5aad050-82f0-9d44-9c6d-0739e17442a3"}, traceId: 213e006c17556806116408617e123d'}
[02:03:32.003] [RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[02:03:32.044] 2025-08-20 02:03:32,044 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:32.044] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6ba3f846-7d13-91d8-9ad3-a0f326960087"}, traceId: 213e062917556806118526626e80c4'}
[02:03:32.044] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:33.451] 2025-08-20 02:03:33,451 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:33.452] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"447abdbc-9f00-99bf-8f16-7daaeda5253c"}, traceId: 213e062917556806132066629e80c4'}
[02:03:33.452] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:33.510] 2025-08-20 02:03:33,510 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:33.510] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c7e556c-c842-9c51-a294-4ba6b91b9b12"}, traceId: 213e01f617556806132633473e139e'}
[02:03:33.510] [ERROR] Max retries reached after 5 attempts
[02:03:33.510] [API_FAILURE] All retries exhausted
[02:03:33.510]   [API_FAILURE] API failed (timeout or max retries)
[02:03:33.511] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:33.511] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:33.511] [AI_DEBUG] 生成的txt_content长度: 4716
[02:03:33.511] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:33.511]   - use_ai_classification=True
[02:03:33.511]   - ai_classifier=True
[02:03:33.511]   - txt_content_len=4716
[02:03:33.511]   - task_model=qwen2.5-72b-instruct
[02:03:33.512] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:33.522] 2025-08-20 02:03:33,522 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:33.522] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:33.522] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:33.523] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:33.523] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:33.523] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:33.523] 2025-08-20 02:03:33,523 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:33.545] 2025-08-20 02:03:33,545 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:33.545] 2025-08-20 02:03:33,545 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:33.545] 2025-08-20 02:03:33,545 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:33.547] [INFO] Tool embedding index loaded successfully
[02:03:33.548] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:33.548] [INFO] Operation semantic index initialized
[02:03:33.548] 
[02:03:33.548] [TURN 1/10]
[02:03:33.548] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:33.661] 2025-08-20 02:03:33,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:33.661] 2025-08-20 02:03:33,661 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:33.661] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:34.920] 2025-08-20 02:03:34,919 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:34.920] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18021d06-ce7c-9c80-b7d2-fa3869524000"}, traceId: 213e062917556806146816636e80c4'}
[02:03:34.920] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:34.962] 2025-08-20 02:03:34,961 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:34.964]   [SEARCH] Query: file reader json
[02:03:34.965] 
[02:03:34.965] [TURN 2/10]
[02:03:34.965] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:35.314] 2025-08-20 02:03:35,314 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:35.315] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"252f7f4b-c2cc-95cc-a6b7-4f7d6b0de77d"}, traceId: 213e063817556806151127540e82eb'}
[02:03:35.315] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:35.704] 2025-08-20 02:03:35,704 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:35.704] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2addc47-2eef-9f6f-8fb6-6a2ec6dd1459"}, traceId: 213e006c17556806154528642e123d'}
[02:03:35.705] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:03:36.630] 2025-08-20 02:03:36,630 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:36.630] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e955d95-1c9a-99d6-b0f3-3e525b0d3ceb"}, traceId: 213e063817556806164527550e82eb'}
[02:03:36.630] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:03:36.716] 2025-08-20 02:03:36,716 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:36.717] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce750cd3-ed96-9915-b46c-6bdce5dc4d9a"}, traceId: 213e062917556806164326643e80c4'}
[02:03:36.717] [RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[02:03:37.805] 2025-08-20 02:03:37,804 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:37.806] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63b63f45-36ba-92e6-b101-92aef0718c6d"}, traceId: 213e063817556806175637558e82eb'}
[02:03:37.806] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:03:39.097] 2025-08-20 02:03:39,097 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:39.098]   [SEARCH] Query: file reader
[02:03:39.098] 
[02:03:39.098] [TURN 2/10]
[02:03:39.100] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:39.499] 2025-08-20 02:03:39,499 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:39.503] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77e7912b-2156-9320-aa8f-1eab8f3bc5d9"}, traceId: 213e006c17556806192488664e123d'}
[02:03:39.503] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:03:40.038] 2025-08-20 02:03:40,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:40.038] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"74a69a8e-1c3b-9c91-96b6-1995d910874c"}, traceId: 213e063817556806197707566e82eb'}
[02:03:40.039] [RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[02:03:40.642] 2025-08-20 02:03:40,642 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:40.643] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b884fe0f-d53e-9bb8-9e1b-f4d9849c4c7f"}, traceId: 213e062917556806204206650e80c4'}
[02:03:40.643] [ERROR] Max retries reached after 5 attempts
[02:03:40.643] [API_FAILURE] All retries exhausted
[02:03:40.643]   [API_FAILURE] API failed (timeout or max retries)
[02:03:40.645] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:40.645] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:40.645] [AI_DEBUG] 生成的txt_content长度: 4647
[02:03:40.645] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:40.645]   - use_ai_classification=True
[02:03:40.645]   - ai_classifier=True
[02:03:40.645] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:40.645]   - txt_content_len=4647
[02:03:40.645]   - task_model=qwen2.5-72b-instruct
[02:03:40.655] 2025-08-20 02:03:40,655 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:40.655] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:40.655] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:40.656] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:40.656] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:40.656] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:40.656] 2025-08-20 02:03:40,656 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:40.680] 2025-08-20 02:03:40,680 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:40.680] 2025-08-20 02:03:40,680 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:40.680] 2025-08-20 02:03:40,680 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:40.683] [INFO] Tool embedding index loaded successfully
[02:03:40.685] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:40.685] [INFO] Operation semantic index initialized
[02:03:40.685] 
[02:03:40.685] [TURN 1/10]
[02:03:40.685] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:40.720] 2025-08-20 02:03:40,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:40.720] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9032269d-a2f6-9fd9-b124-789d167356b7"}, traceId: 213e006c17556806204658669e123d'}
[02:03:40.720] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:03:41.022] 2025-08-20 02:03:41,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:41.023] 2025-08-20 02:03:41,023 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:41.023] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:41.513] 2025-08-20 02:03:41,512 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:41.513] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3459e5f1-39ec-9523-b6ea-e47374098986"}, traceId: 213e066c17556806212738793e7a35'}
[02:03:41.513] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:03:43.099] 2025-08-20 02:03:43,099 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:43.099] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c9883f5f-f125-9f18-911d-0ae5639e5dfa"}, traceId: 213e066c17556806228698797e7a35'}
[02:03:43.099] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:43.585] 2025-08-20 02:03:43,585 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:43.587] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"959778d3-fc15-9acc-bbce-ba4b49ceaacd"}, traceId: 213e063817556806232997579e82eb'}
[02:03:43.587] [ERROR] Max retries reached after 5 attempts
[02:03:43.588] [API_FAILURE] All retries exhausted
[02:03:43.588]   [API_FAILURE] API failed (timeout or max retries)
[02:03:43.588] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:43.588] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:43.589] [AI_DEBUG] 生成的txt_content长度: 8693
[02:03:43.589] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:43.589]   - use_ai_classification=True
[02:03:43.589]   - ai_classifier=True
[02:03:43.589]   - txt_content_len=8693
[02:03:43.589]   - task_model=qwen2.5-72b-instruct
[02:03:43.589] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:43.589] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:43.596] 2025-08-20 02:03:43,596 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:43.596] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:43.596] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:43.597] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:43.597] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:43.597] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:43.597] 2025-08-20 02:03:43,597 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:43.618] 2025-08-20 02:03:43,618 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:43.618] 2025-08-20 02:03:43,618 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:43.618] 2025-08-20 02:03:43,618 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:43.620] [INFO] Tool embedding index loaded successfully
[02:03:43.622] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:43.622] [INFO] Operation semantic index initialized
[02:03:43.622] 
[02:03:43.622] [TURN 1/10]
[02:03:43.622] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:43.760] 2025-08-20 02:03:43,759 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:43.760]   [EARLY_EXIT] No actions taken, continuing...
[02:03:43.760] 
[02:03:43.760] [TURN 3/10]
[02:03:43.761] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:44.152] 2025-08-20 02:03:44,152 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:44.156] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59ac734b-92de-91ba-8427-eac201c1c866"}, traceId: 213e006c17556806239138699e123d'}
[02:03:44.157] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:03:44.477] 2025-08-20 02:03:44,477 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:44.477] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc15dcfc-0158-9783-9609-f3bd1aebd919"}, traceId: 213e007e17556806242163730eee6b'}
[02:03:44.477] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:03:45.096] 2025-08-20 02:03:45,096 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:45.097] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a19dd46c-2b15-9766-8806-14203cbc48d0"}, traceId: 213e066c17556806248538802e7a35'}
[02:03:45.097] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:46.050] 2025-08-20 02:03:46,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:46.052] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6055c2a-5ef2-9f07-b6e5-7175fbb92a92"}, traceId: 213e006c17556806257818708e123d'}
[02:03:46.052] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:46.140] 2025-08-20 02:03:46,139 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:46.142] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ec7c4ac6-7aad-9487-8436-13ce72a69e33"}, traceId: 213e007e17556806259043736eee6b'}
[02:03:46.142] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:03:47.077] 2025-08-20 02:03:47,077 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:47.078] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a06ed08c-7fc7-9802-bf58-c302de55fcb9"}, traceId: 213e066c17556806268098809e7a35'}
[02:03:47.078] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:03:48.056] 2025-08-20 02:03:48,056 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:48.060] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1dba0d57-186f-93c1-ae9b-7187b457e8f2"}, traceId: 213e006c17556806278198719e123d'}
[02:03:48.060] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:03:48.531] 2025-08-20 02:03:48,531 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:48.534] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1257a287-734f-9f43-bb4a-58a8b17e6f2a"}, traceId: 213e007e17556806283503746eee6b'}
[02:03:48.534] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:03:50.268] 2025-08-20 02:03:50,267 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:50.269] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6125693-e6ec-9d5d-a586-cd83af2c5670"}, traceId: 213e007e17556806298433752eee6b'}
[02:03:50.269] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[02:03:50.689] 2025-08-20 02:03:50,689 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:50.690]   [SEARCH] Query: file reader
[02:03:50.691] 
[02:03:50.691] [TURN 2/10]
[02:03:50.692] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:51.101] 2025-08-20 02:03:51,101 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:51.130] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e46e421f-7542-9a94-afdd-72241bef5f35"}, traceId: 213e006c17556806307838735e123d'}
[02:03:51.130] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:03:51.204] 2025-08-20 02:03:51,203 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:51.205] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a882279-92dc-9519-baf1-549bbaed3be6"}, traceId: 213e066c17556806308368819e7a35'}
[02:03:51.208] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:53.220] 2025-08-20 02:03:53,220 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:53.222]   [EARLY_EXIT] No actions taken, continuing...
[02:03:53.222] 
[02:03:53.222] [TURN 3/10]
[02:03:53.222] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:53.539] 2025-08-20 02:03:53,539 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:53.540] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"71d768da-5fed-94ba-878c-f9169fafc873"}, traceId: 213e007e17556806332833768eee6b'}
[02:03:53.540] [ERROR] Max retries reached after 5 attempts
[02:03:53.540] [API_FAILURE] All retries exhausted
[02:03:53.540]   [API_FAILURE] API failed (timeout or max retries)
[02:03:53.546] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:53.546] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:53.546] [AI_DEBUG] 生成的txt_content长度: 4658
[02:03:53.546] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:53.546]   - use_ai_classification=True
[02:03:53.546]   - ai_classifier=True
[02:03:53.546]   - txt_content_len=4658
[02:03:53.546]   - task_model=qwen2.5-72b-instruct
[02:03:53.549] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:53.575] 2025-08-20 02:03:53,575 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:53.575] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:53.575] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:53.578] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:53.578] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:03:53.578] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:53.578] 2025-08-20 02:03:53,578 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:53.604] 2025-08-20 02:03:53,604 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:53.604] 2025-08-20 02:03:53,604 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:53.604] 2025-08-20 02:03:53,604 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:53.606] [INFO] Tool embedding index loaded successfully
[02:03:53.608] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:53.609] [INFO] Operation semantic index initialized
[02:03:53.609] 
[02:03:53.609] [TURN 1/10]
[02:03:53.610] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:53.711] 2025-08-20 02:03:53,711 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:53.712] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"15070ea4-4bd6-9532-ba08-c5e7687d0fc4"}, traceId: 213e066c17556806333698830e7a35'}
[02:03:53.712] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:03:54.136] 2025-08-20 02:03:54,136 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:54.136] 2025-08-20 02:03:54,136 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:54.136] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:54.716] 2025-08-20 02:03:54,716 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:54.721]   [EARLY_EXIT] No actions taken, continuing...
[02:03:54.721] 
[02:03:54.721] [TURN 4/10]
[02:03:54.721] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:54.976] 2025-08-20 02:03:54,976 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:54.978]   [SEARCH] Query: network api fetch
[02:03:54.978] 
[02:03:54.978] [TURN 2/10]
[02:03:54.979] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:55.175] 2025-08-20 02:03:55,175 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:55.179] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e8a3ecb-3934-97c8-a177-a1ab0fe59aef"}, traceId: 213e006c17556806348728754e123d'}
[02:03:55.179] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:03:55.384] 2025-08-20 02:03:55,384 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:55.384] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"11bc4ad4-3b23-9220-b673-073c325091dc"}, traceId: 213e060a17556806351304069e88ee'}
[02:03:55.384] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:03:55.605] 2025-08-20 02:03:55,605 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:55.618] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9566f403-b077-9219-97e2-781c41553e5b"}, traceId: 213e066c17556806353318836e7a35'}
[02:03:55.618] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:03:56.878] 2025-08-20 02:03:56,877 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:56.882]   [EARLY_EXIT] No actions taken, continuing...
[02:03:56.882] 
[02:03:56.882] [TURN 5/10]
[02:03:56.884] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:57.079] 2025-08-20 02:03:57,079 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:57.080] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bb19edf2-80cd-900b-a5e4-8b739c8594f5"}, traceId: 213e060a17556806367884072e88ee'}
[02:03:57.080] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:57.470] 2025-08-20 02:03:57,470 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:57.480] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5c5087b5-ef79-911a-bd08-27f6599bc501"}, traceId: 213e066c17556806372248844e7a35'}
[02:03:57.480] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:03:57.819] 2025-08-20 02:03:57,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:57.824]   [EARLY_EXIT] No actions taken, continuing...
[02:03:57.824] 
[02:03:57.824] [TURN 6/10]
[02:03:57.825] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:58.697] 2025-08-20 02:03:58,696 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:58.702]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:03:58.702] 
[02:03:58.702] [TURN 7/10]
[02:03:58.703] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:58.906] 2025-08-20 02:03:58,906 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:58.909] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73345194-c0aa-95c7-b567-05aceff9e555"}, traceId: 213e060a17556806386664078e88ee'}
[02:03:58.910] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:03:59.050] 2025-08-20 02:03:59,050 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:59.053] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ddb9c59-2904-9846-9563-374de0425d0e"}, traceId: 213e006c17556806388518776e123d'}
[02:03:59.054] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:04:00.011] 2025-08-20 02:04:00,011 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:00.038] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ec7cd9b1-9d95-9b96-ab03-17c7ae7e27cc"}, traceId: 213e066c17556806397598845e7a35'}
[02:04:00.038] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[02:04:00.907] 2025-08-20 02:04:00,907 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:00.920]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:04:00.920] 
[02:04:00.920] [TURN 8/10]
[02:04:00.921] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:01.345] 2025-08-20 02:04:01,345 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:01.346] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"97a6e08e-6a22-982a-a755-13ee5d6183ee"}, traceId: 213e060a17556806411054085e88ee'}
[02:04:01.346] [RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[02:04:02.084] 2025-08-20 02:04:02,083 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:02.089]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:04:02.089] 
[02:04:02.089] [TURN 9/10]
[02:04:02.090] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:02.484] 2025-08-20 02:04:02,483 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:02.487] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3b82640-8ef5-932e-af8c-ef8d4d84c1e7"}, traceId: 213e006c17556806422388796e123d'}
[02:04:02.487] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:04:04.001] 2025-08-20 02:04:04,000 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:04.003]   [EARLY_EXIT] No actions taken, continuing...
[02:04:04.003] 
[02:04:04.003] [TURN 4/10]
[02:04:04.004] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:04.338] 2025-08-20 02:04:04,338 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:04.343] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"31b07c68-f667-97d2-871a-4de438ee47f4"}, traceId: 213e006c17556806441258807e123d'}
[02:04:04.343] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:04:04.393] 2025-08-20 02:04:04,392 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:04.412] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4ea51104-33cf-96e2-bf25-310bda98447c"}, traceId: 213e066c17556806441528858e7a35'}
[02:04:04.412] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:04:06.242] 2025-08-20 02:04:06,242 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:06.243] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe7d9438-a403-9537-a239-6c093d2dec2d"}, traceId: 213e060a17556806460204103e88ee'}
[02:04:06.243] [ERROR] Max retries reached after 5 attempts
[02:04:06.243] [API_FAILURE] All retries exhausted
[02:04:06.243]   [API_FAILURE] API failed (timeout or max retries)
[02:04:06.246] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:06.246] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:06.246] [AI_DEBUG] 生成的txt_content长度: 8899
[02:04:06.246] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:06.246]   - use_ai_classification=True
[02:04:06.246]   - ai_classifier=True
[02:04:06.246]   - txt_content_len=8899
[02:04:06.246]   - task_model=qwen2.5-72b-instruct
[02:04:06.246] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:06.247] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:06.249] Progress: 20/35 (Success: 0)
[02:04:06.259] 2025-08-20 02:04:06,259 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:06.260] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:06.260] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:06.260] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:06.260] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:06.260] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:06.260] 2025-08-20 02:04:06,260 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:06.265] 2025-08-20 02:04:06,264 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:06.274] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b219129d-f4f9-9cc4-8776-cda3f0486d08"}, traceId: 213e066c17556806460118866e7a35'}
[02:04:06.274] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:04:06.291] 2025-08-20 02:04:06,290 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:06.291] 2025-08-20 02:04:06,291 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:06.291] 2025-08-20 02:04:06,291 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:06.293] [INFO] Tool embedding index loaded successfully
[02:04:06.294] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:06.294] [INFO] Operation semantic index initialized
[02:04:06.295] 
[02:04:06.295] [TURN 1/10]
[02:04:06.295] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:06.858] 2025-08-20 02:04:06,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:06.858] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"14cafbd7-e06f-9d70-b170-278909f2ea70"}, traceId: 213e006c17556806465938818e123d'}
[02:04:06.858] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:07.096] 2025-08-20 02:04:07,096 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:07.100] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"96236d9e-6f81-9776-b3fb-98690fc97765"}, traceId: 213e043a17556806468785896e1ebf'}
[02:04:07.101] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:08.165] 2025-08-20 02:04:08,165 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:08.176]   [EARLY_EXIT] No actions taken, continuing...
[02:04:08.176] 
[02:04:08.176] [TURN 5/10]
[02:04:08.176] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:08.597] 2025-08-20 02:04:08,595 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:08.606] 2025-08-20 02:04:08,606 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:08.607] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bb5df88e-6d05-92f4-a5f4-32174ea6a184"}, traceId: 213e066c17556806483218874e7a35'}
[02:04:08.607] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:08.607] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9bc4185-3b27-9f5b-ba02-9af72f30aafe"}, traceId: 213e043a17556806483395905e1ebf'}
[02:04:08.607] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:08.663] 2025-08-20 02:04:08,663 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:08.663] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d32d957-b882-9efc-9d14-4a7424bf9a61"}, traceId: 213e006c17556806484438827e123d'}
[02:04:08.664] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:04:10.382] 2025-08-20 02:04:10,382 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:10.388] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"252db22b-06b9-973c-a1b3-ca527c090058"}, traceId: 213e066c17556806501338879e7a35'}
[02:04:10.388] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:11.718] 2025-08-20 02:04:11,718 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:11.723]   [SEARCH] Query: network api fetch
[02:04:11.723] 
[02:04:11.723] [TURN 2/10]
[02:04:11.724] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:12.113] 2025-08-20 02:04:12,102 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:12.132] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff33b18e-0fbb-9989-b7c4-8dde7218af6b"}, traceId: 213e043a17556806518685919e1ebf'}
[02:04:12.132] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:04:12.926] 2025-08-20 02:04:12,926 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:12.926]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[02:04:12.926] 
[02:04:12.926] [TURN 10/10]
[02:04:12.927] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:12.982] 2025-08-20 02:04:12,982 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:12.992] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d71b2e36-98da-97d1-ab0a-fe8219c31a63"}, traceId: 213e066c17556806527118891e7a35'}
[02:04:12.992] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:04:13.049] 2025-08-20 02:04:13,049 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:13.054] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b8d4196-d83d-97d7-ad29-fba097fceddd"}, traceId: 213e043a17556806528225925e1ebf'}
[02:04:13.054] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:04:13.869] 2025-08-20 02:04:13,867 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:13.872]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[02:04:13.873] [ASSISTED] Task received 5 format helps, final result: failure
[02:04:13.876] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:13.876] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:13.876] [AI_DEBUG] 生成的txt_content长度: 14945
[02:04:13.876] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:13.876]   - use_ai_classification=True
[02:04:13.876]   - ai_classifier=True
[02:04:13.876]   - txt_content_len=14945
[02:04:13.876]   - task_model=qwen2.5-72b-instruct
[02:04:13.876] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:13.876] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:13.887] 2025-08-20 02:04:13,887 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:13.887] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:13.887] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:13.888] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:13.888] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:13.888] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:13.888] 2025-08-20 02:04:13,888 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:13.915] 2025-08-20 02:04:13,915 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:13.915] 2025-08-20 02:04:13,915 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:13.915] 2025-08-20 02:04:13,915 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:13.918] [INFO] Tool embedding index loaded successfully
[02:04:13.919] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:13.919] [INFO] Operation semantic index initialized
[02:04:13.919] 
[02:04:13.919] [TURN 1/10]
[02:04:13.920] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:14.712] 2025-08-20 02:04:14,711 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:14.713] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"58172bb7-42dc-96d8-8848-b2dcd2406fa8"}, traceId: 213e006c17556806544571589e11da'}
[02:04:14.713] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:04:15.517] 2025-08-20 02:04:15,517 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:15.518] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6aaf9d44-367f-9926-871c-02a1f2c930f9"}, traceId: 213e043a17556806552755934e1ebf'}
[02:04:15.518] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:04:15.959] 2025-08-20 02:04:15,959 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:15.964] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"12ab29f8-c875-9d18-a8b4-1636227762ed"}, traceId: 213e006c17556806557421595e11da'}
[02:04:15.964] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:04:16.152] 2025-08-20 02:04:16,152 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:16.163] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7805b66f-da47-9151-9bf3-9663abeff7a0"}, traceId: 213e066c17556806559128904e7a35'}
[02:04:16.163] [RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[02:04:17.802] 2025-08-20 02:04:17,799 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:17.803] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db70f5c1-4260-9f0c-ae80-d8126315c3b7"}, traceId: 213e006c17556806575621599e11da'}
[02:04:17.803] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:18.917] 2025-08-20 02:04:18,916 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:18.919] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bcccf7c4-f72c-9d71-a25c-ba0faf2f71fe"}, traceId: 213e043a17556806586765942e1ebf'}
[02:04:18.919] [RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[02:04:19.658] 2025-08-20 02:04:19,657 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:19.659] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"07b020d1-8fe0-994b-af47-00aada1f2328"}, traceId: 213e006c17556806593841605e11da'}
[02:04:19.659] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:04:21.411] 2025-08-20 02:04:21,411 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:21.416] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"605aaa87-2d02-904b-9650-b1953db18004"}, traceId: 213e066c17556806611728917e7a35'}
[02:04:21.417] [ERROR] Max retries reached after 5 attempts
[02:04:21.417] [API_FAILURE] All retries exhausted
[02:04:21.417]   [API_FAILURE] API failed (timeout or max retries)
[02:04:21.418] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:21.418] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:21.418] [AI_DEBUG] 生成的txt_content长度: 9133
[02:04:21.418] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:21.418]   - use_ai_classification=True
[02:04:21.418]   - ai_classifier=True
[02:04:21.418]   - txt_content_len=9133
[02:04:21.418]   - task_model=qwen2.5-72b-instruct
[02:04:21.418] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:21.418] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:21.427] 2025-08-20 02:04:21,427 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:21.427] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:21.427] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:21.436] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:21.436] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:21.436] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:21.437] 2025-08-20 02:04:21,436 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:21.457] 2025-08-20 02:04:21,457 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:21.457] 2025-08-20 02:04:21,457 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:21.457] 2025-08-20 02:04:21,457 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:21.459] [INFO] Tool embedding index loaded successfully
[02:04:21.460] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:21.460] [INFO] Operation semantic index initialized
[02:04:21.460] 
[02:04:21.460] [TURN 1/10]
[02:04:21.461] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:22.698] 2025-08-20 02:04:22,698 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:22.702] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a29d08be-da68-97c7-a4f8-4f441bcdcafa"}, traceId: 213e006c17556806624761613e11da'}
[02:04:22.702] [ERROR] Max retries reached after 5 attempts
[02:04:22.702] [API_FAILURE] All retries exhausted
[02:04:22.702]   [API_FAILURE] API failed (timeout or max retries)
[02:04:22.703] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:22.703] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:22.703] [AI_DEBUG] 生成的txt_content长度: 4187
[02:04:22.703] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:22.703]   - use_ai_classification=True
[02:04:22.703]   - ai_classifier=True
[02:04:22.703]   - txt_content_len=4187
[02:04:22.703]   - task_model=qwen2.5-72b-instruct
[02:04:22.704] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:22.711] 2025-08-20 02:04:22,711 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:22.711] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:22.711] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:22.711] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:22.711] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:22.711] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:22.711] 2025-08-20 02:04:22,711 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:22.730] 2025-08-20 02:04:22,730 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:22.730] 2025-08-20 02:04:22,730 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:22.730] 2025-08-20 02:04:22,730 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:22.733] [INFO] Tool embedding index loaded successfully
[02:04:22.733] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:22.733] [INFO] Operation semantic index initialized
[02:04:22.733] 
[02:04:22.733] [TURN 1/10]
[02:04:22.734] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:22.736] 2025-08-20 02:04:22,736 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:22.741] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01122586-43d4-9563-aa89-75139caf29ec"}, traceId: 213e043a17556806624995960e1ebf'}
[02:04:22.741] [ERROR] Max retries reached after 5 attempts
[02:04:22.741] [API_FAILURE] All retries exhausted
[02:04:22.741]   [API_FAILURE] API failed (timeout or max retries)
[02:04:22.741] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:22.748] 2025-08-20 02:04:22,748 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:22.748] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:22.748] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:22.748] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:22.748] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:22.748] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:22.748] 2025-08-20 02:04:22,748 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:22.766] 2025-08-20 02:04:22,766 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:22.766] 2025-08-20 02:04:22,766 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:22.766] 2025-08-20 02:04:22,766 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:22.768] [INFO] Tool embedding index loaded successfully
[02:04:22.769] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:22.769] [INFO] Operation semantic index initialized
[02:04:22.769] 
[02:04:22.769] [TURN 1/10]
[02:04:22.770] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:22.782] 2025-08-20 02:04:22,782 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:22.786]   [SEARCH] Query: network api fetch
[02:04:22.787] 
[02:04:22.787] [TURN 2/10]
[02:04:22.787] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:23.089] 2025-08-20 02:04:23,089 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:23.089] 2025-08-20 02:04:23,089 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:23.089] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:23.091] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:23.091] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:23.091] [AI_DEBUG] 生成的txt_content长度: 8899
[02:04:23.091] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:23.091]   - use_ai_classification=True
[02:04:23.091]   - ai_classifier=True
[02:04:23.091]   - txt_content_len=8899
[02:04:23.091]   - task_model=qwen2.5-72b-instruct
[02:04:23.091] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:23.195] 2025-08-20 02:04:23,195 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:23.196] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c715b00-3793-9f93-a1b9-5b2d8201ddcc"}, traceId: 213e007b17556806629281258eedd5'}
[02:04:23.196] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:23.520] 2025-08-20 02:04:23,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:23.521] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9aa171e8-8367-9bbe-a47d-b120f10941b9"}, traceId: 213e042f17556806632878970e265f'}
[02:04:23.521] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:24.153] 2025-08-20 02:04:24,153 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:24.155]   [SEARCH] Query: network api fetch
[02:04:24.155] 
[02:04:24.155] [TURN 2/10]
[02:04:24.158] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:24.537] 2025-08-20 02:04:24,537 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:24.538] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e3b6f8a8-ebc0-9427-995b-600222f4b924"}, traceId: 213e060a17556806642924931e8995'}
[02:04:24.538] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:24.779] 2025-08-20 02:04:24,779 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:24.783] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8fb4aa1-72da-9354-b23a-9e55f94bf410"}, traceId: 213e007b17556806645511262eedd5'}
[02:04:24.783] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:04:25.266] 2025-08-20 02:04:25,266 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:25.267] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2343fae6-ba61-93e9-ac62-3193cb0ad4cc"}, traceId: 213e042f17556806650438975e265f'}
[02:04:25.267] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:26.184] 2025-08-20 02:04:26,183 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:26.185] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b3ef4412-a3d7-91f1-861b-ca509e0d3dc4"}, traceId: 213e007b17556806659461266eedd5'}
[02:04:26.185] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:04:26.200] 2025-08-20 02:04:26,200 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:26.201] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b63f5831-f367-9d7e-9387-fb7cd7374b8d"}, traceId: 213e060a17556806659374937e8995'}
[02:04:26.201] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:26.954] 2025-08-20 02:04:26,954 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:26.954] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cd55e0af-7681-90e1-b953-80d78ca747a1"}, traceId: 213e042f17556806667368982e265f'}
[02:04:26.955] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:04:27.977] 2025-08-20 02:04:27,977 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:27.979]   [EARLY_EXIT] No actions taken, continuing...
[02:04:27.979] 
[02:04:27.979] [TURN 3/10]
[02:04:27.979] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:28.811] 2025-08-20 02:04:28,809 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:28.814] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eda153ac-cb4e-95ef-a9c5-462e32e9ed62"}, traceId: 213e042f17556806685818988e265f'}
[02:04:28.815] [RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[02:04:28.918] 2025-08-20 02:04:28,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:28.943] 2025-08-20 02:04:28,943 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:28.944] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"45480edc-313b-98d9-8b3c-c819a69b054c"}, traceId: 213e007b17556806686591270eedd5'}
[02:04:28.944] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:04:28.945]   [EARLY_EXIT] No actions taken, continuing...
[02:04:28.945] 
[02:04:28.945] [TURN 4/10]
[02:04:28.946] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:29.954] 2025-08-20 02:04:29,954 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:29.955]   [EARLY_EXIT] No actions taken, continuing...
[02:04:29.955] 
[02:04:29.955] [TURN 5/10]
[02:04:29.956] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:30.325] 2025-08-20 02:04:30,324 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:30.325] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ade75a1-9a61-96f9-965e-168d781ac2f5"}, traceId: 213e060a17556806700894953e8995'}
[02:04:30.326] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:04:31.648] 2025-08-20 02:04:31,647 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:31.649] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d686f406-27fd-98de-9221-14f6dff80e2e"}, traceId: 213e007b17556806713811279eedd5'}
[02:04:31.649] [ERROR] Max retries reached after 5 attempts
[02:04:31.649] [API_FAILURE] All retries exhausted
[02:04:31.649]   [API_FAILURE] API failed (timeout or max retries)
[02:04:31.652] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.652] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:31.652] [AI_DEBUG] 生成的txt_content长度: 8955
[02:04:31.652] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.652]   - use_ai_classification=True
[02:04:31.652]   - ai_classifier=True
[02:04:31.652]   - txt_content_len=8955
[02:04:31.652]   - task_model=qwen2.5-72b-instruct
[02:04:31.652] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:31.653] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:31.687] 2025-08-20 02:04:31,687 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:31.687] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:31.687] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:31.687] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:31.687] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:31.687] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:31.687] 2025-08-20 02:04:31,687 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:31.717] 2025-08-20 02:04:31,717 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:31.717] 2025-08-20 02:04:31,717 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:31.717] 2025-08-20 02:04:31,717 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:31.720] [INFO] Tool embedding index loaded successfully
[02:04:31.721] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:31.721] [INFO] Operation semantic index initialized
[02:04:31.722] 
[02:04:31.722] [TURN 1/10]
[02:04:31.722] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:31.785] 2025-08-20 02:04:31,785 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:31.786]   [EARLY_EXIT] No actions taken, continuing...
[02:04:31.786] 
[02:04:31.786] [TURN 6/10]
[02:04:31.787] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:32.144] 2025-08-20 02:04:32,144 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:32.145] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b12230c0-24d4-981b-ad49-4c5da2fe7d89"}, traceId: 213e060a17556806719234963e8995'}
[02:04:32.145] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:33.421] 2025-08-20 02:04:33,421 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:33.424]   [SEARCH] Query: network api fetch
[02:04:33.424] 
[02:04:33.424] [TURN 2/10]
[02:04:33.424] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:33.666] 2025-08-20 02:04:33,666 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:33.667] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"196b834e-3406-9962-9baa-ad26ef387147"}, traceId: 213e042f17556806734051008e265f'}
[02:04:33.667] [ERROR] Max retries reached after 5 attempts
[02:04:33.667] [API_FAILURE] All retries exhausted
[02:04:33.667]   [API_FAILURE] API failed (timeout or max retries)
[02:04:33.669] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:33.669] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:33.670] [AI_DEBUG] 生成的txt_content长度: 4153
[02:04:33.670] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:33.670]   - use_ai_classification=True
[02:04:33.670]   - ai_classifier=True
[02:04:33.670]   - txt_content_len=4153
[02:04:33.670]   - task_model=qwen2.5-72b-instruct
[02:04:33.672] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:33.685] 2025-08-20 02:04:33,684 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:33.685] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:33.685] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:33.685] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:33.685] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:33.685] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:33.685] 2025-08-20 02:04:33,685 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:33.692] 2025-08-20 02:04:33,692 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:33.693] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6113d1c3-5577-97ab-b312-14fd4ad45e01"}, traceId: 213e060a17556806734464970e8995'}
[02:04:33.693] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:04:33.711] 2025-08-20 02:04:33,711 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:33.711] 2025-08-20 02:04:33,711 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:33.711] 2025-08-20 02:04:33,711 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:33.715] [INFO] Tool embedding index loaded successfully
[02:04:33.716] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:33.716] [INFO] Operation semantic index initialized
[02:04:33.716] 
[02:04:33.716] [TURN 1/10]
[02:04:33.716] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:33.793] 2025-08-20 02:04:33,793 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:33.798] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b1d9a3f0-b0ca-95d0-b45e-49405464d11e"}, traceId: 213e06a017556806735568938e792f'}
[02:04:33.798] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:34.052] 2025-08-20 02:04:34,052 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:34.053] 2025-08-20 02:04:34,053 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:34.053] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:34.472] 2025-08-20 02:04:34,472 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:34.472] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a536c708-5ba9-9e96-b902-81c73a43d1b0"}, traceId: 213e060917556806742322236e7197'}
[02:04:34.472] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:04:34.882] 2025-08-20 02:04:34,881 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:34.913] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa5f43f2-4d98-90a0-921c-b8d45951938e"}, traceId: 213e06a017556806747068945e792f'}
[02:04:34.913] [RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[02:04:35.108] 2025-08-20 02:04:35,108 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:35.108] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4ab33fdf-48cf-9c48-8ae9-6323b497cb41"}, traceId: 213e060a17556806748514974e8995'}
[02:04:35.108] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:04:35.897] 2025-08-20 02:04:35,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:35.897] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cbc5af9f-a332-9a2e-97bf-ce1e949645d5"}, traceId: 213e060917556806756602241e7197'}
[02:04:35.897] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:04:37.012] 2025-08-20 02:04:37,012 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:37.014] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9ace2e1-3c32-9934-880d-f522b405aa0a"}, traceId: 213e06a017556806767868952e792f'}
[02:04:37.014] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:37.015] 2025-08-20 02:04:37,015 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:37.016] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5ddb94f9-261e-976c-85b9-49406be48ad2"}, traceId: 213e060a17556806768494979e8995'}
[02:04:37.016] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:04:38.024] 2025-08-20 02:04:38,023 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:38.025] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0efb0ff-56a9-9839-8b83-b69be0184dc5"}, traceId: 213e060917556806778112246e7197'}
[02:04:38.025] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:04:38.728] 2025-08-20 02:04:38,728 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:38.732] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efb668b3-84fc-98d3-9886-3850a57cc53c"}, traceId: 213e06a017556806784928959e792f'}
[02:04:38.732] [RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[02:04:39.859] 2025-08-20 02:04:39,859 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:39.860] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d304b134-3a01-996c-b6d0-2d49cc698430"}, traceId: 213e060a17556806796304984e8995'}
[02:04:39.860] [ERROR] Max retries reached after 5 attempts
[02:04:39.860] [API_FAILURE] All retries exhausted
[02:04:39.860]   [API_FAILURE] API failed (timeout or max retries)
[02:04:39.864] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:39.864] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:39.864] [AI_DEBUG] 生成的txt_content长度: 9505
[02:04:39.864] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:39.864]   - use_ai_classification=True
[02:04:39.864]   - ai_classifier=True
[02:04:39.864]   - txt_content_len=9505
[02:04:39.864]   - task_model=qwen2.5-72b-instruct
[02:04:39.864] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:39.864] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:39.874] 2025-08-20 02:04:39,874 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:39.874] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:39.874] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:39.875] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:39.875] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:39.875] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:39.875] 2025-08-20 02:04:39,875 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:39.902] 2025-08-20 02:04:39,902 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:39.902] 2025-08-20 02:04:39,902 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:39.902] 2025-08-20 02:04:39,902 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:39.905] [INFO] Tool embedding index loaded successfully
[02:04:39.906] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:39.906] [INFO] Operation semantic index initialized
[02:04:39.906] 
[02:04:39.906] [TURN 1/10]
[02:04:39.906] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:40.695] 2025-08-20 02:04:40,695 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:40.699] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6cc67c72-204d-96bb-a3fc-acb4675f1eb9"}, traceId: 213e007e17556806804644472eefbc'}
[02:04:40.699] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:04:40.707] 2025-08-20 02:04:40,707 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:40.708] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51e0cbc2-990d-99af-9e52-87d94c68ebce"}, traceId: 213e060917556806804622259e7197'}
[02:04:40.708] [RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[02:04:42.006] 2025-08-20 02:04:42,005 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:42.006] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03fd2ddc-4d7b-94bf-b895-06cba7dfed27"}, traceId: 213e007e17556806817784478eefbc'}
[02:04:42.006] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:43.147] 2025-08-20 02:04:43,147 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:43.149] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"75e0ac4d-6ecc-971e-8f22-00e05f8890ca"}, traceId: 213e007e17556806829224486eefbc'}
[02:04:43.149] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:04:43.575] 2025-08-20 02:04:43,575 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:43.578] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ebeb63c0-cdf3-96a7-9a6b-cdb669dcd3f8"}, traceId: 213e06a017556806833458985e792f'}
[02:04:43.578] [ERROR] Max retries reached after 5 attempts
[02:04:43.578] [API_FAILURE] All retries exhausted
[02:04:43.578]   [API_FAILURE] API failed (timeout or max retries)
[02:04:43.580] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:43.580] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:43.580] [AI_DEBUG] 生成的txt_content长度: 8822
[02:04:43.580] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:43.580]   - use_ai_classification=True
[02:04:43.580]   - ai_classifier=True
[02:04:43.580]   - txt_content_len=8822
[02:04:43.580]   - task_model=qwen2.5-72b-instruct
[02:04:43.580] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:43.581] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:43.590] 2025-08-20 02:04:43,590 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:43.590] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:43.590] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:43.591] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:43.591] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:43.591] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:43.592] 2025-08-20 02:04:43,592 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:43.629] 2025-08-20 02:04:43,629 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:43.629] 2025-08-20 02:04:43,629 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:43.629] 2025-08-20 02:04:43,629 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:43.631] [INFO] Tool embedding index loaded successfully
[02:04:43.632] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:43.633] [INFO] Operation semantic index initialized
[02:04:43.633] 
[02:04:43.633] [TURN 1/10]
[02:04:43.633] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:44.999] 2025-08-20 02:04:44,998 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:45.001]   [SEARCH] Query: file reader
[02:04:45.001] 
[02:04:45.001] [TURN 2/10]
[02:04:45.002] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:45.385] 2025-08-20 02:04:45,385 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:45.385] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4737a679-3782-92d5-b4ed-fd3d8b39fa9b"}, traceId: 213e011517556806851361919e92b1'}
[02:04:45.385] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:04:45.517] 2025-08-20 02:04:45,517 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:45.520] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d30085ed-7e86-9bff-8a34-b7c560684d6e"}, traceId: 213e007e17556806852904499eefbc'}
[02:04:45.520] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:04:45.845] 2025-08-20 02:04:45,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:45.846] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e2a2d07-eee7-9c26-bf3b-be9c80bc3736"}, traceId: 213e060917556806856062354e7197'}
[02:04:45.846] [ERROR] Max retries reached after 5 attempts
[02:04:45.846] [API_FAILURE] All retries exhausted
[02:04:45.846]   [API_FAILURE] API failed (timeout or max retries)
[02:04:45.848] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:45.848] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:45.848] [AI_DEBUG] 生成的txt_content长度: 4593
[02:04:45.848] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:45.848]   - use_ai_classification=True
[02:04:45.848]   - ai_classifier=True
[02:04:45.848]   - txt_content_len=4593
[02:04:45.848]   - task_model=qwen2.5-72b-instruct
[02:04:45.850] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:45.860] 2025-08-20 02:04:45,860 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:45.861] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:45.861] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:45.861] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:45.861] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:45.861] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:45.861] 2025-08-20 02:04:45,861 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:45.887] 2025-08-20 02:04:45,887 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:45.887] 2025-08-20 02:04:45,887 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:45.887] 2025-08-20 02:04:45,887 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:45.890] [INFO] Tool embedding index loaded successfully
[02:04:45.891] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:45.891] [INFO] Operation semantic index initialized
[02:04:45.891] 
[02:04:45.891] [TURN 1/10]
[02:04:45.892] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:46.371] 2025-08-20 02:04:46,371 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:46.372] 2025-08-20 02:04:46,372 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:46.373] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:46.655] 2025-08-20 02:04:46,655 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:46.659] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03a35923-39ba-976b-b845-de224ab0f21c"}, traceId: 213e006d17556806864427081e110e'}
[02:04:46.659] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:47.012] 2025-08-20 02:04:47,011 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:47.013]   [EARLY_EXIT] No actions taken, continuing...
[02:04:47.013] 
[02:04:47.013] [TURN 3/10]
[02:04:47.015] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:47.393] 2025-08-20 02:04:47,393 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:47.394] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7c2317fe-8cd4-9656-9c87-1312f605320a"}, traceId: 213e011517556806871491931e92b1'}
[02:04:47.394] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:48.533] 2025-08-20 02:04:48,533 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:48.537] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7f01202-1a6a-984c-9fea-0c9a709eca7e"}, traceId: 213e007e17556806883204505eefbc'}
[02:04:48.537] [ERROR] Max retries reached after 5 attempts
[02:04:48.537] [API_FAILURE] All retries exhausted
[02:04:48.537]   [API_FAILURE] API failed (timeout or max retries)
[02:04:48.539] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:48.539] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:48.539] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:48.539] [AI_DEBUG] 生成的txt_content长度: 4629
[02:04:48.539] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:48.540]   - use_ai_classification=True
[02:04:48.540]   - ai_classifier=True
[02:04:48.540]   - txt_content_len=4629
[02:04:48.540]   - task_model=qwen2.5-72b-instruct
[02:04:48.549] 2025-08-20 02:04:48,548 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:48.549] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"95e2201b-d1fc-9249-b916-30bedfaad0dc"}, traceId: 213e011517556806883011937e92b1'}
[02:04:48.549] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:04:48.552] 2025-08-20 02:04:48,552 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:48.552] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:48.552] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:48.552] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:48.552] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:48.552] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:48.552] 2025-08-20 02:04:48,552 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:48.578] 2025-08-20 02:04:48,578 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:48.578] 2025-08-20 02:04:48,578 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:48.578] 2025-08-20 02:04:48,578 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:48.581] [INFO] Tool embedding index loaded successfully
[02:04:48.582] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:48.582] [INFO] Operation semantic index initialized
[02:04:48.582] 
[02:04:48.582] [TURN 1/10]
[02:04:48.583] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:48.685] 2025-08-20 02:04:48,684 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:48.685] 2025-08-20 02:04:48,685 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:48.685] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:48.686] Progress: 30/35 (Success: 0)
[02:04:49.019] 2025-08-20 02:04:49,019 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:49.023]   [SEARCH] Query: file reader
[02:04:49.023] 
[02:04:49.023] [TURN 2/10]
[02:04:49.023] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:49.388] 2025-08-20 02:04:49,387 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:49.391] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"734d28a8-bb0e-93d9-9a7b-e1f1922ef267"}, traceId: 213e006d17556806891577095e110e'}
[02:04:49.392] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:49.860] 2025-08-20 02:04:49,859 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:49.861]   [SEARCH] Query: file reader
[02:04:49.861] 
[02:04:49.861] [TURN 2/10]
[02:04:49.861] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:50.770] 2025-08-20 02:04:50,770 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:50.771]   [EARLY_EXIT] No actions taken, continuing...
[02:04:50.771] 
[02:04:50.771] [TURN 3/10]
[02:04:50.771] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:50.910] 2025-08-20 02:04:50,910 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:50.910] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fbb65fbc-0358-98ec-8cdd-125058c958b2"}, traceId: 213e011517556806907011948e92b1'}
[02:04:50.911] [RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[02:04:51.092] 2025-08-20 02:04:51,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:51.092] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"204303b3-9ad8-96e4-96f7-5a5f9f3270e5"}, traceId: 213e06c017556806909051571e8343'}
[02:04:51.092] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:51.720] 2025-08-20 02:04:51,719 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:51.724]   [EARLY_EXIT] No actions taken, continuing...
[02:04:51.724] 
[02:04:51.724] [TURN 3/10]
[02:04:51.724] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:52.085] 2025-08-20 02:04:52,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:52.111] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df12db0d-2b33-9141-b036-382c4cf4730b"}, traceId: 213e006d17556806918587109e110e'}
[02:04:52.111] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:52.834] 2025-08-20 02:04:52,834 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:52.834] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b806586e-cfc0-90db-892c-8decdd55eba7"}, traceId: 213e06c017556806926071578e8343'}
[02:04:52.834] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:04:52.912] 2025-08-20 02:04:52,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:52.913] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"37df9ec1-d7c9-989b-bff4-670cd56b013f"}, traceId: 213e011517556806927141957e92b1'}
[02:04:52.913] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:04:53.894] 2025-08-20 02:04:53,893 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:53.898] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e64c3982-995a-91fc-bd27-6b0069777cb1"}, traceId: 213e006d17556806936627115e110e'}
[02:04:53.898] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:55.221] 2025-08-20 02:04:55,221 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:55.221] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b2a20398-dccd-9722-8217-fb8a3e1da091"}, traceId: 213e06c017556806948661592e8343'}
[02:04:55.222] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:56.040] 2025-08-20 02:04:56,040 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:56.040] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d351279-69cd-95cd-9fec-3f072cabf69f"}, traceId: 213e011517556806958061964e92b1'}
[02:04:56.040] [ERROR] Max retries reached after 5 attempts
[02:04:56.040] [API_FAILURE] All retries exhausted
[02:04:56.040]   [API_FAILURE] API failed (timeout or max retries)
[02:04:56.043] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:56.043] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:56.043] [AI_DEBUG] 生成的txt_content长度: 8783
[02:04:56.043] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:56.043]   - use_ai_classification=True
[02:04:56.043]   - ai_classifier=True
[02:04:56.043]   - txt_content_len=8783
[02:04:56.043]   - task_model=qwen2.5-72b-instruct
[02:04:56.043] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:56.043] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:56.053] 2025-08-20 02:04:56,053 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:56.053] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:56.053] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:56.059] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:56.059] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:04:56.059] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:56.059] 2025-08-20 02:04:56,059 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:56.085] 2025-08-20 02:04:56,085 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:56.085] 2025-08-20 02:04:56,085 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:56.085] 2025-08-20 02:04:56,085 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:56.087] [INFO] Tool embedding index loaded successfully
[02:04:56.088] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:56.088] [INFO] Operation semantic index initialized
[02:04:56.088] 
[02:04:56.088] [TURN 1/10]
[02:04:56.089] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:56.458] 2025-08-20 02:04:56,458 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:56.460] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3043e8d8-7e13-9fe2-814b-4d1d3aeb921e"}, traceId: 213e006d17556806962447172e110e'}
[02:04:56.460] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[02:04:56.876] 2025-08-20 02:04:56,875 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:56.884] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2039d126-ce17-94bd-8195-53395429fa4e"}, traceId: 213e064717556806966384164e8ae7'}
[02:04:56.884] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:04:56.937] 2025-08-20 02:04:56,937 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:56.937] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"95e27ba3-b9b9-9a3b-ab4f-c9a125b8f734"}, traceId: 213e06c017556806967031597e8343'}
[02:04:56.937] [RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[02:04:57.749] 2025-08-20 02:04:57,749 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:57.753] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1446cda4-0c66-9e6b-a71b-dc3e2b76815e"}, traceId: 213e064717556806975224185e8ae7'}
[02:04:57.753] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:04:59.696] 2025-08-20 02:04:59,696 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:59.696] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"da9ad4d0-1d11-9e94-8e68-ce01969e8faf"}, traceId: 213e064717556806994404230e8ae7'}
[02:04:59.696] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:04:59.716] 2025-08-20 02:04:59,716 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:59.719] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5a92bf7-ca2b-9c76-9268-17183289e4cd"}, traceId: 213e006d17556806995277208e110e'}
[02:04:59.719] [RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[02:05:00.785] 2025-08-20 02:05:00,785 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:00.786] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"348e710b-1d9a-9af8-9ce6-b52ee4d01a7d"}, traceId: 213e06c017556807005481607e8343'}
[02:05:00.786] [ERROR] Max retries reached after 5 attempts
[02:05:00.786] [API_FAILURE] All retries exhausted
[02:05:00.787]   [API_FAILURE] API failed (timeout or max retries)
[02:05:00.790] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:00.790] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:00.790] [AI_DEBUG] 生成的txt_content长度: 9147
[02:05:00.790] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:00.791]   - use_ai_classification=True
[02:05:00.791]   - ai_classifier=True
[02:05:00.791]   - txt_content_len=9147[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:05:00.791] 
[02:05:00.791]   - task_model=qwen2.5-72b-instruct
[02:05:00.791] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:00.804] 2025-08-20 02:05:00,804 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:05:00.804] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:05:00.804] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:05:00.804] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:05:00.804] [MCPEmbeddingManager] Reusing existing singleton instance (id: 6075427408)
[02:05:00.804] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:05:00.804] 2025-08-20 02:05:00,804 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:05:00.832] 2025-08-20 02:05:00,831 - mcp_embedding_manager - INFO - FAISS index loaded
[02:05:00.832] 2025-08-20 02:05:00,832 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:05:00.832] 2025-08-20 02:05:00,832 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:05:00.834] [INFO] Tool embedding index loaded successfully
[02:05:00.835] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:05:00.835] [INFO] Operation semantic index initialized
[02:05:00.835] 
[02:05:00.835] [TURN 1/10]
[02:05:00.836] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:02.103] 2025-08-20 02:05:02,103 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:02.105]   [SEARCH] Query: file reader
[02:05:02.105] 
[02:05:02.105] [TURN 2/10]
[02:05:02.105] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:02.473] 2025-08-20 02:05:02,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:02.474] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c96e581e-ba74-930d-9948-82c2b82de52d"}, traceId: 213e06c317556807022432368e7ab4'}
[02:05:02.474] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:05:02.636] 2025-08-20 02:05:02,636 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:02.640] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fdeb964b-9b28-9483-8fac-74aa03c60a41"}, traceId: 213e064717556807024214296e8ae7'}
[02:05:02.640] [RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[02:05:04.764] 2025-08-20 02:05:04,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:04.768]   [EARLY_EXIT] No actions taken, continuing...
[02:05:04.768] 
[02:05:04.768] [TURN 4/10]
[02:05:04.769] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:04.880] 2025-08-20 02:05:04,879 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:04.881]   [EARLY_EXIT] No actions taken, continuing...
[02:05:04.881] 
[02:05:04.881] [TURN 3/10]
[02:05:04.882] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:05.146] 2025-08-20 02:05:05,146 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:05.152] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d31f9a6-0c51-924a-9308-506e353cf6cf"}, traceId: 213e006d17556807049027271e110e'}
[02:05:05.153] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:05:05.823] 2025-08-20 02:05:05,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:05.823]   [EARLY_EXIT] No actions taken, continuing...
[02:05:05.823] 
[02:05:05.823] [TURN 4/10]
[02:05:05.823] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:06.689] 2025-08-20 02:05:06,689 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:06.690]   [EARLY_EXIT] No actions taken, continuing...
[02:05:06.690] 
[02:05:06.690] [TURN 5/10]
[02:05:06.692] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:06.747] 2025-08-20 02:05:06,747 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:06.752] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6169b3a2-4b5a-9186-9ce4-10ab5d460f2f"}, traceId: 213e006d17556807065147275e110e'}
[02:05:06.752] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:05:06.773] 2025-08-20 02:05:06,773 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:06.775] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eb7af939-9457-928a-92ba-ebe817b0b03a"}, traceId: 213e064717556807065174327e8ae7'}
[02:05:06.775] [ERROR] Max retries reached after 5 attempts
[02:05:06.775] [API_FAILURE] All retries exhausted
[02:05:06.775]   [API_FAILURE] API failed (timeout or max retries)
[02:05:06.777] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:06.777] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:06.777] [AI_DEBUG] 生成的txt_content长度: 4384
[02:05:06.777] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:06.777]   - use_ai_classification=True
[02:05:06.777]   - ai_classifier=True
[02:05:06.777]   - txt_content_len=4384
[02:05:06.777]   - task_model=qwen2.5-72b-instruct
[02:05:07.069] 2025-08-20 02:05:07,067 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:07.069] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"751b8e2c-8e11-993d-a2dc-1bea2a9d8074"}, traceId: 213e06c317556807068312383e7ab4'}
[02:05:07.069] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:05:07.219] 2025-08-20 02:05:07,219 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:07.220] 2025-08-20 02:05:07,220 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:07.220] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:08.395] 2025-08-20 02:05:08,394 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:08.396] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"451c93bd-5106-9355-8fdb-43380518779c"}, traceId: 213e06c317556807082102389e7ab4'}
[02:05:08.396] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:05:08.555] 2025-08-20 02:05:08,555 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:08.558] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"624501d3-2520-9f35-bea5-927572794927"}, traceId: 213e006d17556807083197284e110e'}
[02:05:08.558] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:05:10.504] 2025-08-20 02:05:10,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:10.505] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b6a8ff9-2e9a-967c-b960-cc00f71fd154"}, traceId: 213e06c317556807103062396e7ab4'}
[02:05:10.505] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:05:11.085] 2025-08-20 02:05:11,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:11.110] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b80e6ff-bda9-9fdd-b1f7-13c1a9512cd2"}, traceId: 213e006d17556807107827292e110e'}
[02:05:11.111] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:05:13.980] 2025-08-20 02:05:13,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:13.982]   [EARLY_EXIT] No actions taken, continuing...
[02:05:13.982] 
[02:05:13.982] [TURN 6/10]
[02:05:13.982] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:14.794] 2025-08-20 02:05:14,794 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:14.796]   [EARLY_EXIT] No actions taken, continuing...
[02:05:14.796] 
[02:05:14.796] [TURN 5/10]
[02:05:14.797] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:14.994] 2025-08-20 02:05:14,994 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:14.995]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:05:14.995] 
[02:05:14.995] [TURN 7/10]
[02:05:14.995] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:15.200] 2025-08-20 02:05:15,200 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:15.202] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e52cd037-799d-98f8-bf82-338ffd9eebdd"}, traceId: 213e006d17556807149327312e110e'}
[02:05:15.202] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:16.150] 2025-08-20 02:05:16,149 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:16.155]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:05:16.155] 
[02:05:16.155] [TURN 8/10]
[02:05:16.157] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:16.869] 2025-08-20 02:05:16,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:16.873] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b30316af-faf6-9432-b95f-917c463e4670"}, traceId: 213e006d17556807166717316e110e'}
[02:05:16.873] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:05:17.116] 2025-08-20 02:05:17,115 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:17.117]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:05:17.117] 
[02:05:17.117] [TURN 9/10]
[02:05:17.117] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:17.477] 2025-08-20 02:05:17,477 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:17.478] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"52a1cc46-3ee9-9390-b9cd-c628e2c9ce18"}, traceId: 213e06c317556807172582420e7ab4'}
[02:05:17.478] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:05:18.342] 2025-08-20 02:05:18,342 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:18.346] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"13b934db-8fd6-900c-bb2f-dcaa40e7695d"}, traceId: 213e006d17556807181647322e110e'}
[02:05:18.346] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:18.505] 2025-08-20 02:05:18,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:18.505] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"426116e9-a876-93da-9a1d-9b8460947f6f"}, traceId: 213e06c317556807183272422e7ab4'}
[02:05:18.505] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:05:20.081] 2025-08-20 02:05:20,081 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:20.081] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9c91482-b4b4-940d-94f0-61667a7605e0"}, traceId: 213e006d17556807198277327e110e'}
[02:05:20.081] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:05:20.842] 2025-08-20 02:05:20,841 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:20.843] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa6b4cae-f9ff-9920-aa59-ff895588d241"}, traceId: 213e06c317556807206042429e7ab4'}
[02:05:20.843] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:05:22.318] 2025-08-20 02:05:22,317 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:22.319] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa744979-717c-91f5-95be-e3e4886ca530"}, traceId: 213e006d17556807220927332e110e'}
[02:05:22.319] [ERROR] Max retries reached after 5 attempts
[02:05:22.319] [API_FAILURE] All retries exhausted
[02:05:22.319]   [API_FAILURE] API failed (timeout or max retries)
[02:05:22.322] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:22.322] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:22.322] [AI_DEBUG] 生成的txt_content长度: 9285
[02:05:22.322] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:22.322]   - use_ai_classification=True
[02:05:22.322]   - ai_classifier=True
[02:05:22.322]   - txt_content_len=9285
[02:05:22.322]   - task_model=qwen2.5-72b-instruct
[02:05:22.322] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:24.980] 2025-08-20 02:05:24,980 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:24.983]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[02:05:24.983] 
[02:05:24.983] [TURN 10/10]
[02:05:24.984] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:25.978] 2025-08-20 02:05:25,978 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:25.978]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[02:05:25.978] [ASSISTED] Task received 5 format helps, final result: failure
[02:05:25.980] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:25.980] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:25.980] [AI_DEBUG] 生成的txt_content长度: 15101
[02:05:25.980] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:25.980]   - use_ai_classification=True
[02:05:25.980]   - ai_classifier=True
[02:05:25.980]   - txt_content_len=15101
[02:05:25.980]   - task_model=qwen2.5-72b-instruct
[02:05:25.980] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:25.987] 
[02:05:25.987] [INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[02:05:25.987] 2025-08-20 02:05:25,987 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[02:05:25.990] [INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[02:05:25.991] 2025-08-20 02:05:25,991 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[02:05:25.992] [INFO] 数据已同步到Parquet存储
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO - Database saved successfully
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO - ============================================================
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO - Batch test completed at 2025-08-20T02:05:25.992310
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO - Summary:
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO -   - Total tests: 35
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO -   - Successful: 0
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO -   - Failed: 35
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO -   - Success rate: 0.0%
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250820_020152.log
[02:05:25.992] 2025-08-20 02:05:25,992 - batch_test_runner - INFO - ============================================================
[02:05:25.994] 
[02:05:25.994] ✅ 批测试完成
[02:05:25.994]    成功: 0/35
[02:05:25.994]    失败: 35/35
[02:05:25.994] 
[02:05:25.994] 📤 最终保存35个测试结果...
[02:05:25.995] [DEBUG] 创建新的manager实例: key=True_
[02:05:25.995] ✅ 已保存 35 个测试结果到数据库
[02:05:26.094] [INFO] 已将 5 个汇总写入Parquet
[02:05:26.192] [INFO] 刷新manager缓存: key=True_

==================================================
分片 qwen2.5-72b-instruct_easy_key1 完成
退出码: 0
总行数: 2393
运行时间: 218.0秒
时间: 2025-08-20T02:05:27.831443
