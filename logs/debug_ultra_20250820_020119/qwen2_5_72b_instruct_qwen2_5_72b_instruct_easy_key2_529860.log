===== 分片 qwen2.5-72b-instruct_easy_key2 =====
时间: 2025-08-20T02:02:09.861710
模型: qwen2.5-72b-instruct
实例: qwen-key2
命令: python -u smart_batch_runner.py --model qwen2.5-72b-instruct --deployment qwen-key2 --prompt-types optimal --difficulty easy --task-types all --num-instances 6 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[02:02:11.705] 2025-08-20 02:02:11,705 - faiss.loader - INFO - Loading faiss.
[02:02:11.719] 2025-08-20 02:02:11,719 - faiss.loader - INFO - Successfully loaded faiss.
[02:02:12.696] [INFO] 使用Parquet存储格式
[02:02:13.071] [INFO] 使用Parquet存储格式
[02:02:13.075] [INFO] 使用PARQUET存储格式
[02:02:13.076] 
[02:02:13.076] ============================================================
[02:02:13.076] 智能批测试: qwen2.5-72b-instruct (idealab)
[02:02:13.076] Prompt types: ['optimal']
[02:02:13.076] 难度: easy
[02:02:13.076] 目标: 每种配置 6 个实例
[02:02:13.076] ============================================================
[02:02:13.106] ○ simple_task         :   0/  6 已完成 (需要补充 6 个)
[02:02:13.110] ○ basic_task          :   0/  6 已完成 (需要补充 6 个)
[02:02:13.115] ○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
[02:02:13.120] ○ api_integration     :   0/  6 已完成 (需要补充 6 个)
[02:02:13.125] ○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)
[02:02:13.125] 
[02:02:13.125] ⏳ 需要运行 30 个新测试
[02:02:13.125] 
[02:02:13.125] ▶ 准备 simple_task (6 个实例)...
[02:02:13.125] 
[02:02:13.125] ▶ 准备 basic_task (6 个实例)...
[02:02:13.125] 
[02:02:13.125] ▶ 准备 data_pipeline (6 个实例)...
[02:02:13.125] 
[02:02:13.125] ▶ 准备 api_integration (6 个实例)...
[02:02:13.125] 
[02:02:13.125] ▶ 准备 multi_stage_pipeline (6 个实例)...
[02:02:13.125] 
[02:02:13.125] ▶ 开始执行 30 个测试...
[02:02:13.125] 📦 批量提交模式：每20个测试保存一次
[02:02:13.125] ⚠️  检测到idealab API，调整并发: workers=3, qps=5.0
[02:02:13.127] 2025-08-20 02:02:13,127 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[02:02:13.187] 2025-08-20 02:02:13,187 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[02:02:13.187] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x305ce4ef0>
[02:02:13.187] 2025-08-20 02:02:13,187 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[02:02:13.187] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - ============================================================
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - Batch test runner initialized
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - Log file: logs/batch_test_20250820_020213.log
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - ============================================================
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - Running 30 tests with 3 workers, QPS limit: 5.0
[02:02:13.188] 2025-08-20 02:02:13,188 - batch_test_runner - INFO - Initializing test components...
[02:02:13.517] 2025-08-20 02:02:13,516 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[02:02:13.517] 2025-08-20 02:02:13,517 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[02:02:13.517] 2025-08-20 02:02:13,517 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[02:02:13.517] [DEBUG] Creating new ToolCapabilityManager instance
[02:02:13.517] [OperationEmbeddingIndex] Initializing with unified API client manager
[02:02:13.517] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[02:02:13.517] 2025-08-20 02:02:13,517 - api_client_manager - INFO - Loaded configuration from config/config.json
[02:02:13.524] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[02:02:13.524] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[02:02:13.524] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[02:02:14.261] 2025-08-20 02:02:14,261 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[02:02:14.263] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[02:02:14.314] [INFO] Loaded 4150 embeddings from persistent cache
[02:02:14.314] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[02:02:14.315] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[02:02:14.315] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[02:02:14.315] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[02:02:14.320] [INFO] Successfully loaded FAISS index with dimension 3072
[02:02:14.320] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[02:02:14.320] [INFO] Loaded 15 operations with dimension 3072
[02:02:14.320] [INFO] Successfully loaded cached index
[02:02:14.320] [INFO] Operation semantic index initialized
[02:02:14.320] [INFO] Using device: cpu
[02:02:14.320] [INFO] Initialized tool success tracking attributes
[02:02:14.320] [INFO] Initializing embedding manager for enhanced tool selection
[02:02:14.320] [MCPEmbeddingManager] Creating new singleton instance
[02:02:14.321] [MCPEmbeddingManager] Initializing with unified API client manager
[02:02:14.328] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[02:02:14.328] [MCPEmbeddingManager] Client initialized successfully
[02:02:14.328] 2025-08-20 02:02:14,328 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[02:02:14.494] 2025-08-20 02:02:14,494 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[02:02:14.742] 2025-08-20 02:02:14,742 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[02:02:14.742] 2025-08-20 02:02:14,742 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[02:02:14.766] 2025-08-20 02:02:14,766 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[02:02:14.837] 2025-08-20 02:02:14,837 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[02:02:15.366] 2025-08-20 02:02:15,365 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[02:02:15.366] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[02:02:15.366] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[02:02:15.366] 2025-08-20 02:02:15,366 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:15.749] 2025-08-20 02:02:15,749 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:15.749] 2025-08-20 02:02:15,749 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:15.749] 2025-08-20 02:02:15,749 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:15.752] [SUCCESS] Loaded 30 tool embeddings
[02:02:15.752] 2025-08-20 02:02:15,752 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[02:02:15.752] [SUCCESS] Embedding manager initialized with 30 tools
[02:02:15.752] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[02:02:15.752] [INFO] Loading full MCP protocol registry...
[02:02:15.753] 2025-08-20 02:02:15,752 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:15.753] [INFO] Loaded full tool registry with 30 tools
[02:02:15.753] 2025-08-20 02:02:15,753 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[02:02:15.753] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[02:02:15.753] [INFO] Embedding manager ready with 30 tools
[02:02:15.753] [WARNING] Embedding manager exists but has no embeddings
[02:02:15.753] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[02:02:15.753] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[02:02:15.754] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[02:02:15.754] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:02:15.754] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[02:02:15.754] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[02:02:15.754] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:02:15.754] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:02:15.754] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:02:15.754] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:02:15.754] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[02:02:15.754] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:02:15.754] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[02:02:15.754] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[02:02:15.754] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[02:02:15.754] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[02:02:15.754] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:02:15.754] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:02:15.754] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[02:02:15.754] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[02:02:15.754] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[02:02:15.754] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[02:02:15.754] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[02:02:15.754] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[02:02:15.754] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[02:02:15.754] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[02:02:15.754] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[02:02:15.754] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[02:02:15.754] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[02:02:15.754] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[02:02:15.754] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[02:02:15.754] 2025-08-20 02:02:15,754 - mdp_workflow_generator - INFO - Loaded 30 tools
[02:02:15.754] [INFO] Setting default state_dim based on loaded tools
[02:02:15.754] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[02:02:15.754] 2025-08-20 02:02:15,754 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[02:02:15.754] [INFO] Setting default action_dim based on loaded tools
[02:02:15.754] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[02:02:15.754] 2025-08-20 02:02:15,754 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[02:02:15.754] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[02:02:15.754] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[02:02:15.754] [INFO] ⚡ Will use pre-generated workflows or random policy
[02:02:15.754] 2025-08-20 02:02:15,754 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[02:02:15.754] [INFO] Initializing TaskManager...
[02:02:16.845] 2025-08-20 02:02:16,845 - unified_training_manager - INFO - Using device: cpu
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO - Task filtering results:
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO -   Total: 5040 -> 5040
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO -   simple_task: 320 -> 320
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[02:02:16.957] 2025-08-20 02:02:16,957 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[02:02:16.960] 2025-08-20 02:02:16,960 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[02:02:16.960] [TaskManager] Difficulty level 'easy': 1096 tasks
[02:02:16.960] [TaskManager] Difficulty level 'very_easy': 856 tasks
[02:02:16.960] [TaskManager] Difficulty level 'medium': 1136 tasks
[02:02:16.960] [TaskManager] Difficulty level 'hard': 1096 tasks
[02:02:16.960] [TaskManager] Difficulty level 'very_hard': 856 tasks
[02:02:16.962] [INFO] TaskManager initialized with 5040 tasks
[02:02:16.962] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[02:02:16.962] [INFO] Initializing ToolCallVerifier...
[02:02:16.963] [INFO] ToolCallVerifier initialized with 30 tools
[02:02:16.963] [INFO] Output tools identified: 1
[02:02:16.963] [INFO] Component initialization status:
[02:02:16.963]   - embedding_manager: initialized
[02:02:16.963]   - task_manager: initialized
[02:02:16.963]   - output_verifier: initialized
[02:02:16.963]   - tool_capability_manager: initialized
[02:02:16.963]   - tool_success_rates: initialized with 0 entries
[02:02:16.963] [INFO] MDPWorkflowGenerator initialization complete
[02:02:16.963] 2025-08-20 02:02:16,963 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[02:02:16.963] 2025-08-20 02:02:16,963 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[02:02:16.963] 2025-08-20 02:02:16,963 - batch_test_runner - INFO -   - task_manager: ✓
[02:02:16.963] 2025-08-20 02:02:16,963 - batch_test_runner - INFO -   - output_verifier: ✓
[02:02:16.963] 2025-08-20 02:02:16,963 - batch_test_runner - INFO -   - embedding_manager: ✓
[02:02:16.963] 2025-08-20 02:02:16,963 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[02:02:16.963] 2025-08-20 02:02:16,963 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[02:02:16.963] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:16.963] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:16.963] [FlawedWorkflowGenerator] Initialized with 30 tools
[02:02:16.963] [FlawedWorkflowGenerator] RAG support: disabled
[02:02:16.964] DEBUG: Checking generator attributes
[02:02:16.964]   - has tool_capabilities: True
[02:02:16.964]   - has tool_capability_manager: True
[02:02:16.964]   - has task_manager: True
[02:02:16.964] [INFO] Loaded 30 tools from generator
[02:02:16.964] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[02:02:16.964] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:16.964] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:16.964] [INFO] Initializing LLM client using APIClientManager
[02:02:16.972] [INFO] Using Azure OpenAI client
[02:02:16.972] [DEBUG] Checking if generator has tool_capability_manager attribute
[02:02:16.972] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[02:02:16.972] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:16.972] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:16.972] [FlawedWorkflowGenerator] Initialized with 30 tools
[02:02:16.972] [FlawedWorkflowGenerator] RAG support: enabled
[02:02:16.972] [INFO] FlawedWorkflowGenerator initialized successfully
[02:02:16.972] [INFO] Initializing StableScorer for Phase 2 scoring
[02:02:16.972] <tool_capability_manager.ToolCapabilityManager object at 0x319fbf650>
[02:02:16.972] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:16.972] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:16.972] [INFO] Loaded tool success history for 0 tools
[02:02:16.972] [INFO] StableScorer initialized with semantic capability
[02:02:16.972] [INFO] StableScorer initialized successfully
[02:02:16.972] [INFO] Loading task instances...
[02:02:16.972] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[02:02:16.978] [INFO] Loaded 630 task instances
[02:02:16.978] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[02:02:16.979] 2025-08-20 02:02:16,978 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[02:02:16.979] 2025-08-20 02:02:16,979 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[02:02:17.313] 2025-08-20 02:02:17,313 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[02:02:17.313] 2025-08-20 02:02:17,313 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[02:02:17.329] 2025-08-20 02:02:17,329 - batch_test_runner - INFO - Initialization complete
[02:02:17.372] 2025-08-20 02:02:17,372 - batch_test_runner - INFO - Starting batch test with 30 tasks, 3 workers
[02:02:17.372] 2025-08-20 02:02:17,372 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[02:02:17.373] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:17.373] 2025-08-20 02:02:17,373 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
[02:02:17.380] 2025-08-20 02:02:17,380 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:17.380] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:17.380] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:17.380] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:17.380] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:17.380] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:17.380] 2025-08-20 02:02:17,380 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:17.689] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:17.689] 2025-08-20 02:02:17,689 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:17.689] 2025-08-20 02:02:17,689 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:17.689] 2025-08-20 02:02:17,689 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:17.691] [INFO] Tool embedding index loaded successfully
[02:02:17.704] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:17.705] [INFO] Operation semantic index initialized
[02:02:17.705] 
[02:02:17.705] [TURN 1/10]
[02:02:17.705] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:17.711] 2025-08-20 02:02:17,711 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:17.711] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:17.711] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:17.712] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:17.712] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:17.712] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:17.712] 2025-08-20 02:02:17,712 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:17.733] 2025-08-20 02:02:17,733 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:17.733] 2025-08-20 02:02:17,733 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:17.733] 2025-08-20 02:02:17,733 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:17.735] [INFO] Tool embedding index loaded successfully
[02:02:17.736] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:17.736] [INFO] Operation semantic index initialized
[02:02:17.736] 
[02:02:17.736] [TURN 1/10]
[02:02:17.737] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:17.884] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:17.895] 2025-08-20 02:02:17,895 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:17.895] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:17.895] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:17.895] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:17.895] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:17.895] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:17.895] 2025-08-20 02:02:17,895 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:17.918] 2025-08-20 02:02:17,918 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:17.918] 2025-08-20 02:02:17,918 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:17.918] 2025-08-20 02:02:17,918 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:17.921] [INFO] Tool embedding index loaded successfully
[02:02:17.922] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:17.922] [INFO] Operation semantic index initialized
[02:02:17.922] 
[02:02:17.922] [TURN 1/10]
[02:02:17.922] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:18.530] 2025-08-20 02:02:18,530 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:18.549] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a14d8294-0269-98da-ae58-627461655ac1"}, traceId: 213e007f17556805384157227eec55'}
[02:02:18.550] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:02:18.589] 2025-08-20 02:02:18,589 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:18.590] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b6e066f-6530-9906-9572-f7444a54ccc0"}, traceId: 213e007e17556805384174259eed49'}
[02:02:18.590] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:02:18.759] 2025-08-20 02:02:18,759 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:18.763] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f9bfb93-70eb-9d3a-899c-f9050d6f22f7"}, traceId: 213e06a017556805386291845e75b3'}
[02:02:18.763] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:19.592] 2025-08-20 02:02:19,591 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:19.597] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a41b03eb-3bbd-9a93-b9fb-8c7bd8a24608"}, traceId: 213e007e17556805394074265eed49'}
[02:02:19.597] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:02:20.249] 2025-08-20 02:02:20,249 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:20.253] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"636ffb73-a0ac-95bb-bace-df071898677f"}, traceId: 213e007f17556805401437231eec55'}
[02:02:20.254] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:02:20.725] 2025-08-20 02:02:20,724 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:20.735]   [SEARCH] Query: data validation parser
[02:02:20.737] 
[02:02:20.737] [TURN 2/10]
[02:02:20.748] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:21.873] 2025-08-20 02:02:21,872 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:21.874] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c29473b-5857-9709-8c14-c7e62c5a0891"}, traceId: 213e007e17556805417564271eed49'}
[02:02:21.874] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:02:21.997] 2025-08-20 02:02:21,997 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:21.998]   [INFO] Tool info request: data_processing_validator
[02:02:21.998] 
[02:02:21.998] [TURN 3/10]
[02:02:21.998] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:23.057] 2025-08-20 02:02:23,057 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:23.058]   [SEARCH] Query: data validation parser
[02:02:23.059] 
[02:02:23.059] [TURN 2/10]
[02:02:23.059] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:23.402] 2025-08-20 02:02:23,402 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:23.404] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"881bd5fd-49e3-9210-9d66-450d00acd48c"}, traceId: 213e007f17556805432867242eec55'}
[02:02:23.404] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:02:23.436] 2025-08-20 02:02:23,435 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:23.439]   [INFO] Tool info request: data_processing_parser
[02:02:23.439] 
[02:02:23.439] [TURN 4/10]
[02:02:23.440] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:23.803] 2025-08-20 02:02:23,803 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:23.804] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa2ecebd-bfbe-9b5a-bf46-ea158f892ad1"}, traceId: 213e06a017556805436671866e75b3'}
[02:02:23.804] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:02:24.355] 2025-08-20 02:02:24,355 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:24.360] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03163ef8-f428-90a5-9b6b-fc3eabbd1de5"}, traceId: 213e007e17556805441794276eed49'}
[02:02:24.360] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:02:24.675] 2025-08-20 02:02:24,675 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:24.680] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10bbe093-7482-9308-b334-893e70003790"}, traceId: 213e06a017556805445571868e75b3'}
[02:02:24.680] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:26.064] 2025-08-20 02:02:26,063 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:26.066]   [INFO] Tool info request: data_processing_validator
[02:02:26.067] 
[02:02:26.067] [TURN 3/10]
[02:02:26.070] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:26.706] 2025-08-20 02:02:26,705 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:26.707] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f0cbe828-a033-9cfb-9d50-1554969a4024"}, traceId: 213e007e17556805465734288eed49'}
[02:02:26.707] [ERROR] Max retries reached after 5 attempts
[02:02:26.707] [API_FAILURE] All retries exhausted
[02:02:26.707]   [API_FAILURE] API failed (timeout or max retries)
[02:02:26.711] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:26.711] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:26.711] [AI_DEBUG] 生成的txt_content长度: 4243
[02:02:26.711] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:26.711]   - use_ai_classification=True
[02:02:26.711]   - ai_classifier=True
[02:02:26.711]   - txt_content_len=4243
[02:02:26.711]   - task_model=qwen2.5-72b-instruct
[02:02:26.713] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:26.727] 2025-08-20 02:02:26,727 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:26.727] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:26.727] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:26.727] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:26.727] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:26.727] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:26.728] 2025-08-20 02:02:26,728 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:26.753] 2025-08-20 02:02:26,753 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:26.753] 2025-08-20 02:02:26,753 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:26.753] 2025-08-20 02:02:26,753 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:26.756] [INFO] Tool embedding index loaded successfully
[02:02:26.758] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:26.758] [INFO] Operation semantic index initialized
[02:02:26.759] 
[02:02:26.759] [TURN 1/10]
[02:02:26.759] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:26.838] 2025-08-20 02:02:26,838 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:26.842] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1026efc-df22-9a59-9514-b490b8ac4784"}, traceId: 213e06a017556805467191873e75b3'}
[02:02:26.842] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:02:27.204] 2025-08-20 02:02:27,203 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:27.209]   [INFO] Tool info request: data_processing_parser
[02:02:27.209] 
[02:02:27.209] [TURN 4/10]
[02:02:27.209] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:27.287] 2025-08-20 02:02:27,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:27.287] 2025-08-20 02:02:27,287 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:27.287] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:02:27.601] 2025-08-20 02:02:27,601 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:27.602] 2025-08-20 02:02:27,602 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:27.603] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1fb47db5-aed3-9a6e-a6a3-32e8d6706ec2"}, traceId: 213e06c817556805474231603e8170'}
[02:02:27.603] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:27.613] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"402e3830-0099-9769-81d0-d2658863d770"}, traceId: 213e007f17556805474387258eec55'}
[02:02:27.613] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:28.763] 2025-08-20 02:02:28,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:28.766] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ee4b5cf-36ee-91f7-b0f9-48b08577f1b9"}, traceId: 213e06a017556805486391877e75b3'}
[02:02:28.766] [RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[02:02:29.100] 2025-08-20 02:02:29,099 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:29.100] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"37fae7ad-0b1c-94be-8a21-80bc16aeec27"}, traceId: 213e007f17556805489177264eec55'}
[02:02:29.100] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:02:30.365] 2025-08-20 02:02:30,365 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:30.366]   [SEARCH] Query: data validation parser
[02:02:30.366] 
[02:02:30.366] [TURN 2/10]
[02:02:30.366] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:30.703] 2025-08-20 02:02:30,703 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:30.704] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4a449c2-9eda-9df4-8ec0-5e4cc5956b91"}, traceId: 213e06c817556805505861609e8170'}
[02:02:30.704] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:02:31.871] 2025-08-20 02:02:31,870 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:31.871] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a7a9bc5c-8156-9661-93bf-b62de5062772"}, traceId: 213e06c817556805517301610e8170'}
[02:02:31.872] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:02:31.931] 2025-08-20 02:02:31,931 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:31.937]   [EARLY_EXIT] No actions taken, continuing...
[02:02:31.937] 
[02:02:31.937] [TURN 5/10]
[02:02:31.937] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:32.277] 2025-08-20 02:02:32,277 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:32.283] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a8a480f5-e19c-9480-9f18-ed0832d0e363"}, traceId: 213e007f17556805521667282eec55'}
[02:02:32.283] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:02:33.046] 2025-08-20 02:02:33,045 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:33.049] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3b6863b-4762-991b-bf93-161465e7e3c1"}, traceId: 213e06a017556805529231887e75b3'}
[02:02:33.049] [ERROR] Max retries reached after 5 attempts
[02:02:33.049] [API_FAILURE] All retries exhausted
[02:02:33.049]   [API_FAILURE] API failed (timeout or max retries)
[02:02:33.055] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:33.055] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:33.056] [AI_DEBUG] 生成的txt_content长度: 10635
[02:02:33.056] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:33.056]   - use_ai_classification=True
[02:02:33.056]   - ai_classifier=True
[02:02:33.056]   - txt_content_len=10635
[02:02:33.056]   - task_model=qwen2.5-72b-instruct
[02:02:33.056] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:33.056] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:33.066] 2025-08-20 02:02:33,066 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:33.066] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:33.066] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:33.066] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:33.066] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:33.066] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:33.067] 2025-08-20 02:02:33,067 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:33.101] 2025-08-20 02:02:33,101 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:33.102] 2025-08-20 02:02:33,101 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:33.102] 2025-08-20 02:02:33,102 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:33.104] [INFO] Tool embedding index loaded successfully
[02:02:33.106] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:33.107] [INFO] Operation semantic index initialized
[02:02:33.108] 
[02:02:33.108] [TURN 1/10]
[02:02:33.109] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:33.431] 2025-08-20 02:02:33,431 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:33.437] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c7a74001-2b2a-92c2-9af2-919036acc273"}, traceId: 213e007f17556805532747284eec55'}
[02:02:33.437] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:02:33.999] 2025-08-20 02:02:33,999 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:34.002] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"13789987-e0fb-984a-b415-94825ec892c5"}, traceId: 213e006917556805538076948edfd1'}
[02:02:34.003] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:02:34.850] 2025-08-20 02:02:34,849 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:34.850] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86f15029-3e6b-912f-9b9c-5610f4a203cf"}, traceId: 213e007f17556805546547300eec55'}
[02:02:34.850] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:02:34.893] 2025-08-20 02:02:34,893 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:34.894] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2fcc071c-6095-9415-ab24-341fa8a2a9a5"}, traceId: 213e006917556805547026952edfd1'}
[02:02:34.894] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:35.184] 2025-08-20 02:02:35,184 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:35.184]   [INFO] Tool info request: data_processing_validator
[02:02:35.184] 
[02:02:35.184] [TURN 3/10]
[02:02:35.184] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:35.535] 2025-08-20 02:02:35,535 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:35.536] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c13d6d7c-0613-907e-9144-19ceb41e676f"}, traceId: 213e06c817556805553321621e8170'}
[02:02:35.536] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:02:36.385] 2025-08-20 02:02:36,385 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:36.389] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"618e62a5-1ae6-9c02-9524-3757879bc147"}, traceId: 213e006917556805561716960edfd1'}
[02:02:36.390] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:02:36.667] 2025-08-20 02:02:36,666 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:36.667] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08a24737-3110-9114-bde1-1806638f88e5"}, traceId: 213e06c817556805564311631e8170'}
[02:02:36.667] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:02:36.727] 2025-08-20 02:02:36,726 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:36.732] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d0882bb-1b17-9d38-ae51-d55dc172f09e"}, traceId: 213e007f17556805565007309eec55'}
[02:02:36.732] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:02:38.420] 2025-08-20 02:02:38,420 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:38.421] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dc94fb1c-899e-96e1-a270-4f93a3f6d947"}, traceId: 213e06c817556805581731642e8170'}
[02:02:38.421] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:02:39.401] 2025-08-20 02:02:39,398 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:39.402] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff6b984e-d72d-981b-9051-e659d419dff7"}, traceId: 213e006917556805592106968edfd1'}
[02:02:39.402] [RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[02:02:40.909] 2025-08-20 02:02:40,909 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:40.927]   [EARLY_EXIT] No actions taken, continuing...
[02:02:40.927] 
[02:02:40.927] [TURN 6/10]
[02:02:40.933] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:41.886] 2025-08-20 02:02:41,885 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:41.890]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:02:41.890] 
[02:02:41.890] [TURN 7/10]
[02:02:41.898] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:42.092] 2025-08-20 02:02:42,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:42.093]   [INFO] Tool info request: data_processing_parser
[02:02:42.094] 
[02:02:42.094] [TURN 4/10]
[02:02:42.095] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:42.502] 2025-08-20 02:02:42,501 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:42.503] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f67da82-a05b-9afe-9c90-cea2e0d68673"}, traceId: 213e06c817556805622441657e8170'}
[02:02:42.503] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:02:42.847] 2025-08-20 02:02:42,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:42.850]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:02:42.851] 
[02:02:42.851] [TURN 8/10]
[02:02:42.851] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:42.897] 2025-08-20 02:02:42,896 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:42.897] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a8a12db7-1ad9-9fcb-a961-935d2a7ff9fd"}, traceId: 213e006917556805626286990edfd1'}
[02:02:42.897] [ERROR] Max retries reached after 5 attempts
[02:02:42.897] [API_FAILURE] All retries exhausted
[02:02:42.898]   [API_FAILURE] API failed (timeout or max retries)
[02:02:42.901] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:42.901] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:42.901] [AI_DEBUG] 生成的txt_content长度: 4394
[02:02:42.901] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:42.901]   - use_ai_classification=True
[02:02:42.901]   - ai_classifier=True
[02:02:42.901]   - txt_content_len=4394
[02:02:42.901]   - task_model=qwen2.5-72b-instruct
[02:02:42.903] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:42.930] 2025-08-20 02:02:42,930 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:42.930] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:42.930] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:42.930] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:42.931] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:42.931] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:42.931] 2025-08-20 02:02:42,931 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:42.967] 2025-08-20 02:02:42,967 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:42.967] 2025-08-20 02:02:42,967 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:42.967] 2025-08-20 02:02:42,967 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:42.970] [INFO] Tool embedding index loaded successfully
[02:02:42.971] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:42.971] [INFO] Operation semantic index initialized
[02:02:42.971] 
[02:02:42.971] [TURN 1/10]
[02:02:42.972] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:43.292] 2025-08-20 02:02:43,292 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:43.294] 2025-08-20 02:02:43,294 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:43.294] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:02:43.420] 2025-08-20 02:02:43,419 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:43.420] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6cbe9f70-2004-95f7-a7f6-e70dfc87c52c"}, traceId: 213e06c817556805631591666e8170'}
[02:02:43.420] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:43.862] 2025-08-20 02:02:43,861 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:43.862] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d75077e-8524-9bf4-aad9-2dd1b84a4e0f"}, traceId: 213e007b17556805635766403eec6a'}
[02:02:43.862] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:02:43.881] 2025-08-20 02:02:43,880 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:43.882]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:02:43.882] 
[02:02:43.882] [TURN 9/10]
[02:02:43.883] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:44.873] 2025-08-20 02:02:44,873 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:44.874]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[02:02:44.874] 
[02:02:44.874] [TURN 10/10]
[02:02:44.875] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:45.066] 2025-08-20 02:02:45,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:45.067] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03ca90fe-c1f7-959e-b985-cc3381c45462"}, traceId: 213e06c817556805648201673e8170'}
[02:02:45.067] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:02:45.512] 2025-08-20 02:02:45,512 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:45.517] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8458c2e3-36da-93a2-b542-5fc901335f02"}, traceId: 213e007b17556805652896410eec6a'}
[02:02:45.517] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:02:45.971] 2025-08-20 02:02:45,971 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:45.978]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[02:02:45.978] [ASSISTED] Task received 5 format helps, final result: failure
[02:02:45.980] [DEBUG] Got result for task: has_result=True, save_logs=True[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:45.980] 
[02:02:45.980] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:45.980] [AI_DEBUG] 生成的txt_content长度: 16516
[02:02:45.980] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:45.980]   - use_ai_classification=True
[02:02:45.980]   - ai_classifier=True
[02:02:45.980]   - txt_content_len=16516
[02:02:45.980]   - task_model=qwen2.5-72b-instruct
[02:02:45.980] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:45.988] 2025-08-20 02:02:45,988 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:45.988] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:45.988] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:45.988] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:45.988] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:45.988] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:45.988] 2025-08-20 02:02:45,988 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:46.006] 2025-08-20 02:02:46,006 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:46.006] 2025-08-20 02:02:46,006 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:46.006] 2025-08-20 02:02:46,006 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:46.008] [INFO] Tool embedding index loaded successfully
[02:02:46.009] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:46.009] [INFO] Operation semantic index initialized
[02:02:46.009] 
[02:02:46.009] [TURN 1/10]
[02:02:46.009] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:46.868] 2025-08-20 02:02:46,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:46.872] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99eff9f4-2b08-9602-ab3f-863d5176e23b"}, traceId: 213e006b17556805666742376eeba6'}
[02:02:46.872] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:48.123] 2025-08-20 02:02:48,123 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:48.132] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e682e039-1873-92b4-b3d3-4c9342b7eebf"}, traceId: 213e007b17556805678846425eec6a'}
[02:02:48.133] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:02:48.433] 2025-08-20 02:02:48,433 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:48.443] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"852e4bf2-50dd-998f-b159-850833286ea3"}, traceId: 213e006b17556805681962379eeba6'}
[02:02:48.443] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:02:48.657] 2025-08-20 02:02:48,657 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:48.657] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed00d481-bf0f-99e7-a8fe-2c8799c8f725"}, traceId: 213e06c817556805684111682e8170'}
[02:02:48.657] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:50.446] 2025-08-20 02:02:50,446 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:50.447] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f27e474d-308c-9a59-990e-dd26bcd42e80"}, traceId: 213e006b17556805701502389eeba6'}
[02:02:50.447] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:02:50.828] 2025-08-20 02:02:50,828 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:50.829] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed9356c3-f5f1-96c6-bb80-f1053faf588b"}, traceId: 213e06c817556805706181691e8170'}
[02:02:50.830] [ERROR] Max retries reached after 5 attempts
[02:02:50.830] [API_FAILURE] All retries exhausted
[02:02:50.830]   [API_FAILURE] API failed (timeout or max retries)
[02:02:50.840] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:50.840] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:50.840] [AI_DEBUG] 生成的txt_content长度: 10679
[02:02:50.840] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:50.840]   - use_ai_classification=True
[02:02:50.840]   - ai_classifier=True
[02:02:50.840]   - txt_content_len=10679
[02:02:50.840]   - task_model=qwen2.5-72b-instruct
[02:02:50.840] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:02:50.842] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:50.861] 2025-08-20 02:02:50,861 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:50.861] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:50.861] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:50.862] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:50.863] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:50.863] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:50.863] 2025-08-20 02:02:50,862 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:50.911] 2025-08-20 02:02:50,911 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:50.911] 2025-08-20 02:02:50,911 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:50.911] 2025-08-20 02:02:50,911 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:50.915] [INFO] Tool embedding index loaded successfully
[02:02:50.916] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:50.916] [INFO] Operation semantic index initialized
[02:02:50.917] 
[02:02:50.917] [TURN 1/10]
[02:02:50.918] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:51.747] 2025-08-20 02:02:51,747 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:51.747] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d6474e9-22e0-9af8-8ea0-69dda873aef9"}, traceId: 213e06a117556805715141066e891a'}
[02:02:51.748] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:02:51.786] 2025-08-20 02:02:51,786 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:51.791]   [SEARCH] Query: data validation parser
[02:02:51.791] 
[02:02:51.791] [TURN 2/10]
[02:02:51.792] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:52.170] 2025-08-20 02:02:52,170 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:52.177] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eb5be96b-5ee8-9c29-8cf8-e8bd8a2ec9a9"}, traceId: 213e007b17556805719386445eec6a'}
[02:02:52.177] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:02:53.170] 2025-08-20 02:02:53,170 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:53.171] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe34e896-16aa-9e78-b848-dfc96ad67a54"}, traceId: 213e06a117556805729341075e891a'}
[02:02:53.171] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:02:54.017] 2025-08-20 02:02:54,016 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:54.017] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10886e06-b2e9-9bc3-b1f9-e53268d9ebb2"}, traceId: 213e006b17556805738082400eeba6'}
[02:02:54.017] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:02:54.151] 2025-08-20 02:02:54,150 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:54.151]   [INFO] Tool info request: data_processing_validator
[02:02:54.152] 
[02:02:54.152] [TURN 3/10]
[02:02:54.152] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:54.591] 2025-08-20 02:02:54,591 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:54.592] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"087480f2-ee40-94e9-8f8d-89aafd55f539"}, traceId: 213e007b17556805743326463eec6a'}
[02:02:54.592] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:02:55.168] 2025-08-20 02:02:55,165 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:55.168] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f75a7590-c4d7-9de4-863c-99b2ba75e162"}, traceId: 213e06a117556805749081090e891a'}
[02:02:55.169] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:02:55.972] 2025-08-20 02:02:55,972 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:55.975] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f3b30301-5ec8-9de4-b922-9782bc4e4bed"}, traceId: 213e007b17556805757336475eec6a'}
[02:02:55.975] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:02:56.222] 2025-08-20 02:02:56,222 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:56.223] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff6dd072-47c7-989e-a120-50f99a6c18af"}, traceId: 213e006b17556805759412409eeba6'}
[02:02:56.223] [ERROR] Max retries reached after 5 attempts
[02:02:56.223] [API_FAILURE] All retries exhausted
[02:02:56.223]   [API_FAILURE] API failed (timeout or max retries)
[02:02:56.226] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:56.226] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:56.226] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:56.226] [AI_DEBUG] 生成的txt_content长度: 4409
[02:02:56.226] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:56.226]   - use_ai_classification=True
[02:02:56.226]   - ai_classifier=True
[02:02:56.226]   - txt_content_len=4409
[02:02:56.226]   - task_model=qwen2.5-72b-instruct
[02:02:56.240] 2025-08-20 02:02:56,240 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:56.240] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:56.240] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:56.240] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:56.240] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:56.240] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:56.240] 2025-08-20 02:02:56,240 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:56.265] 2025-08-20 02:02:56,265 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:56.265] 2025-08-20 02:02:56,265 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:56.265] 2025-08-20 02:02:56,265 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:56.268] [INFO] Tool embedding index loaded successfully
[02:02:56.268] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:56.268] [INFO] Operation semantic index initialized
[02:02:56.268] 
[02:02:56.268] [TURN 1/10]
[02:02:56.269] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:56.609] 2025-08-20 02:02:56,609 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:56.610] 2025-08-20 02:02:56,610 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:56.610] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:02:56.778] 2025-08-20 02:02:56,778 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:56.778] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91a5bad6-6b5b-9a18-9190-3ddb2365c737"}, traceId: 213e06a117556805765741109e891a'}
[02:02:56.778] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:02:57.065] 2025-08-20 02:02:57,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:57.066] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f8f2cde-0cac-945e-b0a6-0d596048d035"}, traceId: 213e066e17556805768668926e7fe9'}
[02:02:57.066] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:02:57.625] 2025-08-20 02:02:57,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:57.628] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18589876-4bb5-9d02-9803-2a30c05f96c7"}, traceId: 213e007b17556805773886477eec6a'}
[02:02:57.628] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:02:58.785] 2025-08-20 02:02:58,784 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:02:58.786]   [SEARCH] Query: file reader
[02:02:58.787] 
[02:02:58.787] [TURN 2/10]
[02:02:58.788] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:59.196] 2025-08-20 02:02:59,196 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:59.197] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"35d2235e-0983-9be3-b400-e7aa71bae201"}, traceId: 213e066e17556805789418958e7fe9'}
[02:02:59.197] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:02:59.520] 2025-08-20 02:02:59,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:59.524] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"53fc6908-8427-913b-90c2-e6ccdeef87b2"}, traceId: 213e007b17556805792866481eec6a'}
[02:02:59.524] [RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[02:02:59.823] 2025-08-20 02:02:59,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:02:59.824] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4316d095-b67a-9678-ba31-8818b43ec905"}, traceId: 213e06a117556805796431127e891a'}
[02:02:59.824] [ERROR] Max retries reached after 5 attempts
[02:02:59.824] [API_FAILURE] All retries exhausted
[02:02:59.824]   [API_FAILURE] API failed (timeout or max retries)
[02:02:59.825] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:02:59.825] [AI_DEBUG] 测试失败，准备调用AI分类
[02:02:59.825] [AI_DEBUG] 生成的txt_content长度: 4456
[02:02:59.825] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:02:59.825]   - use_ai_classification=True
[02:02:59.825]   - ai_classifier=True
[02:02:59.825]   - txt_content_len=4456
[02:02:59.825]   - task_model=qwen2.5-72b-instruct
[02:02:59.826] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:02:59.834] 2025-08-20 02:02:59,834 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:02:59.834] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:02:59.834] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:02:59.834] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:02:59.834] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:02:59.834] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:02:59.834] 2025-08-20 02:02:59,834 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:02:59.857] 2025-08-20 02:02:59,857 - mcp_embedding_manager - INFO - FAISS index loaded
[02:02:59.858] 2025-08-20 02:02:59,857 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:02:59.858] 2025-08-20 02:02:59,857 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:02:59.861] [INFO] Tool embedding index loaded successfully
[02:02:59.862] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:02:59.862] [INFO] Operation semantic index initialized
[02:02:59.862] 
[02:02:59.862] [TURN 1/10]
[02:02:59.862] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:02:59.963] 2025-08-20 02:02:59,963 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:02:59.964] 2025-08-20 02:02:59,964 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:02:59.964] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:00.670] 2025-08-20 02:03:00,670 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:00.672] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8d8758b-f525-9695-b75e-369970709dc2"}, traceId: 213e066c17556805804405534e796f'}
[02:03:00.672] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:03:00.692] 2025-08-20 02:03:00,692 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:00.693] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"31822d43-ccd1-972c-830f-da074d2c499f"}, traceId: 213e066e17556805804338996e7fe9'}
[02:03:00.693] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:03:01.625] 2025-08-20 02:03:01,625 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:01.625] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8b52857-9935-91cc-9102-678bb10b64ef"}, traceId: 213e066c17556805813955538e796f'}
[02:03:01.626] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:03:01.892] 2025-08-20 02:03:01,892 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:01.892] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5fd9fbf4-4dba-9366-a69e-b1c15762f3bd"}, traceId: 213e066e17556805816021016e7fe9'}
[02:03:01.892] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:02.911] 2025-08-20 02:03:02,910 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:02.911] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18fa8903-64ad-9505-b7be-a74da4837686"}, traceId: 213e066c17556805825995552e796f'}
[02:03:02.911] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:03:03.865] 2025-08-20 02:03:03,864 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:03.866] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c96e979b-0d64-9c83-a0ff-c6dd13502458"}, traceId: 213e066e17556805835981052e7fe9'}
[02:03:03.866] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:03:04.892] 2025-08-20 02:03:04,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:04.896]   [INFO] Tool info request: data_processing_parser
[02:03:04.896] 
[02:03:04.896] [TURN 4/10]
[02:03:04.897] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:04.925] 2025-08-20 02:03:04,925 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:04.928]   [SEARCH] Query: file reader
[02:03:04.928] 
[02:03:04.928] [TURN 2/10]
[02:03:04.929] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:05.323] 2025-08-20 02:03:05,323 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:05.333] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86cd3cdb-b1bb-9aca-9d64-69be7f44104a"}, traceId: 213e066c17556805850755579e796f'}
[02:03:05.333] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:03:05.827] 2025-08-20 02:03:05,827 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:05.832]   [EARLY_EXIT] No actions taken, continuing...
[02:03:05.832] 
[02:03:05.832] [TURN 5/10]
[02:03:05.833] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:06.851] 2025-08-20 02:03:06,850 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:06.851]   [EARLY_EXIT] No actions taken, continuing...
[02:03:06.851] 
[02:03:06.851] [TURN 6/10]
[02:03:06.852] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:07.005] 2025-08-20 02:03:07,004 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:07.006]   [EARLY_EXIT] No actions taken, continuing...
[02:03:07.006] 
[02:03:07.006] [TURN 3/10]
[02:03:07.007] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:07.023] 2025-08-20 02:03:07,023 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:07.031] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d81b692d-6c5b-952a-898f-88448a6bc1d8"}, traceId: 213e066c17556805867665585e796f'}
[02:03:07.032] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:07.405] 2025-08-20 02:03:07,405 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:07.406] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d2319e7-1bc7-9be9-b189-e0fb95c0b4ee"}, traceId: 213e066e17556805871671081e7fe9'}
[02:03:07.406] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:07.857] 2025-08-20 02:03:07,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:07.858]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:03:07.858] 
[02:03:07.858] [TURN 7/10]
[02:03:07.858] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:08.810] 2025-08-20 02:03:08,809 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:08.810] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"218d1c23-647b-91e4-849c-a0e3972ed3f9"}, traceId: 213e066e17556805885641107e7fe9'}
[02:03:08.810] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:08.982] 2025-08-20 02:03:08,981 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:08.982] 2025-08-20 02:03:08,982 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:08.983]   [EARLY_EXIT] No actions taken, continuing...
[02:03:08.983] 
[02:03:08.983] [TURN 3/10]
[02:03:08.985]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:03:08.985] 
[02:03:08.985] [TURN 8/10]
[02:03:08.985] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:08.986] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:10.125] 2025-08-20 02:03:10,123 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:10.189]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:03:10.194] 
[02:03:10.194] [TURN 9/10]
[02:03:10.215] 2025-08-20 02:03:10,215 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:10.217] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"967726d0-d2c6-91a3-92e3-17f53f0049d8"}, traceId: 213e066e17556805899351126e7fe9'}
[02:03:10.219] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:03:10.248] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:10.276] 2025-08-20 02:03:10,276 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:10.290]   [EARLY_EXIT] No actions taken, continuing...
[02:03:10.290] 
[02:03:10.290] [TURN 4/10]
[02:03:10.291] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:10.660] 2025-08-20 02:03:10,659 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:10.661] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ce1ad91-ae46-9906-8b6e-0b10334f3310"}, traceId: 213e007b17556805904226535eec6a'}
[02:03:10.662] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:10.677] 2025-08-20 02:03:10,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:10.685] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4a1d64b-4667-9028-9609-b655726e3d33"}, traceId: 213e066c17556805904455596e796f'}
[02:03:10.685] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:03:12.052] 2025-08-20 02:03:12,051 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:12.056] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"69bb13a9-84ec-94ae-97da-8b2444b80957"}, traceId: 213e007b17556805918616539eec6a'}
[02:03:12.056] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:12.212] 2025-08-20 02:03:12,212 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:12.220] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29453619-6cd8-918e-ae70-a9cbdd5067dc"}, traceId: 213e066c17556805920275602e796f'}
[02:03:12.221] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:12.956] 2025-08-20 02:03:12,956 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:12.957] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c9b46a4f-18a9-9cbe-a6a3-4cfa94b1558a"}, traceId: 213e066e17556805926951156e7fe9'}
[02:03:12.957] [RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[02:03:13.474] 2025-08-20 02:03:13,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:13.477] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"37500dcf-5996-9f74-80f4-e5c29169948a"}, traceId: 213e007b17556805932316556eec6a'}
[02:03:13.477] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:03:13.578] 2025-08-20 02:03:13,578 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:13.586] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ae3b4d1-9bab-921a-8a34-a51c9f2ef200"}, traceId: 213e066c17556805933115608e796f'}
[02:03:13.586] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:03:16.675] 2025-08-20 02:03:16,675 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:16.679] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5d9bc51f-c76d-9c0a-9072-108d987ab986"}, traceId: 213e007b17556805964166572eec6a'}
[02:03:16.680] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:03:16.775] 2025-08-20 02:03:16,775 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:16.782] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f055fc6b-0c7c-9d73-942b-d016a802710f"}, traceId: 213e066c17556805965285612e796f'}
[02:03:16.782] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:03:17.456] 2025-08-20 02:03:17,456 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:17.456] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef5b6cfc-3e22-9f1e-9dc2-9921b3c3c7cd"}, traceId: 213e066e17556805972251178e7fe9'}
[02:03:17.456] [ERROR] Max retries reached after 5 attempts
[02:03:17.456] [API_FAILURE] All retries exhausted
[02:03:17.456]   [API_FAILURE] API failed (timeout or max retries)
[02:03:17.459] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:17.459] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:17.459] [AI_DEBUG] 生成的txt_content长度: 8780
[02:03:17.459] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:17.459]   - use_ai_classification=True
[02:03:17.459]   - ai_classifier=True
[02:03:17.459]   - txt_content_len=8780
[02:03:17.459]   - task_model=qwen2.5-72b-instruct
[02:03:17.459] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:17.460] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:17.475] 2025-08-20 02:03:17,475 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:17.475] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:17.475] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:17.475] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:17.475] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:17.475] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:17.475] 2025-08-20 02:03:17,475 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:17.506] 2025-08-20 02:03:17,506 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:17.506] 2025-08-20 02:03:17,506 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:17.506] 2025-08-20 02:03:17,506 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:17.508] [INFO] Tool embedding index loaded successfully
[02:03:17.509] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:17.509] [INFO] Operation semantic index initialized
[02:03:17.510] 
[02:03:17.510] [TURN 1/10]
[02:03:17.510] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:19.077] 2025-08-20 02:03:19,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:19.087]   [SEARCH] Query: file reader
[02:03:19.087] 
[02:03:19.087] [TURN 2/10]
[02:03:19.136] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:19.524] 2025-08-20 02:03:19,523 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:19.525] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc062bcc-dc43-9e56-98d2-53f843a65386"}, traceId: 213e06bc17556805992894869e81e9'}
[02:03:19.525] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:19.850] 2025-08-20 02:03:19,850 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:19.852] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8439d798-febb-9865-9233-73d0ad2eb5e5"}, traceId: 213e066c17556805996015621e796f'}
[02:03:19.852] [ERROR] Max retries reached after 5 attempts
[02:03:19.852] [API_FAILURE] All retries exhausted
[02:03:19.852]   [API_FAILURE] API failed (timeout or max retries)
[02:03:19.854] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:19.854] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:19.854] [AI_DEBUG] 生成的txt_content长度: 8882
[02:03:19.854] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:19.854]   - use_ai_classification=True
[02:03:19.854]   - ai_classifier=True
[02:03:19.854]   - txt_content_len=8882
[02:03:19.854]   - task_model=qwen2.5-72b-instruct
[02:03:19.854] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:19.854] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:19.862] 2025-08-20 02:03:19,862 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:19.862] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:19.862] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:19.863] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:19.863] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:19.863] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:19.863] 2025-08-20 02:03:19,863 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:19.885] 2025-08-20 02:03:19,885 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:19.885] 2025-08-20 02:03:19,885 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:19.885] 2025-08-20 02:03:19,885 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:19.888] [INFO] Tool embedding index loaded successfully
[02:03:19.889] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:19.889] [INFO] Operation semantic index initialized
[02:03:19.889] 2025-08-20 02:03:19,889 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:19.889] 
[02:03:19.889] [TURN 1/10]
[02:03:19.890] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:19.894]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[02:03:19.894] 
[02:03:19.894] [TURN 10/10]
[02:03:19.894] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:21.017] 2025-08-20 02:03:21,017 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:21.018] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a9635d7e-6fea-9b7c-9e28-6d2ef87bc7df"}, traceId: 213e066d17556806007688451e80e5'}
[02:03:21.018] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:21.125] 2025-08-20 02:03:21,124 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:21.129]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[02:03:21.129] [ASSISTED] Task received 5 format helps, final result: failure
[02:03:21.130] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:21.130] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:21.130] [AI_DEBUG] 生成的txt_content长度: 16516
[02:03:21.130] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:21.130]   - use_ai_classification=True
[02:03:21.130]   - ai_classifier=True
[02:03:21.130]   - txt_content_len=16516
[02:03:21.130]   - task_model=qwen2.5-72b-instruct
[02:03:21.130] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:21.130] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:21.134] Progress: 10/30 (Success: 0)
[02:03:21.141] 2025-08-20 02:03:21,141 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:21.142] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:21.142] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:21.142] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:21.142] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:21.142] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:21.142] 2025-08-20 02:03:21,142 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:21.166] 2025-08-20 02:03:21,166 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:21.167] 2025-08-20 02:03:21,166 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:21.167] 2025-08-20 02:03:21,166 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:21.169] [INFO] Tool embedding index loaded successfully
[02:03:21.170] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:21.170] [INFO] Operation semantic index initialized
[02:03:21.170] 
[02:03:21.170] [TURN 1/10]
[02:03:21.171] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:22.013] 2025-08-20 02:03:22,012 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:22.086] 2025-08-20 02:03:22,086 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:22.086] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"910ef1f8-fe2e-91d3-8461-4051ba856c23"}, traceId: 213e042f17556806017575785e2284'}
[02:03:22.086] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:22.086]   [EARLY_EXIT] No actions taken, continuing...
[02:03:22.086] 
[02:03:22.086] [TURN 3/10]
[02:03:22.087] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:22.993] 2025-08-20 02:03:22,993 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:22.994]   [EARLY_EXIT] No actions taken, continuing...
[02:03:22.994] 
[02:03:22.994] [TURN 4/10]
[02:03:22.995] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:23.011] 2025-08-20 02:03:23,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:23.022]   [SEARCH] Query: file reader
[02:03:23.022] 
[02:03:23.022] [TURN 2/10]
[02:03:23.023] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:23.417] 2025-08-20 02:03:23,416 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:23.425] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d371057-ceb3-9176-a55d-8eab67ed15be"}, traceId: 213e066d17556806031778499e80e5'}
[02:03:23.425] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:23.457] 2025-08-20 02:03:23,457 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:23.458] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c85e88cc-3731-91ac-b3cc-17d3b8807809"}, traceId: 213e042f17556806032315795e2284'}
[02:03:23.458] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:03:24.039] 2025-08-20 02:03:24,039 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:24.040]   [EARLY_EXIT] No actions taken, continuing...
[02:03:24.040] 
[02:03:24.040] [TURN 5/10]
[02:03:24.040] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:25.045] 2025-08-20 02:03:25,045 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:25.046]   [EARLY_EXIT] No actions taken, continuing...
[02:03:25.046] 
[02:03:25.046] [TURN 6/10]
[02:03:25.047] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:25.060] 2025-08-20 02:03:25,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:25.060] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d74bccf0-b66b-9ccb-96be-6050589b5929"}, traceId: 213e042f17556806048285803e2284'}
[02:03:25.060] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[02:03:25.420] 2025-08-20 02:03:25,420 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:25.431]   [EARLY_EXIT] No actions taken, continuing...
[02:03:25.431] 
[02:03:25.431] [TURN 3/10]
[02:03:25.431] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:25.817] 2025-08-20 02:03:25,816 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:25.825] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c839e56d-2d80-935d-b5e3-df083b95d7e3"}, traceId: 213e066d17556806055838510e80e5'}
[02:03:25.825] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:25.884] 2025-08-20 02:03:25,884 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:25.885]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:03:25.885] 
[02:03:25.885] [TURN 7/10]
[02:03:25.885] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:27.191] 2025-08-20 02:03:27,190 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:27.193]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:03:27.193] 
[02:03:27.193] [TURN 8/10]
[02:03:27.193] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:27.201] 2025-08-20 02:03:27,201 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:27.209] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"612aea2a-4763-9b0c-82d1-6cb2914402f7"}, traceId: 213e066d17556806069588514e80e5'}
[02:03:27.209] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:28.276] 2025-08-20 02:03:28,276 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:28.279]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:03:28.279] 
[02:03:28.279] [TURN 9/10]
[02:03:28.302] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:28.713] 2025-08-20 02:03:28,713 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:28.723] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"213ffb71-5330-972c-b62d-5954c5380fdf"}, traceId: 213e06bc17556806084564920e81e9'}
[02:03:28.723] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:03:29.246] 2025-08-20 02:03:29,246 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:29.247]   [SEARCH] Query: file reader
[02:03:29.247] 
[02:03:29.247] [TURN 2/10]
[02:03:29.247] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:29.375] 2025-08-20 02:03:29,375 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:29.380]   [EARLY_EXIT] No actions taken, continuing...
[02:03:29.380] 
[02:03:29.380] [TURN 4/10]
[02:03:29.380] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:29.638] 2025-08-20 02:03:29,638 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:29.638] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a970fd76-fdde-9199-a7b8-48b9fe857c2e"}, traceId: 213e042f17556806093965824e2284'}
[02:03:29.638] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:03:29.768] 2025-08-20 02:03:29,768 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:29.780] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2425156-cd4e-9e6d-b480-878163257749"}, traceId: 213e066d17556806095338528e80e5'}
[02:03:29.780] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:03:29.861] 2025-08-20 02:03:29,861 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:29.862] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"235001d0-0f39-91a0-b38d-fb72a78c19c3"}, traceId: 213e06bc17556806095944925e81e9'}
[02:03:29.862] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:30.596] 2025-08-20 02:03:30,595 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:30.596] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b35bffd-137c-999a-89e2-40c2963e5bda"}, traceId: 213e042f17556806103565828e2284'}
[02:03:30.596] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:31.583] 2025-08-20 02:03:31,583 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:31.613] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c651f16d-82a2-9415-8145-2f303b25297f"}, traceId: 213e066d17556806112448536e80e5'}
[02:03:31.613] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:03:31.897] 2025-08-20 02:03:31,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:31.897]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[02:03:31.897] 
[02:03:31.897] [TURN 10/10]
[02:03:31.898] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:31.998] 2025-08-20 02:03:31,998 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:31.999] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3be6cd26-fbe7-9cf7-ae9c-05ef4012be32"}, traceId: 213e042f17556806117075832e2284'}
[02:03:31.999] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:03:32.969] 2025-08-20 02:03:32,969 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:32.970]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[02:03:32.970] [ASSISTED] Task received 5 format helps, final result: failure
[02:03:32.971] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:32.972] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:32.972] [AI_DEBUG] 生成的txt_content长度: 14597
[02:03:32.972] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:32.972]   - use_ai_classification=True
[02:03:32.972]   - ai_classifier=True[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:32.972] 
[02:03:32.972]   - txt_content_len=14597
[02:03:32.972]   - task_model=qwen2.5-72b-instruct
[02:03:32.972] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:32.980] 2025-08-20 02:03:32,980 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:32.980] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:32.980] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:32.980] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:32.980] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:32.981] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:32.981] 2025-08-20 02:03:32,981 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:33.003] 2025-08-20 02:03:33,003 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:33.003] 2025-08-20 02:03:33,003 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:33.003] 2025-08-20 02:03:33,003 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:33.005] [INFO] Tool embedding index loaded successfully
[02:03:33.006] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:33.006] [INFO] Operation semantic index initialized
[02:03:33.007] 
[02:03:33.007] [TURN 1/10]
[02:03:33.007] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:33.851] 2025-08-20 02:03:33,851 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:33.852] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"519aad93-d7b5-9d2a-925d-5fb356369f31"}, traceId: 213e066d17556806135588542e80e5'}
[02:03:33.852] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:03:33.871] 2025-08-20 02:03:33,871 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:33.875] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f3bf236-95ce-96ea-8b72-9317607d96eb"}, traceId: 213e065517556806136381084e82e5'}
[02:03:33.875] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:03:35.423] 2025-08-20 02:03:35,423 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:35.424] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"52047265-4944-96b1-8a20-dc649d5265c4"}, traceId: 213e042f17556806151735842e2284'}
[02:03:35.424] [RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[02:03:35.704] 2025-08-20 02:03:35,704 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:35.704] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6fed1ad0-8a2b-9bab-b1d6-37798b9218bf"}, traceId: 213e065517556806155041094e82e5'}
[02:03:35.704] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:37.481] 2025-08-20 02:03:37,481 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:37.508] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e06f1e2b-1260-9229-a05b-8b4d2e308508"}, traceId: 213e066d17556806172258555e80e5'}
[02:03:37.508] [RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[02:03:37.723] 2025-08-20 02:03:37,723 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:37.724]   [SEARCH] Query: file reader
[02:03:37.724] 
[02:03:37.724] [TURN 2/10]
[02:03:37.725] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:38.123] 2025-08-20 02:03:38,122 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:38.126] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"97b5a1e7-ffaf-9d42-9805-a7c8b3d0bdaf"}, traceId: 213e065517556806178731107e82e5'}
[02:03:38.126] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:03:39.329] 2025-08-20 02:03:39,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:39.334] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5aff11ab-c84f-9747-aca2-cd7eb6eefe04"}, traceId: 213e065517556806190801114e82e5'}
[02:03:39.334] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:03:40.537] 2025-08-20 02:03:40,536 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:40.537] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1a94855-76de-9cab-aef5-3621cbe81479"}, traceId: 213e042f17556806202265859e2284'}
[02:03:40.537] [ERROR] Max retries reached after 5 attempts
[02:03:40.537] [API_FAILURE] All retries exhausted
[02:03:40.537]   [API_FAILURE] API failed (timeout or max retries)
[02:03:40.538] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:40.538] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:40.538] [AI_DEBUG] 生成的txt_content长度: 8709
[02:03:40.538] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:40.538]   - use_ai_classification=True
[02:03:40.538]   - ai_classifier=True
[02:03:40.538]   - txt_content_len=8709
[02:03:40.538]   - task_model=qwen2.5-72b-instruct
[02:03:40.538] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:40.538] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:40.545] 2025-08-20 02:03:40,545 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:40.545] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:40.545] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:40.546] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:40.546] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:40.546] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:40.546] 2025-08-20 02:03:40,546 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:40.568] 2025-08-20 02:03:40,568 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:40.568] 2025-08-20 02:03:40,568 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:40.568] 2025-08-20 02:03:40,568 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:40.570] [INFO] Tool embedding index loaded successfully
[02:03:40.571] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:40.571] [INFO] Operation semantic index initialized
[02:03:40.572] 
[02:03:40.572] [TURN 1/10]
[02:03:40.572] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:40.764] 2025-08-20 02:03:40,764 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:40.769] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06df6e6e-0e32-92ea-870b-472d1f4d9dda"}, traceId: 213e065517556806205341122e82e5'}
[02:03:40.769] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:03:41.337] 2025-08-20 02:03:41,337 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:41.338] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78d0d0ad-e452-9a26-9f35-5fd4756d788e"}, traceId: 213e060b17556806211506813e8917'}
[02:03:41.338] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:41.959] 2025-08-20 02:03:41,959 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:41.966] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4763e19a-8c0b-9dc0-8cbf-90011c7cbec9"}, traceId: 213e066d17556806217298570e80e5'}
[02:03:41.966] [ERROR] Max retries reached after 5 attempts
[02:03:41.966] [API_FAILURE] All retries exhausted
[02:03:41.966]   [API_FAILURE] API failed (timeout or max retries)
[02:03:41.967] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:41.967] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:41.967] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:41.967] [AI_DEBUG] 生成的txt_content长度: 8888
[02:03:41.967] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:41.967]   - use_ai_classification=True
[02:03:41.967]   - ai_classifier=True
[02:03:41.967]   - txt_content_len=8888
[02:03:41.967]   - task_model=qwen2.5-72b-instruct
[02:03:41.967] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:03:41.978] 2025-08-20 02:03:41,977 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:41.978] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:41.978] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:41.978] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:41.978] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:41.978] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:41.978] 2025-08-20 02:03:41,978 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:42.003] 2025-08-20 02:03:42,002 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:42.003] 2025-08-20 02:03:42,003 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:42.003] 2025-08-20 02:03:42,003 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:42.006] [INFO] Tool embedding index loaded successfully
[02:03:42.007] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:42.007] [INFO] Operation semantic index initialized
[02:03:42.007] 
[02:03:42.007] [TURN 1/10]
[02:03:42.007] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:42.845] 2025-08-20 02:03:42,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:42.845] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bd291f7b-b612-9268-89af-91049f1dd221"}, traceId: 213e060b17556806226106818e8917'}
[02:03:42.845] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:03:42.912] 2025-08-20 02:03:42,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:42.918] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db3fe5fa-3ee0-9dc1-894e-acaef21c3c46"}, traceId: 213e064e17556806226796219e834d'}
[02:03:42.918] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:03:43.506] 2025-08-20 02:03:43,506 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:43.585] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5af3297e-0ce0-9c4a-b4f2-1d76d9f9d6f9"}, traceId: 213e065517556806232671140e82e5'}
[02:03:43.585] [RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[02:03:44.586] 2025-08-20 02:03:44,586 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:44.592] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d022fbb0-b450-98a2-9e54-56982558f74f"}, traceId: 213e064e17556806243646226e834d'}
[02:03:44.592] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:03:45.001] 2025-08-20 02:03:45,001 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:45.001] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"40e1c161-d45b-94b3-8611-020a68d41ba3"}, traceId: 213e060b17556806247666831e8917'}
[02:03:45.001] [RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[02:03:47.051] 2025-08-20 02:03:47,051 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:47.078] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5c86bbd0-7913-9510-b4e7-b67cf298e937"}, traceId: 213e064e17556806268096240e834d'}
[02:03:47.078] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:03:48.677] 2025-08-20 02:03:48,675 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:48.678] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc2761d2-0c39-979d-a29a-a069af0f1579"}, traceId: 213e060b17556806284316849e8917'}
[02:03:48.678] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:03:49.941] 2025-08-20 02:03:49,941 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:50.002]   [EARLY_EXIT] No actions taken, continuing...
[02:03:50.002] 
[02:03:50.002] [TURN 3/10]
[02:03:50.003] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:50.267] 2025-08-20 02:03:50,267 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:50.268] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dfb29bcf-fd4a-9133-9357-07b4511d9cc1"}, traceId: 213e064e17556806297806251e834d'}
[02:03:50.268] [RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[02:03:50.546] 2025-08-20 02:03:50,546 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:50.547] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"31c1c5c8-f371-9ed1-a86f-242a9debdf26"}, traceId: 213e080f17556806301504125e0d27'}
[02:03:50.547] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:03:51.735] 2025-08-20 02:03:51,734 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:51.736] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e3b51b7e-b264-9893-a03b-902403b1c84d"}, traceId: 213e060b17556806313866859e8917'}
[02:03:51.736] [ERROR] Max retries reached after 5 attempts
[02:03:51.736] [API_FAILURE] All retries exhausted
[02:03:51.736]   [API_FAILURE] API failed (timeout or max retries)
[02:03:51.751] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:51.751] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:51.752] [AI_DEBUG] 生成的txt_content长度: 4714
[02:03:51.752] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:51.752]   - use_ai_classification=True
[02:03:51.752]   - ai_classifier=True
[02:03:51.752]   - txt_content_len=4714
[02:03:51.752]   - task_model=qwen2.5-72b-instruct
[02:03:51.755] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:51.766] 2025-08-20 02:03:51,766 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:51.766] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:51.766] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:51.766] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:51.766] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:51.766] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:51.766] 2025-08-20 02:03:51,766 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:51.793] 2025-08-20 02:03:51,793 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:51.793] 2025-08-20 02:03:51,793 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:51.793] 2025-08-20 02:03:51,793 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:51.796] [INFO] Tool embedding index loaded successfully
[02:03:51.796] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:51.797] [INFO] Operation semantic index initialized
[02:03:51.797] 
[02:03:51.797] [TURN 1/10]
[02:03:51.797] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:52.396] 2025-08-20 02:03:52,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:52.396] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9d1159d-f8a1-94f9-bf8b-2858921db4b1"}, traceId: 213e080f17556806319394130e0d27'}
[02:03:52.396] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:03:52.518] 2025-08-20 02:03:52,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:52.519] 2025-08-20 02:03:52,518 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:52.519] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:52.831] 2025-08-20 02:03:52,830 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:52.833] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22cd7fbb-590c-9fed-9d03-3ec4fc9e1dc3"}, traceId: 213e007617556806325804660e11c6'}
[02:03:52.834] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:03:53.066] 2025-08-20 02:03:53,066 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:53.155] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9851bf98-9efd-9a7d-8106-142667593b0a"}, traceId: 213e064e17556806328146266e834d'}
[02:03:53.156] [ERROR] Max retries reached after 5 attempts
[02:03:53.156] [API_FAILURE] All retries exhausted
[02:03:53.156]   [API_FAILURE] API failed (timeout or max retries)
[02:03:53.158] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:03:53.158] [AI_DEBUG] 测试失败，准备调用AI分类
[02:03:53.158] [AI_DEBUG] 生成的txt_content长度: 4711
[02:03:53.158] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:03:53.158]   - use_ai_classification=True
[02:03:53.158]   - ai_classifier=True
[02:03:53.158]   - txt_content_len=4711
[02:03:53.158]   - task_model=qwen2.5-72b-instruct
[02:03:53.161] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:03:53.169] 2025-08-20 02:03:53,169 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:03:53.169] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:03:53.169] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:03:53.169] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:03:53.169] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:03:53.169] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:03:53.169] 2025-08-20 02:03:53,169 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:03:53.187] 2025-08-20 02:03:53,187 - mcp_embedding_manager - INFO - FAISS index loaded
[02:03:53.187] 2025-08-20 02:03:53,187 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:03:53.187] 2025-08-20 02:03:53,187 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:03:53.190] [INFO] Tool embedding index loaded successfully
[02:03:53.190] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:03:53.190] [INFO] Operation semantic index initialized
[02:03:53.191] 
[02:03:53.191] [TURN 1/10]
[02:03:53.191] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:53.287] 2025-08-20 02:03:53,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:03:53.287] 2025-08-20 02:03:53,287 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:03:53.287] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:03:54.106] 2025-08-20 02:03:54,105 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:54.112] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1cfc2df0-349e-9e43-b65d-d651b97319f8"}, traceId: 213e064e17556806338593176e8229'}
[02:03:54.112] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:03:54.140] 2025-08-20 02:03:54,140 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:54.140] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a5eb053-4226-9500-9075-459a8aa80dae"}, traceId: 213e007617556806339044662e11c6'}
[02:03:54.140] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:03:54.997] 2025-08-20 02:03:54,997 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:54.997] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"42909c01-1823-96af-af89-2dee2cf52af4"}, traceId: 213e080f17556806347664140e0d27'}
[02:03:54.997] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:03:55.580] 2025-08-20 02:03:55,580 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:55.580] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2dfb2af5-8fef-9b61-8c6b-ebfc5b116a26"}, traceId: 213e064e17556806353253186e8229'}
[02:03:55.580] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:03:55.952] 2025-08-20 02:03:55,951 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:55.952] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"95e182db-296e-9bdc-814b-6a10b3757d2a"}, traceId: 213e007617556806357174669e11c6'}
[02:03:55.952] [RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[02:03:57.806] 2025-08-20 02:03:57,806 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:57.813] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ddcd6740-8c0d-99b1-aa86-543f2d2f8e6d"}, traceId: 213e064e17556806375743195e8229'}
[02:03:57.813] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:03:59.004] 2025-08-20 02:03:59,003 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:59.005]   [EARLY_EXIT] No actions taken, continuing...
[02:03:59.005] 
[02:03:59.005] [TURN 4/10]
[02:03:59.006] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:59.786] 2025-08-20 02:03:59,786 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:03:59.790] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"67b291a6-dd95-91d5-8cfe-e7ac42c0b1be"}, traceId: 213e064e17556806395483199e8229'}
[02:03:59.790] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:03:59.875] 2025-08-20 02:03:59,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:59.876]   [SEARCH] Query: file reader json
[02:03:59.878] 
[02:03:59.878] [TURN 2/10]
[02:03:59.879] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:03:59.884] 2025-08-20 02:03:59,884 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:03:59.885]   [EARLY_EXIT] No actions taken, continuing...
[02:03:59.885] 
[02:03:59.885] [TURN 5/10]
[02:03:59.886] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:00.740] 2025-08-20 02:04:00,739 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:00.741]   [EARLY_EXIT] No actions taken, continuing...
[02:04:00.741] 
[02:04:00.741] [TURN 3/10]
[02:04:00.744] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:00.791] 2025-08-20 02:04:00,790 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:00.791]   [EARLY_EXIT] No actions taken, continuing...
[02:04:00.791] 
[02:04:00.791] [TURN 6/10]
[02:04:00.791] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:01.094] 2025-08-20 02:04:01,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:01.094] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"87ad01ce-566c-9cb5-a773-3fe13dbd87be"}, traceId: 213e007617556806408924686e11c6'}
[02:04:01.094] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:04:01.188] 2025-08-20 02:04:01,188 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:01.189] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63f05a2e-04c9-931d-ae6d-991266f5718c"}, traceId: 213e080f17556806409374163e0d27'}
[02:04:01.190] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:04:02.039] 2025-08-20 02:04:02,039 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:02.040] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f38663f2-3c23-95cb-89b8-09f881551ff4"}, traceId: 213e007617556806417964687e11c6'}
[02:04:02.040] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:04:02.528] 2025-08-20 02:04:02,528 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:02.529] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c462a982-de82-990a-8ca6-a078be051a56"}, traceId: 213e080f17556806422824173e0d27'}
[02:04:02.529] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:04:03.409] 2025-08-20 02:04:03,408 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:03.413] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5ee4457-b9dc-908c-a7c8-68c664705ed5"}, traceId: 213e064e17556806431583205e8229'}
[02:04:03.413] [ERROR] Max retries reached after 5 attempts
[02:04:03.413] [API_FAILURE] All retries exhausted
[02:04:03.413]   [API_FAILURE] API failed (timeout or max retries)
[02:04:03.414] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:03.414] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:03.414] [AI_DEBUG] 生成的txt_content长度: 4717
[02:04:03.417] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:03.417]   - use_ai_classification=True
[02:04:03.417]   - ai_classifier=True
[02:04:03.417]   - txt_content_len=4717
[02:04:03.417]   - task_model=qwen2.5-72b-instruct
[02:04:03.418] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:03.539] 2025-08-20 02:04:03,539 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:03.539] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:03.539] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:03.560] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:03.563] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:03.563] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:03.568] 2025-08-20 02:04:03,568 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:03.799] 2025-08-20 02:04:03,798 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:03.799] 2025-08-20 02:04:03,799 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:03.799] 2025-08-20 02:04:03,799 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:03.804] [INFO] Tool embedding index loaded successfully
[02:04:03.824] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:03.824] [INFO] Operation semantic index initialized
[02:04:03.825] 
[02:04:03.825] [TURN 1/10]
[02:04:03.828] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:03.884] 2025-08-20 02:04:03,883 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:03.885] 2025-08-20 02:04:03,884 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:03.885] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:04.113] 2025-08-20 02:04:04,113 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:04.114] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93d4fecf-8a1e-9af3-bcfc-0ca632709111"}, traceId: 213e007617556806438644697e11c6'}
[02:04:04.114] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:04:04.712] 2025-08-20 02:04:04,712 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:04.713] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"16412ab0-b082-9ca3-9a64-119042c2e11c"}, traceId: 213e080f17556806444424178e0d27'}
[02:04:04.714] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:04:04.918] 2025-08-20 02:04:04,918 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:04.922] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1561f4c-e966-992a-8f0f-6a46de29a1c1"}, traceId: 213e041917556806446948971e2ba4'}
[02:04:04.922] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:06.267] 2025-08-20 02:04:06,267 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:06.268] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6262fe04-8e33-9658-9351-a16d86e089ad"}, traceId: 213e007617556806460284703e11c6'}
[02:04:06.268] [RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[02:04:06.563] 2025-08-20 02:04:06,563 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:06.567] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"537275fe-2b27-947f-9d23-fc2f3686aae5"}, traceId: 213e041917556806463298986e2ba4'}
[02:04:06.567] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:04:08.081] 2025-08-20 02:04:08,080 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:08.082] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"30359249-9bf8-90a1-b7b3-9e90e6e529cf"}, traceId: 213e080f17556806478244193e0d27'}
[02:04:08.082] [RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[02:04:08.855] 2025-08-20 02:04:08,855 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:08.856] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d3abcdad-fb0f-95ec-a434-eb6cab4297cd"}, traceId: 213e041917556806486201014e2ba4'}
[02:04:08.856] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:04:09.073] 2025-08-20 02:04:09,072 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:09.073] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"12cc684c-7ae4-9759-bdd1-1348e0c4e0c8"}, traceId: 213e007617556806488604713e11c6'}
[02:04:09.073] [ERROR] Max retries reached after 5 attempts
[02:04:09.073] [API_FAILURE] All retries exhausted
[02:04:09.073]   [API_FAILURE] API failed (timeout or max retries)
[02:04:09.082] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:09.082] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:09.082] [AI_DEBUG] 生成的txt_content长度: 9047
[02:04:09.082] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:09.082]   - use_ai_classification=True
[02:04:09.082]   - ai_classifier=True
[02:04:09.082]   - txt_content_len=9047
[02:04:09.082]   - task_model=qwen2.5-72b-instruct
[02:04:09.083] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:09.084] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:09.092] 2025-08-20 02:04:09,092 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:09.092] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:09.092] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:09.092] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:09.092] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:09.092] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:09.093] 2025-08-20 02:04:09,093 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:09.120] 2025-08-20 02:04:09,119 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:09.120] 2025-08-20 02:04:09,119 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:09.120] 2025-08-20 02:04:09,120 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:09.122] [INFO] Tool embedding index loaded successfully
[02:04:09.123] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:09.123] [INFO] Operation semantic index initialized
[02:04:09.124] 
[02:04:09.124] [TURN 1/10]
[02:04:09.124] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:09.895] 2025-08-20 02:04:09,895 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:09.897] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b23c71b9-e73a-9ead-8c30-68bfccaf3abb"}, traceId: 213e001317556806496715576e0bb2'}
[02:04:09.897] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:11.524] 2025-08-20 02:04:11,524 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:11.528] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e9b2db84-0c02-930b-b897-89f351917ba3"}, traceId: 213e041917556806512971055e2ba4'}
[02:04:11.528] [RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[02:04:11.568] 2025-08-20 02:04:11,568 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:11.569] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b855a243-3440-90f9-a4a2-1399d948e720"}, traceId: 213e001317556806513415582e0bb2'}
[02:04:11.569] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:12.926] 2025-08-20 02:04:12,926 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:12.926] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"13c6bfde-24c5-9693-b0de-96913ab32d2b"}, traceId: 213e080f17556806526334206e0d27'}
[02:04:12.926] [ERROR] Max retries reached after 5 attempts
[02:04:12.926] [API_FAILURE] All retries exhausted
[02:04:12.926]   [API_FAILURE] API failed (timeout or max retries)
[02:04:12.927] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:12.927] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:12.927] [AI_DEBUG] 生成的txt_content长度: 9338
[02:04:12.927] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:12.927]   - use_ai_classification=True
[02:04:12.927]   - ai_classifier=True
[02:04:12.927]   - txt_content_len=9338
[02:04:12.927]   - task_model=qwen2.5-72b-instruct
[02:04:12.927] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:12.927] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:12.935] 2025-08-20 02:04:12,935 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:12.935] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:12.935] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:12.936] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:12.936] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:12.936] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:12.936] 2025-08-20 02:04:12,936 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:12.963] 2025-08-20 02:04:12,962 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:12.963] 2025-08-20 02:04:12,963 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:12.963] 2025-08-20 02:04:12,963 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:12.965] [INFO] Tool embedding index loaded successfully
[02:04:12.966] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:12.966] [INFO] Operation semantic index initialized
[02:04:12.966] 
[02:04:12.966] [TURN 1/10]
[02:04:12.966] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:13.718] 2025-08-20 02:04:13,718 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:13.719]   [SEARCH] Query: network api fetch
[02:04:13.719] 
[02:04:13.719] [TURN 2/10]
[02:04:13.720] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:13.734] 2025-08-20 02:04:13,734 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:13.738] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2aa0fef-f559-9c83-a00c-0b61dcee1248"}, traceId: 213e06c117556806535152227e8ad0'}
[02:04:13.738] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:14.099] 2025-08-20 02:04:14,099 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:14.100] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9fa4e9db-0b7a-9350-8bb9-99f6eafd3eca"}, traceId: 213e001317556806538535595e0bb2'}
[02:04:14.100] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:04:15.465] 2025-08-20 02:04:15,465 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:15.465] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bb5a3bb4-2200-9005-a7bf-4dcc3f9b5752"}, traceId: 213e001317556806552825601e0bb2'}
[02:04:15.465] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:15.702] 2025-08-20 02:04:15,702 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:15.702]   [SEARCH] Query: network api fetch
[02:04:15.702] 
[02:04:15.702] [TURN 2/10]
[02:04:15.703] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:16.079] 2025-08-20 02:04:16,079 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:16.082] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a4538d7-1296-9058-8da1-bcf4fbac3a5d"}, traceId: 213e06c117556806558342240e8ad0'}
[02:04:16.082] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:04:16.533] 2025-08-20 02:04:16,533 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:16.534] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ebfbd58d-76a2-9374-8081-340ca7bb3a2c"}, traceId: 213e041917556806563071130e2ba4'}
[02:04:16.534] [ERROR] Max retries reached after 5 attempts
[02:04:16.534] [API_FAILURE] All retries exhausted
[02:04:16.534]   [API_FAILURE] API failed (timeout or max retries)
[02:04:16.537] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:16.537] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:16.537] [AI_DEBUG] 生成的txt_content长度: 4175
[02:04:16.537] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:16.537]   - use_ai_classification=True
[02:04:16.537]   - ai_classifier=True
[02:04:16.537]   - txt_content_len=4175
[02:04:16.537]   - task_model=qwen2.5-72b-instruct
[02:04:16.538] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:16.554] 2025-08-20 02:04:16,553 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:16.554] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:16.554] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:16.554] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:16.554] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:16.555] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:16.555] 2025-08-20 02:04:16,555 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:16.582] 2025-08-20 02:04:16,582 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:16.582] 2025-08-20 02:04:16,582 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:16.582] 2025-08-20 02:04:16,582 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:16.585] [INFO] Tool embedding index loaded successfully
[02:04:16.586] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:16.586] [INFO] Operation semantic index initialized
[02:04:16.586] 
[02:04:16.586] [TURN 1/10]
[02:04:16.586] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:16.918] 2025-08-20 02:04:16,918 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:16.919] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9218deb6-c1d8-9d4e-8cb8-543387463229"}, traceId: 213e001317556806566645607e0bb2'}
[02:04:16.919] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:04:16.980] 2025-08-20 02:04:16,979 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:16.982] 2025-08-20 02:04:16,981 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:16.983] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:17.042] 2025-08-20 02:04:17,042 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:17.044] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4949f61c-f679-9167-ba21-3f2adb23841e"}, traceId: 213e06c117556806568152246e8ad0'}
[02:04:17.044] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:17.348] 2025-08-20 02:04:17,348 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:17.353] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5af7de17-3eb1-9ffe-a911-73445f9e90c7"}, traceId: 213e058a17556806571783463e35e4'}
[02:04:17.353] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:18.844] 2025-08-20 02:04:18,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:18.851] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"801dc4a2-0e05-91b3-8ee5-5c2f82b93c60"}, traceId: 213e058a17556806586033468e35e4'}
[02:04:18.851] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:04:19.096] 2025-08-20 02:04:19,096 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:19.101]   [EARLY_EXIT] No actions taken, continuing...
[02:04:19.101] 
[02:04:19.101] [TURN 3/10]
[02:04:19.102] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:19.460] 2025-08-20 02:04:19,460 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:19.471] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3063a7aa-6bc1-95fc-a31a-1da2d336fbb6"}, traceId: 213e06c117556806592342253e8ad0'}
[02:04:19.471] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:20.776] 2025-08-20 02:04:20,776 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:20.776]   [EARLY_EXIT] No actions taken, continuing...
[02:04:20.777] 
[02:04:20.777] [TURN 3/10]
[02:04:20.777] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:21.157] 2025-08-20 02:04:21,157 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:21.157] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"878e513d-1965-9938-aea3-4ffad0669ae8"}, traceId: 213e001317556806609105618e0bb2'}
[02:04:21.158] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:21.762] 2025-08-20 02:04:21,761 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:21.766]   [EARLY_EXIT] No actions taken, continuing...
[02:04:21.766] 
[02:04:21.766] [TURN 4/10]
[02:04:21.766] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:21.773] 2025-08-20 02:04:21,773 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:21.777]   [SEARCH] Query: network api fetch
[02:04:21.777] 
[02:04:21.777] [TURN 2/10]
[02:04:21.778] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:22.069] 2025-08-20 02:04:22,069 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:22.074] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8212da4b-05b5-9cac-8964-f79f1358a1e4"}, traceId: 213e06c117556806618982259e8ad0'}
[02:04:22.074] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:22.139] 2025-08-20 02:04:22,139 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:22.143] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a2d8c7de-a565-994d-beba-fe2966a1eb7c"}, traceId: 213e058a17556806619113482e35e4'}
[02:04:22.144] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:22.830] 2025-08-20 02:04:22,830 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:22.830] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5c2de7ac-d493-9b4c-a600-cd7225ace9f4"}, traceId: 213e001317556806625705625e0bb2'}
[02:04:22.830] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:04:23.624] 2025-08-20 02:04:23,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:23.630] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1194b142-9269-9876-89f6-8d950e9c7c93"}, traceId: 213e06c117556806634382264e8ad0'}
[02:04:23.630] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:23.834] 2025-08-20 02:04:23,834 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:23.834] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3812d2f-de16-94b0-90a1-b762cd5d44e6"}, traceId: 213e058a17556806635753487e35e4'}
[02:04:23.834] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:25.018] 2025-08-20 02:04:25,018 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:25.024] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"23dbe7e1-b81a-9f27-a47e-69362185dfd0"}, traceId: 213e058a17556806647763493e35e4'}
[02:04:25.024] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:25.251] 2025-08-20 02:04:25,251 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:25.256] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dc888df7-a6a8-9765-9b61-b26b05d2fdf1"}, traceId: 213e06c117556806650212273e8ad0'}
[02:04:25.256] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:04:25.265] 2025-08-20 02:04:25,265 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:25.266] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"536ad2ff-22ad-91bc-9156-09e8c8e24d36"}, traceId: 213e001317556806650235649e0bb2'}
[02:04:25.266] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:04:26.543] 2025-08-20 02:04:26,543 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:26.546] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b2be5728-2c1a-9d87-871a-b1b66e97bb18"}, traceId: 213e058a17556806663213499e35e4'}
[02:04:26.546] [RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[02:04:28.125] 2025-08-20 02:04:28,125 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:28.126] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1a8bbdf-3ae8-933e-b783-1ddcdcb2f558"}, traceId: 213e06c117556806678982288e8ad0'}
[02:04:28.127] [RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[02:04:29.079] 2025-08-20 02:04:29,079 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:29.081]   [EARLY_EXIT] No actions taken, continuing...
[02:04:29.081] 
[02:04:29.081] [TURN 4/10]
[02:04:29.082] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:29.450] 2025-08-20 02:04:29,449 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:29.450] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aea3794e-ec0a-99a6-975c-28a9a6b0bcf0"}, traceId: 213e001317556806692185768e0bb2'}
[02:04:29.450] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:30.680] 2025-08-20 02:04:30,679 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:30.680] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c80df93e-c887-9128-99bd-e5c808f03aca"}, traceId: 213e001317556806704135820e0bb2'}
[02:04:30.680] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:04:31.175] 2025-08-20 02:04:31,174 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:31.178] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d04dc422-fbc8-9c5e-aa1b-39945c21e095"}, traceId: 213e058a17556806709223510e35e4'}
[02:04:31.178] [ERROR] Max retries reached after 5 attempts
[02:04:31.178] [API_FAILURE] All retries exhausted
[02:04:31.178]   [API_FAILURE] API failed (timeout or max retries)
[02:04:31.182] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.182] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:31.182] [AI_DEBUG] 生成的txt_content长度: 8899
[02:04:31.182] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.182]   - use_ai_classification=True
[02:04:31.183]   - ai_classifier=True
[02:04:31.183]   - txt_content_len=8899
[02:04:31.183]   - task_model=qwen2.5-72b-instruct
[02:04:31.183] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:31.183] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:31.185] Progress: 20/30 (Success: 0)
[02:04:31.195] 2025-08-20 02:04:31,194 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:31.195] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:31.195] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:31.195] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:31.195] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:31.195] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:31.195] 2025-08-20 02:04:31,195 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:31.243] 2025-08-20 02:04:31,243 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:31.243] 2025-08-20 02:04:31,243 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:31.243] 2025-08-20 02:04:31,243 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:31.246] [INFO] Tool embedding index loaded successfully
[02:04:31.247] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:31.247] [INFO] Operation semantic index initialized
[02:04:31.248] 
[02:04:31.248] [TURN 1/10]
[02:04:31.248] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:31.788] 2025-08-20 02:04:31,788 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:31.796] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db55f078-2702-9740-8ec9-0e9496884a2b"}, traceId: 213e06c117556806715662298e8ad0'}
[02:04:31.796] [ERROR] Max retries reached after 5 attempts
[02:04:31.796] [API_FAILURE] All retries exhausted
[02:04:31.796]   [API_FAILURE] API failed (timeout or max retries)
[02:04:31.797] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:31.797] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:31.797] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:31.797] [AI_DEBUG] 生成的txt_content长度: 9185
[02:04:31.797] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:31.797]   - use_ai_classification=True
[02:04:31.797]   - ai_classifier=True
[02:04:31.797]   - txt_content_len=9185
[02:04:31.797]   - task_model=qwen2.5-72b-instruct
[02:04:31.797] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:31.806] 2025-08-20 02:04:31,806 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:31.806] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:31.806] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:31.807] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:31.807] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:31.807] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:31.807] 2025-08-20 02:04:31,807 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:31.828] 2025-08-20 02:04:31,828 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:31.828] 2025-08-20 02:04:31,828 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:31.828] 2025-08-20 02:04:31,828 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:31.831] [INFO] Tool embedding index loaded successfully
[02:04:31.832] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:31.832] [INFO] Operation semantic index initialized
[02:04:31.832] 
[02:04:31.832] [TURN 1/10]
[02:04:31.832] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:32.060] 2025-08-20 02:04:32,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:32.060] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8aaf71f9-0842-9433-a751-a955e37d1c63"}, traceId: 213e065017556806718085842e7f2d'}
[02:04:32.060] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:04:32.593] 2025-08-20 02:04:32,592 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:32.593] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9cbe3e9-173d-968c-ae19-084af5f408a4"}, traceId: 213e063717556806723551870e8868'}
[02:04:32.594] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:32.966] 2025-08-20 02:04:32,966 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:32.967] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aad67e54-d027-9527-b01b-58bffa06f31f"}, traceId: 213e065017556806727285849e7f2d'}
[02:04:32.967] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:33.078] 2025-08-20 02:04:33,078 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:33.079] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5938defe-8011-9163-b2f4-09b421a86225"}, traceId: 213e001317556806728555848e0bb2'}
[02:04:33.079] [RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[02:04:34.184] 2025-08-20 02:04:34,184 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:34.184] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"031dd9c2-4137-95f6-90b1-33b29b16f455"}, traceId: 213e063717556806739651876e8868'}
[02:04:34.184] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:35.047] 2025-08-20 02:04:35,046 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:35.047] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0729bb5b-0ed7-9556-a59c-6630930cbad9"}, traceId: 213e001317556806747915870e0bb2'}
[02:04:35.047] [RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[02:04:35.579] 2025-08-20 02:04:35,579 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:35.579] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"251cae8b-ba8c-9dfe-88cf-d41c66d1bcba"}, traceId: 213e065017556806753205856e7f2d'}
[02:04:35.579] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:35.992] 2025-08-20 02:04:35,992 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:35.993] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f58fdc87-8500-9984-958a-ecce448fbc76"}, traceId: 213e063717556806757641883e8868'}
[02:04:35.993] [RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[02:04:38.188] 2025-08-20 02:04:38,188 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:38.189] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c376f748-a0d9-9396-8504-99065cdf381c"}, traceId: 213e065017556806779515866e7f2d'}
[02:04:38.189] [RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[02:04:39.768] 2025-08-20 02:04:39,767 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:39.770]   [SEARCH] Query: network api fetch
[02:04:39.771] 
[02:04:39.771] [TURN 2/10]
[02:04:39.771] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:40.145] 2025-08-20 02:04:40,144 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:40.145] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1b9f133c-45ab-9b88-9383-83833aa2fbd5"}, traceId: 213e063717556806799071896e8868'}
[02:04:40.145] [RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[02:04:40.754] 2025-08-20 02:04:40,754 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:40.757]   [EARLY_EXIT] No actions taken, continuing...
[02:04:40.757] 
[02:04:40.757] [TURN 5/10]
[02:04:40.757] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:41.033] 2025-08-20 02:04:41,032 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:41.033] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"16870620-911f-95c7-be39-cfefb17c7077"}, traceId: 213e063717556806807961900e8868'}
[02:04:41.033] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:41.137] 2025-08-20 02:04:41,137 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:41.138] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de5bea21-d14f-9501-b2e4-b3716ba60702"}, traceId: 213e001317556806808915942e0bb2'}
[02:04:41.138] [RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[02:04:42.378] 2025-08-20 02:04:42,377 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:42.378] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eeaee075-3200-9932-9e37-5fed7c9f3ed3"}, traceId: 213e065017556806821405885e7f2d'}
[02:04:42.378] [ERROR] Max retries reached after 5 attempts
[02:04:42.379] [API_FAILURE] All retries exhausted
[02:04:42.379]   [API_FAILURE] API failed (timeout or max retries)
[02:04:42.381] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:42.381] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:42.381] [AI_DEBUG] 生成的txt_content长度: 4153
[02:04:42.381] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:42.381]   - use_ai_classification=True
[02:04:42.381]   - ai_classifier=True
[02:04:42.381]   - txt_content_len=4153
[02:04:42.381]   - task_model=qwen2.5-72b-instruct
[02:04:42.384] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:42.393] 2025-08-20 02:04:42,393 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:42.393] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:42.393] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:42.393] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:42.393] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:42.393] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:42.394] 2025-08-20 02:04:42,394 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:42.422] 2025-08-20 02:04:42,422 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:42.422] 2025-08-20 02:04:42,422 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:42.422] 2025-08-20 02:04:42,422 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:42.426] [INFO] Tool embedding index loaded successfully
[02:04:42.433] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:42.434] [INFO] Operation semantic index initialized
[02:04:42.435] 
[02:04:42.435] [TURN 1/10]
[02:04:42.436] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:42.772] 2025-08-20 02:04:42,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:04:42.772] 2025-08-20 02:04:42,772 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:04:42.773] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:04:42.848] 2025-08-20 02:04:42,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:42.849]   [EARLY_EXIT] No actions taken, continuing...
[02:04:42.849] 
[02:04:42.849] [TURN 6/10]
[02:04:42.850] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:43.531] 2025-08-20 02:04:43,531 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:43.532] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1809050f-67fa-90c0-9b3b-40de30a31489"}, traceId: 213e063717556806833481907e8868'}
[02:04:43.532] [RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[02:04:43.668] 2025-08-20 02:04:43,668 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:43.674]   [SEARCH] Query: data processing parser
[02:04:43.675] 
[02:04:43.675] [TURN 2/10]
[02:04:43.676] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:43.735] 2025-08-20 02:04:43,735 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:43.739]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:04:43.739] 
[02:04:43.739] [TURN 7/10]
[02:04:43.740] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:44.029] 2025-08-20 02:04:44,028 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:44.034] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"615a3af6-cfd4-98b0-89be-61a5a5b566a1"}, traceId: 213e04ea17556806838137040e3487'}
[02:04:44.035] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:04:44.105] 2025-08-20 02:04:44,105 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:44.106] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cde9333f-d3f1-903c-89ec-dcf7a8e1abee"}, traceId: 213e001317556806838755957e0bb2'}
[02:04:44.106] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:04:45.429] 2025-08-20 02:04:45,429 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:45.434] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"499a16d3-6f6f-9cc9-9341-408baa68b0a7"}, traceId: 213e04ea17556806851437043e3487'}
[02:04:45.434] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:04:45.762] 2025-08-20 02:04:45,761 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:45.763] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ae868b27-18b3-9381-b5ff-1c14d35f34b4"}, traceId: 213e001317556806855065964e0bb2'}
[02:04:45.763] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:04:46.351] 2025-08-20 02:04:46,351 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:46.352] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7fda313-9794-9f04-a193-2df8b9146a61"}, traceId: 213e063717556806861591917e8868'}
[02:04:46.352] [RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[02:04:47.576] 2025-08-20 02:04:47,576 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:47.579] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f24c2d0-5b89-9248-b67c-2d223996002b"}, traceId: 213e04ea17556806873897051e3487'}
[02:04:47.579] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:04:47.893] 2025-08-20 02:04:47,892 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:47.897] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d113c228-31e4-9b7d-841b-5ea111728904"}, traceId: 213e001317556806876595974e0bb2'}
[02:04:47.899] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:04:49.569] 2025-08-20 02:04:49,569 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:49.570] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fbe03221-f7b7-98a2-a6e2-a279ad07363d"}, traceId: 213e001317556806892715978e0bb2'}
[02:04:49.570] [RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[02:04:50.067] 2025-08-20 02:04:50,066 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:50.067] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c1b22d87-b6d8-969e-b75e-3b5aaecdf394"}, traceId: 213e04ea17556806898267064e3487'}
[02:04:50.067] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:04:50.632] 2025-08-20 02:04:50,632 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:50.633] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8c1882a-df85-96cd-84b3-3c86f9a496ef"}, traceId: 213e063717556806904031934e8868'}
[02:04:50.633] [ERROR] Max retries reached after 5 attempts
[02:04:50.633] [API_FAILURE] All retries exhausted
[02:04:50.633]   [API_FAILURE] API failed (timeout or max retries)
[02:04:50.634] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:50.634] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:50.634] [AI_DEBUG] 生成的txt_content长度: 8899
[02:04:50.634] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:04:50.634]   - use_ai_classification=True
[02:04:50.634]   - ai_classifier=True
[02:04:50.634]   - txt_content_len=8899
[02:04:50.634]   - task_model=qwen2.5-72b-instruct
[02:04:50.634] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:50.634] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:50.641] 2025-08-20 02:04:50,641 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:50.641] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:50.641] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:50.642] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:50.642] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:50.642] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:50.642] 2025-08-20 02:04:50,642 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:50.673] 2025-08-20 02:04:50,673 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:50.673] 2025-08-20 02:04:50,673 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:50.674] 2025-08-20 02:04:50,673 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:50.676] [INFO] Tool embedding index loaded successfully
[02:04:50.691] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:50.692] [INFO] Operation semantic index initialized
[02:04:50.692] 
[02:04:50.692] [TURN 1/10]
[02:04:50.692] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:51.475] 2025-08-20 02:04:51,475 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:51.475] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea6539e8-1e54-949d-88e1-dadc41d49175"}, traceId: 213e064b17556806912117928e7b1d'}
[02:04:51.475] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:04:52.720] 2025-08-20 02:04:52,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:52.720] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06f696d9-608d-93ef-a25c-62e45ed69691"}, traceId: 213e064b17556806924897933e7b1d'}
[02:04:52.720] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:04:53.182] 2025-08-20 02:04:53,182 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:53.187] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4c94a548-5116-9ccc-a3e2-22dfd100a916"}, traceId: 213e04ea17556806929547077e3487'}
[02:04:53.187] [ERROR] Max retries reached after 5 attempts
[02:04:53.187] [API_FAILURE] All retries exhausted
[02:04:53.187]   [API_FAILURE] API failed (timeout or max retries)
[02:04:53.190] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:04:53.190] [AI_DEBUG] 测试失败，准备调用AI分类
[02:04:53.190] [AI_DEBUG] 生成的txt_content长度: 8445
[02:04:53.191] [AI_DEBUG] _ai_classify_with_txt_content called:[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:04:53.191]   - use_ai_classification=True
[02:04:53.191]   - ai_classifier=True
[02:04:53.191]   - txt_content_len=8445
[02:04:53.191]   - task_model=qwen2.5-72b-instruct
[02:04:53.191] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:04:53.191] 
[02:04:53.204] 2025-08-20 02:04:53,204 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:04:53.204] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:04:53.204] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:04:53.204] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:04:53.204] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:04:53.204] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:04:53.205] 2025-08-20 02:04:53,204 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:04:53.249] 2025-08-20 02:04:53,249 - mcp_embedding_manager - INFO - FAISS index loaded
[02:04:53.249] 2025-08-20 02:04:53,249 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:04:53.249] 2025-08-20 02:04:53,249 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:04:53.252] [INFO] Tool embedding index loaded successfully
[02:04:53.253] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:04:53.255] [INFO] Operation semantic index initialized
[02:04:53.256] 
[02:04:53.256] [TURN 1/10]
[02:04:53.256] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:53.987] 2025-08-20 02:04:53,987 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:53.988] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"62a98e08-60d8-9563-ac51-2a7d2a0d2643"}, traceId: 213e065017556806937727084e7ff3'}
[02:04:53.988] [RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[02:04:54.872] 2025-08-20 02:04:54,872 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:54.873]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:04:54.873] 
[02:04:54.873] [TURN 8/10]
[02:04:54.874] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:55.169] 2025-08-20 02:04:55,169 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:55.169] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5f61bbbc-2d6d-9425-bb2c-d0cfd35c8f04"}, traceId: 213e065017556806948747124e7ff3'}
[02:04:55.170] [RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[02:04:55.832] 2025-08-20 02:04:55,832 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:55.834]   [SEARCH] Query: data processing parser
[02:04:55.834] 
[02:04:55.834] [TURN 2/10]
[02:04:55.836] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:55.917] 2025-08-20 02:04:55,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:55.918]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:04:55.918] 
[02:04:55.918] [TURN 9/10]
[02:04:55.919] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:56.311] 2025-08-20 02:04:56,311 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:56.311] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"afc4dbcd-90e5-95a5-9a45-1f89ea07cab8"}, traceId: 213e001317556806960546016e0bb2'}
[02:04:56.311] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:56.704] 2025-08-20 02:04:56,704 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:04:56.705]   [EARLY_EXIT] No actions taken, continuing...
[02:04:56.705] 
[02:04:56.705] [TURN 3/10]
[02:04:56.706] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:04:57.230] 2025-08-20 02:04:57,230 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:57.231] 2025-08-20 02:04:57,231 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:57.231] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6c589be-9d7c-9106-9bf6-97de6df5d319"}, traceId: 213e064b17556806968407952e7b1d'}
[02:04:57.231] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:04:57.231] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"292947c7-229f-99cb-b663-62102510ef0f"}, traceId: 213e065017556806967907189e7ff3'}
[02:04:57.231] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:04:57.816] 2025-08-20 02:04:57,815 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:57.816] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"afa9f19e-a78c-9649-9536-0160fa0b9780"}, traceId: 213e001317556806975696048e0bb2'}
[02:04:57.816] [RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[02:04:58.673] 2025-08-20 02:04:58,672 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:58.673] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b6f0dec-8718-9a54-8425-89e6e8f7f502"}, traceId: 213e064b17556806984447958e7b1d'}
[02:04:58.673] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:04:59.061] 2025-08-20 02:04:59,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:04:59.062] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e05247bc-e0a4-9b52-9f31-372d118e0ca8"}, traceId: 213e065017556806988037245e7ff3'}
[02:04:59.062] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:05:00.067] 2025-08-20 02:05:00,067 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:00.067] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd75d1cf-1053-9d91-891f-b1be51e10e75"}, traceId: 213e001317556806997516079e0bb2'}
[02:05:00.067] [RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[02:05:00.900] 2025-08-20 02:05:00,900 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:00.900] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"493ed531-b045-99e2-8f94-c20dfe5df130"}, traceId: 213e064b17556807006687972e7b1d'}
[02:05:00.900] [RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[02:05:02.920] 2025-08-20 02:05:02,920 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:02.924]   [SEARCH] Query: file reader
[02:05:02.925] 
[02:05:02.925] [TURN 2/10]
[02:05:02.926] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:03.065] 2025-08-20 02:05:03,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:03.066] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5fc91892-a4fb-9f4a-9d22-8942a11ee6d8"}, traceId: 213e001317556807028186126e0bb2'}
[02:05:03.066] [RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[02:05:03.767] 2025-08-20 02:05:03,767 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:03.769]   [EARLY_EXIT] No actions taken, continuing...
[02:05:03.769] 
[02:05:03.769] [TURN 3/10]
[02:05:03.770] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:04.132] 2025-08-20 02:05:04,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:04.132] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"84975501-316f-9d27-9226-2f694a860b32"}, traceId: 213e065017556807039057265e7ff3'}
[02:05:04.132] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:05:04.474] 2025-08-20 02:05:04,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:04.474] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c1c873d-5752-9a83-9bef-c51e4565c540"}, traceId: 213e064b17556807042428030e7b1d'}
[02:05:04.475] [RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[02:05:05.453] 2025-08-20 02:05:05,452 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:05.454] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0dd79bb-8a47-91ec-a8a8-4f5ad69a563f"}, traceId: 213e065017556807052007268e7ff3'}
[02:05:05.454] [RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[02:05:05.590] 2025-08-20 02:05:05,590 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:05.592] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e9ccbc0d-1a38-9a87-8a82-65873f5dbc69"}, traceId: 213e001317556807053406166e0bb2'}
[02:05:05.592] [ERROR] Max retries reached after 5 attempts
[02:05:05.592] [API_FAILURE] All retries exhausted
[02:05:05.592]   [API_FAILURE] API failed (timeout or max retries)
[02:05:05.592] [ASSISTED] Task received 3 format helps, final result: failure
[02:05:05.595] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:05.595] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:05.595] [AI_DEBUG] 生成的txt_content长度: 12702
[02:05:05.595] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:05.595]   - use_ai_classification=True
[02:05:05.595] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:05:05.595]   - ai_classifier=True
[02:05:05.595]   - txt_content_len=12702
[02:05:05.595]   - task_model=qwen2.5-72b-instruct
[02:05:05.595] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:05.606] 2025-08-20 02:05:05,606 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:05:05.606] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:05:05.606] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:05:05.610] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:05:05.610] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:05:05.610] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:05:05.610] 2025-08-20 02:05:05,610 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:05:05.636] 2025-08-20 02:05:05,636 - mcp_embedding_manager - INFO - FAISS index loaded
[02:05:05.636] 2025-08-20 02:05:05,636 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:05:05.636] 2025-08-20 02:05:05,636 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:05:05.638] [INFO] Tool embedding index loaded successfully
[02:05:05.639] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:05:05.639] [INFO] Operation semantic index initialized
[02:05:05.640] 
[02:05:05.640] [TURN 1/10]
[02:05:05.640] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:06.520] 2025-08-20 02:05:06,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:06.527] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"678ee2d0-91a9-908a-800d-22afc5af3929"}, traceId: 213e007617556807062893919e1208'}
[02:05:06.527] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:05:06.706] 2025-08-20 02:05:06,706 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:06.707] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cfaebe27-a234-9ef4-9752-476e0d020dc0"}, traceId: 213e065017556807064797272e7ff3'}
[02:05:06.707] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:05:07.810] 2025-08-20 02:05:07,810 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:07.812]   [EARLY_EXIT] No actions taken, continuing...
[02:05:07.812] 
[02:05:07.812] [TURN 4/10]
[02:05:07.813] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:08.179] 2025-08-20 02:05:08,178 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:08.180] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e784cf5a-8443-9f25-bc76-eac79f7d3520"}, traceId: 213e064b17556807079488042e7b1d'}
[02:05:08.180] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:08.317] 2025-08-20 02:05:08,317 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:08.324] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f9846f0a-b3ba-9e9a-9569-a2a55b33e333"}, traceId: 213e007617556807080483925e1208'}
[02:05:08.324] [RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[02:05:09.770] 2025-08-20 02:05:09,769 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:09.771] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f307b984-25a3-90e0-97ac-7792b6056aba"}, traceId: 213e065017556807095897279e7ff3'}
[02:05:09.771] [RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[02:05:09.882] 2025-08-20 02:05:09,881 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:09.882] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c143c15a-1619-9f2c-969a-8a6a5ea5251c"}, traceId: 213e064b17556807096008047e7b1d'}
[02:05:09.883] [RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[02:05:10.670] 2025-08-20 02:05:10,670 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:10.675] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"020830e4-cf92-9b49-afce-2e0d09f46b59"}, traceId: 213e007617556807104193937e1208'}
[02:05:10.675] [RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[02:05:11.451] 2025-08-20 02:05:11,451 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:11.451] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dc964686-4494-9177-85e4-5c17a8dc74f2"}, traceId: 213e064b17556807112298062e7b1d'}
[02:05:11.451] [RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[02:05:13.751] 2025-08-20 02:05:13,750 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:13.755] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"21606195-4106-96b4-ac04-97158b1642da"}, traceId: 213e007617556807135083946e1208'}
[02:05:13.755] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:05:13.826] 2025-08-20 02:05:13,826 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:13.827] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7205cfd7-4d71-9fd2-9f3e-1d060008e7fa"}, traceId: 213e065017556807135597288e7ff3'}
[02:05:13.827] [ERROR] Max retries reached after 5 attempts
[02:05:13.827] [API_FAILURE] All retries exhausted
[02:05:13.827]   [API_FAILURE] API failed (timeout or max retries)
[02:05:13.830] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:13.831] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:13.831] [AI_DEBUG] 生成的txt_content长度: 9156
[02:05:13.831] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:13.831]   - use_ai_classification=True
[02:05:13.831]   - ai_classifier=True
[02:05:13.831]   - txt_content_len=9156
[02:05:13.831]   - task_model=qwen2.5-72b-instruct
[02:05:13.831] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:13.831] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:05:13.846] 2025-08-20 02:05:13,846 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:05:13.846] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:05:13.846] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:05:13.846] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:05:13.846] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:05:13.846] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:05:13.846] 2025-08-20 02:05:13,846 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:05:13.886] 2025-08-20 02:05:13,886 - mcp_embedding_manager - INFO - FAISS index loaded
[02:05:13.886] 2025-08-20 02:05:13,886 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:05:13.886] 2025-08-20 02:05:13,886 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:05:13.888] [INFO] Tool embedding index loaded successfully
[02:05:13.889] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:05:13.889] [INFO] Operation semantic index initialized
[02:05:13.890] 
[02:05:13.890] [TURN 1/10]
[02:05:13.890] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:13.980] 2025-08-20 02:05:13,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:13.980] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"016abe77-2339-9b66-b44d-2e3192a35e00"}, traceId: 213e064b17556807137708069e7b1d'}
[02:05:13.980] [RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[02:05:14.591] 2025-08-20 02:05:14,591 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:14.591] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad2d3a40-e3a4-9340-bc3a-633e628cde93"}, traceId: 213e043117556807144176115e2270'}
[02:05:14.591] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:16.023] 2025-08-20 02:05:16,023 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:16.024] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bab7f8d1-25dd-983c-948e-70b4ab5b55b8"}, traceId: 213e007617556807157533955e1208'}
[02:05:16.024] [ERROR] Max retries reached after 5 attempts
[02:05:16.024] [API_FAILURE] All retries exhausted
[02:05:16.024]   [API_FAILURE] API failed (timeout or max retries)
[02:05:16.028] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:16.028] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:16.029] [AI_DEBUG] 生成的txt_content长度: 4382
[02:05:16.029] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:16.029]   - use_ai_classification=True
[02:05:16.029]   - ai_classifier=True
[02:05:16.029]   - txt_content_len=4382
[02:05:16.029]   - task_model=qwen2.5-72b-instruct
[02:05:16.049] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[02:05:16.064] 2025-08-20 02:05:16,064 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
[02:05:16.064] [InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[02:05:16.064] [InteractiveExecutor] Using prompt type: optimal for API key selection
[02:05:16.064] [InteractiveExecutor] API model name: qwen2.5-72b-instruct
[02:05:16.064] [MCPEmbeddingManager] Reusing existing singleton instance (id: 12983230800)
[02:05:16.064] [MCPEmbeddingManager] Current cache size: 30 embeddings
[02:05:16.064] 2025-08-20 02:05:16,064 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[02:05:16.144] 2025-08-20 02:05:16,143 - mcp_embedding_manager - INFO - FAISS index loaded
[02:05:16.144] 2025-08-20 02:05:16,144 - mcp_embedding_manager - INFO - Updated dimension to 3072
[02:05:16.144] 2025-08-20 02:05:16,144 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[02:05:16.148] [INFO] Tool embedding index loaded successfully
[02:05:16.152] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[02:05:16.152] [INFO] Operation semantic index initialized
[02:05:16.153] 
[02:05:16.153] [TURN 1/10]
[02:05:16.154] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:16.484] 2025-08-20 02:05:16,484 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:16.484] 2025-08-20 02:05:16,484 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:16.484] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:16.614] 2025-08-20 02:05:16,614 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:16.615] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04b5bb5a-20dd-9db6-8aa8-cc47e5c72015"}, traceId: 213e064b17556807163718077e7b1d'}
[02:05:16.615] [ERROR] Max retries reached after 5 attempts
[02:05:16.615] [API_FAILURE] All retries exhausted
[02:05:16.615]   [API_FAILURE] API failed (timeout or max retries)
[02:05:16.616] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:16.616] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:16.616] [AI_DEBUG] 生成的txt_content长度: 8741
[02:05:16.616] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:16.616]   - use_ai_classification=True
[02:05:16.616]   - ai_classifier=True
[02:05:16.616]   - txt_content_len=8741
[02:05:16.616]   - task_model=qwen2.5-72b-instruct
[02:05:16.616] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:16.881] 2025-08-20 02:05:16,881 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:16.883] 2025-08-20 02:05:16,883 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:16.885]   [SEARCH] Query: file reader json
[02:05:16.885] 
[02:05:16.885] [TURN 2/10]
[02:05:16.885] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"56f4f718-0627-937f-a57d-046d9dc218d0"}, traceId: 213e059617556807167044222e3d94'}
[02:05:16.885] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:16.885] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:17.937] 2025-08-20 02:05:17,937 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:17.938]   [EARLY_EXIT] No actions taken, continuing...
[02:05:17.938] 
[02:05:17.938] [TURN 3/10]
[02:05:17.938] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:18.301] 2025-08-20 02:05:18,301 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:18.301] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27eaeced-afe6-965c-ba59-b130128978a0"}, traceId: 213e043117556807180726140e2270'}
[02:05:18.301] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:05:18.508] 2025-08-20 02:05:18,507 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:18.516] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"199f5692-df0e-939f-b581-112e53d962f3"}, traceId: 213e059617556807183234227e3d94'}
[02:05:18.516] [RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[02:05:20.011] 2025-08-20 02:05:20,011 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:20.012] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab64cf4c-0ac5-9726-8797-b6761aba62db"}, traceId: 213e043117556807198336142e2270'}
[02:05:20.012] [RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[02:05:20.796] 2025-08-20 02:05:20,794 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:20.797] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aeafa36c-87ca-9688-9623-064768e61a7e"}, traceId: 213e059617556807205524234e3d94'}
[02:05:20.797] [RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[02:05:21.440] 2025-08-20 02:05:21,440 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:21.442] [LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"030c36da-9922-9fbc-af2a-197b0febbbec"}, traceId: 213e043117556807212196145e2270'}
[02:05:21.443] [RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[02:05:22.558] 2025-08-20 02:05:22,558 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:22.561] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"beeeae12-659c-92a3-83ab-f41d7937ebaf"}, traceId: 213e059617556807223214244e3d94'}
[02:05:22.561] [RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[02:05:24.643] 2025-08-20 02:05:24,643 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:24.645] [LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"abde6661-11c4-90b8-bd31-7aa345ade8df"}, traceId: 213e043117556807244166153e2270'}
[02:05:24.645] [RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[02:05:25.978] 2025-08-20 02:05:25,978 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:25.978] [LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fcddd0cd-de3b-9573-a890-7c4ff26fdb7c"}, traceId: 213e059617556807256884265e3d94'}
[02:05:25.979] [ERROR] Max retries reached after 5 attempts
[02:05:25.979] [API_FAILURE] All retries exhausted
[02:05:25.979]   [API_FAILURE] API failed (timeout or max retries)
[02:05:25.991] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:25.991] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:25.991] [AI_DEBUG] 生成的txt_content长度: 4601
[02:05:25.991] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:25.991]   - use_ai_classification=True
[02:05:25.991]   - ai_classifier=True
[02:05:25.991]   - txt_content_len=4601
[02:05:25.991]   - task_model=qwen2.5-72b-instruct
[02:05:26.572] 2025-08-20 02:05:26,571 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 400 Bad Request"
[02:05:26.573] 2025-08-20 02:05:26,572 - txt_based_ai_classifier - ERROR - AI model call failed: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.1 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
[02:05:26.573] [AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.6
[02:05:28.998] 2025-08-20 02:05:28,997 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:29.000]   [EARLY_EXIT] No actions taken, continuing...
[02:05:29.000] 
[02:05:29.000] [TURN 4/10]
[02:05:29.001] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:29.867] 2025-08-20 02:05:29,866 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:29.870]   [EARLY_EXIT] No actions taken, continuing...
[02:05:29.870] 
[02:05:29.870] [TURN 5/10]
[02:05:29.870] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:30.819] 2025-08-20 02:05:30,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:30.821]   [EARLY_EXIT] No actions taken, continuing...
[02:05:30.821] 
[02:05:30.821] [TURN 6/10]
[02:05:30.823] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:31.477] 2025-08-20 02:05:31,477 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:31.477]   [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns
[02:05:31.477] 
[02:05:31.477] [TURN 7/10]
[02:05:31.478] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:31.844] 2025-08-20 02:05:31,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:31.845] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e36d153f-d470-9ab9-9b92-3783022b9c2c"}, traceId: 213e043117556807316116206e2270'}
[02:05:31.845] [RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[02:05:32.751] 2025-08-20 02:05:32,751 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:32.752] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ebf6dc02-7781-9406-94f0-2066f51755cb"}, traceId: 213e043117556807325636209e2270'}
[02:05:32.752] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:34.963] 2025-08-20 02:05:34,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:34.965]   [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns
[02:05:34.965] 
[02:05:34.965] [TURN 8/10]
[02:05:34.966] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:35.297] 2025-08-20 02:05:35,296 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:35.297] [LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d777d83-405d-97f8-bdfc-b45fc20d2a1e"}, traceId: 213e043117556807351026216e2270'}
[02:05:35.297] [RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[02:05:36.690] 2025-08-20 02:05:36,690 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[02:05:36.691] [LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b348cb27-fb01-91a6-ad90-60bb1c531b74"}, traceId: 213e043117556807364546219e2270'}
[02:05:36.691] [RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[02:05:38.847] 2025-08-20 02:05:38,847 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:38.848]   [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns
[02:05:38.849] 
[02:05:38.849] [TURN 9/10]
[02:05:38.849] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:39.817] 2025-08-20 02:05:39,817 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:39.818]   [FORMAT_ISSUE] Turn 9: No tools executed after multiple turns
[02:05:39.818] 
[02:05:39.818] [TURN 10/10]
[02:05:39.819] [LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[02:05:40.874] 2025-08-20 02:05:40,873 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
[02:05:40.874]   [FORMAT_ISSUE] Turn 10: No tools executed after multiple turns
[02:05:40.875] [ASSISTED] Task received 5 format helps, final result: failure
[02:05:40.877] [DEBUG] Got result for task: has_result=True, save_logs=True
[02:05:40.877] [AI_DEBUG] 测试失败，准备调用AI分类
[02:05:40.877] [AI_DEBUG] 生成的txt_content长度: 15153
[02:05:40.877] [AI_DEBUG] _ai_classify_with_txt_content called:
[02:05:40.877]   - use_ai_classification=True
[02:05:40.877]   - ai_classifier=True
[02:05:40.877]   - txt_content_len=15153
[02:05:40.877]   - task_model=qwen2.5-72b-instruct
[02:05:40.877] [AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.95
[02:05:40.880] Progress: 30/30 (Success: 0)
[02:05:40.881] 
[02:05:40.881] [INFO] Batch writing 30 records to database (qwen2.5-72b-instruct:30)
[02:05:40.881] 2025-08-20 02:05:40,881 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-72b-instruct:30)
[02:05:40.882] [INFO] Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
[02:05:40.882] 2025-08-20 02:05:40,882 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
[02:05:40.883] [INFO] 数据已同步到Parquet存储
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO - Database saved successfully
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO - ============================================================
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO - Batch test completed at 2025-08-20T02:05:40.883324
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO - Summary:
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO -   - Total tests: 30
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO -   - Successful: 0
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO -   - Failed: 30
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO -   - Success rate: 0.0%
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250820_020213.log
[02:05:40.883] 2025-08-20 02:05:40,883 - batch_test_runner - INFO - ============================================================
[02:05:40.884] 
[02:05:40.884] ✅ 批测试完成
[02:05:40.884]    成功: 0/30
[02:05:40.884]    失败: 30/30
[02:05:40.884] 
[02:05:40.884] 📤 最终保存30个测试结果...
[02:05:40.885] [DEBUG] 创建新的manager实例: key=True_
[02:05:40.994] [INFO] 已将 5 个汇总写入Parquet
[02:05:40.994] [INFO] 刷新缓存到磁盘 (已累积30个结果)
[02:05:40.995] ✅ 已保存 30 个测试结果到数据库
[02:05:41.073] [INFO] 刷新manager缓存: key=True_

==================================================
分片 qwen2.5-72b-instruct_easy_key2 完成
退出码: 0
总行数: 2202
运行时间: 212.8秒
时间: 2025-08-20T02:05:42.710767
