=== 测试开始时间: 2025年 8月30日 星期六 05时59分47秒 EDT ===
=== 环境变量 ===
USE_RESULT_COLLECTOR=true
STORAGE_FORMAT=json
CUSTOM_WORKERS=50
=== 命令执行 ===
INFO:__main__:使用环境变量 RATE_MODE: fixed
INFO:__main__:初始化实例池: 17个实例 (2个Azure + 6个IdealLab)
INFO:result_collector:ResultCollector初始化，临时目录: temp_results
INFO:result_collector:ResultAggregator初始化
INFO:__main__:🆕 启用ResultCollector模式，支持零冲突并发
INFO:__main__:资源池状态: 17个实例, 容量1306
INFO:__main__:
🎯 检测到Qwen模型，使用队列调度器
INFO:__main__:   模型: qwen2.5-72b-instruct → Key0
INFO:__main__:   Prompt类型: flawed_missing_step
INFO:__main__:   难度: easy
INFO:__main__:🔄 Key0: 执行 qwen2.5-72b-instruct-easy
INFO:__main__:🎯 使用qwen智能分片策略: qwen2.5-72b-instruct
INFO:__main__:🔄 真正多Key并发策略:
INFO:__main__:   模型: qwen2.5-72b-instruct (规模: 72b)
INFO:__main__:   使用Keys: key0, key1, key2
INFO:__main__:   总实例数: 20
INFO:__main__:   分片数: 3 (每个key独立分片)
INFO:__main__:   实例分配: [7, 7, 6]
INFO:__main__:   🚀 启用3倍API并发！
INFO:__main__:🚀 启动3个分片并发执行
INFO:__main__:  IdealLab qwen模型限制: qwen-key0 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 0
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_missing_step_key0: qwen-key0
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片1: qwen-key0 (7个实例)
INFO:__main__:  IdealLab qwen模型限制: qwen-key1 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 1
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_missing_step_key1: qwen-key1
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片2: qwen-key1 (7个实例)
INFO:__main__:  使用IdealLab API Key 2
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_missing_step_key2: qwen-key2
INFO:__main__:   实例数: 6, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片3: qwen-key2 (6个实例)
INFO:__main__:等待分片1完成（20实例×50workers，最多等待50分钟）...
2025-08-30 05:59:47,322 - faiss.loader - INFO - Loading faiss.
2025-08-30 05:59:47,322 - faiss.loader - INFO - Loading faiss.
2025-08-30 05:59:47,322 - faiss.loader - INFO - Loading faiss.
2025-08-30 05:59:47,332 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 05:59:47,332 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 05:59:47,333 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 05:59:47,890 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 05:59:47,890 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 05:59:47,890 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 05:59:47,890 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 05:59:47,890 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 05:59:47,890 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 05:59:47,890 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 05:59:47,890 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 05:59:47,890 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 05:59:47,891 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 05:59:47,891 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 05:59:47,891 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 05:59:47,891 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 05:59:47,891 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 05:59:47,891 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 05:59:47,891 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 05:59:47,891 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 05:59:47,891 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 05:59:47,892 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 05:59:47,892 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 05:59:47,892 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 05:59:47,935 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 05:59:47,935 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 05:59:47,935 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 05:59:47,935 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 05:59:47,935 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 05:59:47,935 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 05:59:47,935 - batch_test_runner - INFO - ============================================================
2025-08-30 05:59:47,935 - batch_test_runner - INFO - ============================================================
2025-08-30 05:59:47,935 - batch_test_runner - INFO - ============================================================
2025-08-30 05:59:47,935 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 05:59:47,935 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 05:59:47,935 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 05:59:47,935 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 05:59:47,935 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 05:59:47,935 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_055947.log
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_055947.log
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_055947.log
2025-08-30 05:59:47,936 - batch_test_runner - INFO - ============================================================
2025-08-30 05:59:47,936 - batch_test_runner - INFO - ============================================================
2025-08-30 05:59:47,936 - batch_test_runner - INFO - ============================================================
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Initializing test components...
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Initializing test components...
2025-08-30 05:59:47,936 - batch_test_runner - INFO - Initializing test components...
2025-08-30 05:59:48,410 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 05:59:48,413 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 05:59:48,413 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 05:59:48,414 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 05:59:48,416 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 05:59:48,416 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 05:59:48,417 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 05:59:48,417 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 05:59:48,419 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 05:59:48,419 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 05:59:48,419 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 05:59:48,421 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 05:59:48,965 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 05:59:48,971 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 05:59:48,981 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 05:59:49,086 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 05:59:49,086 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 05:59:49,086 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 05:59:49,454 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 05:59:49,454 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 05:59:49,455 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 05:59:49,878 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 05:59:49,879 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 05:59:49,881 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 05:59:49,882 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 05:59:49,883 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 05:59:49,883 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 05:59:49,963 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 05:59:49,973 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 05:59:49,976 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 05:59:50,089 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 05:59:50,103 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 05:59:50,106 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 05:59:50,421 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 05:59:50,422 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:50,433 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 05:59:50,433 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:50,437 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 05:59:50,438 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:50,464 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:50,464 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:50,464 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:50,466 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:50,466 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:50,466 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:50,470 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:50,470 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:50,470 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:50,476 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 05:59:50,477 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 05:59:50,477 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 05:59:50,478 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 05:59:50,479 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 05:59:50,479 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 05:59:50,486 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 05:59:50,486 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 05:59:50,487 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 05:59:50,487 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 05:59:50,487 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 05:59:50,487 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 05:59:50,487 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 05:59:50,487 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 05:59:50,489 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 05:59:50,489 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 05:59:50,490 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 05:59:50,493 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 05:59:50,493 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 05:59:50,493 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 05:59:50,493 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 05:59:53,153 - unified_training_manager - INFO - Using device: cpu
2025-08-30 05:59:53,153 - unified_training_manager - INFO - Using device: cpu
2025-08-30 05:59:53,153 - unified_training_manager - INFO - Using device: cpu
2025-08-30 05:59:53,876 - unified_training_manager - INFO - Task filtering results:
2025-08-30 05:59:53,876 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 05:59:53,876 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 05:59:53,876 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 05:59:53,876 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 05:59:53,876 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 05:59:53,877 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 05:59:53,877 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 05:59:53,879 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 05:59:53,885 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 05:59:53,885 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 05:59:53,886 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 05:59:53,886 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 05:59:53,886 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 05:59:53,886 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 05:59:53,886 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 05:59:53,903 - unified_training_manager - INFO - Task filtering results:
2025-08-30 05:59:53,903 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 05:59:53,903 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 05:59:53,903 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 05:59:53,903 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 05:59:53,904 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 05:59:53,904 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 05:59:53,904 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 05:59:53,907 - unified_training_manager - INFO - Task filtering results:
2025-08-30 05:59:53,907 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 05:59:53,907 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 05:59:53,907 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 05:59:53,907 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 05:59:53,907 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 05:59:53,907 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 05:59:53,907 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 05:59:53,908 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 05:59:53,908 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 05:59:53,910 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 05:59:53,910 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 05:59:53,910 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 05:59:53,913 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 05:59:53,921 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 05:59:53,922 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 05:59:53,922 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 05:59:53,922 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 05:59:53,922 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 05:59:53,943 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 05:59:53,944 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 05:59:53,961 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 05:59:53,962 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 05:59:53,962 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 05:59:53,964 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 05:59:53,965 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 05:59:53,965 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 05:59:53,966 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 05:59:53,966 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 05:59:53,983 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 05:59:53,983 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 05:59:53,994 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 05:59:53,995 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 05:59:54,418 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 05:59:54,418 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 05:59:54,446 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 05:59:54,446 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 05:59:54,458 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 05:59:54,458 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 05:59:54,487 - batch_test_runner - INFO - Initialization complete
2025-08-30 05:59:54,504 - batch_test_runner - INFO - Initialization complete
2025-08-30 05:59:54,521 - batch_test_runner - INFO - Initialization complete
2025-08-30 05:59:54,596 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-30 05:59:54,596 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 05:59:54,597 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-30 05:59:54,616 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-30 05:59:54,616 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 05:59:54,617 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-30 05:59:54,620 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 05:59:54,626 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 05:59:54,627 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:54,627 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 05:59:54,628 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:54,635 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-30 05:59:54,635 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 05:59:54,635 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-30 05:59:54,639 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 05:59:54,649 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 05:59:54,650 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:54,650 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 05:59:54,651 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:54,659 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 05:59:54,663 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:54,663 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:54,663 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:54,667 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 05:59:54,667 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 05:59:54,667 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:54,668 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 05:59:54,688 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:54,688 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:54,689 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:54,698 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:54,699 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:54,699 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:54,708 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:54,708 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:54,708 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:54,720 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:54,720 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:54,721 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:54,731 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 05:59:54,731 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 05:59:54,731 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 05:59:56,320 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:56,325 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:56,818 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:56,837 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:56,875 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 05:59:57,790 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:58,299 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:58,322 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:58,334 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 05:59:58,961 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 05:59:59,337 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 05:59:59,366 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:00,283 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:00,380 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:00,885 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:01,392 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:01,402 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:01,405 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:02,273 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:02,667 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:03,429 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:04,228 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:05,001 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:05,224 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:05,235 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:05,817 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:06,313 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:06,987 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:07,281 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:08,026 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:08,324 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:08,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:08,951 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:09,471 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_missing_step']
难度: easy
目标: 每种配置 6 个实例
============================================================
○ simple_task         :   0/  6 已完成 (需要补充 6 个)
○ basic_task          :   0/  6 已完成 (需要补充 6 个)
○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
○ api_integration     :   0/  6 已完成 (需要补充 6 个)
○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)

⏳ 需要运行 30 个新测试

▶ 准备 simple_task (6 个实例)...

▶ 准备 basic_task (6 个实例)...

▶ 准备 data_pipeline (6 个实例)...

▶ 准备 api_integration (6 个实例)...

▶ 准备 multi_stage_pipeline (6 个实例)...

▶ 开始执行 30 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x111f81b40>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 06:00:09,492 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:09,492 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:09,507 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:09,517 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:09,517 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:09,517 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:10,114 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:10,471 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:10,849 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:10,997 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:11,495 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:11,510 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:11,510 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:11,538 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:11,538 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:11,538 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_missing_step']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x109a1a210>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 06:00:11,999 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:12,011 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_missing_step']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x11481e560>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 06:00:12,492 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:12,866 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:00:12,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:13,544 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:14,044 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:14,532 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:15,488 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:16,147 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:16,429 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:16,431 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:16,727 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:17,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:17,174 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:17,457 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:18,287 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:18,507 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:19,016 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:19,521 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:19,557 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:19,561 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:19,779 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:20,102 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:20,626 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:20,645 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:20,646 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:20,670 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:20,670 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:20,670 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:20,987 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:22,304 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:22,544 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:22,548 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:23,037 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:23,588 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:23,603 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:23,604 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:23,627 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:23,627 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:23,627 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:24,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:24,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:25,203 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:26,110 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:26,140 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:26,148 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:26,630 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:27,147 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:28,597 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:00:28,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:29,118 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:29,146 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:29,162 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:29,180 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x151bd1950>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3958ba3-18b0-92a5-963a-39cbf9c8ce79"}, traceId: 2150409b17565479960515222e07da'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e091429-aab5-9b42-8519-cd96f42bad55"}, traceId: 2150409517565479960642994eea97'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f6a15c6-b37c-956f-95dc-3173b282aa76"}, traceId: 2150409b17565479975355229e07da'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"706f6435-f7e2-9080-8d61-a123f070154f"}, traceId: 2150409517565479996073010eea97'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"131ba436-483a-9b6f-a2f0-5e4d484eb8db"}, traceId: 2150409b17565480006385259e07da'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2229b1c6-fe5c-997a-9cea-6aa4cd7d3ac0"}, traceId: 2150409517565480014823018eea97'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"97681515-08fd-9fa2-953f-776aee3b9de8"}, traceId: 2150409b17565480044665272e07da'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1a1ba8d0-de9a-90ad-a094-e1fa2d1c0e01"}, traceId: 2150409517565480055023047eea97'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e190b191-89a1-975a-b7af-0bac5451cb10"}, traceId: 2150409517565480081873058eea97'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3bf75a0e-f0bd-9c0b-be9a-f26c8fc868d5"}, traceId: 2150409b17565480086925285e07da'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4498
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4498
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-30 06:00:29,181 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:29,203 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:29,203 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:29,203 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:29,644 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:29,656 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:29,656 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:29,678 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:29,678 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:29,678 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:30,168 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:30,168 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:30,181 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:30,181 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:30,203 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:30,203 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:30,203 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:30,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:30,708 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:30,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x153d451c0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized
[INFO] Operation semantic index initialized

[TURN 1/10]

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5cbf7d0d-f00e-93d8-a2c1-8b26160a00d5"}, traceId: 215045a817565479960324539e7e24'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"353dc9d6-cf1b-99a3-a6fd-ae2548c6999e"}, traceId: 2150415b17565479970183220ee5bd'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"edd2ff4a-950c-9adb-bc46-1e1e1b407482"}, traceId: 215045a817565479985714552e7e24'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"428178c2-fbcd-948c-803a-15416fc34f88"}, traceId: 2150415b17565480006243238ee5bd'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8a456df4-8288-9947-a357-a632ec72589f"}, traceId: 215045a817565480018904566e7e24'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2ed8eb6c-f7bf-9a39-a6b5-23de8359815e"}, traceId: 2150415b17565480025873240ee5bd'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91a3b5f2-ef3c-9fb8-8688-082acb761949"}, traceId: 215045a817565480064944594e7e24'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef3389f2-8703-9c2d-9cb0-71a4fd3b2203"}, traceId: 2150415b17565480075553255ee5bd'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"07ea924d-1000-930e-821e-e1f7f04531de"}, traceId: 215045a817565480086774600e7e24'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70861ba8-18b5-9dfb-becc-a618254d0335"}, traceId: 2150415b17565480096903265ee5bd'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6b26589-8bdf-9ba8-9d1a-6880009e47de"}, traceId: 215045a817565480112154613e7e24'}2025-08-30 06:00:31,214 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:31,756 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:32,454 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:32,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:33,317 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:33,510 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:33,937 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:00:34,172 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:00:34,358 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:34,911 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:35,359 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:35,373 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:35,374 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x12cf87f80>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ac34dc8-ef75-9832-8986-66b5f935f70a"}, traceId: 2150409b17565479960387519e0a91'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"647a3f6f-ca50-9413-8ed3-fe7ef2cd10fd"}, traceId: 2150409b17565479975317533e0a91'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9265e1fb-05b2-980f-8498-c8015a5e4eb9"}, traceId: 215045af17565479985732057e8238'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"60902d0f-b390-9d8d-9b5b-5049030641fe"}, traceId: 2150409b17565480001197546e0a91'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed56778a-c945-9820-9edc-b4a3282e9985"}, traceId: 215045af17565480006322058e8238'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f4a0422b-78b3-9558-aa01-20b741b95809"}, traceId: 215045af17565480034492070e8238'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b06b30b1-089f-9642-8cbe-e7474f56f781"}, traceId: 2150409b17565480044577557e0a91'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1a4d2326-219f-9bff-8987-1d9246506e0d"}, traceId: 215045af17565480075642086e8238'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b83a1c7-07bd-970e-9439-42fdc4485eb8"}, traceId: 215045af17565480107162105e8238'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12444
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12444
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-30 06:00:35,847 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:35,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:36,492 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:37,271 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:37,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:39,370 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:39,449 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:39,467 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:39,467 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:39,492 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:39,492 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:39,492 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:39,508 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:39,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:39,760 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:40,104 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:00:40,451 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:40,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:41,135 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:41,467 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:42,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:42,750 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:42,838 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:43,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:43,853 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:44,381 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:44,382 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:44,401 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:45,511 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:45,661 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:45,677 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:46,311 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:46,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:46,581 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:47,235 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:47,759 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:48,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:49,357 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:49,371 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:49,371 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:49,403 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:49,403 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:49,403 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:49,854 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:50,381 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:50,381 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:51,038 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a693807-824d-9d65-a193-82a651e4541d"}, traceId: 213e064717565480099636497e87ef'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b20bd3ff-d0d5-963a-8022-62f320fd0215"}, traceId: 2150409517565480102153066eea97'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf041a39-c9fa-94c0-aa89-143cac1f72fc"}, traceId: 213e042f17565480122611930e24f9'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f46c36e7-67c2-9085-9bcc-bc94a19241fa"}, traceId: 2150409517565480127583075eea97'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"94cfeac2-0980-9f80-a5af-5c01468bdda7"}, traceId: 213e06c817565480146551121e83c2'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b46826e7-f041-9be0-bcc2-2442b81da268"}, traceId: 2150409517565480166873093eea97'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22b77d18-40e2-908f-90e4-ae9434ca64ca"}, traceId: 213e007f17565480182688682eea02'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6ab4a7f9-27c5-92a4-a0cf-84f999fe5d1e"}, traceId: 2150409517565480187853112eea97'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8dadc9b7-eefb-9d9b-b86f-906e5456ef42"}, traceId: 2150409517565480217783123eea97'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"086ddb26-3d4b-9f84-a4bc-07a281143c01"}, traceId: 213e006b17565480228246036ee9f9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4370
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4370
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27b754b0-71fc-9e11-bdab-9a255a10bb86"}, traceId: 2150457117565480244321505e79d5'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b33af971-f771-9f7a-ac52-fa27aa921779"}, traceId: 2150409517565480258783142eea97'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"384ccd6e-8cf6-97d3-8d64-cfd2755fd0b2"}, traceId: 2150457117565480263751514e79d5'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d589fb33-643b-950b-b215-80044e1b2013"}, traceId: 2150409517565480288743160eea97'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct2025-08-30 06:00:51,429 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:51,442 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:51,952 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:51,971 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:00:51,971 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:51,997 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:51,997 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:51,997 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:53,414 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:53,418 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:53,425 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b35c4f9-0695-9b49-8f08-e2ea9137cae5"}, traceId: 2150415b17565480117283276ee5bd'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad25ba7c-4e67-9e5a-8ce1-e3973c639a04"}, traceId: 215045a817565480156424628e7e24'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fac8cf50-5905-91c0-8883-aed9938606aa"}, traceId: 2150415b17565480187673312ee5bd'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9735b09a-7b55-9dc2-a0bd-b008c3f892c4"}, traceId: 215045a817565480198434643e7e24'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12560
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12560
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18a3f096-7986-9419-ac8d-f58164ea175c"}, traceId: 2150415b17565480207403319ee5bd'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ffd4431f-5def-9a0d-a8e0-e7fba6839225"}, traceId: 213e043117565480215116374e22b1'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8b80eb0-df83-9352-9e5e-19fcb6620e6f"}, traceId: 2150415b17565480232883329ee5bd'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f5f36df6-47a0-926c-ab28-434010acc92e"}, traceId: 213e007617565480238135337e1141'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"46902c2b-6cfd-9331-b7d6-e7043159fd49"}, traceId: 2150415b17565480253543336ee5bd'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fff7265d-be0a-919e-8d6f-53f8a8595240"}, traceId: 213e062b17565480258915552e80b9'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5f0a1cf-2eff-9fca-8858-07f2f36f3b07"}, traceId: 213e007317565480283703769ee312'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"28f17bf5-54c4-97da-8226-26316c8f8130"}, traceId: 2150415b17565480288553346ee5bd'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16552
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16552
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efdc4a95-575f-9ba7-bf7b-6779c916e23b"}, traceId: 2150458117565480304914487e82c3'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...2025-08-30 06:00:53,426 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:00:53,449 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:00:53,449 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:00:53,449 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:00:53,568 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:53,952 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:53,952 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:54,975 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:55,098 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:00:55,498 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:56,012 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:56,528 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:56,528 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:00:57,270 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:58,326 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:00:58,835 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:59,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:59,040 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:00:59,294 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:00:59,818 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:00,340 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8656bd53-b1a7-9f2a-b010-126a342b013c"}, traceId: 2150409b17565480112227580e0a91'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b0d5202e-00f7-9ff4-9b7c-c32e67eb0c7e"}, traceId: 213e059617565480132701516e3db6'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c3af709-77a3-94a5-904d-4615007abbbf"}, traceId: 2150409b17565480137617590e0a91'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af0fb9fa-e7b6-9438-b08e-30ba83c13ba2"}, traceId: 213e06c317565480156705267e7ca3'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b64cf9a3-16bc-9de4-9b1f-763a7151f9ef"}, traceId: 2150409b17565480177227613e0a91'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"577f8954-2e4c-930c-b44a-a825d1c61a6e"}, traceId: 213e043a17565480187933873e20cf'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.85
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"daf95fb5-effd-9a87-bb41-2d324f558bd8"}, traceId: 2150409b17565480193317626e0a91'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"76451b0a-5a50-9537-ad73-b0b88d736828"}, traceId: 2150409b17565480217667637e0a91'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd7ad0bf-ed4e-9f41-b074-cfe9536e9330"}, traceId: 213e006d17565480223015116e1193'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"901f75bb-e731-989d-b891-1ab1f04bae3d"}, traceId: 2150409b17565480258617650e0a91'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9b9c1bf2-8b16-9f59-9c39-f37108f7f471"}, traceId: 213e065117565480288805673e8046'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf36d5b1-7d9e-9f32-afae-82a2bbb8222c"}, traceId: 2150409b17565480293617662e0a91'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14561
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14561
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"48cf0b50-745a-94e1-a1ad-09dae069e0c9"}, traceId: 213e065417565480309171927e7fe1'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_parser

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7691d16-413a-9b20-9934-fb0688a1bcd2"}, traceId: 2150443817565480346188671e89f1'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...2025-08-30 06:01:00,466 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:00,867 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:00,867 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:01,055 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:01,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:02,341 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:02,440 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:03,281 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:03,910 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:04,082 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:04,297 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:04,795 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:04,835 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:05,294 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:05,313 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:05,915 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:05,947 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:06,383 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:06,791 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:06,870 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:07,366 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:08,368 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:09,309 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:09,976 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:10,300 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:10,302 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:10,316 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:10,316 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:10,347 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:10,347 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:10,347 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:11,350 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:11,350 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:11,541 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:11,552 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:11,553 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:11,577 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:11,578 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:11,578 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:12,400 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:13,022 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:13,162 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:13,216 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:13,340 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:14,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:14,655 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:15,135 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:15,160 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:15,661 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:16,172 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d0208938-f81e-9bda-8c25-5523804d072f"}, traceId: 2150458117565480335724498e82c3'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"28866328-5278-9f19-b65a-95293d6b75b5"}, traceId: 2150411817565480346235977e0d77'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e14a60e-2bf3-94e0-9b51-8f0118d75316"}, traceId: 2150458117565480356014509e82c3'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ee6dc364-56a2-9ba0-8e9e-5f1fddd421ae"}, traceId: 2150455217565480364873802e7f9b'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"afe8e121-0a20-9449-901a-d5eab44a47fb"}, traceId: 2150458117565480396234534e82c3'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf94d3d9-2c3e-9d08-b61f-80559965a223"}, traceId: 215040be17565480406512250ededc'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6ed4d35-59f8-9fcd-b570-af4a0ea9ba85"}, traceId: 2150458117565480416134541e82c3'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d51a83a-f6b0-994a-83ee-8df8950569e7"}, traceId: 213e043117565480430923152e2356'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"108bf1eb-229e-9e65-b70c-4c33de152b07"}, traceId: 2150458117565480435934551e82c3'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7adc8753-ae70-906d-955f-3d44ccec38cf"}, traceId: 213e06a017565480458263764e76dd'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18a81092-8c53-95a4-b7fe-41ae3d69da10"}, traceId: 2150458117565480464184558e82c3'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eeed67a9-d2e7-9bf2-83b8-9042aa1bc2f5"}, traceId: 2150417517565480495608308ee0c0'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4fe31033-0ab4-9974-a282-e00a7ce02658"}, traceId: 2150458117565480511264588e82c3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14534
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14534
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2f90c47-c8bc-9df8-8b88-390864a9e202"}, traceId: 2150430c17565480526787374e1e2a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-30 06:01:16,183 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:16,183 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:16,206 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:16,206 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:16,206 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:16,687 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:17,719 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:17,738 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:17,738 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:17,781 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:17,781 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:17,781 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:17,921 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:18,228 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:18,228 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b05177b-b3ab-95a8-8898-ee8cda8d8875"}, traceId: 2150457117565480298731525e79d5'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16380
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16380
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"52f500f3-4ae0-9cc6-ac49-ded80fd02041"}, traceId: 2150430917565480299492109e1dd0'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"49bef7b4-eda2-9c90-9979-cab9df522012"}, traceId: 2150430917565480316482113e1dd0'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e867740f-4c8a-90ea-baaa-616549ade5e2"}, traceId: 2150457117565480325521534e79d5'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"644afb11-e332-9adf-8216-1bddacc9d86c"}, traceId: 2150430917565480345802123e1dd0'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"82cfdc8c-528e-93de-8b74-80298efa13f1"}, traceId: 2150457117565480374881554e79d5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"adf7a0b7-e405-939b-a9ab-c99bc86adbfe"}, traceId: 2150430917565480386002138e1dd0'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4381
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4381
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6ba53bbf-f02a-979b-b894-a02e4207735b"}, traceId: 2150417917565480403701127eeda8'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a56cfcbb-2d82-9445-98ff-86bb2755a22b"}, traceId: 213e059617565480425841607e3db6'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51bbecaf-457b-9465-95ac-e08dcf82f4a4"}, traceId: 2150430917565480447912163e1dd0'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aec31a58-e7a4-982d-917e-dedfebdd5534"}, traceId: 2150436a17565480455531692e21c2'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3caf43c4-5ed9-9d05-a42b-9b5a8e601194"}, traceId: 2150430917565480469222175e1dd0'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b10798a0-297d-9633-aa38-ede89f278f79"}, traceId: 2150430917565480495482183e1dd0'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e096612-1d50-9e6a-b902-e6908a71b785"}, traceId: 213e007d17565480502968770ef065'}2025-08-30 06:01:18,746 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:19,227 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:19,434 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:01:19,541 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:19,911 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:20,340 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:20,588 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:20,872 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:21,073 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:21,144 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:21,381 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:21,382 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:22,376 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:22,376 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1579932b-e588-9779-935a-f7fe43fadf4d"}, traceId: 215040b917565480350786453eefd1'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5ac3468c-8672-99c5-a921-b4e1676b45f3"}, traceId: 2150421317565480370052358e3526'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"00d0e5c9-6445-991f-8030-1d1f48e3660b"}, traceId: 215040b917565480374776459eefd1'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27c4b9b6-2fcc-9773-9632-649a74aed4b2"}, traceId: 213e057b17565480401432466e3e0b'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"48276605-9032-972b-be48-54a24b6a969f"}, traceId: 215040b917565480435776480eefd1'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88b5b8c8-d922-9a67-b350-f8f4a47cabc9"}, traceId: 213e06ba17565480443032820e8979'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"870fa7ff-e8f9-9755-b82c-0329ec14cde3"}, traceId: 215040b917565480457966505eefd1'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a62c99be-66ff-9bcd-abf3-eacf60ca0c01"}, traceId: 213e01f617565480485568179e15cf'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14677
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14677
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fde4e89a-77a8-95f7-8b9a-454055ac354a"}, traceId: 215040b917565480505486574eefd1'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"71f4f1c4-0615-96bb-80b0-2fb5cd82dd31"}, traceId: 215042f917565480506625279e1ad3'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de72f86f-7c18-9a15-aece-70b0b251c7b3"}, traceId: 215040b917565480526536639eefd1'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2708badf-0ec3-9a96-9a17-fa6c5d964bca"}, traceId: 215042f917565480531715328e1ad3'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b5db2d14-f941-9fd1-bcbd-ecab646067f6"}, traceId: 215042f917565480552445339e1ad3'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c1ac741-5860-9a44-a3c7-5d6dda277502"}, traceId: 215040b917565480557536671eefd1'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [SEARCH] Query: data validation

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7a15c65-9ee8-9f91-bdaf-a10c45060e7b"}, traceId: 215040b917565480594806711eefd1'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...2025-08-30 06:01:22,384 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:22,885 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:24,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:24,369 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:24,560 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:24,576 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:24,588 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:24,604 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:24,604 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:24,635 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:24,636 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:24,636 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:25,087 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:25,398 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:26,644 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:27,164 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:27,165 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:27,172 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:27,176 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:27,177 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:27,184 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:27,199 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:27,199 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:27,199 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:29,252 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:29,287 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:29,365 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:30,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:30,230 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:30,754 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:30,754 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:30,754 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:30,765 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:30,766 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:30,790 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:30,790 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:30,790 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:32,375 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:32,557 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:32,562 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:33,899 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:34,477 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:35,130 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:35,210 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"054d9cfc-a8e0-901d-83b1-dc5d3304fb34"}, traceId: 215042f917565480527662118e1b15'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"64f9fa2f-d231-9234-8e24-9f51472b84a1"}, traceId: 2150457917565480542126473e88d5'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"988afa11-0e2c-9988-a95b-4e887d8abf76"}, traceId: 215042f917565480547222135e1b15'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"85410872-53cc-9317-ab3d-526b91215f84"}, traceId: 213e043117565480565422705e2126'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6959622c-42e4-9109-b9d0-c066bc2115a2"}, traceId: 213e069217565480600288351e837b'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb91d19a-bb45-9b26-8c99-cf2f58d3b1bb"}, traceId: 215042f917565480606172163e1b15'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14601
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14601
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"330cb07f-d115-91b7-b55c-ae974d7d1aea"}, traceId: 215042f917565480635142169e1b15'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6db9dea6-8e53-91c5-8c8e-3fb9e08d57b9"}, traceId: 213e065017565480645483460e813c'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d2c54c9-de49-9713-9ec1-b42590afc319"}, traceId: 215042f917565480660972180e1b15'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f785b8fd-8296-9ae8-b82e-32bf6f7b171b"}, traceId: 215042f917565480694972192e1b15'}
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"626bbc93-c763-918f-983a-8d1234ac2788"}, traceId: 213e065017565480707754723e7e46'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a91cff5a-c956-9f89-9afc-dfedf6028acd"}, traceId: 215045f517565480723943771e7f8c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4498
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4498
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"60a5895b-8f19-9a1a-8ff6-31f74082991c"}, traceId: 215045f517565480748823780e7f8c'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a07eb75-de1c-9d78-a991-f608118ee0d4"}, traceId: 215042f917565480753892212e1b15'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted2025-08-30 06:01:35,225 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:35,225 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:35,250 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:35,250 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:35,250 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:35,304 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:35,728 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:35,743 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:35,743 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:35,775 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:35,775 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:35,775 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:36,237 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:36,244 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:36,744 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:36,891 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:37,447 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:37,660 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:38,178 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:38,197 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:38,717 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:39,003 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:39,150 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:01:39,927 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:39,969 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:40,438 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:40,742 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:41,762 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:42,285 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:42,285 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:42,808 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:01:42,910 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:43,857 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:01:44,250 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e783baac-b9e4-956a-8e10-f3fadac6e133"}, traceId: 2150430917565480531732257e1dd0'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81d8fd79-643b-9760-8d19-a0228e8e6345"}, traceId: 213e041917565480557816075e2d86'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2335337e-9ee5-9d92-ae21-e20edaef97ff"}, traceId: 213e007617565480575795018e11e7'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e8722f6-f740-9ccf-9856-0c12dd146de1"}, traceId: 2150430917565480594892288e1dd0'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d606689-eee1-93dd-87d8-ffd87d9db3e3"}, traceId: 213e007017565480600345504eeb7a'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8a7ef70b-b0f4-92a2-80b7-b9fa10730db4"}, traceId: 2150430917565480624892303e1dd0'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"12d3bccb-5e8e-9a67-bc1b-91a447ed4359"}, traceId: 213e063817565480645424458e821c'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9509a519-1047-99d2-b460-e4ded850bc82"}, traceId: 2150430917565480666032331e1dd0'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24c08825-97a1-98dd-a6b9-778b667112a4"}, traceId: 213e064b17565480700401774e7a79'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12423
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12423
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61522cfa-cf28-952f-8c35-5664a5f6378a"}, traceId: 2150430917565480705112348e1dd0'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bcb03d0a-35a6-9904-8ffc-ea631eb36bf3"}, traceId: 2150434117565480716058878e1e83'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"669534a4-14e8-9d82-8559-055fd0073d8e"}, traceId: 2150430917565480727512355e1dd0'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"56020314-6064-958c-838b-38a52aae2b9d"}, traceId: 2150434117565480743678885e1e83'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f2258166-938c-95d7-8996-d5e01a71b68a"}, traceId: 2150430917565480748782376e1dd0'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"be4d5556-cfa7-960f-b327-070b40a3d124"}, traceId: 2150434117565480774478892e1e83'}2025-08-30 06:01:44,818 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "

  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0651122a-5b98-95b8-ac5f-497863da129f"}, traceId: 215042f917565480616375385e1ad3'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ce8fcff-c5ec-9c70-a069-d8a51b4f383e"}, traceId: 215040b917565480645126731eefd1'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4644aa53-6037-9095-8a29-ebc1ba653cc2"}, traceId: 215040b917565480655786735eefd1'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c796790-f378-9122-8d45-f879c429a518"}, traceId: 215042f917565480660975398e1ad3'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2eca8c41-90a9-9147-bcf3-22bc50a867c6"}, traceId: 215042f917565480676055402e1ad3'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"911288cc-5d3a-9aa9-b744-83f29a99dd39"}, traceId: 215040b917565480684716744eefd1'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1bd5aae6-d2b4-97ab-afb0-a4901ca93966"}, traceId: 215042f917565480705145415e1ad3'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"46899059-3600-93f8-b279-97071e2cbdbf"}, traceId: 215040b917565480733526765eefd1'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"76174b60-f79a-96cc-9677-9a2f39c5d393"}, traceId: 215042f917565480738735427e1ad3'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e61c5ee-ee7e-94a9-8d33-093fc34b38fc"}, traceId: 215040b917565480758846775eefd1'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cac2a7e3-ead5-9a9d-9245-69c54342ccb8"}, traceId: 215042f917565480769415440e1ad3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14861
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14861
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22dd5078-952a-9209-9a5b-9daa9a29e024"}, traceId: 215040b917565480784516786eefd1'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"833af97d-2664-9ee2-921c-abec925615c6"}, traceId: 213e065e17565480795956796e80fc'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"71d9e72b-2f6f-9a81-a907-0c2751dc1e73"}, traceId: 215040b917565480810936800eefd1'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2554459e-dffa-9d47-a9c5-eadd42b502a9"}, traceId: 213e066417565480816352189e81f0'}2025-08-30 06:01:45,101 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:45,272 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:45,751 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:45,767 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:45,827 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:45,836 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:45,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:46,339 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:46,897 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:47,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:49,101 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:49,246 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:49,916 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:50,330 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:50,784 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:51,267 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:51,275 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:51,283 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:51,283 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:51,309 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:51,309 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:51,309 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:51,852 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:52,313 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:52,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:52,489 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:52,489 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:52,513 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:52,513 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:52,513 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:52,953 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:53,037 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:53,337 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:54,044 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:54,343 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:54,343 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:54,869 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:55,916 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7ba77977-6a60-9f36-beca-40a5a501057d"}, traceId: 215045f517565480774523788e7f8c'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8275a6a4-1119-938e-901b-c79bdf32dfa8"}, traceId: 2150439017565480784547087e2481'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14516
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14516
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8f089c7-3ae1-98c2-938e-156042207af3"}, traceId: 215045f517565480805993799e7f8c'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c55386cc-59e0-9834-92bd-a352196e907c"}, traceId: 2150439017565480815997098e2481'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"640645ff-16db-9775-a18d-bd4ff23440a1"}, traceId: 2150439017565480832857107e2481'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf2b566b-1464-925d-95e4-a14147629c99"}, traceId: 215045f517565480838073806e7f8c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ab26d47-01fb-9eb1-9adc-c076185c300f"}, traceId: 213e006e17565480851438851e1462'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"792acd08-034a-93e2-82b3-22d663d1f83c"}, traceId: 213e064d17565480869262186e83f0'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a97cbde8-d1c8-9483-93ea-4375d86b6edf"}, traceId: 2150439017565480863997113e2481'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=dependency_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4352
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4352
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a7ca1ab-3840-9791-9005-f5e5c87abf1f"}, traceId: 213e060b17565480894587911e8938'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"368ed989-53b8-9be4-8185-e418a02a3091"}, traceId: 2150439017565480899437136e2481'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a0eb996-6d44-9f70-b60c-ebb4442f98a2"}, traceId: 213e007617565480923258407e1342'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a77abaa-57c0-9757-bd2d-fb8dee3ae59d"}, traceId: 2150439017565480944267161e2481'}
[ERROR] Max retries reached after 5 attempts2025-08-30 06:01:55,926 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:01:55,927 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:01:55,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:55,950 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:01:55,950 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:01:55,950 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:01:56,842 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:01:57,105 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:57,180 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:01:57,396 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:57,399 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:57,490 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:57,922 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:58,418 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:01:58,420 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:59,092 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:59,587 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:01:59,981 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:01:59,989 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:00,495 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:00,506 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:01,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:01,550 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:02,053 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:02,499 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:02,507 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:03,002 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:04,161 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:05,478 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:06,028 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:06,053 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:06,054 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:06,060 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:06,093 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:06,093 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:06,093 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:06,511 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:07,151 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:07,542 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:07,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b79472c3-74e3-9c6a-b701-85138964aaea"}, traceId: 2150430917565480805992411e1dd0'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d5f8a81-dfcb-9679-b231-f7e0c0edb5d9"}, traceId: 2150434117565480816058915e1e83'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"021622bf-bca4-9ea2-872a-5382701d8552"}, traceId: 2150430917565480821202416e1dd0'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ca4468e-b9c8-9dbd-a869-7bc88a575054"}, traceId: 2150434117565480838018921e1e83'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f4cc67a3-0ea2-929c-a2b5-98400fb47f48"}, traceId: 2150430917565480843122423e1dd0'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab7c4492-49d3-96be-b85e-5b2e91b4242e"}, traceId: 2150434117565480864058930e1e83'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"734d82fd-a92d-99d9-8f6c-af87fa5acef4"}, traceId: 2150430917565480885162440e1dd0'}
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d36c6f61-cb77-9e7e-8e26-ff906761b60a"}, traceId: 2150434117565480899528943e1e83'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47373fdc-8c8b-900f-918f-ee7bfd0fd9e6"}, traceId: 2150434117565480949418955e1e83'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12393
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12393
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bbaf80e4-54fd-901c-90f5-9137c1171767"}, traceId: 2150430917565480954512473e1dd0'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78728ce7-7807-9487-87f0-bcad82ba32b4"}, traceId: 215044eb17565480966746768e8180'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a47ec16-046a-9b4d-8ff8-ed750c5d98e6"}, traceId: 2150430917565480979032479e1dd0'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fd9be940-4921-9062-a174-c5b8436c451f"}, traceId: 215044eb17565480991786791e8180'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c3644dab-233a-9af0-9f4d-e85bbed4849d"}, traceId: 2150430917565481004682496e1dd0'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca4a330c-5083-99cd-a435-afc4f04607e9"}, traceId: 215044eb17565481014686802e8180'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.75
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"110efd2c-e153-9889-8a47-86fc2af49fb3"}, traceId: 2150430917565481034752507e1dd0'}2025-08-30 06:02:07,830 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:08,251 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:09,177 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:10,344 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:10,446 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:10,466 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.82
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d46c9e0-3b64-9323-83e9-84f3e3ca2e29"}, traceId: 213e06bc17565480838176117e81e9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d4cec63-b903-933d-8025-2522fd53c955"}, traceId: 213e006c17565480859103671e11db'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c46258fc-592d-9719-bd8b-e289a991eeb2"}, traceId: 215040b917565480863956818eefd1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 21094
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=21094
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: data validation schema compliance

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"499f41fa-7392-9c72-852d-d59afd32c7d5"}, traceId: 213e007317565480904734071ee311'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ee58560-8b5e-9c80-b21c-c0916e8c7b45"}, traceId: 2150436a17565480899471533e2390'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"294835a9-0aab-924d-a22e-b6ead2311123"}, traceId: 215040c017565480915881958edeb8'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10976140-0860-961d-9ef6-b9f551a0cc3c"}, traceId: 2150436a17565480917891541e2390'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12481
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12481
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb3f2391-806f-9f72-bf93-a372005061ab"}, traceId: 2150436a17565480937131548e2390'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"211b6523-b5c0-9453-90f1-4df2a708f253"}, traceId: 2150436a17565480978981566e2390'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4f326f2f-dd8c-9793-aedb-b63d25e2e426"}, traceId: 215040c017565480974092028edeb8'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b57f6b40-b60d-9328-9d33-e1477a9a9db7"}, traceId: 215040c017565480991872037edeb8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9157f573-20a6-9ab8-93d5-1b667662180a"}, traceId: 215040c017565481014772049edeb8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct2025-08-30 06:02:10,466 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:10,510 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:10,511 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:10,511 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:10,987 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:11,019 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:11,030 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:11,030 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:11,053 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:11,053 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:11,053 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:11,459 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:11,506 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:11,651 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:12,169 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:12,211 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:13,079 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:13,112 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:13,645 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:14,153 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:14,668 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:15,316 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:15,330 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:15,331 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:15,356 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:15,356 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:15,356 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:15,747 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:16,210 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:16,775 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:16,784 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:16,795 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:16,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:17,292 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:18,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:18,863 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:19,376 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:19,588 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:19,589 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:20,036 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:20,560 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:20,977 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:21,495 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:21,985 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12598
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12598
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"424fae86-615c-9a4f-a5ae-be723145d7dd"}, traceId: 215040aa17565480968805250ee5fe'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6ab041d-0247-98b1-bbea-1b08463fde57"}, traceId: 215040aa17565480986575263ee5fe'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9fbd9490-4865-9279-b647-073199bcc47d"}, traceId: 213e063817565480997044977e8246'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"592fa362-6f90-9a98-b598-453bee5be31a"}, traceId: 215040aa17565481009575267ee5fe'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1469f8f1-59de-990f-b798-af4ec65c0221"}, traceId: 213e062917565481045392694e7e9b'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f0452193-b50b-9db3-9166-5c1e1620c66d"}, traceId: 215040aa17565481050385276ee5fe'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ae01c57-a514-905d-9744-9f8bd9719bda"}, traceId: 213e066417565481066486978e815a'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f2340bb-b2aa-9208-aa2b-cf6354babda0"}, traceId: 213e04ea17565481085062273e335e'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc130629-74db-924f-bcdb-0245e224f731"}, traceId: 215040aa17565481105035296ee5fe'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12523
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12523
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a2768b42-404f-9126-84b2-7f77f8c27947"}, traceId: 213e001317565481115484908e0da0'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e4c823e-7e43-9324-b67f-fa78ece9c0a6"}, traceId: 2150417c17565481126774233eee06'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f778f307-1b79-9ad8-b1f5-06a5caf030a2"}, traceId: 2150417c17565481145944239eee06'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7bc6792b-124f-9520-93bb-2e64a5c4f8b9"}, traceId: 213e064617565481156353107e0bbf'}2025-08-30 06:02:22,539 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:23,247 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:23,320 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:23,332 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:23,332 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:23,356 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:23,356 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:23,356 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:24,105 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:24,408 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:24,755 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:25,431 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:25,982 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:26,234 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:26,496 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:26,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:27,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:27,525 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:28,088 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:29,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:29,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:29,525 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fab59e08-015d-9460-b2bf-a1ad2c60c08f"}, traceId: 215044eb17565481050486813e8180'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 8: No tools executed after multiple turns

[TURN 9/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8628590f-9bbd-946e-bc9c-c5c1c2368cfe"}, traceId: 2150430917565481105162535e1dd0'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8171fef0-b9bb-92da-9217-63920297f55e"}, traceId: 2150448717565481116972425e810e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4577
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4577
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6513e76-05c0-9063-aa3e-e738288e68b9"}, traceId: 213e041917565481133226968e2af1'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9017b372-4129-910d-a1d3-51840973c887"}, traceId: 2150430917565481135552549e1dd0'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af32e996-6ec6-9dce-83df-c51af250abb9"}, traceId: 2150430917565481166292559e1dd0'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b7d8098c-43cc-9c30-81f8-ba10321bb909"}, traceId: 213e007c17565481171723225ef2a5'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eb28170b-8b05-9dbe-97e0-e4f00ea6edf2"}, traceId: 2150430917565481197292575e1dd0'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca18207b-6c4e-9cc8-bcf6-3a53d393a7bb"}, traceId: 213e04ea17565481217526953e33a6'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"67f6a26a-894f-9353-a662-a55ef47cfc47"}, traceId: 213e06bc17565481234288986e801e'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf66887f-f717-907d-8fb1-8473fa3c7943"}, traceId: 2150430917565481252652587e1dd0'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 3 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 23001
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=23001
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5c6ca97e-6deb-9334-a15a-e1daab170154"}, traceId: 213e06c317565481268002312e7b38'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43fbe338-b89a-978f-ba82-9ebf0ee5dd40"}, traceId: 2150456617565481268806646e7fb2'}2025-08-30 06:02:29,545 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:29,546 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:29,574 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:29,574 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:29,574 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:30,181 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:30,195 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:30,195 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:30,224 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:30,225 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:30,225 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:30,687 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:30,689 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:31,742 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:32,156 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:32,394 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:32,394 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:33,219 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:33,606 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:34,158 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:34,650 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:34,654 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:35,151 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:36,269 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.7
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5abb7f8-025c-9e78-afd9-8a67df22f0cf"}, traceId: 215040c017565481050582058edeb8'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7a3f00e-f052-982b-a2f1-0a79467a0308"}, traceId: 2150438d17565481055681599e2c9b'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a29f6094-5fd9-9574-97e2-906d165aa9ba"}, traceId: 215040c017565481071532067edeb8'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0fed8b7c-f304-979e-9e57-2480641f66fb"}, traceId: 2150438d17565481094901614e2c9b'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d48808a1-5c22-9ad4-a641-0d97b39f8ad0"}, traceId: 215040c017565481125612092edeb8'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"25a0af43-ef5b-9257-a199-690e466412a2"}, traceId: 2150438d17565481135571638e2c9b'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c6319ef2-4955-916f-8264-d97c18b2234f"}, traceId: 215040c017565481166352107edeb8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b4b7e03-8334-975d-bc06-a77a7dc1d453"}, traceId: 2150438d17565481176471658e2c9b'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2df3b08d-2bfb-9e97-873a-df83c9712fae"}, traceId: 215040c017565481186912120edeb8'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9234fc27-da86-9f26-8a6a-5f366ba2c523"}, traceId: 2150438d17565481197241669e2c9b'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad6f7ecd-7667-9e8a-a423-92669957febd"}, traceId: 215040c017565481217322131edeb8'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0bc1acfb-afcc-9646-98ac-e0a07721400a"}, traceId: 2150438d17565481222271673e2c9b'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7afef267-7b89-9298-abb9-79ce0816595e"}, traceId: 2150438d17565481247111679e2c9b'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa773970-9121-9605-a119-61959e1f3e1c"}, traceId: 215040c017565481257822138edeb8'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4fe478f-4d74-9e68-b615-e5320bc9c853"}, traceId: 2150438d17565481296841695e2c9b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16631
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16631
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)2025-08-30 06:02:36,282 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:36,283 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:36,316 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:36,316 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:36,316 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:36,609 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:37,346 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:37,352 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:37,365 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:37,518 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:37,915 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:38,884 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:39,409 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:39,613 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:39,912 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:39,933 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:39,940 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:40,437 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:40,449 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:40,449 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:40,474 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:40,474 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:40,474 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:40,997 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:41,593 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:42,110 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:42,602 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:43,115 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:44,308 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:45,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:45,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:46,405 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ee5e6c6-4419-9420-8447-6023b6e0f20d"}, traceId: 213e06b717565481163702292e7927'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac3d7fdd-5031-9565-99f2-88d8647e04ce"}, traceId: 2150417c17565481166304246eee06'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e1430262-2e08-9101-bcc9-0cad598ec439"}, traceId: 213e06b617565481181902085e80c4'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12819
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12819
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c11ae23d-aaa5-91a4-818a-9e1b47579a8d"}, traceId: 2150417c17565481207744260eee06'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eb5ef784-63ed-9625-8f03-58bb2167085b"}, traceId: 213e06a217565481213167312e83e8'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2497565b-4a16-90a8-8ccf-b3bc3f137c54"}, traceId: 213e007e17565481257846415eefbc'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
Progress: 10/35 (Success: 0)
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ed0176d-6659-9499-a633-57d54b61a21c"}, traceId: 2150417c17565481283934292eee06'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4aa465dd-2c2e-9d44-a0aa-3540cd7775dc"}, traceId: 2150417c17565481307344306eee06'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [SEARCH] Query: file_operations_reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1efffbe2-b550-9fc6-9b96-c935bd8ddcac"}, traceId: 213e042b17565481323761436e1c37'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7fe06cf0-367d-91bc-a8cd-d67b48836d72"}, traceId: 2150417c17565481338804321eee06'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca7008d5-3e75-9105-9f7c-3dc2be28aef7"}, traceId: 2150457117565481360361094e7783'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8fbe61b-fc36-9fb2-8a6d-d1d3e1575a17"}, traceId: 2150417c17565481365204329eee06'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df3cacd8-0ad6-96dc-b136-30e4cbb58ee6"}, traceId: 213e069217565481388523913e82b6'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22b0aebc-aef5-9025-a451-5d47f7286801"}, traceId: 2150417c17565481402244351eee06'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81002940-3b71-9e99-8534-bdac4f0ba345"}, traceId: 213e007f17565481412428054eedc0'}2025-08-30 06:02:46,417 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:46,417 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:46,441 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:46,441 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:46,441 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:46,448 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:46,959 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:47,074 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:47,086 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:47,087 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:47,112 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:47,112 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:47,112 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:47,996 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:48,325 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:48,555 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:48,646 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:48,646 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:49,568 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:49,578 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:49,578 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:49,607 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:49,607 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:49,607 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:50,106 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bbb695d8-8c5c-94fc-8047-f34683aaa06f"}, traceId: 213e004f17565481302343132ee635'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c2117d2-f3c2-93e7-a080-f0f1053b931e"}, traceId: 2150456617565481306826659e7fb2'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b5defd20-4590-940c-aefb-970ff2aef6b1"}, traceId: 2150456617565481328736671e7fb2'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2d2e888-2e56-9147-b9ba-42f346b122b4"}, traceId: 2150457117565481344937618e7782'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12882
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12882
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a8b2578-dffc-9eca-bee9-580eb2e41a8e"}, traceId: 2150456617565481360266685e7fb2'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4dbaecc3-12ed-95e7-b2f5-f08f144a8299"}, traceId: 215042f917565481360987611e1c5f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff14b7f1-2f0a-954c-a106-1ac48dd2c5b8"}, traceId: 215042f917565481385997619e1c5f'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1eab1040-4448-9d3c-8db6-951bdaf657ec"}, traceId: 2150456617565481397236700e7fb2'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f78dfa5d-a793-967c-bf09-98a9454eb66f"}, traceId: 215042f917565481417447633e1c5f'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6669c87c-d2fe-9438-bcba-65c5231332ac"}, traceId: 2150456617565481425526710e7fb2'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1820b03b-972d-916b-be36-cd0982561c3a"}, traceId: 213e063817565481438654191e8036'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12533
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12533
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa2f1f3f-fbc2-9b4f-aa2e-bc3bebd92a3a"}, traceId: 215042f917565481457387649e1c5f'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7149ff6f-ae1c-904c-b33e-fdc2876760fb"}, traceId: 213e06b717565481462662524e7927'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5706ec29-af4e-9a4b-82d2-4bb0d9ec3c77"}, traceId: 213e062b17565481487678160e7e65'}2025-08-30 06:02:50,306 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:50,838 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:51,436 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:51,931 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:52,008 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:02:52,181 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:53,252 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:53,404 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:53,700 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:54,515 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:54,534 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:54,534 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:54,563 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:54,563 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:54,563 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:54,583 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:55,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:55,557 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:55,565 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:55,829 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:56,561 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:56,563 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:02:56,670 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:02:57,627 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:57,643 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:02:57,643 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:02:57,673 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:02:57,673 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:02:57,673 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:02:57,758 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bfefcfd-1311-968e-97af-a900358e18b2"}, traceId: 215040c017565481302242158edeb8'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d25eeaa0-5c4d-96d5-90bf-e3128cbc97b2"}, traceId: 213e065017565481314156775e8099'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e4550f3-18c4-9c3b-9fe4-eeac1f34dc98"}, traceId: 2150417517565481323102168ee145'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b468f2a9-ec63-9d86-9259-56a42a70e589"}, traceId: 215040c017565481334063954ee12b'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7b2dc56b-6bf9-91f2-8949-bef920ccff52"}, traceId: 2150417517565481365192177ee145'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c9b24951-43ce-9008-84bb-33c1d1b8bd74"}, traceId: 2150417517565481380732182ee145'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a67e1d15-0c16-91bb-9a6e-2ccb2dc6ef7a"}, traceId: 213e042f17565481388548511e255b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a05eae68-06f7-9625-84fd-3744c275a340"}, traceId: 2150417517565481407252193ee145'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d67ef724-3ae9-9e3d-a350-47e50cc4c7dc"}, traceId: 213e059717565481425216330e3719'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2eefae5f-b5c0-9079-8768-98e499336a92"}, traceId: 2150417517565481441392201ee145'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"74bb28c5-d952-9477-8a23-c43a6a922646"}, traceId: 213e007f17565481463622134eecd9'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43d959b7-ce58-9ed1-a186-fff8f0dbe0d4"}, traceId: 2150417517565481482412217ee145'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa4ab3c3-ccf6-971f-b2ff-73cce97efc2d"}, traceId: 213e06a017565481499455841e767a'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab99282f-b742-925d-adc0-abc46298f663"}, traceId: 2150417517565481518812232ee145'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18a60017-2807-9371-8134-d378980f21f3"}, traceId: 2150417517565481538692239ee145'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a3c89ef-345e-98cd-b93f-a21dcfaa42ae"}, traceId: 213e006017565481555323317ee004'}2025-08-30 06:02:57,918 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:58,789 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:59,426 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:02:59,762 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:02:59,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:00,706 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:01,230 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:01,230 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:01,249 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:01,249 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:01,279 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:01,279 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:01,279 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:01,754 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:01,754 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:01,806 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:02,277 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:02,289 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:02,289 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:02,313 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:02,313 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:02,313 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"12c21e44-1ded-934b-8dba-8d751f74080d"}, traceId: 2150417c17565481446474377eee06'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c52a74d0-6130-9fd8-ad0b-97dd25f8b2f9"}, traceId: 213e081017565481452583178e0a25'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a04d98f-1461-9508-a094-ad2a81a7576d"}, traceId: 2150417c17565481467624411eee06'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8fc200c8-8ced-95ed-a25d-696d4180484c"}, traceId: 213e006d17565481487806917e127a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12625
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12625
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c43bf65e-8de9-977b-8e52-1833da9e45f0"}, traceId: 2150417c17565481499304429eee06'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29b04c79-c728-9163-a6ea-da26e66371a5"}, traceId: 213e066417565481515424169e8208'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f9a91f3b-300c-9860-8dea-c7249b372b5e"}, traceId: 213e066417565481538744182e8208'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f295f21b-7ac2-978a-848b-d069ec0e79bc"}, traceId: 2150417c17565481543734453eee06'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c23afc0d-8791-9963-8644-6c84e27eea93"}, traceId: 213e066417565481565784199e8208'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bcfc9e42-7cbb-9e64-847b-729bad5bd8db"}, traceId: 2150417c17565481596604469eee06'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13017
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13017
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"977a01c8-6e52-94cc-9274-5d7a03df42f6"}, traceId: 213e066417565481601714221e8208'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0923a6f8-95eb-9e4f-aba1-4a4527c4eed0"}, traceId: 213e081017565481613062862e0bf4'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0bf8389e-666f-97b0-b590-f94434b209a3"}, traceId: 213e066417565481656384241e8208'}
[ERROR] Max retries reached after 5 attempts2025-08-30 06:03:03,211 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:03,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:03,345 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:04,131 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:04,374 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:05,128 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:05,817 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:06,105 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:06,223 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:06,804 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:06,831 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:06,883 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:07,263 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:07,276 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:07,276 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:07,302 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:07,302 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:07,302 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:07,522 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:07,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:08,267 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:08,332 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:08,399 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:08,843 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:09,284 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:10,278 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:10,779 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:10,864 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:11,290 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:11,316 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"13e4cb60-b08a-9e97-a308-6eb8145558da"}, traceId: 215042f917565481494197663e1c5f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9989c2cd-5644-998a-a923-357f7cf358c2"}, traceId: 213e042b17565481515367771e1cfd'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 10/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4581
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4581
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"713d0358-1488-9f61-87ea-bba101389b78"}, traceId: 213e04ea17565481528853394e36da'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1517c66c-8e22-9231-992f-d5cb0b979dda"}, traceId: 213e042b17565481533637779e1cfd'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dbbfe02c-abb8-9e6e-9710-e33de9758dc3"}, traceId: 213e042b17565481565717788e1cfd'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01f33f3e-126a-9242-9f61-d76c033f876d"}, traceId: 213e060a17565481591725834e8a7c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a8fee32-1115-9a17-a964-ffb77d1605d6"}, traceId: 213e042b17565481596587794e1cfd'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"31e4625c-ed2a-922c-969f-9b5fccc74e65"}, traceId: 213e043117565481613547723e21eb'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf939669-e745-943b-a3ac-e69c6b0f2182"}, traceId: 213e06b717565481635636961e76ad'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3decd5f-a02e-99d3-89ba-e1bd7c6e66d9"}, traceId: 213e006b17565481662686937eedb6'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4557
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4557
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb84934e-6146-96df-8ffd-c87feb0f9337"}, traceId: 213e06c217565481678063038e8210'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac8afa01-0e32-9631-a19c-83ab083ebcfe"}, traceId: 213e007917565481678666493ee897'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f56836e2-b080-93f3-9b80-26b4c295986c"}, traceId: 213e007917565481698386502ee897'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...2025-08-30 06:03:11,770 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:12,763 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:13,152 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:13,289 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:13,479 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:14,337 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:14,861 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:14,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:15,535 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:15,547 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:15,547 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:15,574 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:15,574 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:15,574 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:15,791 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:16,433 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:17,353 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:17,358 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:17,489 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:18,406 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:18,407 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:19,192 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:19,439 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:19,873 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:20,375 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:20,873 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:20,897 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:20,899 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:20,928 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:20,928 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:20,928 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:21,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1282aef5-77f0-9600-951e-d2c9953b1612"}, traceId: 2150417517565481570802248ee145'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f54b5e2d-63a6-906f-96f9-fe73bbec700f"}, traceId: 213e007917565481571562396ee93c'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3bf4529e-8b96-9dee-ad5a-9085bff10503"}, traceId: 2150417517565481586462250ee145'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2661b68e-97ad-96f2-bb0e-24e42163571d"}, traceId: 213e007917565481596622404ee93c'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77e86ce7-228d-91db-8ad5-4b1de2f03251"}, traceId: 2150417517565481618352259ee145'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f07b30da-08cb-9a74-a2c1-b396f4ee27da"}, traceId: 213e007917565481623482419ee93c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6174b91-6134-913a-9b91-ddf251abf8e5"}, traceId: 2150417517565481651112271ee145'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f459a931-8814-9c64-9909-2c6eec5eed57"}, traceId: 213e007917565481656392434ee93c'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44c9fc8a-f148-9306-a604-368184f07c8f"}, traceId: 2150417517565481687842278ee145'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"008b106c-de1c-9a3c-a7e9-9ce4047228d1"}, traceId: 213e006b17565481700906662eea7d'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"beeec815-8fd2-943a-9cd1-eb3658a2b873"}, traceId: 213e007917565481724552461ee93c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af9fba39-faef-9021-8f55-da329c729fb5"}, traceId: 213e062917565481743008141e7fa3'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"040ab430-7b1e-90d5-83a1-b50076334eed"}, traceId: 213e007917565481747912469ee93c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ac50d185-0e60-9dc9-813a-d3e27515f393"}, traceId: 213e006717565481763281510ee19c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93960fbd-efec-993d-ad88-2a85b6185d0a"}, traceId: 213e007917565481774792476ee93c'}2025-08-30 06:03:22,202 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:22,336 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:22,724 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:23,250 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:23,422 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:23,423 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:23,451 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:23,451 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:23,451 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:23,656 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:23,672 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:23,672 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:23,696 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:23,696 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:23,696 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f927b9f4-46c2-9b31-99d0-e008f9a67608"}, traceId: 213e081017565481661762886e0bf4'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bfa76b5d-15d1-944c-9b62-0ffe93919a93"}, traceId: 213e057b17565481672326458e3f13'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4615
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4615
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"67d73fa5-2f89-9d17-a350-667e82e38032"}, traceId: 213e081017565481682972893e0bf4'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1852fdad-eae1-99e5-9dfd-ec6e7750c0bb"}, traceId: 213e065017565481695583455e7eca'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e96be437-8e75-9eef-bc65-2d020c23a11a"}, traceId: 213e081017565481706482898e0bf4'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"577e965e-ef83-9600-b10a-b27684ff6cb0"}, traceId: 213e041917565481719535106e2b54'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e606c58a-5cc4-9ea0-929a-1d60bf6365e2"}, traceId: 213e081017565481742952917e0bf4'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c18c423b-f983-9048-a5a4-02db82373261"}, traceId: 213e066317565481758175299e8258'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5f92424-55ed-9dd5-9ee2-d6553e85d94d"}, traceId: 213e081017565481768322927e0bf4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12487
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12487
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7635d1e-ac8f-995e-a4ff-664eb53e58d5"}, traceId: 213e043a17565481786463984e1e9e'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b7a1a42e-d585-9c8f-b7e9-f3bbb391f4a0"}, traceId: 213e043a17565481809283990e1e9e'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"704449a2-0f14-9bde-a1de-c442420b37f1"}, traceId: 2150454417565481814516978e81c5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-30 06:03:24,150 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:24,150 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:25,214 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:25,218 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:25,398 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:25,420 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:26,491 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:27,062 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:27,570 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:27,589 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:28,096 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:29,382 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:29,950 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:30,148 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:30,457 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:30,477 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:30,959 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:30,973 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:31,971 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:32,219 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:33,089 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:33,104 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:33,105 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:33,129 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:33,129 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:33,129 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:33,615 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:34,111 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:34,343 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"141df39b-8392-9e0b-a50d-a62d774ba244"}, traceId: 213e007917565481711486512ee897'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"11c7c505-b6a6-92a1-8155-2c01753828ba"}, traceId: 213e065117565481742784282e814e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12389
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12389
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77876354-8e59-9560-8ccc-6c346a7422c8"}, traceId: 213e007917565481752946524ee897'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a91a71b-a28d-96aa-b33a-f31d73b88f10"}, traceId: 213e065917565481750954243e8074'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"07867a40-c578-90c7-af15-039a0bed23da"}, traceId: 215042f917565481799267883e1af4'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e374be93-316c-9fa6-9e30-564c6f043ea7"}, traceId: 213e007917565481804196553ee897'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4563
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4563
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"09d76440-567d-9ea0-ab7b-e3cabc716eae"}, traceId: 2150438d17565481824658059e2e8a'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bd49fc0-5b9e-9434-bbad-a8b2428f34e0"}, traceId: 213e060c17565481825613802e87cf'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68256079-ff46-9393-886d-363f49e90eec"}, traceId: 213e060c17565481843573807e87cf'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f022a41-e1c9-9535-bfbd-651c09c823ae"}, traceId: 213e060c17565481864903814e87cf'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34cf2793-c614-958a-b2bf-c0bb0731d914"}, traceId: 215045b417565481875078912e831d'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1cee2e62-eb47-9744-a830-30e4f7111f28"}, traceId: 215045be17565481900261410e802f'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d77681b8-2e41-904a-a2a7-f620065fc497"}, traceId: 213e060c17565481905193827e87cf'}2025-08-30 06:03:34,654 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:35,153 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:35,172 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:35,172 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:35,196 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:35,196 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:35,196 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:35,703 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:35,722 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:35,722 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:35,763 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:35,763 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:35,763 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:36,623 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:36,880 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:37,405 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:37,644 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:37,662 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:37,662 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:37,684 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:37,685 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:37,685 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:37,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:38,129 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:38,156 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:39,152 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:39,192 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:39,206 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:39,207 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:39,215 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:39,229 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:39,229 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:39,229 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:40,168 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:40,183 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:40,687 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:41,031 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:41,167 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:41,179 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:41,179 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:41,203 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:41,203 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:41,203 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:41,809 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:41,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2efbb86f-8e06-9e69-bba0-7d11b6f20d2f"}, traceId: 213e043a17565481838484000e1e9e'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"94b60aaf-889b-9a58-92c1-56e4d7dea381"}, traceId: 213e042d17565481835446364e210b'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4531
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4531
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bd3178e4-fbc7-975d-becb-70d0c4ee1332"}, traceId: 213e042d17565481874916379e210b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1fadd847-e150-9ecc-90f0-f122f5a125a9"}, traceId: 213e043a17565481880114013e1e9e'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"468ca67a-a638-97d7-88d3-5f3f3206f9a8"}, traceId: 213e042d17565481894926387e210b'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6babd5ba-3c4b-957a-9ed3-f37862f5fe5c"}, traceId: 213e043a17565481905154026e1e9e'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"446dd572-1ecb-9419-afaa-05e1f4c3a7fc"}, traceId: 213e042d17565481924826405e210b'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"caf5bdf9-f368-92ce-a78f-d7f7777a33ef"}, traceId: 213e043a17565481935034031e1e9e'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e4a9e6fe-a64b-9394-b60d-8a23f85b3d8e"}, traceId: 213e042d17565481965746417e210b'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a776e44c-d309-9de6-be94-2e55d95fb6a5"}, traceId: 213e043a17565481976274046e1e9e'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1a43c964-4bc9-9a5c-93be-d678e3fb9398"}, traceId: 213e042d17565482001046428e210b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12515
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12515
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"edf40ad6-2f4b-9ffc-84d3-1e7b8b370579"}, traceId: 213e007d17565482016066693ef0a7'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf5e11c1-f513-9d95-a62a-29e6c5ae21fd"}, traceId: 213e043a17565482028814060e1e9e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-30 06:03:41,858 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:42,823 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:42,825 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:42,985 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:43,876 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:43,939 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:44,383 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:44,887 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"84cda4cb-42a3-9797-8b90-81b02b0a1ea3"}, traceId: 215041a817565481804354340e33f7'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fea9616b-6add-926a-84ab-ca46b7c5d070"}, traceId: 213e007917565481809252487ee93c'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e666bd52-0e1b-969f-a801-a1e886b3df89"}, traceId: 215040ed17565481824684664ebcd8'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"41458cc0-9cb6-9bd9-bb8b-526e8f690b21"}, traceId: 213e066d17565481854862089e8140'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"816e7f27-2b94-95a4-8809-28b9f9313de0"}, traceId: 213e007917565481864802504ee93c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea0de11b-264e-94e3-948f-0737fae9d546"}, traceId: 213e011517565481880445542e93da'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d3c89df1-5e05-96af-a0a9-15a8a9ace1bf"}, traceId: 215040cc17565481885297256ed649'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8ea86c6-6dc6-966e-8a47-0493ecbe56a7"}, traceId: 213e011517565481919055554e93da'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2964a87f-55a5-9191-a836-4d95823e5d6e"}, traceId: 213e062017565481947644872e83a2'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d784f076-07c3-92aa-b307-a2ab38787fd9"}, traceId: 213e011517565481965655579e93da'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca9baba9-f4f6-9d98-a50d-52459b4735eb"}, traceId: 213e007417565481967076095eed9e'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"239383e6-caa0-9f37-bb66-594e65c35451"}, traceId: 213e011517565481986655588e93da'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"da57c09b-2dfe-9f45-986a-26a407d1121d"}, traceId: 213e007417565481990946118eed9e'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5187f9d8-7393-9aaf-bae1-9cd07f0137a8"}, traceId: 213e011517565482008435598e93da'}2025-08-30 06:03:44,905 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:45,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:45,865 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:46,426 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:46,438 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:46,438 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:46,460 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:46,460 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:46,460 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:46,888 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:46,901 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:46,902 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:47,389 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:47,403 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:47,848 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:47,960 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:48,001 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:48,008 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:48,895 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:49,314 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:49,420 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:50,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:50,589 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:51,081 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:51,607 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:51,634 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:52,105 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:52,641 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:53,126 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"034fec25-0b65-91db-8b73-9557f98a1b28"}, traceId: 213e043b17565481932396001e2200'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8dba2b2-43fa-9205-8622-6c592b230eee"}, traceId: 213e060c17565481955423850e87cf'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"40a912ac-f204-965a-8940-f583c8327124"}, traceId: 213e007c17565481976408831ef118'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8768ff2b-7f69-979b-8c28-e317906bace4"}, traceId: 213e060c17565481996053864e87cf'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ac0336f-764f-90f6-9cda-3504dc24c714"}, traceId: 213e060c17565482018743872e87cf'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13012
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13012
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c5e43e1-e2ea-98bc-8349-e9a1e3f427f8"}, traceId: 213e060c17565482044493881e87cf'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d0999f50-de3f-9429-95a3-9f88cf43e1e0"}, traceId: 213e007217565482045884984eed51'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"97cf31c6-9c57-9c3f-a4e9-d02cb7ee5a64"}, traceId: 213e007217565482068155004eed51'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93760ad5-8c67-9a3b-b423-300045c56f52"}, traceId: 213e060c17565482073153890e87cf'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"807bda11-0e8a-94b3-86f8-74f94919a9fa"}, traceId: 213e007217565482096925039eed51'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b85ff4e-667b-965e-a40f-807f024ab3f6"}, traceId: 213e060c17565482123143907e87cf'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12676
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12676
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88109243-5048-9b07-9073-fb3875e3cf04"}, traceId: 213e007217565482128375092eed51'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61f48e5a-fec9-9a3c-a784-0ab540f14c37"}, traceId: 213e006017565482136016806ee31e'}2025-08-30 06:03:53,862 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:54,153 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:54,171 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:54,183 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:54,183 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:54,208 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:54,208 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:54,208 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:54,906 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:55,188 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:03:55,213 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:55,226 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:55,226 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:55,251 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:55,251 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:55,251 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:55,605 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:55,876 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:03:56,390 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:56,760 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:56,760 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:57,192 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:57,286 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:57,679 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:57,695 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:03:57,695 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:03:57,720 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:03:57,720 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:03:57,720 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:03:58,229 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:03:59,254 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:03:59,906 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:03:59,980 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:00,303 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:00,320 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:00,321 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:00,350 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:00,351 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:00,351 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:00,812 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:01,329 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:01,373 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:02,003 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:02,058 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:02,398 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:02,924 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:03,052 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:03,953 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c56487a-1796-98d3-9d6f-c97b6ec2fb64"}, traceId: 213e057b17565482034065798e409e'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2b8281e-4c65-9c6d-b41a-e66b7b6251b1"}, traceId: 213e069217565482046291645e83aa'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e72f5f8-2a8d-95d0-925d-a3513a6eb4a4"}, traceId: 213e060a17565482057476348e8953'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ba264e75-e867-996c-974f-f44b26763fad"}, traceId: 213e069217565482062971652e83aa'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12613
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12613
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9ba9149-067d-9f51-a197-fd74cc6d1d77"}, traceId: 213e064b17565482102273196e78ae'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"acd89ee8-bc51-9bbd-97ca-0b1f0b5eb6d1"}, traceId: 213e069217565482102131660e83aa'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa816b9e-ed7e-9e30-b3bd-2151a5c417c7"}, traceId: 213e069217565482138821676e83aa'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d58eb75e-5de8-9ba1-b5ac-f2d8b5c158d5"}, traceId: 213e064b17565482144151837e7827'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a2bc02be-1e17-9236-9d7b-28caa89bc278"}, traceId: 213e069217565482168741687e83aa'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.64
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4703
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4703
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bacecc4-abc8-9158-a8c9-00146ceecace"}, traceId: 213e058a17565482173706357e345a'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"248f8044-b2c3-9c07-af7e-f64a9a16cb8c"}, traceId: 213e042b17565482194248485e1cdc'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24bb1ade-d6f2-9a33-b2a9-22200c3783c9"}, traceId: 213e058a17565482199116365e345a'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ae4de32e-0dd6-953e-838f-8aa049e5f9d0"}, traceId: 213e060c17565482210764371e8732'}2025-08-30 06:04:04,483 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:04,484 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:05,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:05,535 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:05,539 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"642346ec-9665-9e37-aeeb-647600cf7581"}, traceId: 213e007417565482023796131eed9e'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"da5eb722-408a-90eb-b8cd-e537541c7390"}, traceId: 213e011517565482033815612e93da'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c64e1701-c105-9f24-b8b4-53d2cc00c98e"}, traceId: 213e007417565482044486134eed9e'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fee3f6b0-a1af-9323-b10c-67f323f5b7f5"}, traceId: 213e007417565482068076146eed9e'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e4ba3bb0-82f8-9887-84a5-8dd95965324e"}, traceId: 213e007417565482091666158eed9e'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f96ddb3a-2172-9e0b-8160-b2cb7b9ccbf0"}, traceId: 213e011517565482096725648e93da'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d5bb33e-bd6c-972c-a091-e3556b8c9062"}, traceId: 213e011517565482114115655e93da'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06e35855-2b75-907e-b523-5f70678b224b"}, traceId: 213e011517565482133425667e93da'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c47a81b-3e8e-9e3e-a190-4953d45f4fcc"}, traceId: 213e007417565482149346175eed9e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"45325c8f-c82a-9fb7-a017-1edf5535113e"}, traceId: 213e006817565482166198485ee6cb'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f729ed76-8a06-98b3-8ff0-67a31507bd42"}, traceId: 213e011517565482173595677e93da'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"41126328-17bf-9798-81da-343f9663bade"}, traceId: 213e00cd17565482194213580e95aa'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dbcd8bf7-4c68-9984-8df6-664b407fa97c"}, traceId: 213e011517565482204025684e93da'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d90df9f9-c3f5-92cf-b1f9-e146838dadf4"}, traceId: 213e006c17565482221011294e11da'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27c03d8b-6076-9a77-83ff-a28972bbb196"}, traceId: 213e007917565482222266382eea03'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"84eae149-59ed-9a91-b02c-6b2a7ffc2a8e"}, traceId: 213e007917565482241086391eea03'}2025-08-30 06:04:06,045 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:04:06,305 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:06,447 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:04:06,450 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246449333.json
2025-08-30 06:04:06,450 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246450096.json
2025-08-30 06:04:06,450 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246450465.json
2025-08-30 06:04:06,451 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246450816.json
2025-08-30 06:04:06,451 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246451480.json
2025-08-30 06:04:06,452 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246451887.json
2025-08-30 06:04:06,452 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246452190.json
2025-08-30 06:04:06,452 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246452515.json
2025-08-30 06:04:06,453 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246452787.json
2025-08-30 06:04:06,459 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246453099.json
2025-08-30 06:04:06,459 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246459133.json
2025-08-30 06:04:06,459 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246459509.json
2025-08-30 06:04:06,460 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246459766.json
2025-08-30 06:04:06,460 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246460183.json
2025-08-30 06:04:06,460 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246460413.json
2025-08-30 06:04:06,460 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246460638.json
2025-08-30 06:04:06,461 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246460935.json
2025-08-30 06:04:06,461 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246461230.json
2025-08-30 06:04:06,461 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246461550.json
2025-08-30 06:04:06,462 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548246461753.json
2025-08-30 06:04:06,496 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:06,971 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:07,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:07,803 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:09,014 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:09,341 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:09,918 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:09,969 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:09,990 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:09,991 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:10,018 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:10,018 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:10,018 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:10,916 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:11,123 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:12,087 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:12,361 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:12,492 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:12,736 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:13,261 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:13,301 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:14,063 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:15,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:15,635 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:16,159 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:16,160 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:16,177 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:16,177 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:16,209 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:16,209 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:16,209 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:17,091 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:17,731 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:17,742 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:17,743 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:17,769 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:17,769 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:17,769 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:17,960 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:18,661 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"87946f8a-15b0-93ed-bc63-96d4eb7d1c63"}, traceId: 213e006817565482158791473ee5a2'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce8cbc0a-b09c-9cd1-81ed-1af03df335a4"}, traceId: 213e065517565482189144042e8208'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22e9d0a1-1177-90e5-89e3-55bae8e72b99"}, traceId: 213e007217565482183965131eed51'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4526
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4526
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50344e7d-7573-9aea-bf3d-f9578df8c32c"}, traceId: 213e043517565482215843964e2db4'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ecc0455-9254-9282-b820-a8c9726b0495"}, traceId: 213e006e17565482226004731e1509'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"99b60576-e507-96a7-a039-0ae0de5d4e23"}, traceId: 213e043517565482241253972e2db4'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c99ba64d-cb8a-9fe9-91ad-6e7f75af6aea"}, traceId: 2150454117565482256163280e77b4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7840655e-a21f-988c-a75d-fc2065c0499d"}, traceId: 213e043517565482261263978e2db4'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4574
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4574
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ef322f5-cbf5-9844-b76e-c8ee3db08ba0"}, traceId: 213e004f17565482272233475ee98f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"95494ea1-5d08-9bc2-8588-c6d2433b71ec"}, traceId: 213e043517565482286173988e2db4'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9064dcf6-74a5-91c8-8985-7412e3c747d9"}, traceId: 213e004f17565482298113480ee98f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a248fef3-90df-9aad-908d-e4df7c3e8a83"}, traceId: 213e043517565482308474006e2db4'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"277b6398-f1dd-9cf1-a367-f9a8c9ec8f1d"}, traceId: 213e004f17565482323543485ee98f'}2025-08-30 06:04:19,113 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:19,167 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:19,186 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:19,380 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:19,594 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:20,877 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:21,256 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:21,796 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:21,817 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:21,818 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:21,862 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:21,862 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:21,862 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:22,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:22,320 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:22,976 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:23,341 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:23,529 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:23,894 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:23,909 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:23,910 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:23,935 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:23,935 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:23,935 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:24,305 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:24,347 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:25,072 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:25,377 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:25,388 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:25,389 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:25,412 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:25,412 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:25,412 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:25,885 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:26,147 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:26,178 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9e1198cb-265b-9f3e-8c48-93557e687f3e"}, traceId: 213e058a17565482230956380e345a'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0314e840-82d1-9dbd-91d1-c8d480fe5fa8"}, traceId: 215045b817565482236235405e8113'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4531
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4531
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73660dec-23db-9095-9405-1fccd9688428"}, traceId: 213e058a17565482271346394e345a'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc3ffd87-bd35-9bb7-986c-69142f692807"}, traceId: 213e043517565482285795259e2c8c'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3712bb7-d1b8-9f35-852c-96c31d160b1f"}, traceId: 213e058a17565482293066399e345a'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66271692-a989-9099-9e08-d2654d8d2dbc"}, traceId: 213e06b717565482303468212e76af'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"37b5694b-34df-939b-a4c9-7819fbfa7fa0"}, traceId: 213e058a17565482318536408e345a'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2d09891-d6f5-9014-a369-d47ac26b68e2"}, traceId: 213e058a17565482348885327e3388'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"548dac7e-124f-98ca-8013-21eb0d6b88be"}, traceId: 213e058a17565482359106421e345a'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"777762c7-1cf5-9a04-86b5-c88624c76cdd"}, traceId: 213e06b717565482364463780e77b7'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"40bff37b-ec9c-99fd-858d-8d26b5909cc1"}, traceId: 213e058a17565482395236428e345a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12773
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12773
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ef54379-f365-9451-9f4f-0b92b813fea8"}, traceId: 2150417c17565482400704444ef11f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4ec97c5c-d279-9990-ad7f-fca21b13efd0"}, traceId: 215040aa17565482426878078ee99b'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b95bd714-eb42-926e-aeee-c770ba11c41d"}, traceId: 213e06a017565482432045697e7869'}2025-08-30 06:04:26,516 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:26,941 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:26,977 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:27,174 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:27,407 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:28,002 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:28,421 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:29,141 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:29,425 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:29,441 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:30,412 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cade5b8e-a47d-9d49-85c7-64802512b9a6"}, traceId: 215045b817565482271581775e81b8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc7b1d73-6840-9e88-a1b9-8a2eccc8e604"}, traceId: 213e007917565482266246401eea03'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4406e914-5fec-9bcc-9929-4c3c1fc6c382"}, traceId: 213e058a17565482286266361e3598'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff408b6c-1e53-942d-8c31-33a7ed2ccef8"}, traceId: 213e007917565482308386411eea03'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ec2695a-542f-9354-8ab4-6b18231d9459"}, traceId: 213e007c17565482313673345eef09'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d79feb3-7196-9179-b6fb-913a761fb6a1"}, traceId: 213e007617565482334056513e147b'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a2324a6-f259-9431-b652-d7ea2fb03af4"}, traceId: 213e007917565482338976417eea03'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de2db5ed-aa4a-950b-930e-f01e09e39c2f"}, traceId: 213e006f17565482364591798ee626'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0dc612c4-b22b-9997-a02b-d89ab79529a1"}, traceId: 2150430c17565482369505406e2164'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2d5f0a88-d044-9b87-b110-7f047afe180a"}, traceId: 213e006f17565482384781805ee626'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c7eee5fe-f214-9418-98bf-bf9c951f4b70"}, traceId: 2150409b17565482392527324e0b55'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f3aacc8-6594-9123-b928-d8725e56e824"}, traceId: 213e006f17565482405751809ee626'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9fd71ae6-8bdd-91da-a785-ac304d86c6bf"}, traceId: 2150416417565482416371111e123f'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6717109f-7084-9594-a584-1b70de79ec7c"}, traceId: 2150460817565482442615028e7818'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"816e2e15-618b-9396-8a59-5a4c17e969a5"}, traceId: 213e006f17565482447701828ee626'}2025-08-30 06:04:30,505 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:31,136 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:31,890 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:32,286 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:32,296 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:32,792 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:32,798 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:32,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:33,259 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:04:33,260 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273260121.json
2025-08-30 06:04:33,261 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273261021.json
2025-08-30 06:04:33,261 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273261529.json
2025-08-30 06:04:33,262 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273261844.json
2025-08-30 06:04:33,263 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273262755.json
2025-08-30 06:04:33,263 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273263242.json
2025-08-30 06:04:33,264 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273263710.json
2025-08-30 06:04:33,264 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273264164.json
2025-08-30 06:04:33,264 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273264498.json
2025-08-30 06:04:33,265 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273264878.json
2025-08-30 06:04:33,265 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273265253.json
2025-08-30 06:04:33,265 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273265669.json
2025-08-30 06:04:33,266 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273265889.json
2025-08-30 06:04:33,266 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273266121.json
2025-08-30 06:04:33,266 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273266328.json
2025-08-30 06:04:33,266 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273266734.json
2025-08-30 06:04:33,267 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273267029.json
2025-08-30 06:04:33,267 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273267341.json
2025-08-30 06:04:33,267 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273267628.json
2025-08-30 06:04:33,268 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548273267835.json
2025-08-30 06:04:33,353 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:33,716 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:33,835 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:04:33,853 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:34,387 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:35,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:35,310 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:35,556 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:35,882 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "

[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"21ae4673-2132-9d37-8978-03c448fd7f48"}, traceId: 213e043517565482344174023e2db4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13498
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13498
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20d4ddce-0c29-9d14-9611-7cc68f9d0466"}, traceId: 2150430d17565482356641586e997d'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"87c86199-a14e-9931-a847-a0e25f64a4d3"}, traceId: 213e004f17565482359103502ee98f'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fbfec460-7d75-9a1d-8ebd-1252a0d150a9"}, traceId: 215041d717565482374688323e3723'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1efff927-aabb-9aca-a158-19a053db939a"}, traceId: 2150429e17565482405836554e2210'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"62bb692f-f252-95b6-8db9-85509c7ef8de"}, traceId: 213e004f17565482437093558ee98f'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0d2ce33-9bf1-9596-808f-d9e9e0c983ed"}, traceId: 213e004f17565482457083566ee98f'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a71b01a-7f16-9fb7-b24b-3134748fa0d0"}, traceId: 2150421317565482462404140e3505'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aacc7a05-3dfb-9fac-851d-145dd19b7e85"}, traceId: 213e007217565482485423736eebc5'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10008f5b-589c-90a2-8576-3688c096ceed"}, traceId: 213e004f17565482491533578ee98f'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a293419-1992-975a-9591-1a4a2fab09b3"}, traceId: 213e004f17565482515753586ee98f'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"32aa2f4b-1da5-9b29-a51c-7d20662e28cc"}, traceId: 2150443817565482525152364e8996'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"781f63b2-670a-9d3e-bff6-bac1d7dabbf0"}, traceId: 213e004f17565482548443596ee98f'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b3f8cfa2-4108-99cf-9376-5c0882855c70"}, traceId: 2150430c17565482553922852e1e2b'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c81b3994-f267-9889-b012-171eec0ddacb"}, traceId: 213e06c317565482578906274e7ca3'}2025-08-30 06:04:36,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:36,818 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:36,821 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:37,342 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:37,354 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:37,354 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:37,397 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:37,397 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:37,397 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:37,800 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:37,824 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:37,832 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:38,064 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:38,349 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:39,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:39,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:40,311 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:40,800 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:40,805 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:40,976 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:41,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:04:41,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:42,122 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:42,992 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:43,032 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:43,525 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:43,554 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:43,554 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:43,590 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:43,590 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:43,590 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:44,318 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:44,862 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:45,006 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:45,020 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:45,020 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:45,047 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:45,051 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:45,052 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:45,052 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:45,530 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:46,042 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:46,062 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:46,074 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:46,074 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:46,116 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:46,116 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:46,116 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:46,568 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:46,852 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:47,615 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:47,698 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:47,795 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:47,822 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:48,140 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:48,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:49,805 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:50,027 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:50,038 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:50,129 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:50,559 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f40c2b1-9ee4-9394-b779-679ff3e1a44b"}, traceId: 213e06a017565482447755706e7869'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0cd07e8-52b3-9c34-a31a-3a150c22c266"}, traceId: 213e060c17565482455512843e8a08'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 0)
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34129f22-168d-9a8e-8766-b3c708ede14e"}, traceId: 213e06a017565482475205716e7869'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"97c263e1-ed58-9a66-a6dd-5980f79eb231"}, traceId: 213e006b17565482501387881eea1a'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9eec6370-ca40-965d-80c4-12cc12553607"}, traceId: 213e06a017565482515915727e7869'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fb3f87ee-9b1b-939e-b742-e4eafc52843a"}, traceId: 215045a817565482553923972e8015'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13074
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13074
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5ed3f61-0565-9d91-9435-d640129ce47a"}, traceId: 213e06a017565482568925748e7869'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a7f5189d-3a58-946b-a542-4d2123b24c9d"}, traceId: 213e007c17565482588346722ef143'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24efc9ff-60d1-9f88-9593-3d029d310b9d"}, traceId: 213e066317565482586432293e7fb6'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6dc6267e-0f2a-9dcc-9852-cade5e7d6c8e"}, traceId: 213e007c17565482615466732ef143'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c6ae0d9-2c5a-9a79-91d0-d51727616775"}, traceId: 213e006c17565482626097727e12c1'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77a71a2f-bd28-9da4-8eb7-33f68ad6374c"}, traceId: 213e007c17565482635506736ef143'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a64562e-6f42-9b09-aee2-7b65d5c3a69c"}, traceId: 213e006e17565482651314857e1509'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.772025-08-30 06:04:51,028 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:51,039 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1e01c2bb-822e-9573-8d76-92218209b3b7"}, traceId: 215045c117565482468817089e8197'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"884c1b80-1462-935d-861a-fb2ae6143afa"}, traceId: 213e006f17565482496741843ee626'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"53cb688b-03a5-976a-8028-1c3d8c436288"}, traceId: 213e03e217565482508524306e1e11'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5cab14d-c83e-9eca-959b-96cb03c871d8"}, traceId: 213e03e217565482525184309e1e11'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b423cc2c-c123-90b5-81f9-7a80e9704f0b"}, traceId: 213e065e17565482532685707e809a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5e67d95-0c2c-9dd2-96f4-f21f58b9a77c"}, traceId: 213e03e217565482543514315e1e11'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efb3c648-c8d0-94fa-a9f7-07da1200ba6a"}, traceId: 2150421317565482563375401e33ed'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ced86e2e-e322-9b97-bba5-6e1ade1f72d2"}, traceId: 213e03e217565482584074326e1e11'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df01d948-9ecc-928b-8613-cc7e75cdd61f"}, traceId: 215045b717565482588545239e7f65'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f689eb3-1dd1-9af7-a192-31eb24e41aa2"}, traceId: 213e03e217565482631244346e1e11'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3b8d7c7a-6662-9111-8408-6bfe5e49c17b"}, traceId: 213e06b717565482635673883e77b7'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a8fad57-caea-97dc-8aef-13bb9b2fdb55"}, traceId: 213e011517565482647896551e93fc'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7260013c-ed13-92d2-b578-85d6f0a59414"}, traceId: 215045af17565482663765964e7e5c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f8452f3-815b-9a27-b538-5e3e83fde77a"}, traceId: 213e011517565482666406555e93fc'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5fe0484c-fc00-9bad-a06e-a40b4d0c9535"}, traceId: 213e011517565482686676564e93fc'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27ac7cc9-afb6-9487-8d9e-c7880452af33"}, traceId: 213e064d17565482696505723e82e9'}2025-08-30 06:04:51,039 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:51,064 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:51,064 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:51,064 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:52,111 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:04:52,234 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:52,495 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:52,584 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:53,080 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34eb480a-462a-9af3-9023-f28efc4e8580"}, traceId: 213e004f17565482583903606ee98f'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d13d676-29ba-941a-acaf-1dd6ef0092f3"}, traceId: 215044eb17565482605133076e7f90'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d204f05-48d8-92e2-a807-a99803d63486"}, traceId: 213e004f17565482615363619ee98f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13648
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13648
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5c419f1f-046f-97dc-ad76-56720b0560fd"}, traceId: 213e066c17565482627498192e7a98'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6f96bd86-be87-9b19-ae79-eaf520724e58"}, traceId: 2150416417565482646151151e121e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c9a63d4-c475-96fe-bf45-c54ba3f43b67"}, traceId: 213e001317565482662567189e0aab'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ee0ff585-a763-943f-aade-e8d7c6b2b187"}, traceId: 213e066c17565482666278203e7a98'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f03123a-2548-9f09-8a01-4e3acb6e09d5"}, traceId: 213e001317565482686527200e0aab'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8be21c7-b6d9-9103-a16c-618def7f1696"}, traceId: 213e066c17565482696718214e7a98'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ceabe133-f412-97ab-be5d-17bee9dee354"}, traceId: 213e066c17565482714988219e7a98'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.78
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13498
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13498
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa9bfc91-64f5-96d9-a98b-91ba34446f5b"}, traceId: 213e001317565482729337212e0aab'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"603376d9-5eba-9e0c-909e-28efa37722a8"}, traceId: 213e066c17565482745258224e7a98'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]2025-08-30 06:04:53,090 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:53,094 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:53,110 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:53,110 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:53,145 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:53,145 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:53,145 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:53,593 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:54,205 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:55,303 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:55,814 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:55,837 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:04:56,269 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:56,271 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:56,790 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:56,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:57,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:57,298 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:57,299 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:57,321 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:57,321 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:57,321 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:58,104 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:04:58,393 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:04:58,398 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:58,901 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:58,926 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:04:58,926 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:04:58,955 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:04:58,955 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:04:58,955 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:04:59,009 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:59,401 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:59,417 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:04:59,964 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:00,580 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:00,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:00,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:01,503 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:01,522 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:02,034 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:02,923 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:03,869 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:03,869 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:04,395 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:04,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:04,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:05,443 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:06,860 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:06,934 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:07,036 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:07,036 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:07,071 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:07,076 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:07,076 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:07,076 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:08,424 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:08,470 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:08,486 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:08,486 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:08,514 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:08,514 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:08,514 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:08,676 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:08,984 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:08,986 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:09,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:09,524 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:10,045 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:10,064 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:10,071 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:10,071 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:10,102 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:10,102 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:10,102 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:10,526 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:10,564 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:11,613 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13323
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13323
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e50a66a2-9258-9e70-a0fe-e006ec250f07"}, traceId: 213e043117565482671586894e2398'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1b1d8216-d32c-9b72-a871-0737b56c500f"}, traceId: 213e007c17565482676506758ef143'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"15eb0e69-a996-93d1-9d94-dae7ec98d0c2"}, traceId: 213e007c17565482715086776ef143'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4f3edcb6-5574-927b-82c9-788b219f2bfc"}, traceId: 215044eb17565482725683797e7f93'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"89d30d0b-e4ce-9713-96f5-025001cbca4d"}, traceId: 213e007c17565482736046788ef143'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59762346-5bff-9abb-9469-de6e9df794be"}, traceId: 213e007c17565482760666803ef143'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"083e030b-dd45-913b-9694-d9894fcdbfd3"}, traceId: 215040aa17565482770897314ee6e5'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34d56d00-9b24-91e1-b335-61a5cf638193"}, traceId: 215044fd17565482795585069e7f72'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d006b8e9-31e0-96af-9322-f188316f4873"}, traceId: 213e006f17565482817463870ee4c2'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de4e1e5f-69c6-94c1-a297-ee0520dee9d4"}, traceId: 213e007c17565482827536831ef143'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"191a2e3a-4c86-93ca-827b-710a9ebb41cd"}, traceId: 213e007c17565482842676839ef143'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b95137a7-e726-910f-a695-db509693b28d"}, traceId: 2150458117565482862576783e81dc'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7670173c-4ca7-9038-ad35-829c067a9866"}, traceId: 213e007c17565482868096851ef143'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a654d21-2598-968d-9c48-8f31f68d6e0e"}, traceId: 2150456117565482878325772e7e78'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7ebf000-9317-907b-adef-99179f91b532"}, traceId: 213e007317565482897775902ee343'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b1b3ede3-ab9c-92ae-9873-515c4882248b"}, traceId: 213e007c17565482902716872ef143'}2025-08-30 06:05:12,029 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c797aee4-d84e-918e-8d8d-8b18b1b72263"}, traceId: 213e001317565482760477228e0aab'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a236a9fd-c591-97cd-a505-75e0d30f88a2"}, traceId: 213e001317565482770647233e0aab'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"720005c2-80b4-97e3-93c4-1d972404a9b8"}, traceId: 213e066c17565482775778232e7a98'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73314ea8-24c7-9fb5-9c06-b67995ab7a3c"}, traceId: 213e001317565482795257244e0aab'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4afd154-23ee-991e-93f7-4b78f5580fcb"}, traceId: 213e001317565482822307258e0aab'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7dca7e49-86d7-9d4d-8aa6-9780cdec1029"}, traceId: 213e066c17565482832518249e7a98'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13498
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13498
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1182ef08-78d9-9d3d-a698-90fa62a78c12"}, traceId: 2150456117565482852976496e80ca'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7dcb18e-2d96-9b41-bb87-d589d3bc46d0"}, traceId: 213e001317565482857767267e0aab'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0c1885b-b807-9e74-a308-49079980df4e"}, traceId: 213e007f17565482869364324eede1'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"daf2dbf6-c62e-9d1e-8108-e04c415057d8"}, traceId: 213e066d17565482890566185e82b2'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"119ed01a-fc81-97ba-bd21-0950038c0e00"}, traceId: 213e007f17565482893294334eede1'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13427
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13427
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0e5b950-0fe5-9305-8a46-da7529ae57c5"}, traceId: 215045af17565482917474705e7f42'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3bc90900-0498-9a38-b6b7-92e6b54ccf38"}, traceId: 213e007f17565482928054344eede1'}2025-08-30 06:05:12,151 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:13,036 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2616c869-ada4-92d0-b887-3895752e90cb"}, traceId: 213e011517565482725596576e93fc'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2a44383-0698-954d-937b-4086ad668a66"}, traceId: 2150454117565482731021583e79c4'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b1ea7994-6db8-9c6b-81e5-77c4f76c61ff"}, traceId: 2150411817565482747817100e0a76'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4970b99-097e-9132-94ed-79a151c1bba6"}, traceId: 213e011517565482765696595e93fc'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"32491fcd-1a39-926d-8772-6883e9130033"}, traceId: 215045b417565482775371822e82fc'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d09c5d76-680a-91d3-9f4c-70ddd7cb805b"}, traceId: 2150458717565482778303645e80fb'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1607d589-4977-9c55-8519-76af8eb184b8"}, traceId: 213e007317565482800723209ee41a'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d5ab4bf4-00be-97c2-a9b3-cdf97b3dbb87"}, traceId: 2150458717565482807376653e7f90'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"12a5cdea-dbc0-9a24-ae62-7a07d1142e1f"}, traceId: 2150421317565482835927042e3777'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"593056a5-e62d-952b-b6bd-0240f9ca754b"}, traceId: 213e06ba17565482842786608e89bb'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b0e9385a-d3b1-971e-a5a6-805ca486de11"}, traceId: 2150436817565482875596323e1e84'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6e45cf4-e467-9d12-8df6-bfaae57a8d3b"}, traceId: 213e041917565482878155836e2de8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83c495ec-0245-9c33-a2e6-cf4d3382ea99"}, traceId: 213e041917565482897675843e2de8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2c715da-156c-912c-967e-b123fbcad9a9"}, traceId: 213e041717565482902871626e96ae'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)2025-08-30 06:05:13,047 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:13,067 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:13,072 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:13,072 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:13,098 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:13,098 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:13,099 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:13,555 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:14,359 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:14,548 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:15,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:15,079 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:15,090 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:15,090 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:15,116 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:15,116 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:15,117 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:15,404 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:16,338 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:16,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:16,975 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:17,349 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:17,739 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:18,450 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:18,455 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:18,461 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:18,461 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:18,486 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:18,486 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:18,486 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:18,550 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:19,599 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:19,967 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:20,001 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:20,124 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:20,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:20,765 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:21,031 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:21,037 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:21,546 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:21,557 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:21,558 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:21,580 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:21,580 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:21,580 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:22,591 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:22,626 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:22,631 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:23,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:23,267 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:23,546 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:24,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:24,841 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:25,253 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:25,895 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:26,269 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:26,492 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:26,805 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:27,023 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:27,327 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:27,339 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:28,310 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:28,562 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:28,852 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:29,229 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:29,749 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:30,085 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:30,158 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:31,133 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8d432f7-3b6d-9c09-bd8b-7ca2036aa33f"}, traceId: 2150456617565482923197936e836d'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6cb47dcc-f946-9c9c-baca-b0ddb4182d59"}, traceId: 213e007c17565482928126890ef143'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18082
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18082
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1d602e9-5feb-9d4c-9815-b4d40eb892d9"}, traceId: 213e007017565482939163784ee8e6'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"86d140a9-3f34-9777-8b65-365f8f7048bc"}, traceId: 213e06bc17565482965386495e829e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06e111f0-d652-9fad-9a7d-22fd4063e271"}, traceId: 213e080f17565482982392682e0dab'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"759de597-03fa-97c9-9324-6dacf632d908"}, traceId: 213e007017565482986313800ee8e6'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13990
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13990
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c37803f-1cf9-9c80-81a8-6f8ae82b37d6"}, traceId: 213e080f17565483007262686e0dab'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f2c77831-48b0-9af4-b158-1e7be1a61799"}, traceId: 213e007017565483012393806ee8e6'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f102c1c6-293d-9691-a6bf-b00790138c0b"}, traceId: 213e080f17565483035712697e0dab'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f2b76bdc-fbdf-9888-bddd-bda8dc81ef82"}, traceId: 213e007017565483045983816ee8e6'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2cd2b09e-7024-95f1-bf74-65f9bca2ca16"}, traceId: 213e007017565483082083828ee8e6'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7b55a5e5-762c-96e5-8f51-7b53de94341c"}, traceId: 213e080f17565483087212719e0dab'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34d311da-d7d4-93c1-9295-2d615a5933bc"}, traceId: 213e080f17565483108172726e0dab'}2025-08-30 06:05:31,858 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:32,358 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:32,376 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:32,377 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:32,403 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:32,403 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:32,403 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:33,004 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:33,378 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:33,388 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:33,388 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:33,412 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:33,412 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:33,412 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:33,626 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:33,940 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:34,018 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7c00ce70-ab8a-9dfa-b59e-9a73141cb510"}, traceId: 213e007f17565482944804352eede1'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de67fa31-76af-9bab-8d2d-b0075c620122"}, traceId: 2150417d17565482960315457e1111'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f76cbc5c-d96a-9435-a81d-9f99dd227302"}, traceId: 213e058a17565482976382603e3387'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"495dee46-0d74-9158-a653-eda214c95729"}, traceId: 213e007f17565482981224363eede1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"480de040-6f8e-9d50-8f61-a72d188c7ebb"}, traceId: 213e080f17565482998167127e0c60'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4400
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4400
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6a632685-1eeb-9a52-aac3-38b30151c78c"}, traceId: 2150423617565483002441691e0d82'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [SEARCH] Query: data processing parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9767e15a-f8b1-9c44-8aaa-9e190ecb8293"}, traceId: 2150417917565483035938513eed03'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"21f3233d-a2eb-9187-85b7-0dc71b2eb79b"}, traceId: 213e080f17565483040827145e0c60'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22c7c048-389e-91b2-bea0-e05d3be4ca9c"}, traceId: 213e080f17565483062877150e0c60'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2605c2f4-0935-91de-826b-402e527e9968"}, traceId: 213e06ba17565483077264160e886f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d8ea72f-19fd-9db9-93fe-43f5bc219f76"}, traceId: 213e080f17565483082027156e0c60'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13493
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13493
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf7ac431-fd03-9b29-b328-cb2df06ab714"}, traceId: 213e063817565483103233776e7ff4'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44ef2219-787e-9494-8e68-ae968256f3ff"}, traceId: 213e080f17565483112537163e0c60'}2025-08-30 06:05:34,646 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:34,656 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2bb81627-cd99-9d3a-88af-55c49c2ab6aa"}, traceId: 213e001317565482919594114e0bd3'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c297c5e2-9353-90b5-86db-7e648d946cad"}, traceId: 213e041917565482917995848e2de8'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f8394e7-5b45-9540-a2e9-12ada570e237"}, traceId: 213e001317565482933194116e0bd3'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8dcd2d6-a766-9b27-b84e-8a2e8d2b1048"}, traceId: 213e001317565482955064122e0bd3'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"28ed6d11-ef8c-92c7-bc2f-7119fe1f11f5"}, traceId: 213e041917565482960095865e2de8'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c27caeca-15dc-9577-aecf-ff0d4bf9bf48"}, traceId: 213e041917565482976245870e2de8'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ef2258d-9dfd-9057-b4b1-96b9542687eb"}, traceId: 213e001317565482986344132e0bd3'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1352f6b4-df3f-98db-8769-bfe4dc5e5e01"}, traceId: 213e041917565483007385878e2de8'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"719af965-93f5-90aa-89f1-cd34cafc3c0e"}, traceId: 213e041917565483035855882e2de8'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"80930652-76f8-974a-bf59-2f4286a32ee1"}, traceId: 2150419d17565483061138805e2e71'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad9363bd-cefb-9f09-b1d7-f01e805f4ae3"}, traceId: 213e06a217565483079373365e81b8'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b30923b9-0fc7-9dd2-b401-8a63f7ca8968"}, traceId: 213e041917565483092565895e2de8'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9fe6fd09-def6-9a4a-9890-c1c15c458282"}, traceId: 213e060b17565483097926222e88d5'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6a877ca5-0a14-9964-a29b-d18fddb1ca9a"}, traceId: 2150456617565483113927391e8266'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"94a1bc73-8cfe-9c8d-b9a2-f1371955a49d"}, traceId: 213e069217565483127953518e815c'}2025-08-30 06:05:34,941 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:34,955 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:34,955 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:34,985 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:34,986 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:34,986 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:35,927 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:36,437 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:36,587 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:36,927 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:37,624 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:37,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:38,290 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:38,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:38,899 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:40,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:40,071 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:40,584 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:41,304 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:41,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:42,418 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:42,431 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:42,431 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:42,456 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:42,456 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:42,456 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:42,554 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:42,782 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:43,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:43,861 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:43,984 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:44,269 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:44,281 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:44,287 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:44,287 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:44,301 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:44,311 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:44,311 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:44,311 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:44,763 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:45,288 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:45,488 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:46,178 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:46,632 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:46,666 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:47,759 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:48,290 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:48,307 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:48,308 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:48,331 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:48,331 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:48,331 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:05:48,634 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d97760ae-84dc-9c0f-94ab-e852465b38dc"}, traceId: 213e007017565483122703838ee8e6'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13508
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13508
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"059a762a-71fb-9c7d-b600-4b8bcf1c7d31"}, traceId: 213e080f17565483127662736e0dab'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f638d056-9615-9158-bc4f-c4418e9a4afc"}, traceId: 213e057b17565483135308935e3fb8'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5690dc42-0c92-99f1-a082-fdae7628aba6"}, traceId: 213e080f17565483155652746e0dab'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8adac0d6-2198-9f0e-8b8f-9a841ffa5558"}, traceId: 213e059717565483182154996e34d5'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9fd8e8f-e33b-9f25-bee9-13f4aa3114b2"}, traceId: 213e080f17565483207792760e0dab'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13391
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13391
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e794d936-a5a3-9baf-863a-4c9d144666bd"}, traceId: 213e064e17565483218575618e8078'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de5493d7-a4d6-91ca-82dd-a840fd71f56d"}, traceId: 215040b917565483224127372ef13b'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0aeb8c76-ac85-93dd-8f59-4aafdee0e31b"}, traceId: 215040b917565483244557384ef13b'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"632c9115-f496-90b3-9a0c-d96c97e53714"}, traceId: 2150416717565483262716174eedd3'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb8e3623-63ab-9a04-892d-60207255d1ac"}, traceId: 215040b917565483265537391ef13b'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ffb3b5dc-5788-9a95-a6cf-21b9fa639641"}, traceId: 2150452b17565483290098324e778a'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"853b7498-f518-9fb1-90d5-32ed43501244"}, traceId: 215040b917565483302947406ef13b'}2025-08-30 06:05:48,800 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:49,343 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:49,580 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:49,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:50,377 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:50,536 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:50,606 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:50,955 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:51,321 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:51,858 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:52,353 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:53,303 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:53,579 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:53,921 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:05:53,987 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:05:54,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:54,887 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:54,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:55,438 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:56,941 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:56,986 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:57,030 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:57,749 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "

[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a551834c-e814-948a-b5cf-b83c98536581"}, traceId: 213e007a17565483142687108ee5ef'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"21a7abad-4a0f-9b52-8268-731c79ca4bea"}, traceId: 213e080f17565483142997173e0c60'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e1e3bdb-27f2-954b-be44-9dc1cc3afbe1"}, traceId: 215041e117565483161733476e343c'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"95765f7f-edce-9bf5-9da8-3be2cf6d247b"}, traceId: 2150416317565483166114375e167c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"975f8813-f63d-9f42-8108-b80b80948ff2"}, traceId: 215041e117565483187103485e343c'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11756
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11756
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e197fb3b-8238-9a90-bf0e-5c27e158abe6"}, traceId: 213e01f617565483202827864e158d'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f314f94-2767-9a31-86df-1b7de816f710"}, traceId: 215041e117565483218353496e343c'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efb4181e-5e72-99b2-8763-a18080760dba"}, traceId: 2150417717565483232951664edb5a'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1a18af51-bdf4-9bf9-ae7d-9593d0e69c9e"}, traceId: 2150457a17565483257522286e0b3c'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"13d453ef-8ba0-9aa8-ab8a-24ed1f36662d"}, traceId: 215041e117565483260293504e343c'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.6
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4463f913-a9c8-9e30-88ee-5b128437b6bf"}, traceId: 215040cc17565483292855534ed66a'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e0ef7b3-ecca-930c-abb2-ca8c1d60cb66"}, traceId: 215041e117565483315923519e343c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4453
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4453
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"09b84850-8c8d-994c-a4bf-e8411b74ee8f"}, traceId: 215044eb17565483332355097e7f92'}2025-08-30 06:05:58,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:05:58,687 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:59,173 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:05:59,192 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:05:59,193 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:05:59,217 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:05:59,218 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:05:59,218 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:05:59,218 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:00,182 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:00,712 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:00,885 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:01,082 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:01,543 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:01,978 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a35fdba-248b-9141-86d0-d3b181abd0fd"}, traceId: 2150456617565483137877406e8266'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3564f406-e421-9cb8-9a0d-4fe97378647e"}, traceId: 2150460e17565483150843269e7a1e'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a63397fc-21a3-9357-ae71-1018475fbd88"}, traceId: 2150456617565483165867416e8266'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9d4eb4a7-0cc7-92d8-a2cc-86ad15eeb217"}, traceId: 213e057b17565483181964167e3e4d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27d0d790-138d-9032-98b5-8fc056d526ba"}, traceId: 2150438d17565483193061663e2d61'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d35783db-cefa-9a33-95ad-19c0cfbe2f46"}, traceId: 2150456617565483202567442e8266'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"284db6ef-e96e-9835-987c-e47cbf08d3dc"}, traceId: 2150438d17565483218401676e2d61'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"02fa6627-fa99-9323-9c79-eb4089ee8c8c"}, traceId: 2150456617565483227617456e8266'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bd231a24-98b8-92a7-878a-cf4c5f7955db"}, traceId: 2150456617565483254997473e8266'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7b0ba5cc-26aa-9a10-98d3-a5281c6aff3b"}, traceId: 2150438d17565483265591691e2d61'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68772f09-85fc-96d0-b28e-5f248eb06f71"}, traceId: 2150456617565483277947482e8266'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5dfc6241-e6f3-9152-86e4-c9874daad123"}, traceId: 2150438d17565483293781702e2d61'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8907444-9677-9154-854d-f43b3388af94"}, traceId: 2150456617565483326037496e8266'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf7406c5-b1cf-9747-bc5a-1ac8f6771e45"}, traceId: 2150438d17565483331531718e2d61'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4072389-133d-9172-9499-d1028662c826"}, traceId: 2150434117565483339204783e1f49'}2025-08-30 06:06:03,303 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:03,638 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:03,646 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:04,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:04,688 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:05,591 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:06,471 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:07,008 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:08,110 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:08,122 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:08,123 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:08,148 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:08,148 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:08,148 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:08,999 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:09,045 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:10,049 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:10,062 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:10,062 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:10,087 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:10,087 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:10,087 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:10,121 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:11,663 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:11,674 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:11,674 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:11,702 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f31ee283-b5d2-97dc-a159-b5ac07b8d51b"}, traceId: 213e06c317565483328643024e7b38'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"be832db3-8c77-97bb-bfb6-9a7b606297f1"}, traceId: 215040b917565483341677419ef13b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4288
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4288
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8ef4db6-4155-9bb5-a679-761e3b97ffe3"}, traceId: 2150459f17565483358186311e7ed2'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5361ce5e-56a5-9e3a-9ee0-9809a2a2554f"}, traceId: 215045c117565483368647739e81d9'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5201e6bf-8faa-9e7f-8901-37ac0f7c5aaf"}, traceId: 2150459f17565483376236334e7ed2'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4386fb32-3e0a-935e-9d1b-327304242263"}, traceId: 2150459f17565483408276376e7ed2'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bef6b4c9-b8a7-951c-affc-2e3152981525"}, traceId: 2150415d17565483416663102e13dc'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13672
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13672
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"45293681-003d-99b4-a59b-d8b4b39f59cd"}, traceId: 213e006817565483432304598ee51d'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe5c1ebf-ea22-9e21-8b15-304052fcaa36"}, traceId: 2150459f17565483434986405e7ed2'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9880fd20-92cc-9732-9f0c-68bd4c69c605"}, traceId: 215045b417565483454442378e80ab'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8fdfdc29-9b92-9e56-b084-0240df32c074"}, traceId: 2150459f17565483475306423e7ed2'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4411
[AI_DEBUG] _ai_classify_with_txt_content called:2025-08-30 06:06:11,702 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:11,702 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:11,702 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:12,152 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:13,157 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:13,687 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:14,023 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:14,558 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:14,569 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:14,570 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:14,598 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:14,598 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:14,598 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:15,062 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:15,775 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:15,829 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:16,111 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:16,682 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:16,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:17,417 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:17,850 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:18,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:18,091 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378091251.json
2025-08-30 06:06:18,092 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378091730.json
2025-08-30 06:06:18,092 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378092054.json
2025-08-30 06:06:18,092 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378092410.json
2025-08-30 06:06:18,092 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378092656.json
2025-08-30 06:06:18,093 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378093023.json
2025-08-30 06:06:18,093 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378093318.json
2025-08-30 06:06:18,094 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378093948.json
2025-08-30 06:06:18,094 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378094224.json
2025-08-30 06:06:18,094 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548378094462.json
2025-08-30 06:06:18,323 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:18,893 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:19,350 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:19,928 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:20,304 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:20,975 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:21,884 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:22,028 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:22,401 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:23,976 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:25,421 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:25,453 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:25,460 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385458009.json
2025-08-30 06:06:25,460 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385460433.json
2025-08-30 06:06:25,461 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385461036.json
2025-08-30 06:06:25,462 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385462045.json
2025-08-30 06:06:25,463 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385462674.json
2025-08-30 06:06:25,464 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385463527.json
2025-08-30 06:06:25,464 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385464558.json
2025-08-30 06:06:25,465 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385465068.json
2025-08-30 06:06:25,465 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385465475.json
2025-08-30 06:06:25,466 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385465998.json
2025-08-30 06:06:25,467 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-72b-instruct:30)
2025-08-30 06:06:25,470 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 30 个结果到收集器: qwen2.5-72b-instruct_70287_1756548385467449.json
2025-08-30 06:06:25,470 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
2025-08-30 06:06:25,502 - batch_test_runner - INFO - Database saved successfully
2025-08-30 06:06:25,502 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 06:06:25,502 - batch_test_runner - INFO - ============================================================
2025-08-30 06:06:25,502 - batch_test_runner - INFO - Batch test completed at 2025-08-30T06:06:25.502953
2025-08-30 06:06:25,502 - batch_test_runner - INFO - Summary:
2025-08-30 06:06:25,503 - batch_test_runner - INFO -   - Total tests: 30
2025-08-30 06:06:25,503 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 06:06:25,503 - batch_test_runner - INFO -   - Failed: 30
2025-08-30 06:06:25,503 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 06:06:25,503 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_055947.log
2025-08-30 06:06:25,503 - batch_test_runner - INFO - ============================================================
2025-08-30 06:06:25,503 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 06:06:25,503 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 06:06:25,503 - result_merger - INFO - 发现61个新的结果文件
2025-08-30 06:06:25,532 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 06:06:25,532 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 06:06:25,641 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:25,722 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:25,734 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:25,735 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:25,766 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:25,766 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:25,766 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50600227-6308-92ff-ab2a-70ed80ec4105"}, traceId: 2150438d17565483356541734e2d61'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b52d478-29e1-93f4-83b5-8c0c5f0aa26d"}, traceId: 213e066d17565483361823386e835b'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"119819ae-f4c4-92cc-afe2-afbf7ff402e0"}, traceId: 213e066417565483381685891e81cf'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8945585e-6261-97da-8068-6bcd06b7ecd8"}, traceId: 2150438d17565483393001751e2d61'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e969b3f7-bbb6-9509-a2a3-620ee6bb3a35"}, traceId: 2150438d17565483434981773e2d61'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f21c16aa-8a5a-9113-9fe7-ba967f7ac0e9"}, traceId: 213e006f17565483445271275ee477'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f1ed8256-e4b8-96c9-b10c-14e4613e2f37"}, traceId: 213e006917565483463898028ede85'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04a8a46c-2f1a-9feb-b62b-874f36659a65"}, traceId: 2150449017565483496483214e82a8'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fbd9c349-3d9e-900c-b2c8-c0ef4625bbae"}, traceId: 2150438d17565483510711819e2d61'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab5f8947-7237-93a5-8fa1-d39ec17430df"}, traceId: 215045b017565483536616456e82ca'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"94552d23-a4b9-9b06-b210-1725719ba934"}, traceId: 2150438d17565483541381843e2d61'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"edcddb9a-3f57-9e0b-ba39-559c197678e5"}, traceId: 2150438d17565483562501848e2d61'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"76240391-d735-9c22-844e-5fd03af905a6"}, traceId: 215041a817565483584183873e3311'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54244ee4-ae38-9c8f-8e00-9aab20e1c7b8"}, traceId: 2150438d17565483589171869e2d61'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ce36240-9e5c-98bf-b13d-15ce4c4fedbc"}, traceId: 2150438d17565483606921876e2d61'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b9e411c9-f689-9481-9707-20c5deb789fc"}, traceId: 2150423617565483611984343e0b1d'}2025-08-30 06:06:26,073 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:26,972 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:27,229 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:27,380 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:28,020 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:28,944 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:29,852 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:30,271 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:30,272 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of an incorrect agent decision (tool choice, parameters, sequence, or dependencies). No tools were executed and the error appears to be an exte
2025-08-30 06:06:30,356 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:30,416 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:30,654 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:30,654 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:30,679 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:30,679 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:30,680 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:30,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:32,023 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:32,454 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:32,461 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:33,936 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:33,967 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:34,991 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:35,509 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4411
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b52578aa-51ea-9329-bf1c-7922594530dd"}, traceId: 215041a817565483485917005e347b'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b56a919-f00e-9c39-9e97-36c61ac95525"}, traceId: 2150417d17565483497238908e10ac'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a21b7c39-c15c-96d1-a6f3-d2dd23c4be04"}, traceId: 2150417d17565483515878917e10ac'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a627dfcb-1e30-97be-b072-23c94454a5ea"}, traceId: 215040b917565483541567720ef054'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4374242-f00f-9e51-a3c3-ce3c4b7819d6"}, traceId: 2150417d17565483546588929e10ac'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d65af94a-b005-9567-8be9-4327e9ddd771"}, traceId: 2150455f17565483562645333e7f78'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.8
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1b4ef539-6909-9e6a-a65f-b078e920fd2c"}, traceId: 2150417d17565483579038940e10ac'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e3f64595-70e9-95ae-93e8-58181570a49d"}, traceId: 2150456617565483594385906e82ea'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"33e3f860-abf9-9876-83a7-e7106838044f"}, traceId: 2150417d17565483599428954e10ac'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"add6e0c9-5d5b-9217-b38d-8ff9342d4905"}, traceId: 2150417d17565483628581878e13b1'}
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6e36d5d5-75ea-962c-bcbc-018f1de56259"}, traceId: 2150417d17565483633608962e10ac'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef5cf956-b905-9a06-85ba-444a1e77e58f"}, traceId: 2150417d17565483662188973e10ac'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"853b2d01-debc-987b-80ce-ae50bf4be4c7"}, traceId: 2150430917565483692776553e1c65'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12348
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12348
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ed1ad375-3854-93e3-b54f-1edf046db396"}, traceId: 2150417d17565483708778991e10ac'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eb7b5a38-b258-9222-9e63-383f5a87cef8"}, traceId: 215042f817565483708938426e2717'}2025-08-30 06:06:35,512 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:36,207 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:36,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:37,617 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:38,136 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:38,836 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:39,704 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:39,705 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool for an API integration task, resulting in no execution path and inability to proceed; this is a wrong 
2025-08-30 06:06:39,814 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:39,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:40,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:41,943 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:41,954 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:42,901 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:43,389 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:44,062 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:44,423 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:44,439 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:44,439 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:44,464 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:44,464 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:44,464 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:44,509 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:45,110 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:45,110 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified: there were no required tools specified, no tools executed, and no evidence of incorrect tool selection, parameterizatio
2025-08-30 06:06:46,000 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:46,154 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:46,520 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:47,045 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:47,842 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:49,047 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:49,437 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:49,438 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select an appropriate tool to perform the API integration task; no API client/tool was invoked, resulting in no action taken and ove
2025-08-30 06:06:49,821 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:49,832 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:50,335 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d014413-c3b5-9a7c-873c-a581f5657ce2"}, traceId: 2150423617565483638604355e0b1d'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a7b1f076-b8e2-9383-8280-caf87f41ba9b"}, traceId: 2150423617565483657024369e0b1d'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73f86e33-9f7f-9e7f-9b47-bb76ad76ee62"}, traceId: 2150449017565483673082763e7f4e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7524b5db-0969-9c68-8e87-ccce05d07035"}, traceId: 2150423617565483682694384e0b1d'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81cb2229-d090-9405-9de6-5f657b6bd647"}, traceId: 2150416a17565483693494844ee0a3'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8db2ef1-27c3-92eb-a00d-4e7f4ef1f952"}, traceId: 2150416a17565483713724858ee0a3'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6aa0069a-800f-9e74-aa92-7dfb91476af8"}, traceId: 2150423617565483737624415e0b1d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a9cd006b-4665-9f52-b3dc-ead067315545"}, traceId: 2150416a17565483742624876ee0a3'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [SEARCH] Query: data parsing

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1dce3805-182f-910e-ae7a-e0a39b09562c"}, traceId: 2150458117565483764407268e8116'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"21200e54-ffcc-974e-8c32-9d199f7f7b14"}, traceId: 2150416a17565483775484887ee0a3'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8a9839b-64dc-993c-8ee4-697117993bfd"}, traceId: 2150417d17565483786061028e10ac'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7ad29a76-cbe4-9586-aa66-543ad5736bc0"}, traceId: 2150448717565483812992795e7ede'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5cdf96bf-a466-9f86-89fb-22ae16ac688f"}, traceId: 2150436a17565483849011843e213e'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3525100f-79ac-91af-97b6-253a88419c0c"}, traceId: 2150416017565483849491068ef128'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully2025-08-30 06:06:50,353 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:06:50,353 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:06:50,375 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:06:50,375 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:06:50,375 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:06:50,810 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:50,849 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:51,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:51,825 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:51,853 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:52,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:52,994 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:53,746 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:53,860 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:53,879 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:53,917 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:06:53,917 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize the required API integration tool(s); no tools were executed, resulting in 0% coverage and no progress. This
2025-08-30 06:06:54,269 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:54,817 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:55,524 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:55,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:06:55,958 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:06:56,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:57,084 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:57,138 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:57,664 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:58,688 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:06:58,688 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:06:59,708 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:00,465 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
[INFO] Tool embedding index loaded successfully

[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b708fee6-5d7f-9827-9df5-e2d08c3f5d38"}, traceId: 2150455f17565483724227991e801c'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5f9d93bf-0ff5-91d2-ba8c-84a19e049978"}, traceId: 215042f817565483732428437e2717'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"675d1523-6f53-9ec8-98e6-0cefbd30e6d7"}, traceId: 215042f817565483753088445e2717'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cabb4557-ca9f-93af-b90b-20adb40e8f6d"}, traceId: 215040ed17565483770683466ebf09'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.62
💾 智能Checkpoint: 保存10个结果...
   触发原因: 数量=10, 时间=131.6s, 强制=False
✅ Checkpoint完成: 成功保存 10/10 个结果
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12319
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12319
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f983f5c3-baa8-9a3f-b325-e1f4d5a2fb8b"}, traceId: 2150417d17565483795595850e1132'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f6a0510-463d-9891-b41e-3b7973b6958d"}, traceId: 215042f817565483811138482e2717'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd574967-dfa3-92fc-acdc-a63a469f1cb6"}, traceId: 2150458117565483816431866e8115'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10c4a1d4-1817-94ff-a9d5-1ab7ef3cea5a"}, traceId: 215042f817565483846348499e2717'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e257511f-38c7-9c22-a3b4-62046414bd02"}, traceId: 215042f817565483864248513e2717'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"26514c87-c54d-9847-b29e-b716b7532303"}, traceId: 2150416717565483872756525eecca'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d50b0620-0125-9358-a248-ae2ba4612c82"}, traceId: 213e066417565483901416874e8041'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fac62ecb-29e2-936e-a868-47decb75a833"}, traceId: 215042f817565483900738539e2717'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1a431aec-6668-91df-8ed4-f2879573fcb9"}, traceId: 213e006017565483916832031ee3c3'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e8b51c7e-7cc3-998a-8c4c-1ddee085e33d"}, traceId: 215042f817565483921718552e2717'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1498933-d602-9c10-be0e-4d4976d3560f"}, traceId: 215042f817565483946988562e2717'}2025-08-30 06:07:01,000 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:07:01,511 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:01,512 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not execute any tools or steps for the simple_task, effectively not following the required workflow; this is a sequencing/flow decision 
2025-08-30 06:07:01,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:01,937 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:07:01,947 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:02,925 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:04,872 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:07:05,792 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:05,921 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:07:06,301 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:06,604 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 06:07:06,970 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:06,970 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown internal error with no tools executed; no evidence of a specific agent decision error (no wrong tool selection, parameter misconfiguration, incorre
2025-08-30 06:07:07,510 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:08,697 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:08,712 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:07:08,713 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:07:08,755 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:07:08,755 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:07:08,755 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:07:09,659 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:11,068 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:11,082 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:07:11,082 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:07:11,107 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:07:11,107 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:07:11,108 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:07:11,196 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:11,424 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:11,685 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:11,686 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error (no tools selected, no parameters set, no sequence attempted). The error message is 'Unknown error', suggest
2025-08-30 06:07:11,935 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"974b2869-53a7-904d-b0ea-4a97cc822844"}, traceId: 2150415d17565483866094901e119f'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"851f33fe-bcc6-9820-83a4-89221343327e"}, traceId: 2150415d17565483881844905e119f'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8de7afc-34ad-9a6c-8aa4-0c115e2cefd2"}, traceId: 2150415d17565483900754919e119f'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"594469de-a89e-9971-a2a5-42221e9faa17"}, traceId: 215045b417565483917467803e8257'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [SEARCH] Query: data parsing

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb7d1b0e-de7d-9af8-86e5-4c01086949cb"}, traceId: 2150415d17565483936834931e119f'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e64ab3c0-c119-9bc9-b7f5-d843e2c6f5e6"}, traceId: 215045b417565483952137822e8257'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"18a64a60-670c-9d3b-a28d-e19afb4b8829"}, traceId: 215045b417565483967787832e8257'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d06cf108-c157-91e7-a5cb-d7c87f0e7bd8"}, traceId: 2150415d17565483972834946e119f'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8dbc63ed-4d13-9a25-bd07-45d24b4dbc63"}, traceId: 2150415d17565483995654956e119f'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1bcca204-93af-99a2-9976-868d64a12c22"}, traceId: 215045b417565484000747850e8257'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b5b29fa0-e228-979f-ab43-5a7413f7503d"}, traceId: 2150415d17565484011834964e119f'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8f8dac4-c0c6-9b5e-90cd-3d19235e001a"}, traceId: 215045b417565484025957863e8257'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2c10d6a4-742a-9213-815d-7cfec54b23bd"}, traceId: 215045b417565484052157879e8257'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"344b1410-dbca-9031-a325-e56f8f83bb41"}, traceId: 2150415d17565484057254981e119f'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8a99cfb-d7c8-9d11-b9fe-59d53cba6965"}, traceId: 2150415d17565484095555003e119f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-30 06:07:12,437 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:13,021 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:14,406 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:14,926 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:15,436 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:17,322 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:17,977 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:18,196 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:19,946 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 06:07:19,959 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 06:07:19,959 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 06:07:19,992 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 06:07:19,992 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 06:07:19,992 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 06:07:20,458 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:21,648 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:21,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:22,172 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:22,173 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified due to lack of actionable interaction data: there were no required tools (0/0) and no tool executions to assess tool cho
2025-08-30 06:07:22,885 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:23,417 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:25,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:25,509 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:25,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:26,490 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:27,417 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:27,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:28,606 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:29,146 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:30,939 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:32,334 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:32,867 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:33,832 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:34,709 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:34,710 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were required or executed for the basic_task (tool coverage 0%). There is no evidence of a wrong tool choice; the failure appears to be d
2025-08-30 06:07:34,732 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 06:07:35,661 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ec752adb-2246-9022-8e8b-6dc136d8ae56"}, traceId: 2150415d17565483954611941e1146'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"26d2eee9-ae54-9239-9206-091e6a452259"}, traceId: 215042f817565483985518583e2717'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f23bf284-4bae-95fa-b6d0-aa61136b4bb8"}, traceId: 215042f817565484036098607e2717'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13073
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13073
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"20c36b4f-fb55-961b-9e3a-e57053b41b89"}, traceId: 2150430c17565484042196547e1e6f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ace40d8d-200c-99e1-8de1-1a6bf2ece246"}, traceId: 215040cc17565484053855145ed6ac'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bb39a65e-de60-93d8-a87c-4003bdaabcbe"}, traceId: 213e007317565484062565580ee41b'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"89ca3172-b6c2-9fea-a897-3b584f3c92ad"}, traceId: 215040cc17565484075725151ed6ac'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b75c4ff-43c7-978b-b2be-fe8c683ca858"}, traceId: 215042f817565484087933987e26b4'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0879b18-5ae5-9f0a-bfe2-72c6f6785f7e"}, traceId: 215040cc17565484110785172ed6ac'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.76
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7317645-80c4-97f8-ba07-33d39ae92fc1"}, traceId: 2150415b17565484147717887ee3ad'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"328cb133-3d15-9f1b-8dd5-9dcad3e42a88"}, traceId: 215040cc17565484163045199ed6ac'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2d7e5334-a58c-9fe6-8f30-68f6a4766303"}, traceId: 213e006917565484173932245ee1e1'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fd22605d-3511-998e-af6c-4db87119b387"}, traceId: 215040cc17565484189265212ed6ac'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81adde01-53c6-9b1c-910a-e37ba134c5a5"}, traceId: 213e058a17565484196884526e36f1'}2025-08-30 06:07:37,331 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:39,291 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:41,002 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:41,004 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for a data_pipeline task; the workflow cannot proceed without choosing and executing the appropriate data ingest
2025-08-30 06:07:43,526 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:48,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 06:07:49,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:49,641 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision (no tools executed, no parameters set, and no sequence defined). With required tools coverage reported as 0% and
2025-08-30 06:07:55,682 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:55,686 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548475684021.json
2025-08-30 06:07:55,687 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548475686910.json
2025-08-30 06:07:55,687 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548475687190.json
2025-08-30 06:07:55,687 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548475687469.json
2025-08-30 06:07:55,687 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70286_1756548475687760.json
2025-08-30 06:07:55,688 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
2025-08-30 06:07:55,690 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 35 个结果到收集器: qwen2.5-72b-instruct_70286_1756548475688464.json
2025-08-30 06:07:55,690 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
2025-08-30 06:07:55,727 - batch_test_runner - INFO - Database saved successfully
2025-08-30 06:07:55,727 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 06:07:55,728 - batch_test_runner - INFO - ============================================================
2025-08-30 06:07:55,728 - batch_test_runner - INFO - Batch test completed at 2025-08-30T06:07:55.728354
2025-08-30 06:07:55,728 - batch_test_runner - INFO - Summary:
2025-08-30 06:07:55,728 - batch_test_runner - INFO -   - Total tests: 35
2025-08-30 06:07:55,728 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 06:07:55,728 - batch_test_runner - INFO -   - Failed: 35
2025-08-30 06:07:55,728 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 06:07:55,728 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_055947.log
2025-08-30 06:07:55,728 - batch_test_runner - INFO - ============================================================
2025-08-30 06:07:55,728 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 06:07:55,729 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 06:07:55,729 - result_merger - INFO - 发现6个新的结果文件
2025-08-30 06:07:55,747 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 06:07:55,747 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 06:07:56,064 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:07:56,066 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision/error is identifiable. The task shows an unknown runtime error with no tools executed and no evidence of tool selection, parameter 
2025-08-30 06:08:00,154 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:00,154 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool for the api_integration task; no required tools were invoked, resulting in zero tool coverage and a fa
2025-08-30 06:08:05,143 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:05,144 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Insufficient information to determine a specific agent decision error; the log lacks tool usage, parameters, or dependency/sequence details. In a mult
2025-08-30 06:08:06,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:06,832 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected for the task and no clarification was sought for an unknown task; the agent failed to identify or pick an appropriate tool (o

[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a5186dbd-5407-96da-ab8c-481cc9e9a9b7"}, traceId: 2150438d17565483339133010e2b72'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f894b25-c8f8-9e1c-9eb1-1d08211d037a"}, traceId: 215044eb17565483356435119e7f92'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c9b420d-27e6-9743-bf03-aba21a3ee365"}, traceId: 215044eb17565483368295124e7f92'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a5f3e38-dcfd-9476-ab82-0433287b5e75"}, traceId: 215044eb17565483398005138e7f92'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ddd8bac3-e633-94e3-ab3c-2a144f4f6371"}, traceId: 2150434117565483405651009e1ee6'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6f7a030f-e1e3-9f4d-b0eb-4bea696c1803"}, traceId: 215044eb17565483434885159e7f92'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4424
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4424
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4577686960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"449db237-371e-980d-a3f2-6ac160402e27"}, traceId: 213e064b17565483440254128e790e'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77633e9e-6416-92c6-8bda-64433589d361"}, traceId: 213e007317565483447583134ee498'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2cc05b9b-f1b1-986c-987e-e82a106229bd"}, traceId: 213e043b17565483458752271e21de'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e81c37b-2998-904d-b0f6-2d79680ff8ad"}, traceId: 213e006917565483480672505ee073'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5194cac-15b5-9177-aa5f-dff9bd20260c"}, traceId: 2150430d17565483488267537e975d'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.85
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a7ef31b-f2a4-9bbb-a852-1ae1426bf673"}, traceId: 215045be17565483505816232e8092'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d412f5f-100a-934d-9957-c6cdb9bb6486"}, traceId: 215042f817565483525671501e25cc'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6438157a-2d90-96d8-88b3-abbcd00b17e8"}, traceId: 215045f517565483528422580e7f4a'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d238a2cd-cd83-98cc-bdc9-9baf6d17f4e4"}, traceId: 2150416017565483562127203ef0c5'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts2025-08-30 06:08:09,837 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:09,838 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision error identified. The error message is generic ('Unknown error') with no tool execution details. In absence of evidence of wro
2025-08-30 06:08:15,702 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:15,704 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to determine a specific agent decision error. There are no documented tool selections, parameters, or sequence decisions, and the 
2025-08-30 06:08:15,961 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:15,963 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were required by the task, yet the agent produced a complete failure due to inaction (no tool calls or steps executed). This represents a
2025-08-30 06:08:20,694 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:20,695 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or follow the expected multi_stage_pipeline sequence (no tools invoked, no steps completed), effectively break
2025-08-30 06:08:21,017 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:21,018 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any required tool(s) for the api_integration task; no tools were executed, indicating a decision to proceed w
2025-08-30 06:08:26,628 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:26,629 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tools for the multi-stage pipeline; no execution tools were chosen, leading to complete failure.",
  "confi
2025-08-30 06:08:31,683 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:31,685 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute the required basic_task at all, effectively failing to initiate the expected execution sequence. No tools were used, and
2025-08-30 06:08:32,514 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:32,515 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select/initialize the necessary tools for the multi_stage_pipeline; no tools were chosen or executed, effectively skipping require
2025-08-30 06:08:35,411 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:35,412 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No clear agent decision error detected: there is no evidence of tool selection, parameter, or sequence mistakes. The error message is unknown and no tools 
2025-08-30 06:08:40,528 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:40,528 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The failure is described as an unknown error with no t
2025-08-30 06:08:42,609 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:42,611 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task had 0 required tools (0/0 coverage), yet the agent produced an 'Unknown error' without establishing a clear handling approach. This indic
2025-08-30 06:08:45,785 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:45,785 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a faulty agent decision (tool choice, parameters, sequence, or dependencies). The error is reported as 'Unknown error' with no exec
2025-08-30 06:08:48,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:48,637 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No primary agent decision error detected. The task required no tools (coverage 0/0), and there is no evidence of tool selection, parameterization, sequenci
2025-08-30 06:08:51,906 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:51,907 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decisions or tool executions were recorded for the data_pipeline task. Without observed tool usage, parameters, sequence, or dependencies
2025-08-30 06:08:54,990 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:54,990 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not execute any stage and did not follow the required pipeline sequence (A→B→C). No tools were selected or actions taken, indicating a f
2025-08-30 06:08:58,751 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:58,752 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any required tools for the multi_stage_pipeline (no tools executed), leading to zero coverage and no correct 

[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a489616-e9a9-9507-b344-40a314a0c3e5"}, traceId: 215040cc17565484216555227ed6ac'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1774c991-b9c9-9b96-9deb-a576e6a621c6"}, traceId: 2150438d17565484250422664e2b0f'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"51c71987-306a-9936-8d2c-1fe1040bbc9a"}, traceId: 215040cc17565484255345247ed6ac'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8572cfe6-e3e2-9b92-8ab3-aac2e9572b51"}, traceId: 215045a817565484302754796e8015'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 17522
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=17522
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5717031984)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de02440c-e8ef-9863-9349-cc8e8d2d0bc7"}, traceId: 215040cc17565484306475275ed6ac'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"479bae31-7ca4-90a2-a686-f5a2bd165429"}, traceId: 2150456617565484322498722e82c9'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2364135b-8a3b-9f02-8043-6695fc02f90f"}, traceId: 2150456617565484341448730e82c9'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98aa0746-d2a9-98a0-9241-f40172025eb0"}, traceId: 2150456617565484371828745e82c9'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13045
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13045
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"845ec1ee-ba23-9677-81ba-6231b10cb7d2"}, traceId: 2150456617565484421208762e82c9'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68a6c6dd-5659-9c11-9d7f-374f814e3e7a"}, traceId: 2150456617565484452008775e82c9'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.64
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bff2b8e9-25db-95dd-b62d-beab04f15435"}, traceId: 2150456617565484483548788e82c9'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"da56cb97-8238-9a79-8fe6-73765b63eb71"}, traceId: 2150456617565484501718795e82c9'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9217fcb7-6684-9c15-8a77-23cc47266c3f"}, traceId: 2150456617565484548728817e82c9'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"502fd5d8-efd1-9e86-a578-d0fed26c4252"}, traceId: 2150456617565484564538822e82c9'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"97cb7fae-5dd9-9851-9436-a7ce1c018cc5"}, traceId: 2150456617565484585168832e82c9'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"679ded53-57d6-960c-a57e-460dae7acb99"}, traceId: 2150456617565484627378851e82c9'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2589236a-81a3-9680-bafa-36af33e539ef"}, traceId: 2150456617565484673088874e82c9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15297
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15297
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.72
💾 智能Checkpoint: 保存5个结果...
   触发原因: 数量=5, 时间=97.6s, 强制=True
✅ Checkpoint完成: 成功保存 5/5 个结果

[INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_060755.json
[SAVE_ENHANCED] 开始增强保存，时间: 06:07:55
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-72b-instruct的新prompt_type: flawed_missing_step
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.38) - Insufficient information to determine a specific a
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No actionable agent decision error identified. The
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - Insufficient information to determine a specific a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.80)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.55) - The task had 0 required tools (0/0 coverage), yet 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.80) - No primary agent decision error detected. The task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)2025-08-30 06:08:59,099 - result_merger - INFO - 模型qwen2.5-72b-instruct保存40/40条记录
2025-08-30 06:08:59,100 - result_merger - INFO - 合并完成，共处理6个文件，保存40条记录
2025-08-30 06:08:59,101 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 06:08:59,101 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 4)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.05s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 23)
[INFO] 最终合并完成: 6 个文件
2025-08-30 06:08:59,223 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 06:08:59,223 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-30 06:08:59,487 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:08:59,489 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed; the agent did not initiate or follow the required API integration workflow (e.g., setup/authentication, API call, and re
2025-08-30 06:09:08,294 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:08,294 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "For a basic_task that required no tools, the correct approach would be to directly complete the task (or provide output) without invoking any tool
2025-08-30 06:09:13,041 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:13,042 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or observable agent decision was made; the failure is an unknown error with 0% tool coverage and no evidence of a wrong tool choice, incorrec
2025-08-30 06:09:19,046 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:19,046 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or configured to address the (unknown) data_pipeline task. The agent failed to choose an appropriate tool or tool sequence,
2025-08-30 06:09:25,147 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:25,148 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision error can be identified: no tools were executed and thus no tool selection, parameter, sequence, or dependency decisions to critiqu
2025-08-30 06:09:29,856 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:29,857 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to start the data_pipeline task; no initial tool was chosen, effectively stopping progress before any acti
2025-08-30 06:09:34,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:34,976 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the data_pipeline task, leaving the workflow with zero executed tools. This indicates the agent failed t
2025-08-30 06:09:39,619 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:39,619 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any of the required data_pipeline tools (no data_loader/reader invoked), resulting in 0% tool coverage. The task re
2025-08-30 06:09:44,390 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:44,391 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or an inappropriate tool was chosen for an unknown task, indicating a tool-selection error; the agent failed to identify or s
2025-08-30 06:09:49,078 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:49,078 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision errors can be inferred: there were no tool selections, parameterizations, or sequence decisions recorded, and the error message is 
2025-08-30 06:09:54,416 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:09:54,416 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision. The task shows an 'Unknown error' with no tool usage or executed steps to assess tool selection, parameter configura
2025-08-30 06:10:00,767 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:00,767 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions/tools were executed and no task workflow was followed, effectively breaking the expected execution sequence for a basic_task (A→B→C).",
2025-08-30 06:10:07,943 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:07,944 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "In a multi_stage_pipeline task, the failure appears to stem from not executing the stages in the required order or skipping prerequisite steps, in
2025-08-30 06:10:16,810 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:16,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or explicit action taken for a simple task; the agent did not make a decision to execute any steps, resulting in complete failure due to inac
2025-08-30 06:10:22,480 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:22,481 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient task data and an 'Unknown error' message provide no basis to determine if the agent made a wrong decision (tool selection, parameter config, s
2025-08-30 06:10:27,109 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:27,110 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient observable agent decisions to identify a primary agent error. No tools were executed, no parameters or sequence were demonstrated, and the err
2025-08-30 06:10:31,961 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:31,961 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of an agent decision error: there were no tool executions, selections, or parameter configurations to evaluate, and the error message is generi
2025-08-30 06:10:44,585 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:44,585 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were taken and no tools were executed; the agent failed to initiate the required workflow sequence for basic_task (i.e., the expected A
2025-08-30 06:10:50,811 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:50,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any tool for a task that requires action; no tools were invoked and no execution steps were performed. This co
2025-08-30 06:10:54,995 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:54,996 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and initialize any of the required data_pipeline tools (no tool was executed). This indicates a tool selection decision
2025-08-30 06:10:59,615 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:10:59,616 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select an appropriate tool (or any tool) for the unknown multi-stage task; no tools were executed, indicating a tool-selection d
2025-08-30 06:11:04,104 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:04,105 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a wrong agent decision (tool selection, parameters, sequence, or dependencies). The error message is generic (Unknown error), sugge
2025-08-30 06:11:10,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:10,752 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task was unknown and produced no actionable steps, yet the agent failed to select or define an appropriate toolset to proceed (i.e., no tool/p
2025-08-30 06:11:16,577 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:16,578 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent did not establish or respect the prerequisite sequence of the multi_stage_pipeline (no tools were invoked), indicating the pipeline dependen
2025-08-30 06:11:19,881 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:19,882 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any API integration tool; no tools were used despite the task requiring API integration actions, indicating
2025-08-30 06:11:24,976 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:24,977 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the multi_stage_pipeline; the agent failed to choose the required tools (tool selection step skipped), leadi
2025-08-30 06:11:29,500 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:29,501 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "An unknown/system-level error occurred with no tools executed and no identifiable agent decision (tool selection, parameter configuration, sequence, or dep
2025-08-30 06:11:34,777 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:34,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision errors identifiable: there were no tools selected or executed, no parameters configured, and no sequence or dependency steps attempted. T
2025-08-30 06:11:40,619 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:40,619 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of an incorrect agent decision. The error message is a generic 'Unknown error' with no tool execution data available, making it impossible to a
2025-08-30 06:11:51,363 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:51,363 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent tool decisions were made (no tools were required or executed for the basic_task), so there is no agent decision error in tool selection, parameter
2025-08-30 06:11:58,429 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:11:58,430 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or establish a plan for the API integration task, effectively failing to follow the required task sequence (no
2025-08-30 06:12:04,958 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:04,959 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool for an api_integration task; no tools were used (zero coverage), indicating a wrong decision to skip/tool 
2025-08-30 06:12:10,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:10,130 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify any agent decision error; there were no tool selections, parameter configurations, or execution sequence to critique, 

[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15294
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15294
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef503264-ab1a-9f53-9726-1499d351c8af"}, traceId: 2150417717565483624482670edb9e'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"25e79f20-4b54-9a56-8ea8-bc62a8d5873e"}, traceId: 2150423617565483648435691e0c70'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"55c7fadb-9678-961a-94e0-6abf16dd9d2d"}, traceId: 215040ed17565483682534647ebc73'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"378068c7-e08a-9dae-99e5-ab3071729601"}, traceId: 215045b417565483729465188e808a'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a7b8987-a362-98e0-8d27-b644da41d053"}, traceId: 2150417517565483766676774eddea'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12541
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12541
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=max_turns_errors, confidence=0.7
Progress: 30/30 (Success: 0)
💾 智能Checkpoint: 保存10个结果...
   触发原因: 数量=10, 时间=112.2s, 强制=True
✅ Checkpoint完成: 成功保存 10/10 个结果

[INFO] Batch writing 30 records to database (qwen2.5-72b-instruct:30)
[INFO] Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_060625.json
[SAVE_ENHANCED] 开始增强保存，时间: 06:06:25
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No evidence of an incorrect agent decision (tool c
[V3_UPDATE] 创建新prompt类型结构: qwen2.5-72b-instruct -> flawed_missing_step
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62) - Agent did not select or initialize any tool for an
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error identified: there were no 
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.79)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - Unknown internal error with no tools executed; no 
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.65) - No evidence of a concrete agent decision error (no
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.58) - No agent decision error identified due to lack of 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65) - No agent-level decision/error is identifiable. The
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72) - Agent did not select or initialize any tool for th
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.68) - No tool was selected for the task and no clarifica
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...2025-08-30 06:12:10,659 - openai._base_client - INFO - Retrying request to /chat/completions in 0.472301 seconds
2025-08-30 06:12:17,237 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:17,237 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error can be identified from the provided context: there were no tools executed (0/0 coverage) and the error is 'Unknown error'. Without 
2025-08-30 06:12:25,498 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:28,069 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:28,070 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed due to an internal unknown error, effectively failing at the tool-selection/initialization decision step and pr
2025-08-30 06:12:31,759 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:34,568 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:34,568 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "There were no required tools for this simple_task, yet the agent treated tool usage as part of the workflow, effectively selecting/attempting a to
2025-08-30 06:12:39,171 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:39,172 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize the required data_pipeline tools (0% tooling coverage); no tools were executed, indicating a tool-choice dec
2025-08-30 06:12:44,323 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:48,445 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:48,446 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Task declared no required tools and there were no tools executed; thus there is no agent decision error (no tool selection/parameter/configuration/sequence
2025-08-30 06:12:53,691 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:56,343 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:12:56,344 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed (tool coverage 0%), indicating the agent failed to choose an appropriate tool for the data_pipeline task. With no
2025-08-30 06:13:00,465 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"929269fa-fd55-94c2-8289-b2680987341c"}, traceId: 213e064617565484108713736e0c01'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 7: No tools executed after multiple turns

[TURN 8/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d5f5533-3aa5-9cc9-ad0d-925392815619"}, traceId: 2150430c17565484130047793e20e0'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c3a1c7d-4c48-9e9e-919b-04b72f39930b"}, traceId: 215045b417565484134947929e8257'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f5f4186-347c-9dc8-b810-4f60b598adc2"}, traceId: 215045b417565484157937940e8257'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ceb18592-ec74-9517-82b7-ae4d2dcde4a4"}, traceId: 213e006a17565484163181893ee006'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"45f29fae-4c50-99a7-b395-79ead68a5f99"}, traceId: 213e065017565484184396496e7f6f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"00f12f01-a496-979a-bb08-d1fc3a9e2e69"}, traceId: 215045b417565484179127949e8257'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b8b2303-4fd6-90bb-a51b-cb4930ba1b35"}, traceId: 215045b417565484216537987e8257'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b372992-fbba-9d54-856d-6b0e6c1679a3"}, traceId: 215044da17565484221786765e805b'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [FORMAT_ISSUE] Turn 6: No tools executed after multiple turns

[TURN 7/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad500bee-4c7a-9fe2-838e-282633f540ec"}, traceId: 2150456117565484267651992e7f5f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e0db0ef-e407-9411-b979-b9eb3bb15226"}, traceId: 2150413117565484279258623eeaad'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 2 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0b132a4-a9a6-9374-bb13-3f73fb412304"}, traceId: 215045b417565484289252443e7fa2'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a60d16d1-ff15-9cc7-b4bf-fa0df6423a0d"}, traceId: 2150436817565484311748508e1f8b'}2025-08-30 06:13:02,540 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:02,540 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error is reported as Unknown. There is insufficient evidence to attribute the failure to a specific agent decisi
2025-08-30 06:13:07,933 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:07,934 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: no tools were selected or executed, and there is only a generic 'Unknown error'. Therefore, the failure cannot be attribu
2025-08-30 06:13:10,405 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:12,359 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:12,359 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task, resulting in complete failure. This indicates a wrong tool choice/omission at the in
2025-08-30 06:13:18,793 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:18,794 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not initiate or execute any steps in the required API integration sequence, effectively breaking the intended workflow order. No tools w
2025-08-30 06:13:21,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:23,722 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:23,723 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "For a multi-stage pipeline, the agent did not select or specify any tools to execute, resulting in no steps being performed. This indicates a wron
2025-08-30 06:13:29,427 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:29,427 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified: no tools were selected or executed, no parameters specified, and no sequence decisions were made. The error appears ext
2025-08-30 06:13:30,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:35,418 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:35,418 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute failure to an agent decision. No tools were executed, so there is no evidence of wrong tool choice, incorrect paramet
2025-08-30 06:13:36,754 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:40,291 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:40,291 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select and/or invoke any necessary tool for the api_integration task, resulting in 0% tool coverage and a complete failure. This
2025-08-30 06:13:45,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:45,532 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:45,533 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tools to perform the multi_stage_pipeline task; no tools were invoked, indicating a failure in tool selecti
2025-08-30 06:13:48,980 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:48,980 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or invoke any tool for the basic_task task; no tool was chosen or executed, effectively a tool selection decision error (no
2025-08-30 06:13:52,176 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:13:52,176 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for an api_integration task, indicating the agent chose not to engage any of the required tooling (tool selectio
2025-08-30 06:13:53,982 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:00,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:00,504 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed. The task context is unknown, so the agent failed to choose a tool or proceed with any tooling, indicating a to
2025-08-30 06:14:01,490 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:08,200 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:14,214 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:14,216 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or attempted for the api_integration task; the agent effectively opted for no tooling or an unspecified approach. In typical 
2025-08-30 06:14:17,516 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:17,518 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857518304.json
2025-08-30 06:14:17,519 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857518975.json
2025-08-30 06:14:17,519 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857519424.json
2025-08-30 06:14:17,520 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857519906.json
2025-08-30 06:14:17,520 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857520343.json
2025-08-30 06:14:17,521 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857520815.json
2025-08-30 06:14:17,521 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857521160.json
2025-08-30 06:14:17,521 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857521594.json
2025-08-30 06:14:17,522 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857521861.json
2025-08-30 06:14:17,523 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857522574.json
2025-08-30 06:14:17,523 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857523180.json
2025-08-30 06:14:17,523 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857523521.json
2025-08-30 06:14:17,524 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857524009.json
2025-08-30 06:14:17,524 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857524422.json
2025-08-30 06:14:17,525 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857524684.json
2025-08-30 06:14:17,525 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857525071.json
2025-08-30 06:14:17,525 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857525328.json
2025-08-30 06:14:17,525 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857525689.json
2025-08-30 06:14:17,526 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857525932.json
2025-08-30 06:14:17,530 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548857526405.json
2025-08-30 06:14:21,426 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:21,427 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error (tool choice, parameters, sequence, or dependencies). The error message is generic ('U
2025-08-30 06:14:23,695 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:28,542 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:28,542 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or establish a workflow order. There is no evidence of a sequence being followed (e.g., A→B→C), nor any tool u
2025-08-30 06:14:32,404 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:32,918 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:32,918 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any appropriate API/tool for an api_integration task; no API client or request tool was used, so the required t
2025-08-30 06:14:36,596 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:36,596 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize the required data_pipeline tool(s); no tool was used (0% tooling coverage), indicating a wrong or missing tool 
2025-08-30 06:14:40,194 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:46,150 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:46,152 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actionable workflow sequence was defined or executed: the agent did not select nor run any tools due to missing task details, failing to establ
2025-08-30 06:14:46,620 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:50,495 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:50,495 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of an agent decision error (tool choice, parameters, sequence, or dependencies). The task shows Unknown error with no tools executed, indicatin
2025-08-30 06:14:55,727 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:55,727 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error: the task is unknown, no tools were executed, and the error appears systemic/unknown rather than a misdecision such as
2025-08-30 06:14:57,287 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:59,828 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:14:59,829 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize the necessary data_pipeline tools; proceeded without any tool invocation, resulting in no data processing st
2025-08-30 06:15:07,215 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:07,216 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to perform the basic_task, effectively choosing no tool. This is a wrong tool decision since action requir
2025-08-30 06:15:11,356 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:13,851 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:13,851 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or invoke any tool for the multi_stage_pipeline task; no required tools were chosen, effectively stopping progress and 
2025-08-30 06:15:19,290 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de902e76-01f3-9a3b-a5fa-e2dd660219bb"}, traceId: 2150417c17565484316602027eeeac'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e1f298cc-b6fd-9e3e-a238-9fd9da0a83b0"}, traceId: 2150417c17565484336342033eeeac'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c6a29eb8-9731-962c-a905-4273cc6f4088"}, traceId: 213e062017565484346787474e8048'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ddb94478-5e29-95e6-b6dd-e686134c0f3a"}, traceId: 2150417c17565484365422045eeeac'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"847ccf50-4e1d-9580-9e63-c23efea0c888"}, traceId: 213e042f17565484391982000e22a6'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[ASSISTED] Task received 1 format helps, final result: failure
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_missing_step for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 4763554480)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8e039c6a-a8b4-94d4-9f26-91074be846c5"}, traceId: 2150417c17565484396882063eeeac'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6a64ea7b-ae57-9da3-8683-3b5bda05c19c"}, traceId: 2150456617565484407988756e82c9'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f530bde4-bd38-9c4e-95ab-956a58867140"}, traceId: 2150456617565484426298767e82c9'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8a262997-020a-9f9f-b2d4-e3c9a99c7ca7"}, traceId: 2150417c17565484446932091eeeac'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1bb32e4-9574-9c4e-a237-5d0e34c7420b"}, traceId: 2150456617565484457068777e82c9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b7874f2-cc60-9167-a16a-6af7e66195ff"}, traceId: 2150456617565484478418785e82c9'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef23d588-3b8b-9cde-9a27-bf7d827d007e"}, traceId: 2150456617565484515568805e82c9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=dependency_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15365
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15365
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12531
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12531
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12989
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12989
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.85
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12527
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12527
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类2025-08-30 06:15:20,208 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:20,209 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision could be evaluated: there were no tools executed and the task details are unknown, resulting in a failure that appears to be a
2025-08-30 06:15:25,792 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:25,793 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool appropriate for an API integration task (no required tool was utilized). This indicates a wrong tool decis
2025-08-30 06:15:26,454 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:31,538 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:31,539 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage occurred and the error reported is unknown, making it impossible to infer any specific agent decision error. The failure appears to be a syst
2025-08-30 06:15:32,865 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:36,553 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:36,553 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required API/tool for the integration task (no tools were used), indicating a wrong/toolless decision at the ve
2025-08-30 06:15:41,503 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:42,164 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:42,164 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to identify a specific agent decision error. No tools were executed and there is no explicit error message, so we cannot determine
2025-08-30 06:15:47,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:49,965 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:49,966 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool/step for the task, effectively making no decision about which tool to use (or whether to act at all). 
2025-08-30 06:15:53,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:54,621 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:15:54,621 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and the error message is ambiguous ('Unknown error'). There is no evidence of a wrong agent decision (tool choice, param
2025-08-30 06:16:01,238 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:02,090 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:02,091 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The error message is generic ('Unknown error') with no observable agent decisions (no tools executed, no parameters or sequence choices). There is no evide
2025-08-30 06:16:09,499 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:09,900 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:09,901 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed (coverage 0%), and the error is reported as 'Unknown error'. There is insufficient evidence of a mis-decision by the age
2025-08-30 06:16:14,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:14,618 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "For an api_integration task, no tool was selected or invoked. The agent failed at the tool-selection stage by not choosing an appropriate tool (e.

[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No clear agent decision error detected: there is n
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.75) - There is no evidence of a wrong agent decision (to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - There is no evidence of a faulty agent decision (t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No tool usage or observable agent decision was mad
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.68) - No tools were selected or configured to address th
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.75) - No agent-level decision error can be identified: n
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60) - No tool was selected or an inappropriate tool was 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No agent-level decision errors can be inferred: th
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_missing_step -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No evidence of a wrong agent decision. The task sh
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.65) - Insufficient task data and an 'Unknown error' mess
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - Insufficient observable agent decisions to identif
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 10)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No evidence of an agent decision error: there were
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72) - The agent did not select an appropriate tool (or a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - There is no evidence of a wrong agent decision (to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65) - The task was unknown and produced no actionable st
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - An unknown/system-level error occurred with no too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.65) - No agent decision errors identifiable: there were 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.65) - No evidence of an incorrect agent decision. The er
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 12)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - Insufficient information to identify any agent dec
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 9)2025-08-30 06:16:20,166 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:20,167 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or use any tool (no tools executed) for a task that requires action; effectively a wrong (or missing) decision about tool
2025-08-30 06:16:20,825 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:20,827 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980826510.json
2025-08-30 06:16:20,827 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980827349.json
2025-08-30 06:16:20,828 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980827751.json
2025-08-30 06:16:20,828 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980828080.json
2025-08-30 06:16:20,828 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980828403.json
2025-08-30 06:16:20,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980828803.json
2025-08-30 06:16:20,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980830190.json
2025-08-30 06:16:20,830 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980830626.json
2025-08-30 06:16:20,831 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980830920.json
2025-08-30 06:16:20,831 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980831181.json
2025-08-30 06:16:20,831 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980831502.json
2025-08-30 06:16:20,831 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980831747.json
2025-08-30 06:16:20,832 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980831956.json
2025-08-30 06:16:20,832 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980832171.json
2025-08-30 06:16:20,832 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980832410.json
2025-08-30 06:16:20,833 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
2025-08-30 06:16:20,837 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 35 个结果到收集器: qwen2.5-72b-instruct_70285_1756548980835356.json
2025-08-30 06:16:20,837 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
2025-08-30 06:16:20,872 - batch_test_runner - INFO - Database saved successfully
2025-08-30 06:16:20,873 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 06:16:20,873 - batch_test_runner - INFO - ============================================================
2025-08-30 06:16:20,873 - batch_test_runner - INFO - Batch test completed at 2025-08-30T06:16:20.873192
2025-08-30 06:16:20,873 - batch_test_runner - INFO - Summary:
2025-08-30 06:16:20,873 - batch_test_runner - INFO -   - Total tests: 35
2025-08-30 06:16:20,873 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 06:16:20,873 - batch_test_runner - INFO -   - Failed: 35
2025-08-30 06:16:20,873 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 06:16:20,873 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_055947.log
2025-08-30 06:16:20,873 - batch_test_runner - INFO - ============================================================
2025-08-30 06:16:20,873 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 06:16:20,873 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 06:16:20,874 - result_merger - INFO - 发现36个新的结果文件
2025-08-30 06:16:20,893 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 06:16:20,894 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制

[AI_DEBUG] 生成的txt_content长度: 12897
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12897
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12529
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12529
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13231
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13231
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4574
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4574
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12617
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12617
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12466
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12466
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.66
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4533
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4533
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4574
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4574
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12941
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12941
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.6
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4675
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4675
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4294
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4294
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13427
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13427
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4288
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4288
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13356
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13356
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13559
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13559
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 18082
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=18082
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13362
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13362
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4453
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4453
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 11538
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=11538
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.75
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12324
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12324
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.71
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16628
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16628
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 15267
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=15267
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.88
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12361
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12361
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4470
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4470
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
💾 智能Checkpoint: 保存15个结果...
   触发原因: 数量=15, 时间=123.3s, 强制=False
✅ Checkpoint完成: 成功保存 15/15 个结果

[INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_061620.json
[SAVE_ENHANCED] 开始增强保存，时间: 06:16:20
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-72b-instruct的新prompt_type: flawed_missing_step
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: dependency_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 20)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'dependency_errors' -> 'dependency_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: dependency_errors -> dependency_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors2025-08-30 06:16:26,909 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:26,911 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task, indicating a failure at the tool selection/initialization step. With no required to
2025-08-30 06:16:29,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:29,167 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task, and the error reported is unknown. The absence of any tool usage implies the agent 
2025-08-30 06:16:33,767 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:33,768 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or apply any tool to handle the task; there is no executed tool, indicating a tool-selection/omission decision error rath
2025-08-30 06:16:40,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:40,999 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "There is no information about tools used, dependencies, or execution order. Without logs showing prerequisite data loading or dependency handling, we 
2025-08-30 06:16:43,844 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:43,844 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were executed and there is an 'Unknown error' with no guidance on required dependencies or prerequisites. This points to a missing/untouched 
2025-08-30 06:16:46,304 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:46,305 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: no tools were selected or executed, and there is no evidence of incorrect tool choice, wrong parameters, improper sequenc
2025-08-30 06:16:54,501 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:54,502 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown/system-level error with no tooling executed; there is no clear evidence of agent-caused decisions (tool_selection, parameter_config, sequence_order
2025-08-30 06:16:58,432 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:16:58,434 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to handle the task (no tools executed). This indicates a missing/incorrect tool choice or no tool usag
2025-08-30 06:17:01,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:01,969 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any tools or perform any workflow steps, effectively failing to follow the required task sequence (no A→B→C actions were
2025-08-30 06:17:04,601 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:04,601 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent-level decision was made because the task required no tools and the failure is an unknown error with no tool execution. Therefore, there
2025-08-30 06:17:08,487 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:08,488 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task, effectively breaking the required dependency chain (loader → processor → sink). The agen
2025-08-30 06:17:10,706 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:10,706 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error detected: no tools were selected or executed, no parameters provided, and no sequence or dependencies applied. The failure
2025-08-30 06:17:15,862 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:15,862 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed and no action taken for a simple task; the agent effectively abstained from selecting a method to proceed, which is a wrong
2025-08-30 06:17:22,293 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:22,294 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task required no tools, yet the agent did not produce any output. This inaction indicates a mis-ordered/incorrect workflow decision: rather th
2025-08-30 06:17:23,264 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:23,265 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or plan any tool because the task was unknown/undefined. This indicates a wrong or missing tool selection decision given the 
2025-08-30 06:17:28,585 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:28,585 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision error can be identified: the error is reported as Unknown error with no executed tools and no required tools defined. Without 
2025-08-30 06:17:31,204 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:31,205 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any actions or execute any tools, effectively failing to follow any required workflow sequence. This inaction constitute
2025-08-30 06:17:34,493 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:34,494 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed for the task; error is reported as unknown, and there is no evidence of incorrect tool choice, wrong parameters, imprope
2025-08-30 06:17:35,564 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:35,564 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize an appropriate tool to handle the task, resulting in no tool invocation and an unknown error before any process
2025-08-30 06:17:41,257 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:41,257 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision (no tools used, no parameters set, no sequence executed) and the error message is Unknown error. Without observa
2025-08-30 06:17:44,900 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:44,901 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task requires no tool execution (0/0 coverage). The complete failure despite the absence of explicit error details suggests the agent attempte
2025-08-30 06:17:49,429 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:49,430 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The pipeline failed with an unknown error before any tool could be executed, suggesting the agent did not establish or respect prerequisites/dependenc
2025-08-30 06:17:51,691 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:51,692 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or configured for the multi_stage_pipeline task, leaving the workflow uninitiated. This represents a tool selection decisio
2025-08-30 06:17:56,548 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:56,548 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any tool/approach for the task. There was no execution or plan, indicating a decision to skip tool use or too
2025-08-30 06:17:58,664 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:17:58,665 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent executed no steps and effectively skipped the required workflow; there was no action sequence started or completed (A→B→C), leading to f
2025-08-30 06:18:02,370 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:02,381 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not establish or follow the required multi-stage pipeline sequence (A→B→C). No tools were engaged, indicating an incorrect or missin
2025-08-30 06:18:03,918 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:03,920 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked (0% tool coverage) and the task ended with an unknown error before any action. This implies a misdecision at the
2025-08-30 06:18:06,349 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:06,350 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required tools for the multi_stage_pipeline task; no tools were executed (0% coverage), indicating a wrong 
2025-08-30 06:18:12,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:12,013 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool (no tools required, but the decision path normally starts with a tool action). This indicates a missin
2025-08-30 06:18:12,278 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:12,278 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No discernible agent decision error could be identified: the task ended with an unknown/system-level error and no tools were executed or configured, making
2025-08-30 06:18:18,869 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:18,869 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or initiated due to an unknown error; the failure stems from an agent decision at the tool-selection stage (no tool chosen to
2025-08-30 06:18:22,259 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:22,260 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The task produced an 'Unknown error' with no tools executed and no observable agent decision data. There is insufficient information to attribute the failu
2025-08-30 06:18:24,735 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:24,736 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions could be evaluated: there were no tools executed and task details are unknown. The error appears to be a system/unknown failure rather t
2025-08-30 06:18:30,212 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:30,213 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No required data_pipeline tool was selected or initialized (e.g., data_loader), resulting in no workflow execution. This indicates an omission/inc
2025-08-30 06:18:30,447 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:30,448 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit error message and no tools were executed; there is insufficient information to attribute the failure to a specific agent decision (tool selecti
2025-08-30 06:18:37,598 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:37,599 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the task, effectively making a no-action/tool engagement decision. Even though no explicit 
2025-08-30 06:18:38,942 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:38,943 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps in the expected workflow (no actions were performed). This constitutes an incorrect sequence/flow, as the task
2025-08-30 06:18:42,436 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:42,436 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any data_pipeline tool to start the task (Executed Tools: none), resulting in no progress. This indicates a
2025-08-30 06:18:45,328 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:45,329 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed and no integration steps were performed, indicating the workflow sequence for the API integration was not initiated or fo
2025-08-30 06:18:50,407 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:50,408 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Error appears to be an unspecified tool failure (Unknown error) with no tool usage or parameter details available. There is no evidence of incorrect tool s
2025-08-30 06:18:50,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:50,777 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to start the multi-stage pipeline; no tooling step was chosen, resulting in 0% tool coverage. This ind
2025-08-30 06:18:55,120 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:55,120 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error with no tool executions; cannot attribute to an agent decision. This appears to be a system/tool-level failure rather than a specific agent m
2025-08-30 06:18:57,911 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:18:57,911 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task requires no tools (coverage 0/0). The failure stems from an agent decision to attempt tooling or to abort due to an 'Unknown error' when 
2025-08-30 06:19:00,404 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:00,405 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any required tool for the api_integration task; no tools were executed, leading to complete failure. This consti

[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 30)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 30)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 26)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 31)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 32)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors2025-08-30 06:19:04,593 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:04,593 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to initiate or select any action/tool for the basic_task, effectively skipping the required workflow sequence (no steps were executed
2025-08-30 06:19:06,241 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:06,241 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The pipeline failed to progress through the required multi-stage sequence; no tools were executed and prerequisites for downstream stages were never s
2025-08-30 06:19:09,775 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:09,775 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or actions initiated by the agent for a task that requires processing. The agent produced a complete absence of tool usage,

[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.70) - No agent decision error can be identified from the
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.75) - No tools were selected or executed due to an inter
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.62) - No tool was selected or executed (tool coverage 0%
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No tools were selected or executed and the error i
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.78) - No agent decision error detected: no tools were se
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision error identified: no tools were 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60) - Insufficient information to attribute failure to a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72) - The agent did not select and/or invoke any necessa
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.61) - No tools were selected or executed. The task conte
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62) - No tool was selected or attempted for the api_inte
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60) - Insufficient information to identify a specific ag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.55) - No actionable workflow sequence was defined or exe
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No evidence of an agent decision error (tool choic
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - No identifiable agent decision error: the task is 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No actionable agent decision could be evaluated: t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.65) - Agent did not select or invoke any tool appropriat
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 22)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No tool usage occurred and the error reported is u
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No tools were selected or executed and the error m
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.66) - The error message is generic ('Unknown error') wit
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60) - No tools were selected or executed (coverage 0%), 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72)2025-08-30 06:19:10,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:10,014 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked for the required data_pipeline task; the agent failed to choose the appropriate tool (e.g., data_loader) or any to

[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55) - The agent did not select or apply any tool to hand
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.60) - No tools were executed and there is an 'Unknown er
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.82) - Unknown/system-level error with no tooling execute
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60) - Agent did not select or plan any tool because the 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No actionable agent decision error can be identifi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - No tools were selected or executed for the task; e
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - No tools were selected or invoked (0% tool coverag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.62) - The agent did not select or invoke any tool (no to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.65) - The task produced an 'Unknown error' with no tools
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.75) - Error appears to be an unspecified tool failure (U
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55) - The task requires no tools (coverage 0/0). The fai
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 24)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.72)
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 27)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 28)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 29)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 33)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 27)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 28)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors2025-08-30 06:19:16,149 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:16,151 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and there is no evidence of a wrong agent decision (tool selection, parameters, sequence, or dependencies). The failure appears to b
2025-08-30 06:19:16,206 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:16,208 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No detectable agent decision error: the task reported Unknown error with 0 required tools and no tool execution details, indicating a system-level failure 
2025-08-30 06:19:21,310 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:21,311 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong tool choice, incorrect parameters, or improper execution order. The failure is due to an unknown/external error that prevented any t
2025-08-30 06:19:25,199 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:25,199 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decisions were observed (no tool selection, parameters, or sequence were executed). The failure is described as an Unknown error with no evi
2025-08-30 06:19:25,293 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:25,294 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or apply any tool to perform the simple_task; no action/tool usage indicates a tool selection decision error (absent/incorrec
2025-08-30 06:19:25,320 - result_merger - INFO - 模型qwen2.5-72b-instruct保存90/90条记录
2025-08-30 06:19:25,322 - result_merger - INFO - 合并完成，共处理61个文件，保存90条记录
2025-08-30 06:19:25,323 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 06:19:25,324 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 31)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 32)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 27)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 36)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 30)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 36)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 30)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 31)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 35)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 36)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 20)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 25)
[AI-CLASSIFY-EXISTING] Using existing AI classification: max_turns_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 26)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65) - No detectable agent decision error: the task repor
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 37)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'max_turns_errors' -> 'max_turns_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: max_turns_errors -> max_turns_errors
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[INFO] 最终合并完成: 61 个文件
2025-08-30 06:19:25,461 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 06:19:25,461 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-30 06:19:29,750 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:29,750 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select the required tools for the data_pipeline task (or selected an inappropriate/none tool), causing no workflow to run and result
2025-08-30 06:19:34,008 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:34,008 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate an appropriate data processing tool (e.g., data_loader/pdf_reader) and produced no tool executions. This indi
2025-08-30 06:19:39,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:39,196 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any necessary tool(s) for the data_pipeline task, effectively resulting in no tooling being used. This constitutes a wrong to
2025-08-30 06:19:43,232 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:43,232 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke an appropriate tool for the data_pipeline task (no tools were executed, zero tool coverage). This indicates a wrong
2025-08-30 06:19:48,374 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:48,375 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of incorrect agent decision (tool choice, parameters, sequence, or dependencies). The error is reported as 'Unknown error' with no tool executi
2025-08-30 06:19:54,922 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:54,922 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detectable: the task indicates 0% tool coverage (no tools required) and the error message is 'Unknown error'. With no tools execute
2025-08-30 06:19:59,510 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:19:59,511 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error message is 'Unknown error'. There is insufficient information to evaluate any agent decision (tool choice, parameters,
2025-08-30 06:20:03,286 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:03,287 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision error: no tools were executed and no explicit error message or trace is provided to indicate wrong tool choice, 
2025-08-30 06:20:08,461 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:08,461 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the API integration task. The agent failed to choose the required tool(s), effectively making a missing/inco
2025-08-30 06:20:14,355 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:14,356 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tool appropriate for a multi_stage_pipeline; no tools were executed despite the task requiring staged proce
2025-08-30 06:20:19,797 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:19,797 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Primary agent decision error: The agent failed to select and initialize any tool for the api_integration task; no tools were invoked and no config
2025-08-30 06:20:26,607 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:26,607 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed (coverage 0%), and the error message is 'Unknown error'. There is insufficient information to attribute a wrong agent de
2025-08-30 06:20:34,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:34,758 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The task shows an unknown/system-level error with no tools exec
2025-08-30 06:20:42,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:42,855 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the api_integration task. The agent effectively made a 'no-tool' decision in the tool-selection phase, prev
2025-08-30 06:20:51,556 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:51,556 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize the necessary tools for the multi_stage_pipeline; no tools were executed (0% coverage) and no processing step
2025-08-30 06:20:59,405 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:20:59,406 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task is a 'simple_task' with no required tools specified. Any tool invocation would be an inappropriate tool choice, indicating the agent sele
2025-08-30 06:21:11,272 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:11,272 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed due to an unknown error, preventing any verification of the intended workflow sequence. Because the task could not progre
2025-08-30 06:21:17,654 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:17,655 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision could be evaluated due to lack of tool executions and an unspecified 'Unknown error'. Without tool usage trace, there is no ba
2025-08-30 06:21:23,149 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:23,149 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed; there is no evidence of a wrong agent decision (tool choice, parameters, sequence, or dependencies). The failure appear
2025-08-30 06:21:27,247 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:27,247 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tool to complete the basic_task; there is no tooling plan or actions chosen, indicating a missing/incorrect to
2025-08-30 06:21:34,264 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:34,265 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the basic_task, effectively not initiating the required action or workflow. This indicates 
2025-08-30 06:21:44,397 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:44,397 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No tools were executed and no workflow steps completed, so there is no observable sequence to evaluate. The failure appears to be inaction rather 
2025-08-30 06:21:56,975 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:21:56,976 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The execution trace shows zero tools used and no tool was selected. With an unknown error and no tool invocation, there is no evidence of a correc
2025-08-30 06:22:02,045 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:02,045 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision was made (no tools chosen or executed). The failure appears to be a system-level Unknown error rather than a wrong tool choice, incorrect
2025-08-30 06:22:06,741 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:06,741 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke the appropriate API integration tool for an api_integration task; no tools were executed due to an absence of to
2025-08-30 06:22:15,388 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:15,388 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any actions or tool executions, effectively failing to follow the expected workflow sequence for the task. This inaction
2025-08-30 06:22:19,610 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:19,610 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to define or follow the required multi-stage pipeline sequence; no stages/tools were invoked and dependencies between stages were
2025-08-30 06:22:24,815 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:24,815 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any API integration tool/library required to perform the task, effectively halting execution before any act
2025-08-30 06:22:29,783 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:29,784 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is labeled 'Unknown error'; there is insufficient evidence to attribute the failure to a specific agent decision (tool
2025-08-30 06:22:37,166 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:37,166 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute a primary agent decision error: no tools were selected or executed and the error is described as unknown. With zero t
2025-08-30 06:22:44,547 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:44,548 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required or executed (Required Tools Coverage 0%), yet the task ended with an unknown/system error. There is no evidence of an agent decision
2025-08-30 06:22:51,809 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:51,809 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "No tool executions occurred and there is no tooling coverage for the task. This suggests the agent failed to satisfy or respect the workflow dependenc
2025-08-30 06:22:57,378 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:22:57,378 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and invoke any of the required tools for the api_integration task; no tools were used (0% coverage), indicating a tool 
2025-08-30 06:23:01,629 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:01,629 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize any API integration tool; no tool was invoked for the required api_integration task, effectively stalling th
2025-08-30 06:23:07,081 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:07,081 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed despite the task seemingly requiring tooling; the agent failed to perform the necessary tool selection step, lead

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 14)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 24)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.42) - No tools were selected or executed for the data_pi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 35)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.42)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error detected: no tools were se
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60) - The agent did not select or invoke any tool to han
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 32)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65) - No observable agent-level decision was made becaus
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.45)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.75) - Agent did not select or initialize an appropriate 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 33)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - There is no evidence of any agent decision (no too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.58) - The pipeline failed with an unknown error before a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 28)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.62) - No discernible agent decision error could be ident
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60) - No tool was selected or initiated due to an unknow
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.72) - No agent decisions could be evaluated: there were 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.70)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.82) - The agent did not select or invoke any tool to sta
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - Unknown error with no tool executions; cannot attr
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85) - Agent failed to select and invoke any required too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 41)2025-08-30 06:23:11,632 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:11,632 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent decision errors: the log shows 'Unknown error' with no tools executed and 0% tool coverage. This suggests an external/system failure r
2025-08-30 06:23:17,245 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:17,246 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or apply any tool to address the (unknown) task. There is no record of a chosen tool, and with the task unspecified, a pr
2025-08-30 06:23:23,878 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:23,879 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required for the task (Required Tools Coverage 0%), so there was no agent decision to make. The complete failure cannot be attributed to a to
2025-08-30 06:23:28,000 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:28,000 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke the required tools for the multi_stage_pipeline; no required tools were chosen or executed, resulting in an inco
2025-08-30 06:23:37,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:37,211 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed; the task requires at least one operation, but the agent did not start any step, effectively breaking the expected workfl
2025-08-30 06:23:42,321 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 06:23:42,321 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions or tool actions were performed (no tools executed, unknown error). The error appears external/unspecified rather than a misdecision (too
2025-08-30 06:23:42,321 - result_merger - INFO - 模型qwen2.5-72b-instruct保存70/70条记录
2025-08-30 06:23:42,322 - result_merger - INFO - 合并完成，共处理36个文件，保存70条记录
2025-08-30 06:23:42,323 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 06:23:42,326 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No evidence of a wrong tool choice, incorrect para
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No agent-level decisions were observed (no tool se
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 42)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85) - Agent did not select the required tools for the da
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 43)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.68) - No evidence of incorrect agent decision (tool choi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.72) - No agent decision error detectable: the task indic
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 43)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No tools were executed and the error message is 'U
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75) - Primary agent decision error: The agent failed to 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - No tools were selected or executed (coverage 0%), 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 35)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No evidence of a wrong agent decision (tool choice
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.40) - No actions were executed due to an unknown error, 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.75) - No actionable agent decision could be evaluated du
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 38)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No tools were selected or executed; there is no ev
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 39)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.42)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.45) - The execution trace shows zero tools used and no t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 43)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision was made (no tools chosen or exe
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 37)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75) - Agent failed to select and invoke the appropriate 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 47)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.72) - No tools were executed and the error is labeled 'U
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> data_pipeline (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.68) - Insufficient information to attribute a primary ag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 49)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No tools were required or executed (Required Tools
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> api_integration (total: 50)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.80)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.72) - No tool was selected or executed despite the task 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.72) - No evidence of agent decision errors: the log show
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> multi_stage_pipeline (total: 39)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.62) - The agent did not select or apply any tool to addr
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> basic_task (total: 45)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.45)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.75) - No agent decisions or tool actions were performed 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_missing_step -> simple_task (total: 43)
[INFO] 最终合并完成: 36 个文件
2025-08-30 06:23:42,422 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 06:23:42,422 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片1完成
INFO:__main__:等待分片2完成（20实例×50workers，最多等待50分钟）...
INFO:__main__:✅ 分片2完成
INFO:__main__:等待分片3完成（20实例×50workers，最多等待50分钟）...
INFO:__main__:✅ 分片3完成
INFO:__main__:📊 并发执行结果: 3/3 分片成功
INFO:__main__:✅ Key0: 完成 qwen2.5-72b-instruct-easy
INFO:__main__:最终利用率: 1.1%
=== 测试结束时间: 2025年 8月30日 星期六 06时23分44秒 EDT ===
=== 退出码: 0 ===
