=== 测试开始时间: 2025年 8月30日 星期六 03时33分19秒 EDT ===
=== 环境变量 ===
USE_RESULT_COLLECTOR=true
STORAGE_FORMAT=json
CUSTOM_WORKERS=50
=== 命令执行 ===
INFO:__main__:使用环境变量 RATE_MODE: fixed
INFO:__main__:初始化实例池: 17个实例 (2个Azure + 6个IdealLab)
INFO:result_collector:ResultCollector初始化，临时目录: temp_results
INFO:result_collector:ResultAggregator初始化
INFO:__main__:🆕 启用ResultCollector模式，支持零冲突并发
INFO:__main__:资源池状态: 17个实例, 容量1306
INFO:__main__:
🎯 检测到Qwen模型，使用队列调度器
INFO:__main__:   模型: qwen2.5-72b-instruct → Key0
INFO:__main__:   Prompt类型: flawed_parameter_error
INFO:__main__:   难度: easy
INFO:__main__:🔄 Key0: 执行 qwen2.5-72b-instruct-easy
INFO:__main__:🎯 使用qwen智能分片策略: qwen2.5-72b-instruct
INFO:__main__:🔄 真正多Key并发策略:
INFO:__main__:   模型: qwen2.5-72b-instruct (规模: 72b)
INFO:__main__:   使用Keys: key0, key1, key2
INFO:__main__:   总实例数: 20
INFO:__main__:   分片数: 3 (每个key独立分片)
INFO:__main__:   实例分配: [7, 7, 6]
INFO:__main__:   🚀 启用3倍API并发！
INFO:__main__:🚀 启动3个分片并发执行
INFO:__main__:  IdealLab qwen模型限制: qwen-key0 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 0
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_parameter_error_key0: qwen-key0
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片1: qwen-key0 (7个实例)
INFO:__main__:  IdealLab qwen模型限制: qwen-key1 强制使用 max_workers=1, qps=10
INFO:__main__:    注意: IdealLab API并发限制严格，忽略--max-workers设置
INFO:__main__:  使用IdealLab API Key 1
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_parameter_error_key1: qwen-key1
INFO:__main__:   实例数: 7, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片2: qwen-key1 (7个实例)
INFO:__main__:  使用IdealLab API Key 2
INFO:__main__:🚀 启动分片 qwen2.5-72b-instruct_easy_flawed_parameter_error_key2: qwen-key2
INFO:__main__:   实例数: 6, 模型: qwen2.5-72b-instruct
INFO:__main__:   传递STORAGE_FORMAT=json给子进程
INFO:__main__:   传递USE_PARTIAL_LOADING=true给子进程
INFO:__main__:   传递TASK_LOAD_COUNT=20给子进程
INFO:__main__:   传递SKIP_MODEL_LOADING=true给子进程
INFO:__main__:   传递USE_RESULT_COLLECTOR=true给子进程
INFO:__main__:   传递KMP_DUPLICATE_LIB_OK=TRUE给子进程
INFO:__main__:   设置PYTHONMALLOC=malloc给子进程
INFO:__main__:   分片3: qwen-key2 (6个实例)
INFO:__main__:等待分片1完成（20实例×50workers，最多等待50分钟）...
2025-08-30 03:33:20,369 - faiss.loader - INFO - Loading faiss.
2025-08-30 03:33:20,369 - faiss.loader - INFO - Loading faiss.
2025-08-30 03:33:20,369 - faiss.loader - INFO - Loading faiss.
2025-08-30 03:33:20,396 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 03:33:20,396 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 03:33:20,396 - faiss.loader - INFO - Successfully loaded faiss.
2025-08-30 03:33:21,195 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 03:33:21,195 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 03:33:21,195 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 03:33:21,195 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 03:33:21,195 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 03:33:21,195 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 03:33:21,195 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 03:33:21,195 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 03:33:21,195 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 03:33:21,196 - smart_result_collector - INFO - 自动保存线程已启动
2025-08-30 03:33:21,196 - smart_result_collector - INFO - SmartResultCollector初始化完成
2025-08-30 03:33:21,196 - smart_result_collector - INFO -   - 临时目录: temp_results
2025-08-30 03:33:21,196 - smart_result_collector - INFO -   - 内存阈值: 20
2025-08-30 03:33:21,196 - smart_result_collector - INFO -   - 时间阈值: 300秒
2025-08-30 03:33:21,196 - smart_result_collector - INFO -   - 自动保存: 60秒
2025-08-30 03:33:21,196 - smart_result_collector - INFO -   - 自适应阈值: True
2025-08-30 03:33:21,196 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
2025-08-30 03:33:21,196 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
2025-08-30 03:33:21,197 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 03:33:21,197 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 03:33:21,197 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
2025-08-30 03:33:21,254 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:33:21,254 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 03:33:21,254 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:33:21,254 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 03:33:21,254 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:33:21,254 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
2025-08-30 03:33:21,254 - batch_test_runner - INFO - ============================================================
2025-08-30 03:33:21,254 - batch_test_runner - INFO - ============================================================
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_033321.log
2025-08-30 03:33:21,254 - batch_test_runner - INFO - ============================================================
2025-08-30 03:33:21,254 - batch_test_runner - INFO - ============================================================
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Batch test runner initialized
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_033321.log
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Initializing test components...
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
2025-08-30 03:33:21,254 - batch_test_runner - INFO - ============================================================
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Running 30 tests with 2 workers, QPS limit: None
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Log file: logs/batch_test_20250830_033321.log
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Initializing test components...
2025-08-30 03:33:21,254 - batch_test_runner - INFO - ============================================================
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Running 35 tests with 2 workers, QPS limit: None
2025-08-30 03:33:21,254 - batch_test_runner - INFO - Initializing test components...
2025-08-30 03:33:21,725 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 03:33:21,726 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 03:33:21,726 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 03:33:21,727 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 03:33:21,730 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 03:33:21,730 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 03:33:21,730 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 03:33:21,730 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 03:33:21,732 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
2025-08-30 03:33:21,733 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
2025-08-30 03:33:21,733 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
2025-08-30 03:33:21,733 - api_client_manager - INFO - Loaded configuration from config/config.json
2025-08-30 03:33:22,279 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:33:22,283 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:33:22,284 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:33:22,388 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 03:33:22,389 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 03:33:22,389 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 03:33:22,799 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 03:33:22,799 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 03:33:22,800 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 03:33:23,283 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 03:33:23,284 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 03:33:23,296 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 03:33:23,297 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 03:33:23,297 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
2025-08-30 03:33:23,297 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
2025-08-30 03:33:23,371 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 03:33:23,384 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 03:33:23,394 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 175022829 bytes)
2025-08-30 03:33:23,480 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 03:33:23,495 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 03:33:23,504 - mcp_embedding_manager - INFO - Loaded 7100 cached embeddings
2025-08-30 03:33:23,824 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 03:33:23,824 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:23,844 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 03:33:23,844 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:23,853 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:23,853 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:23,853 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:23,858 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
2025-08-30 03:33:23,858 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:23,875 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 03:33:23,877 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 03:33:23,877 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 03:33:23,888 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 03:33:23,888 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 03:33:23,888 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 03:33:23,888 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 03:33:23,895 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:23,895 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:23,895 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:23,908 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:23,908 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:23,908 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:23,917 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 03:33:23,919 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 03:33:23,919 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 03:33:23,922 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 03:33:23,922 - mdp_workflow_generator - INFO - Embedding index loaded successfully
2025-08-30 03:33:23,923 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 03:33:23,923 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 03:33:23,923 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 03:33:23,924 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 03:33:23,924 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
2025-08-30 03:33:23,927 - mdp_workflow_generator - INFO - Loaded 30 tools
2025-08-30 03:33:23,927 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
2025-08-30 03:33:23,927 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
2025-08-30 03:33:23,927 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
2025-08-30 03:33:26,704 - unified_training_manager - INFO - Using device: cpu
2025-08-30 03:33:26,704 - unified_training_manager - INFO - Using device: cpu
2025-08-30 03:33:26,704 - unified_training_manager - INFO - Using device: cpu
2025-08-30 03:33:27,437 - unified_training_manager - INFO - Task filtering results:
2025-08-30 03:33:27,437 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 03:33:27,437 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 03:33:27,437 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 03:33:27,437 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 03:33:27,437 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 03:33:27,437 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 03:33:27,437 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 03:33:27,457 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 03:33:27,461 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 03:33:27,461 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 03:33:27,461 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 03:33:27,461 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 03:33:27,461 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 03:33:27,461 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 03:33:27,461 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 03:33:27,482 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:33:27,494 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 03:33:27,494 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 03:33:27,495 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 03:33:27,510 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 03:33:27,510 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 03:33:27,538 - unified_training_manager - INFO - Task filtering results:
2025-08-30 03:33:27,538 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 03:33:27,538 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 03:33:27,538 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 03:33:27,538 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 03:33:27,538 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 03:33:27,538 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 03:33:27,538 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 03:33:27,542 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 03:33:27,549 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 03:33:27,549 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 03:33:27,549 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 03:33:27,549 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 03:33:27,549 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 03:33:27,549 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 03:33:27,549 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 03:33:27,558 - unified_training_manager - INFO - Task filtering results:
2025-08-30 03:33:27,558 - unified_training_manager - INFO -   Total: 5040 -> 5040
2025-08-30 03:33:27,559 - unified_training_manager - INFO -   simple_task: 320 -> 320
2025-08-30 03:33:27,559 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
2025-08-30 03:33:27,559 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
2025-08-30 03:33:27,559 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
2025-08-30 03:33:27,559 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
2025-08-30 03:33:27,559 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
2025-08-30 03:33:27,567 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
2025-08-30 03:33:27,572 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:33:27,572 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
2025-08-30 03:33:27,572 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
2025-08-30 03:33:27,572 - batch_test_runner - INFO -   - task_manager: ✓
2025-08-30 03:33:27,572 - batch_test_runner - INFO -   - output_verifier: ✓
2025-08-30 03:33:27,572 - batch_test_runner - INFO -   - embedding_manager: ✓
2025-08-30 03:33:27,572 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
2025-08-30 03:33:27,572 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
2025-08-30 03:33:27,572 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 03:33:27,573 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 03:33:27,573 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 03:33:27,584 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:33:27,585 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
2025-08-30 03:33:27,586 - result_merger - INFO - ResultMerger初始化完成
2025-08-30 03:33:27,586 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
2025-08-30 03:33:27,586 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 03:33:27,586 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 03:33:27,606 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
2025-08-30 03:33:27,606 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
2025-08-30 03:33:27,967 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 03:33:27,967 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 03:33:28,027 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 03:33:28,028 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 03:33:28,031 - batch_test_runner - INFO - Initialization complete
2025-08-30 03:33:28,055 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
2025-08-30 03:33:28,055 - batch_test_runner - INFO - Estimated memory saving: 84.1%
2025-08-30 03:33:28,088 - batch_test_runner - INFO - Initialization complete
2025-08-30 03:33:28,115 - batch_test_runner - INFO - Initialization complete
2025-08-30 03:33:28,135 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-30 03:33:28,135 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 03:33:28,155 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-30 03:33:28,161 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 03:33:28,170 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:28,171 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:28,171 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:28,172 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:28,195 - batch_test_runner - INFO - Starting batch test with 30 tasks, 2 workers
2025-08-30 03:33:28,195 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 03:33:28,195 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 30 tasks
2025-08-30 03:33:28,206 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:28,206 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:28,206 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:28,216 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 03:33:28,223 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:28,224 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:28,224 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:28,224 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:28,225 - batch_test_runner - INFO - Starting batch test with 35 tasks, 2 workers
2025-08-30 03:33:28,225 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
2025-08-30 03:33:28,226 - batch_test_runner - INFO - Batch timeout set to 3600s (60.0 minutes) for 35 tasks
2025-08-30 03:33:28,232 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:28,232 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:28,232 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:28,253 - smart_model_router - INFO - Using idealab for qwen2.5-72b-instruct
2025-08-30 03:33:28,260 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:28,260 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:28,260 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:28,261 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:28,264 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:28,264 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:28,264 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:28,285 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:28,285 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:28,285 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:28,300 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:28,300 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:28,300 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:28,321 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:28,321 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:28,321 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:29,929 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:29,929 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:29,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:29,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:30,345 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:30,362 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:31,922 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:31,924 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:31,934 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:32,026 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:32,430 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:32,443 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:32,967 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:33,767 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:34,768 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:34,768 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:34,833 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:35,169 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:35,590 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:35,916 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:36,096 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:36,357 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:36,856 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:36,861 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:37,888 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:37,899 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:38,385 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:38,395 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:38,892 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:38,904 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:39,201 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:39,617 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:40,127 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:40,639 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:40,659 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:40,678 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:41,883 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:41,896 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:42,392 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_parameter_error']
难度: easy
目标: 每种配置 6 个实例
============================================================
○ simple_task         :   0/  6 已完成 (需要补充 6 个)
○ basic_task          :   0/  6 已完成 (需要补充 6 个)
○ data_pipeline       :   0/  6 已完成 (需要补充 6 个)
○ api_integration     :   0/  6 已完成 (需要补充 6 个)
○ multi_stage_pipeline:   0/  6 已完成 (需要补充 6 个)

⏳ 需要运行 30 个新测试

▶ 准备 simple_task (6 个实例)...

▶ 准备 basic_task (6 个实例)...

▶ 准备 data_pipeline (6 个实例)...

▶ 准备 api_integration (6 个实例)...

▶ 准备 multi_stage_pipeline (6 个实例)...

▶ 开始执行 30 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x107866a80>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 03:33:42,401 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_parameter_error']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x108c83010>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 03:33:42,930 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:43,791 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:44,794 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:44,816 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:44,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:45,808 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:46,048 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:46,328 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:46,827 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping torch imports
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式
[INFO] 使用JSON存储格式

============================================================
智能批测试: qwen2.5-72b-instruct (idealab)
Prompt types: ['flawed_parameter_error']
难度: easy
目标: 每种配置 7 个实例
============================================================
○ simple_task         :   0/  7 已完成 (需要补充 7 个)
○ basic_task          :   0/  7 已完成 (需要补充 7 个)
○ data_pipeline       :   0/  7 已完成 (需要补充 7 个)
○ api_integration     :   0/  7 已完成 (需要补充 7 个)
○ multi_stage_pipeline:   0/  7 已完成 (需要补充 7 个)

⏳ 需要运行 35 个新测试

▶ 准备 simple_task (7 个实例)...

▶ 准备 basic_task (7 个实例)...

▶ 准备 data_pipeline (7 个实例)...

▶ 准备 api_integration (7 个实例)...

▶ 准备 multi_stage_pipeline (7 个实例)...

▶ 开始执行 35 个测试...
📊 自适应checkpoint_interval: 20
📦 批量提交模式：每20个测试保存一次
⚠️  检测到idealab API，调整并发: workers=2, qps=None
🧠 启用SmartResultCollector模式，智能数据管理
[AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x113358be0>
[DEBUG] BatchTestRunner initialized with save_logs=False, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[DEBUG] Creating new ToolCapabilityManager instance
[OperationEmbeddingIndex] Initializing with unified API client manager
['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[OperationEmbeddingIndex] Detecting actual embedding dimension...
[OperationEmbeddingIndex] Detected embedding dimension: 3072
[INFO] Loaded 4150 embeddings from persistent cache
[OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[INFO] Loaded 15 LLM-enhanced operation definitions from cache
[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[INFO] Successfully loaded FAISS index with dimension 3072
[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[INFO] Loaded 15 operations with dimension 3072
[INFO] Successfully loaded cached index
[INFO] Operation semantic index initialized
[INFO] ⚡ SKIP_MODEL_LOADING=true - No device initialization
[INFO] Initialized tool success tracking attributes
[INFO] Initializing embedding manager for enhanced tool selection
[MCPEmbeddingManager] Creating new singleton instance
[MCPEmbeddingManager] Initializing with unified API client manager
[MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[MCPEmbeddingManager] Client initialized successfully
[MCPEmbeddingManager] Singleton created with 0 cached embeddings
[INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[SUCCESS] Loaded 30 tool embeddings
[SUCCESS] Embedding manager initialized with 30 tools
[INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[INFO] Loading full MCP protocol registry...
[INFO] Loaded full tool registry with 30 tools
[INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[INFO] Embedding manager ready with 30 tools
[WARNING] Embedding manager exists but has no embeddings
[INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[INFO] Setting default state_dim based on loaded tools
[INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[INFO] Setting default action_dim based on loaded tools
[INFO] action_dim set to 31 (tools=30 + NO_OP)
[INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[INFO] ⚡ Will use pre-generated workflows or random policy
[INFO] Initializing TaskManager...
[TaskManager] Difficulty level 'easy': 1096 tasks
[TaskManager] Difficulty level 'very_easy': 856 tasks
[TaskManager] Difficulty level 'medium': 1136 tasks
[TaskManager] Difficulty level 'hard': 1096 tasks
[TaskManager] Difficulty level 'very_hard': 856 tasks
[INFO] TaskManager initialized with 5040 tasks
[INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[INFO] Initializing ToolCallVerifier...
[INFO] ToolCallVerifier initialized with 30 tools
[INFO] Output tools identified: 1
[INFO] Component initialization status:
  - embedding_manager: initialized
  - task_manager: initialized
  - output_verifier: initialized
  - tool_capability_manager: initialized
  - tool_success_rates: initialized with 0 entries
[INFO] MDPWorkflowGenerator initialization complete
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: disabled
[INFO] Enhanced manager: AI错误分类系统已启用
[INFO] 检测到并发环境，使用安全存储模式（ResultCollector）2025-08-30 03:33:47,078 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:47,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:47,346 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:47,346 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:47,371 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:47,372 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:47,372 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:47,839 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:48,359 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:48,799 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:48,856 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:49,359 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:49,862 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:49,875 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:49,876 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:49,900 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:49,900 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:49,900 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:50,411 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:50,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:50,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:51,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:51,077 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:51,077 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:51,102 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:51,102 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:51,102 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:51,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:52,039 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:52,112 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:52,537 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:52,555 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:52,555 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:52,581 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:52,581 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:52,581 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:52,761 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:53,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:53,728 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:54,248 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:54,741 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:54,749 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:55,798 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:55,988 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:56,217 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:56,723 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:56,728 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:56,998 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:33:57,714 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:33:57,784 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:57,797 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:33:57,798 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:33:57,820 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:33:57,820 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:33:57,820 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:33:57,873 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:33:58,774 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:58,792 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:33:58,841 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:59,013 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:33:59,102 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x140fcde50>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Tool embedding index loaded successfully
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"38141bc8-b1c3-9dd2-bcca-22b91840d847"}, traceId: 2150413117565392096397337eea5b'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d668a37a-a72d-9e20-ac0e-b9a5cbb85b96"}, traceId: 2150416417565392100824890e140c'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"769e234d-f01f-93dd-a091-2b6301d3d52b"}, traceId: 2150416417565392116504898e140c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7511565e-88cd-92d7-8858-db59d6178f21"}, traceId: 2150413117565392126967349eea5b'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a5a5d8ed-ebf5-9dc2-8028-0c5de74d29eb"}, traceId: 2150416417565392134904916e140c'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1094944f-8823-9e36-9be7-4d0e0b2438dd"}, traceId: 2150413117565392153217361eea5b'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7b1e51b1-e3a6-95fa-8d02-232a6092abef"}, traceId: 2150413117565392165857368eea5b'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e261470-a487-92f0-8441-80f56e96ae4e"}, traceId: 2150416417565392176034935e140c'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"724a8eba-0773-9bd4-b69a-d28665f43cf6"}, traceId: 2150413117565392193537379eea5b'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ae8f76fc-ba2a-9eac-96cd-7e3abb6942d2"}, traceId: 2150413117565392204107383eea5b'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: data processing validator

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47dc0252-797a-9471-9c74-35d712f0459d"}, traceId: 2150416417565392221334955e140c'}2025-08-30 03:33:59,445 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:33:59,931 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:00,461 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x12eb0ee50>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e8ca69f-e519-9320-ab77-1e5ed9b962a4"}, traceId: 215041e117565392096467143e3347'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a7af21e-73eb-9f84-98f5-4687407fb53b"}, traceId: 2150416a17565392096264017edfbc'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e90ec752-4299-9725-ba32-12da7d1ee571"}, traceId: 2150416a17565392116434026edfbc'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"848d7d79-ac8e-9dc7-b1cc-ee249a582f6d"}, traceId: 215041e117565392121727152e3347'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e85c27cc-db11-998f-b974-d15cb3c51ee4"}, traceId: 2150416a17565392144954038edfbc'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"05af50a6-ee54-96f9-9abb-d88aca35fb4c"}, traceId: 215041e117565392160727163e3347'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"56657fe6-fcf7-98a6-9093-4fcca24c6d0f"}, traceId: 215041e117565392181057170e3347'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c925c248-573d-93dd-a075-9e994b4e4f9d"}, traceId: 2150416a17565392186114062edfbc'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63500540-5b6f-9c1a-9aa6-236b37efd3fc"}, traceId: 215041e117565392198567177e3347'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4545d5f3-606e-9c64-849f-c895d4097168"}, traceId: 2150416a17565392203624069edfbc'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6edd3fe1-8d31-9da3-97b5-41a09354ec50"}, traceId: 215041e117565392216057184e3347'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d8aa1bc-9c51-93b1-8730-73c33e258e9f"}, traceId: 2150416a17565392221264076edfbc'}2025-08-30 03:34:00,481 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:00,481 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:00,505 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:00,506 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:00,506 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:00,960 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:00,973 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:01,081 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:01,491 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:02,166 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:02,222 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:02,648 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:03,134 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:03,146 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:03,146 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:03,169 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:03,170 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:03,170 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:03,391 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:03,646 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:03,665 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:04,169 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:04,777 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:04,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:05,816 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:05,916 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:06,101 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:06,112 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:07,025 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:07,034 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:07,040 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:07,053 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:07,474 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:08,724 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:09,297 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:09,792 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:10,555 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:11,070 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] 后台合并进程已启动（每10秒合并一次）
DEBUG: Checking generator attributes
  - has tool_capabilities: True
  - has tool_capability_manager: True
  - has task_manager: True
[INFO] Loaded 30 tools from generator
[INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Initializing LLM client using APIClientManager
[INFO] Using Azure OpenAI client
[DEBUG] Checking if generator has tool_capability_manager attribute
[DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[FlawedWorkflowGenerator] Initialized with 30 tools
[FlawedWorkflowGenerator] RAG support: enabled
[INFO] FlawedWorkflowGenerator initialized successfully
[INFO] Initializing StableScorer for Phase 2 scoring
<tool_capability_manager.ToolCapabilityManager object at 0x1372a8de0>
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Loaded tool success history for 0 tools
[INFO] StableScorer initialized with semantic capability
[INFO] StableScorer initialized successfully
[INFO] Loading task instances...
[INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[INFO] Loaded 630 task instances
[INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Tool embedding index loaded successfully
[INFO] Operation semantic index initialized

[TURN 1/10]
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7495b97c-4f21-968f-a889-efccecb6a77c"}, traceId: 2150456617565392096508245e8287'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d344176-f87a-9f71-b3e2-c1cbab44adab"}, traceId: 2150458117565392100694411e7fee'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3e00410b-3fac-95d3-ae77-c0d996236474"}, traceId: 2150456617565392116488281e8287'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f544ea96-7dcf-981c-acb7-cd4ed9444e42"}, traceId: 2150458117565392121654429e7fee'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f947135a-3e05-9b21-a5de-b4dd5e77c811"}, traceId: 2150456617565392145018323e8287'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f4da3ed6-78b3-93b7-ae2b-399c2283e5bb"}, traceId: 2150458117565392165774450e7fee'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c54d9a42-8564-9423-b3c6-d9522dced9a3"}, traceId: 2150458117565392181004458e7fee'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2cd32c07-8375-9fb6-b095-5e1d6ef497a5"}, traceId: 2150456617565392186168390e8287'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a20384cf-533e-999f-b535-d97810a7bfe9"}, traceId: 2150458117565392203604468e7fee'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0b895e40-ec51-9276-b12d-ea6c59dbb59a"}, traceId: 2150458117565392245114491e7fee'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4f0b8df-7b64-96c4-946b-c315544172ca"}, traceId: 2150456617565392265498439e8287'}2025-08-30 03:34:11,086 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:11,088 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:11,120 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:11,120 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:11,120 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:12,088 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:12,100 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:12,100 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:12,127 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:12,127 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:12,127 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:12,150 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:12,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:12,202 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:12,203 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:12,237 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:12,237 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:12,237 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:13,329 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:13,620 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:13,638 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:13,639 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:13,663 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:13,663 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:13,663 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:13,985 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:14,122 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:14,130 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:14,625 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:14,641 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:14,651 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:14,652 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:14,678 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:14,678 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:14,678 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:14,731 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:15,147 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:15,642 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:15,648 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:16,173 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:16,671 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e634da2b-e65e-90c2-8049-efc0ce66be12"}, traceId: 2150416a17565392245134090edfbc'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61087fd5-38a9-93cb-abe5-f582224278f5"}, traceId: 2150416a17565392270544101edfbc'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12634
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12634
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e124f19-b19c-93aa-b5c5-b8eb29d41786"}, traceId: 215041e117565392275687219e3347'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f19795c8-6bd3-92ce-9df4-3e25b710dbb2"}, traceId: 2150455217565392283448657e822f'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd9f69a2-ed2c-9b9c-a491-b261b44b8266"}, traceId: 215041e117565392290907236e3347'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f49ca20e-28ea-9586-ae6e-365291720b79"}, traceId: 2150417917565392301237593eee4c'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88522976-d7ac-9cce-aec2-7e490338ec64"}, traceId: 2150459f17565392317931697e7fb2'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7c1a0d03-5a3e-917a-9d62-b4be935edd64"}, traceId: 215041e117565392322747266e3347'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"700d7074-aeb9-974e-9ae0-055be68ce619"}, traceId: 213e06a117565392339913170e8c52'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"89434f7e-f3d3-9c3c-920b-df9988ea8b61"}, traceId: 215041e117565392364597280e3347'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.6
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f0e93bb-9a33-9111-adde-3da0f0e11d13"}, traceId: 213e066d17565392375256477e82b3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4591
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4591
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc378400-343a-9d30-b6b3-670da72819ce"}, traceId: 215042ae17565392385656255e93d6'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0cfafc20-08a6-9ab2-99e8-07ba648dd967"}, traceId: 215041e117565392401837289e3347'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager2025-08-30 03:34:16,677 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:17,810 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:17,880 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:18,334 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:18,343 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:18,345 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a7ee641d-45fa-9eff-b6f4-a35f0b6a20dc"}, traceId: 2150413117565392226557395eea5b'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8fed957d-542a-9187-942b-36dd5625099a"}, traceId: 2150416417565392235074960e140c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"face531d-21c9-9e60-afad-f9c5941a1d62"}, traceId: 2150413117565392255357406eea5b'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"707ebf08-9ae7-9871-a095-ddcda1224acf"}, traceId: 2150416417565392260424966e140c'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"50e7691f-781b-93dd-afdc-27377b8bde96"}, traceId: 2150416417565392280774973e140c'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59a5dbfe-26c8-91cb-a490-a55975a3cfe6"}, traceId: 2150413117565392296007447eea5b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16377
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c656ad59-0541-90e5-9437-5b696218e757"}, traceId: 2150456617565392303738985e7ff3'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5126af37-24f2-9b66-9dad-e79a66209cee"}, traceId: 215045c117565392317928422e81bc'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3cfa6f2f-d52b-9514-ad78-d623e4691133"}, traceId: 2150416417565392322755032e140c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3d9b0e08-0e06-94a3-91a1-7c241b1927fa"}, traceId: 215041de17565392334402100e363d'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f533bac-88f3-9f17-8bf1-327c73f2329c"}, traceId: 213e064617565392344825556e09cc'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"32876b39-138e-9890-b55f-ed80db0df832"}, traceId: 215041de17565392359452112e363d'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12336
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12336
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e84b5b4-5782-906c-9174-0f65c209a8d7"}, traceId: 213e066017565392385317195e87a9'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct2025-08-30 03:34:18,346 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:18,370 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:18,370 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:18,370 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:18,566 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:18,571 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:18,848 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:19,269 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:20,328 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:20,358 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:20,385 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:20,664 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:20,782 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:21,186 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:22,562 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:22,740 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:23,059 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:23,075 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:23,075 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:23,102 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:23,102 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:23,102 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:23,551 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:23,584 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:23,595 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:23,595 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:23,620 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:23,620 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:23,620 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ceb81542-942e-967a-a35e-b846b9fd8b49"}, traceId: 2150456617565392285868455e8287'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"28ba8cca-2f19-9319-a9ce-3c2d89ca2aa3"}, traceId: 2150456617565392306158494e8287'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd6c7dcd-b8c4-9d5f-8df6-18de335ac9a5"}, traceId: 215045b417565392307622753e810d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14705
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14705
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"06b1c99a-e0d9-9910-acbc-b6cd623d94aa"}, traceId: 215045b017565392315848866e8310'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3fa0c679-e61f-9dee-ab4d-05f4fedf150b"}, traceId: 2150438d17565392327923130e2b93'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73f27ccd-012b-935e-999f-85aa9709587c"}, traceId: 2150417917565392344786931eeca0'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"359cf687-cb05-92c2-805c-3e5dc6ce5f3a"}, traceId: 2150456617565392364578526e8287'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"957c24a2-9fc6-9d26-9220-3365c9750374"}, traceId: 213e065917565392385323883e7f49'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68b6498d-7255-9862-8fb0-b8009df4d055"}, traceId: 2150456617565392391678536e8287'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e2d3e9ad-28f2-93cb-b450-54e5d91a4ea6"}, traceId: 213e059717565392407044909e36f8'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d77b1726-fb12-9932-bc18-9422b27154c8"}, traceId: 2150456617565392411998543e8287'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e986e56-c23d-96a1-b7ef-1c3f2d4011be"}, traceId: 213e081017565392431302892e0c35'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"21f1adb8-8d6b-9c5e-8b51-bf4bb85532e8"}, traceId: 2150456617565392433938549e8287'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d40f9ea-dea9-99fe-aa14-efb659ae6357"}, traceId: 2150456617565392467748558e8287'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4dbfa82-f705-9abd-a259-654cd7ba54cb"}, traceId: 213e066417565392467858814e8212'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b481a420-9bed-9202-81f7-541668dd8012"}, traceId: 2150456617565392508048575e8287'}2025-08-30 03:34:24,015 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:24,076 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:24,094 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:24,094 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:24,120 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:24,120 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:24,120 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:24,331 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:24,838 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:25,097 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:25,142 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:25,187 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:25,619 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:26,159 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:26,443 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:26,940 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:27,388 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:27,629 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:27,903 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:27,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:28,400 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:28,413 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:28,413 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:28,442 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:28,442 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:28,442 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:28,910 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:29,605 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:29,787 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:30,106 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:30,108 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:30,218 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:30,648 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:31,169 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:31,696 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:31,793 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:31,793 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:32,723 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:33,784 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:33,796 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:33,797 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"23302599-07c4-901d-9fcc-6f707c4982c8"}, traceId: 215042ae17565392406756265e93d6'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a65a9108-9f90-97b5-a5ea-40560b2bb1ac"}, traceId: 215045b417565392418867366e7fa1'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"baf57eca-ad6c-9564-a291-597c3b6c1966"}, traceId: 215042ae17565392433766282e93d6'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7d2fc3e8-b5f6-9b8d-99fc-a3619497f1c7"}, traceId: 215045b417565392438957376e7fa1'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f1c4e12-6976-9653-bbd8-c3f9b5cd918a"}, traceId: 215042ae17565392455606293e93d6'}
[RETRY] 400 error detected, waiting 5.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.84
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14447
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14447
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03160f0d-ebdb-93c2-875d-4ae5837d7847"}, traceId: 215045b417565392467787389e7fa1'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"040447a5-dc40-9bfe-915c-bf5c2c99be1a"}, traceId: 215045b417565392490217401e7fa1'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"05acc197-8ecb-93a0-991c-0942bf7d610c"}, traceId: 2150414417565392519283857edcc1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f0040a9-2757-9682-b471-f7a3831e5ed7"}, traceId: 2150434117565392530808976e1f28'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0aa42a2-ac87-9f77-9ea2-663c4fe572e0"}, traceId: 215045b417565392533547425e7fa1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"092e667b-5c8a-9496-afe2-f3dc1a38bf79"}, traceId: 215045be17565392544774780e8179'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"659765b8-0b01-9c1d-91ef-54c4b8f156a4"}, traceId: 2150416317565392548906749e1322'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5761bc3f-8443-9c2e-83cd-13c350a173c1"}, traceId: 215045be17565392558734786e8179'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82025-08-30 03:34:33,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:34,211 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:34,741 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:35,745 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:35,986 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:36,003 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:36,004 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:36,029 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:36,029 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:36,029 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:36,774 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:36,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:37,037 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:37,297 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:37,309 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:37,309 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:37,340 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:37,341 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:37,341 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:37,351 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:37,781 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:37,893 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "

[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1af4e32a-9509-9e66-a60b-94ebdf9ec480"}, traceId: 215041de17565392396702123e363d'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54ad0523-95b4-9019-a9af-2f57b80edcd8"}, traceId: 215041de17565392423702138e363d'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aa75fe60-9595-97e4-9e9a-e0aea1ecf791"}, traceId: 213e064717565392428938369e88f7'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b39da33a-fca3-9950-837b-9cc28418043e"}, traceId: 215041de17565392443952153e363d'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.6
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4570
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4570
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f7f5ba3-2421-998f-9ba5-7b1eebf26612"}, traceId: 2150414417565392467671589edab1'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0395898b-d780-9e5f-98bb-4dfa3c3f6e1d"}, traceId: 215041de17565392471872165e363d'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7ff95e6b-9cc9-9738-b759-c2d734ded205"}, traceId: 2150414417565392483831599edab1'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eefc8b84-20a3-984e-bc81-c175bc588cfd"}, traceId: 215041de17565392495152178e363d'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e55d7a0f-90cd-9250-80a0-7a0ec7451135"}, traceId: 2150414417565392502941609edab1'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5404dece-0bc9-9eae-b66a-6fe8e6c5d137"}, traceId: 2150414417565392538491621edab1'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"592818fc-1de6-9a80-9816-e51f4970b04b"}, traceId: 215041de17565392543572211e363d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"420888d5-c939-99b4-bba4-fb73986eb3f0"}, traceId: 215045f517565392554124670e8220'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e61f0b85-2f5a-965e-9cfb-30089da8e758"}, traceId: 2150414417565392580641634edab1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection2025-08-30 03:34:38,859 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:38,877 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:38,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:39,002 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:39,370 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:39,796 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16593
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16593
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"39a2bec4-190f-93f0-8635-fd498e1c9190"}, traceId: 215042f817565392518372964e25ab'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22a25493-ed88-9193-87a6-f7679b844162"}, traceId: 2150438d17565392518976802e2c59'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2230eea1-2429-9fc1-ac2e-a0d84aa13992"}, traceId: 2150438d17565392538486809e2c59'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"efc33adf-153e-96ae-bfe2-4c90463af6e6"}, traceId: 2150417917565392543671687eee8f'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5021128f-df31-98bc-94ce-fb145e0f500f"}, traceId: 2150438d17565392553646817e2c59'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e66ac7d-da2d-9ab8-a3b0-7e1322a12501"}, traceId: 2150417917565392563921693eee8f'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"471c70aa-ab4b-99df-99c2-aa2b14757bed"}, traceId: 2150417917565392580761699eee8f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"64d5db42-d234-9f3a-985f-cfd9508363d6"}, traceId: 2150438d17565392585676823e2c59'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"642ff9e5-8541-9183-9e8f-6f3e2921edd8"}, traceId: 2150417917565392604101709eee8f'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"779e34d3-51fb-94c0-bb78-2eabbf7e067e"}, traceId: 2150438d17565392627936837e2c59'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5583c13-187b-9ce8-a909-b9668d4db209"}, traceId: 2150417917565392633141725eee8f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-30 03:34:39,854 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:40,720 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:40,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:40,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:40,923 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:40,923 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:40,950 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:40,950 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:40,950 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:41,430 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:41,908 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:42,052 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:42,155 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:43,018 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:43,435 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:43,852 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:43,938 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:43,953 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:43,953 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:43,975 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:43,975 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:43,975 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:44,072 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:44,462 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:44,658 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:44,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:44,795 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:44,909 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:44,945 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:45,003 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:45,484 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:46,184 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:46,206 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:46,655 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:46,685 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:47,180 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:47,627 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:47,686 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:47,711 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:48,226 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:48,733 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:49,215 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:49,786 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:50,560 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:50,668 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:50,696 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:50,852 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:50,982 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:51,192 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:51,203 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:51,204 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:51,227 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:51,227 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:51,227 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:52,403 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:52,800 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:53,171 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:53,288 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01a691ac-cd47-90b7-bd72-a5752ab5de19"}, traceId: 213e006817565392583224319ee540'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16344
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16344
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ebe02b23-c638-9345-8841-b0cb9eb583c5"}, traceId: 213e006b17565392601298747eecf0'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01d4d7c8-4b73-96a4-a00b-96339dd8673a"}, traceId: 215040be17565392609258526edefe'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c4dd7da1-3297-94af-809f-9ec2d0cb8817"}, traceId: 215040be17565392622908529edefe'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"67a6b463-9956-9a7d-8adf-3ee690103f49"}, traceId: 213e06ba17565392646075776e89bb'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59ac14e9-932f-93f5-bdad-75f2d684ece5"}, traceId: 215040be17565392648348547edefe'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5d908f72-033a-9175-b2a1-25d6275d8626"}, traceId: 215040be17565392676278560edefe'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9aa2d0d1-fd51-94c5-86b6-d92d478f85ab"}, traceId: 213e007517565392681532006eefb3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14695
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14695
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6319a844-c6cd-9c36-a2e7-5ac60436d350"}, traceId: 2150416417565392693226322e1158'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68df9a16-6a9f-98e8-b9e9-8545b52584cf"}, traceId: 2150416417565392708896358e1158'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93017f6f-e29a-98ff-9442-3126f1d3410b"}, traceId: 2150416417565392735116449e1158'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4d2277b-a4f5-9de1-91ee-9dbe5a7b3d79"}, traceId: 215040be17565392744538725edefe'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3c07c9b3-8d30-9424-be71-0b5afc1e697c"}, traceId: 2150416417565392765076560e1158'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct2025-08-30 03:34:53,815 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:54,757 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:54,881 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:54,881 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:34:55,788 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:55,808 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:55,949 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:56,957 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:57,002 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:34:57,483 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:57,483 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:57,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:57,676 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:57,676 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:57,702 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:57,702 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:57,702 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4529
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4529
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4b53375d-ad99-9573-8307-930542010a51"}, traceId: 215045be17565392575604803e8179'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7c2f456f-7951-92a8-83c5-a364d606bdb6"}, traceId: 213e006c17565392583233898e11db'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"127aaf56-162a-9615-8254-4e8fd72c36fd"}, traceId: 213e007517565392601211966eefb3'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0511dc4a-92c8-959a-abc8-cf5b03fb8069"}, traceId: 215045be17565392603974828e8179'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c9afff7-3a91-912e-82c4-bec90a959900"}, traceId: 213e064b17565392625147765e78ed'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4594
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4594
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6217da59-bb6c-9db1-8218-b519a29f4ae6"}, traceId: 215045be17565392638104840e8179'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"91763a3a-5557-9f0f-9f80-d3dd58d92c3e"}, traceId: 2150411617565392649268116ee766'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_validator

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70c27921-5d8d-9b8e-8535-d5a480f5bd80"}, traceId: 213e06a217565392667112105e827e'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fa7c258e-f791-9665-bf17-640efe438cc3"}, traceId: 2150411617565392671238128ee766'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab916dab-4ee7-9473-87b8-4e0e70775d32"}, traceId: 2150411617565392698428154ee766'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
  [INFO] Tool info request: data_processing_parser

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1683354e-780e-9128-a029-c07428850ee9"}, traceId: 213e041717565392703813611e9711'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"90308681-80a1-900e-acd8-8e2631aecbeb"}, traceId: 213e064717565392714314144e8a83'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4529
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4529
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d8761119-038f-9f48-b266-c1dda5ccb97b"}, traceId: 2150411617565392724648249ee766'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88ebfb6a-5c8c-9972-996a-f0efd62d4b81"}, traceId: 2150458117565392735276906e8179'}2025-08-30 03:34:58,005 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:58,015 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:34:58,015 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:34:58,038 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:34:58,038 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:34:58,038 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:34:58,598 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:34:58,776 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:34:59,176 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:34:59,596 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:00,103 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12632
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12632
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"52a4b552-3b2c-9962-9625-4ed97571e853"}, traceId: 213e004f17565392640855588ee6fb'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c84ae6e-5ebd-9c83-9cfa-4ccbcc2fed5a"}, traceId: 215042f917565392648695185e1d45'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"90d845a3-940f-97ed-87b5-7d99af11af6b"}, traceId: 213e060917565392653636672e6fa8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"30347a55-b7bd-955f-8408-d3a301742996"}, traceId: 215042f917565392661595190e1d45'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6f272f1-ebe2-9f25-97b9-9eaf18670a0f"}, traceId: 213e066e17565392673596557e8154'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1e9fc45-0f80-9710-af57-e22af21f78be"}, traceId: 215042f917565392676165197e1d45'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01b5dfa6-59ff-972a-8f9b-9402855945d3"}, traceId: 213e043b17565392695548029e259b'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c33c9df-8f68-98de-b1d9-2fcac4ac1ff7"}, traceId: 215042f917565392698295226e1d45'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4551
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4551
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: data validation parser

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c4a5067-e1c6-9f7e-8973-f580977c4efc"}, traceId: 215042f917565392739355367e1d45'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"31e2e21a-6515-9a0a-a037-0f428f0665ad"}, traceId: 215042f917565392754765387e1d45'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6740b872-8e09-9ed8-acd2-95f94c22c1bc"}, traceId: 213e007417565392756692929eecb7'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"80cfbb4c-c801-9278-93fa-a4fa4204a5c6"}, traceId: 2150421317565392770794409e3547'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3bd69a9d-66bc-9d3d-ac62-ca00a09c16a6"}, traceId: 215042f917565392775075437e1d45'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1260eb3-62d5-9d48-b8e9-0563dbfdfee2"}, traceId: 2150421317565392785354452e3547'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"beb75139-c68d-95be-931c-0ce37c44005b"}, traceId: 215042f917565392795435446e1d45'}2025-08-30 03:35:00,105 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:00,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:00,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:01,039 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:01,151 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:02,085 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:02,613 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:02,904 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:35:03,136 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:03,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:03,585 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:04,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:04,201 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:04,706 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:04,719 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:04,720 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:04,746 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:04,746 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:04,746 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:05,455 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:05,760 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:06,423 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:06,921 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:07,325 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:07,337 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:07,629 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:07,629 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:07,668 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:07,668 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:07,668 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:07,970 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:07,979 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:08,910 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:08,911 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:09,017 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:09,448 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:09,553 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:09,554 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:09,581 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:09,581 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:09,581 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:09,946 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:09,960 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:10,477 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:10,912 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:11,405 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:11,406 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:11,422 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:11,422 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:11,447 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:11,447 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:11,447 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:12,041 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:35:12,567 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:12,914 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:12,948 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:12,969 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:14,304 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:14,799 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6688d59c-352b-9ddf-9928-87108ab9a16d"}, traceId: 215044eb17565392767684683e8204'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b7f0999f-5bf1-96bb-92fa-270aee5ea51d"}, traceId: 2150411617565392770168404ee766'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4768
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4768
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ecb16254-b0ab-9053-bdba-1f78e4048de6"}, traceId: 215040ed17565392816523721ebd34'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b8b2d0a8-6f82-9544-bb76-32dbacbe97a3"}, traceId: 2150439017565392846576752e2650'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b6ec8f9e-cead-9ea5-91d4-6b845df6dfce"}, traceId: 215045be17565392864313818e7fdb'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6224e1e8-f60a-9d23-a647-f1680e567734"}, traceId: 2150448717565392873992544e8049'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88d7f025-2ac0-9922-bddc-6776fdc975c0"}, traceId: 2150415b17565392874624750ee3ad'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ffe204b1-e286-9b6e-816a-5cd6fdd7c04d"}, traceId: 213e007b17565392903178766eec8b'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43673bd8-eca0-9c79-9c43-c4069fe4e385"}, traceId: 213e064617565392906148689e0bbf'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d5b99332-5956-9d1a-b325-0fcc6da9501c"}, traceId: 2150416717565392929334765eee36'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4864ba2-52a8-9719-8813-9b80654a12c0"}, traceId: 213e006017565392934723933ee29b'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e79cffa3-1d3d-95de-93b3-87f65b78fd4b"}, traceId: 2150449a17565392974267858e819d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13214
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13214
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-30 03:35:14,819 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:14,842 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:14,972 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4573
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4573
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"953f80b2-7b48-9df0-8821-cdece344cfe1"}, traceId: 215040be17565392795588868edefe'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0eeed48-2315-9841-b2ff-e9cc7d54fc7f"}, traceId: 2150416417565392806486604e1158'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c038c9f8-49af-9673-99ee-80f6ab40c6b6"}, traceId: 215040be17565392811558897edefe'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bd5a7884-6e50-99a6-b3ac-284c6690d01e"}, traceId: 2150456117565392819246443e8067'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4752
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4752
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"705e34d0-52b1-934a-8773-d8386a6639c3"}, traceId: 215040be17565392841818921edefe'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b7bf3636-3186-93e5-90da-dff9ca7bebf6"}, traceId: 215042f917565392852163082e19a9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"012f332e-e987-90e3-98fd-efd3d6150278"}, traceId: 2150415c17565392869455402eec93'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d26fc6e-1d7c-96af-92fb-686206826662"}, traceId: 215040be17565392879408938edefe'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a21dc40-2ce1-9ce4-9856-0d7fefdd622f"}, traceId: 213e064b17565392903698965e7828'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b16b744a-9658-9e53-9597-99361fdff914"}, traceId: 215040be17565392908518951edefe'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13377
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13377
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c3e63e93-4e6f-9e04-a980-bbcd4274d094"}, traceId: 213e065a17565392921441136e841f'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"af532aa9-99e7-9550-8bfb-3c51018cf35b"}, traceId: 215040c017565392929521698ee14c'}2025-08-30 03:35:14,973 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:14,999 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:14,999 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:14,999 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:15,367 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:16,023 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:16,067 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:16,357 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:16,881 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12665
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12665
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3dd0a1f9-191e-9dcb-8fc8-451bdbae5622"}, traceId: 2150421317565392831584490e3547'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb58c756-16b2-993a-8c5f-421531daf8f0"}, traceId: 215042f917565392836675462e1d45'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e5e3c3e-9454-9292-a6c3-48c476dff304"}, traceId: 215044eb17565392844382330e81e3'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"314e7236-7674-9449-9080-e49a151df931"}, traceId: 2150421317565392846894497e3547'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"70e124ad-5038-9dd3-b7e0-ada58619aae9"}, traceId: 213e06c217565392859318455e8252'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a2697e3-f733-90c1-b2b2-425133bcba13"}, traceId: 2150421317565392864084503e3547'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4573
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4573
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d452908-f438-9406-af41-c9a24bdb0970"}, traceId: 213e006f17565392884707073ee5e4'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1817c6d0-a2a6-9451-8ac7-74b7314d02eb"}, traceId: 2150421317565392889514510e3547'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5068f911-b220-9ede-b446-55772271e372"}, traceId: 213e006c17565392903774314e11db'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12626
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12626
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68af2954-f061-9208-90fc-ec4cbe388f35"}, traceId: 213e066c17565392955487116e77c3'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f21f021c-8c0a-980f-bfe9-3f65ff2ec26b"}, traceId: 215041a817565392966838617e3439'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d598e540-a774-9645-ae6f-3113900cc21d"}, traceId: 2150460e17565392971724969e78b3'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"133b1b1d-790e-9ffb-a186-fc44c492c446"}, traceId: 213e065917565392998022132e815b'}2025-08-30 03:35:17,600 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:17,616 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:17,931 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:17,947 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:17,948 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:17,972 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:17,972 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:17,972 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:19,002 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:19,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:19,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:20,027 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:20,037 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:20,037 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:20,066 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:20,066 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:20,066 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:20,741 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:20,777 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:35:21,076 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:21,602 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:22,024 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:22,032 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:22,659 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:22,676 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:22,676 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:22,701 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:22,702 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:22,702 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:22,902 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:23,379 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:23,386 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:23,818 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:24,015 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:24,801 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:25,271 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:25,794 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:26,320 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:26,468 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:26,478 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:26,479 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:26,500 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:26,500 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:26,500 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:26,739 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:26,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:26,912 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:35:27,776 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:27,892 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:27,892 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:28,841 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:29,040 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:29,085 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:29,376 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:29,988 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:30,142 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:30,175 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:30,943 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:30,956 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a0310a65-4850-977f-ba3f-baa81c5f1fcb"}, traceId: 215040c017565392944851706ee14c'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7f2eb8e-42bf-9bed-945b-43d19f7a093d"}, traceId: 2150454117565392955447693e774f'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"92f6bf89-b147-9648-83a5-d4e4ec2a78ad"}, traceId: 215040c017565392971771719ee14c'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.82
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce5b9bb9-ed96-914b-8a8e-84c4d295c514"}, traceId: 2150457a17565392985092684e0c85'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f01e912-672b-91a1-905d-bd7db6188a1a"}, traceId: 215040c017565393007881729ee14c'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"383c15be-778b-9cab-821d-58da6a2ced48"}, traceId: 213e007f17565393037831756eea87'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4b55b90f-ecdf-94c5-8b33-88d7f6d1a6df"}, traceId: 215040c017565393044451749ee14c'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12536
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12536
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d5a413a-5954-9eb0-92dd-65d194ba0b39"}, traceId: 213e007d17565393052121713ef023'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"81db239c-8958-9b8e-8b4f-e53f31a36a15"}, traceId: 213e006d17565393070917901e125e'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8de14a1-f9a1-975b-837d-ab06e262f5ef"}, traceId: 215041a817565393086351756e3373'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f815a0c6-364b-9aa0-9067-d90db5f27b3f"}, traceId: 215041a817565393096821760e3373'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b7d4b7da-cd55-98ce-9b67-d0664258299e"}, traceId: 2150411617565393097145258ee88f'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8586f8c7-6977-9fc5-83a6-888e993d71db"}, traceId: 215041a817565393111471770e3373'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f6f0ab0-3ab8-9c0b-867b-492844dedad7"}, traceId: 215041a817565393145441778e3373'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-30 03:35:30,957 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:30,981 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:30,981 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:30,981 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:31,439 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:31,448 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:31,652 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:31,749 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:31,749 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:31,771 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:31,771 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:31,771 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:32,115 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:33,027 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:33,135 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:34,066 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:34,082 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:34,378 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:34,595 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:34,707 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:34,846 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:35,630 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:35,963 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"692f3c4f-71aa-9cc4-8748-6c7af794b1d7"}, traceId: 2150460e17565393002804978e78b3'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"475297bf-93ce-96ac-a0b9-4a6a01536181"}, traceId: 2150460e17565393018214984e78b3'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b9fb7ab-37b4-90b9-9c17-5ceb57cb4fed"}, traceId: 213e060917565393023748566e702d'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1301bee2-978c-9e82-af39-19ff96c6059e"}, traceId: 2150460e17565393039184999e78b3'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"515ba736-e449-9f0b-8d89-998249af48b6"}, traceId: 2150460e17565393070655023e78b3'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12542
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12542
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78b44295-686b-971e-ac43-e8462d154529"}, traceId: 215040cc17565393086937753ed49b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"adc77892-c9da-934f-a4a8-34b8a157b5bb"}, traceId: 215040cc17565393106287764ed49b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5f99f9e7-eb50-99d9-bd34-8a133861db63"}, traceId: 2150460e17565393111485039e78b3'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"de549a2d-cc97-9fc8-b6ae-d1bc24bb69a8"}, traceId: 2150409b17565393123048468e07da'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a586b172-9ae0-9c75-966c-9ce1bcd537ae"}, traceId: 215040cc17565393126947772ed49b'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f098de9c-20cc-9cc3-a92d-23bb7f38ccf1"}, traceId: 2150409b17565393140328483e07da'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cd0c7330-5943-9a91-8a72-80aa1be1326f"}, traceId: 215040cc17565393145427779ed49b'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.58
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13396
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13396
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6dec448a-c56a-9f4b-a097-e9ae04e48e2c"}, traceId: 2150409b17565393165948500e07da'}2025-08-30 03:35:36,281 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:36,453 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"338cbdac-1ded-979c-b7da-fd9f15419c5d"}, traceId: 215044da17565392977605078e80df'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d65fe57a-b602-9322-b29d-5e6ccb037d0e"}, traceId: 2150457117565392988941743e7781'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a69d78d8-2820-9028-b814-6439becca013"}, traceId: 2150430917565392993267620e1c44'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4e530bf5-cec6-9966-858d-59a93a2b121a"}, traceId: 2150430917565393002757621e1c44'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"437e1ee0-7cc2-9332-8706-0733f695481a"}, traceId: 2150457117565393007881751e7781'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e74edbda-f015-9325-a3bc-b503f3a9ff52"}, traceId: 2150457117565393028721761e7781'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fdf61968-cde6-906a-8d71-d9b3b72be1e4"}, traceId: 2150430917565393032997632e1c44'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"55343c50-a641-9fcb-93de-0ddf41a59c7a"}, traceId: 2150457117565393054951783e7781'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 16302
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=16302
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"576da87a-0738-9066-b600-4b7c72813c65"}, traceId: 2150430917565393086327655e1c44'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a1c6917-35ff-9186-a99e-ad5a5dfdceda"}, traceId: 2150457117565393091641796e7781'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e357b0c6-4af9-974c-9f88-332fbc081752"}, traceId: 2150430917565393102087665e1c44'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4637396-a0b3-9a71-89c5-de294c3e37ea"}, traceId: 2150436a17565393126608277e211c'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"04a8a049-6f21-9802-b335-28e8159de20a"}, traceId: 2150430917565393126937678e1c44'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aad3d50d-8276-9dba-b778-761a3cb8e7cf"}, traceId: 213e06c817565393145601740e83c2'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...2025-08-30 03:35:37,853 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:37,876 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:38,378 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:38,785 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:38,944 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:39,338 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:40,377 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:40,588 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:40,601 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:40,601 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:40,623 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:40,623 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:40,623 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:40,866 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:40,897 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:41,415 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:41,431 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:41,432 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:41,456 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:41,456 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:41,456 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:41,624 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:42,611 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:42,976 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:42,983 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:42,990 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:43,371 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:43,484 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:43,497 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:43,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:44,213 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:44,944 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:44,957 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:44,957 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:44,984 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:44,984 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:44,984 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:45,410 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:45,419 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:45,422 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:46,128 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:46,421 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:46,920 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:47,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:47,444 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:47,974 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:47,983 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:48,006 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:48,006 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:48,031 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:48,031 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:48,031 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:49,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:35:49,481 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:49,576 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:49,964 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:49,965 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:49,990 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:50,025 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:51,917 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:52,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:52,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:52,010 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13014
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13014
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7ee8bd02-f6d4-945b-bbc3-bf0d42d7f8d0"}, traceId: 213e043117565393158297028e22d4'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c2b4b41d-e821-9276-b663-d187669cfd70"}, traceId: 2150457917565393173845867e8b26'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c4cc1ea-d7bd-9234-bada-fa923da90b8b"}, traceId: 215041a817565393176101788e3373'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7653ee9f-6e95-9cd9-a7b9-088273ee60d9"}, traceId: 215041de17565393187367165e3537'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27142276-079c-9957-b18e-976cc5f3d226"}, traceId: 215041de17565393207577172e3537'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc5d29fe-9e32-9d82-8f40-f6968fd5f324"}, traceId: 213e062b17565393212796923e815d'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5dc0e291-cee6-9828-a0ba-af5f4b18f337"}, traceId: 215041de17565393226147180e3537'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f76fea9d-eddc-9c1d-9b45-7cdff21f79a5"}, traceId: 213e059717565393231397714e3821'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
Progress: 10/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12842
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12842
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c63aac2f-b158-9d5a-b075-78f0a37fffa1"}, traceId: 215041de17565393264787205e3537'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a16a077b-b8d8-98d0-9dcb-0ab311ea4cbd"}, traceId: 215045be17565393275244180e8138'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7be241b1-7b3a-99bd-8b48-5fb0d1eb9263"}, traceId: 213e05ab17565393288256265e3617'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ff27c22c-2b57-9397-9632-55463067e2b4"}, traceId: 215041de17565393306827299e3537'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4918
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4918
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct2025-08-30 03:35:52,028 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:52,029 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:52,051 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:52,051 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:52,051 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:52,435 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:52,442 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"30891854-c267-9f18-96b4-b82edcb3c69b"}, traceId: 2150430917565393160607688e1c44'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0d93f37-284e-944d-9ca0-422f8c5aad0e"}, traceId: 213e007c17565393173581819ef042'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4774
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4774
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"42fbe2c9-5f28-99af-9296-fab0c1e4cf86"}, traceId: 215042f817565393217721421e279b'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78cac3d1-faaf-9b72-a625-42136d8ecc86"}, traceId: 2150457117565393223991821e7afe'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"27cf54ae-a781-9be7-9b42-929ab418d18a"}, traceId: 2150443817565393237431891e87a6'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d25427e5-fdce-9fc1-a713-bfea8524277b"}, traceId: 2150443817565393254611900e87a6'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"34ca02bd-ec1f-9078-9168-4868c8fc8eb8"}, traceId: 213e006917565393262263423edf6e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1677be79-cd14-97c6-90ec-045870edaac4"}, traceId: 215040c017565393275934573edeb8'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1f8d0eda-1294-9614-869e-01e75bfea7bb"}, traceId: 2150443817565393285551970e87a6'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab63e724-b738-9d09-9c16-a404f794511e"}, traceId: 215040c017565393290794607edeb8'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12542
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12542
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66989a8b-b7cb-90ab-b2ec-0a389f3d0cbc"}, traceId: 215040c017565393311794643edeb8'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cae11d36-6da5-997b-8424-5436f0edaf7d"}, traceId: 2150443817565393327502012e87a6'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1b03ea4b-3c0d-91cc-ad08-ea6accd53831"}, traceId: 215040c017565393343234685edeb8'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"49acee4c-c2e3-9ce3-8811-557ea03e5a8c"}, traceId: 215040c017565393361794736edeb8'}2025-08-30 03:35:53,581 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:53,680 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:54,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:35:54,335 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:54,879 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:54,894 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:54,894 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:54,926 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:54,926 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:54,926 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c79d520a-64c0-9b51-b5bc-9f1c6ac036d7"}, traceId: 2150409b17565393192228512e07da'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"871038e9-2da1-959c-8f84-abc0dcccdb88"}, traceId: 215040cc17565393197337792ed49b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"695dace9-7062-9384-83ea-057cfbe3d70c"}, traceId: 2150454417565393204962600e7fd5'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fb28e37e-8380-9c50-947f-40e6215215e8"}, traceId: 2150430917565393217907743e1ef8'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f84a0bb9-d767-9243-9ff1-cc5a5f0e0c90"}, traceId: 213e065e17565393231406820e7f71'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"87f087c8-ee93-9b59-8086-0c3e13445bef"}, traceId: 2150409b17565393249478543e07da'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4621
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4621
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fb0771ed-a79b-9cd3-a1d6-750be807ba55"}, traceId: 2150414417565393264982112edaf3'}
[RETRY] 400 error detected, waiting 4.8s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ac01436-2bfe-90b5-be4a-e6e19807e6e7"}, traceId: 2150409b17565393296018594e07da'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df438a22-afe2-9c5e-8679-9b1d08c17dcd"}, traceId: 2150409b17565393311778600e07da'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Connection error.
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"09188725-4c27-9c08-8d2a-095ccc848dc8"}, traceId: 215042ae17565393328166868e92cf'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb6a2037-cc42-963c-9846-bf68f6ba78f9"}, traceId: 2150409b17565393337958614e07da'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 10/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4690
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4690
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5bb33bf3-234a-9283-abea-b9af323ecb48"}, traceId: 215042ae17565393343246880e92cf'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c3d528f7-98fa-9b64-9574-b7a4932a7bb6"}, traceId: 215042ae17565393356776890e92cf'}2025-08-30 03:35:55,886 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:55,965 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:35:56,089 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:56,102 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:35:56,102 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:35:56,105 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:56,128 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:35:56,128 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:35:56,128 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:35:56,376 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:56,389 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:56,870 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:56,876 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:57,903 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:58,011 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:58,388 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:58,417 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:35:58,424 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:35:59,107 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:00,118 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:00,126 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:00,670 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:00,867 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:00,875 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:00,910 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:01,207 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:01,336 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:01,753 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:02,673 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:02,903 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:02,904 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:03,138 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:03,329 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:03,841 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:03,844 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:04,379 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:04,879 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:05,413 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:05,661 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:06,484 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:06,729 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:06,747 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:06,748 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:06,780 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:06,780 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:06,780 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:06,789 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:07,320 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:07,518 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f27ca3e-93b5-974a-954e-e82421ab776c"}, traceId: 2150416a17565393313955260ee106'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d1917ea-6695-929e-8fef-69e4325a0b26"}, traceId: 215045af17565393317856716e806a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6cb6677e-86a4-961b-b666-6256689e5931"}, traceId: 215040aa17565393345833789ee958'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8c833e2d-0d0a-9ab7-9954-e1b5d0f2185a"}, traceId: 215045af17565393343266725e806a'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2b085993-0ce8-9469-a5ef-b640d255458b"}, traceId: 213e059717565393403432253e3529'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12836
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12836
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ef039dbb-940e-997b-b393-3ccaf6c98ce4"}, traceId: 215045af17565393395676753e806a'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"119182dc-87cd-9937-a01a-9af8cacaba53"}, traceId: 215041a817565393413886325e368c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3ae7abc3-bd8b-9490-9555-81ff6541e029"}, traceId: 215045af17565393427156795e806a'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6b31a86b-d4b3-9c70-a00c-1f74fded744d"}, traceId: 213e066017565393432548830e88f3'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"500ac602-5179-9435-be9c-37d13ee01093"}, traceId: 215045af17565393451356818e806a'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0044251-71f7-9d7a-83da-eded193ca6af"}, traceId: 213e042b17565393461876920e1e69'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d4319623-8413-96e5-9ccb-24dc73622fed"}, traceId: 215045af17565393471776824e806a'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"064ee10d-d6af-9be2-a81b-555e507b87b9"}, traceId: 213e01f617565393497346649e158e'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f44f5731-e229-9dae-82c7-4d1148afdfc6"}, traceId: 215045af17565393516526851e806a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12973
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12973
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）2025-08-30 03:36:07,845 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:08,537 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:08,769 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:08,779 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:08,828 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:08,903 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:09,772 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:09,784 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:09,790 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:09,790 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:09,806 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:09,819 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:09,819 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:09,819 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:09,868 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:10,766 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:10,772 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:10,916 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:11,294 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:11,311 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:11,311 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:11,340 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:11,340 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:11,340 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:11,817 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:11,817 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:11,827 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"191ef8dc-c301-948b-a012-66755cafb588"}, traceId: 215040c017565393380194763edeb8'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d12941b3-4873-9e8c-af01-e01e407c415f"}, traceId: 2150443817565393385292092e87a6'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"15f18585-bff9-96f6-8b79-5b0410f94525"}, traceId: 215040c017565393400894774edeb8'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0142e0f-aed7-955f-a3cc-c1e6cb54c702"}, traceId: 2150443817565393406142123e87a6'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9971984f-6dc2-9108-93a4-6e018e3a701d"}, traceId: 2150443817565393427132142e87a6'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12682
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12682
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b84669f-af58-91b3-823e-d127fa6e19b0"}, traceId: 215040c017565393446314799edeb8'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5848dc69-ec6d-9527-a161-1822ee1701ab"}, traceId: 2150443817565393451392154e87a6'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"518f2155-87b4-9b95-bead-f62b48b5a68a"}, traceId: 213e007417565393458973685eee00'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"914c5894-f23b-929d-8cda-10e20eb7c4c0"}, traceId: 2150443817565393476862164e87a6'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"72267ace-ac8e-95a1-aa74-1e7d502fab40"}, traceId: 215040c017565393492907813edf9f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ab60611a-f925-9a61-a8b6-9bf074ce925a"}, traceId: 213e041917565393497314873e2e8d'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"28663447-e1cf-9b3b-83a8-d8c70ec16cb3"}, traceId: 213e06c117565393516704688e887d'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"700cb724-2d37-992e-97fd-56b2d99acc47"}, traceId: 215040c017565393521487827edf9f'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12634
[AI_DEBUG] _ai_classify_with_txt_content called:2025-08-30 03:36:12,864 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:12,934 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:13,390 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:13,913 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:13,914 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:13,914 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:14,123 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:14,437 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:14,869 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:15,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:16,092 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:16,581 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:17,583 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:17,593 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:17,594 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:17,616 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:17,622 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:17,622 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:17,622 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:18,107 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:18,632 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:18,643 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:18,700 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:19,155 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ead0efd6-ee8a-9353-92c3-94e637b79306"}, traceId: 2150409b17565393375088630e07da'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2366baf9-8d45-9aff-b836-8bf921c1510b"}, traceId: 215042ae17565393390406902e92cf'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5e2d51a5-d37d-92d4-bc56-753e570d84df"}, traceId: 2150409b17565393411358645e07da'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7e2c6eb-c44e-983f-bbfd-e16bec3c0ae6"}, traceId: 2150460e17565393423304695e7a3f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13006
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13006
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d487659-50e9-9744-9c56-82295a34ccf2"}, traceId: 215042ae17565393432356984e92cf'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c8f08b8f-331f-98e3-a456-9443367658ca"}, traceId: 2150460e17565393439514706e7a3f'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"17ddc57d-2dcf-9f06-8a17-4fe547cd7b19"}, traceId: 215042ae17565393451337011e92cf'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"53361d90-6504-941f-9fb8-bcaed3672d1a"}, traceId: 215042ae17565393466687021e92cf'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"16a3e628-687a-99f0-a888-f7d1117c04ad"}, traceId: 2150460e17565393476994722e7a3f'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"12ca3271-db34-9648-9972-af64b6a9f792"}, traceId: 215042ae17565393492077034e92cf'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4faf89ee-ee87-94eb-a9eb-af5a6dc24f3d"}, traceId: 2150460e17565393497254741e7a3f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"47eb22f2-39b3-9f76-a95f-9f30c3ed62c7"}, traceId: 2150460e17565393516624751e7a3f'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7b2b2ce-3be1-96f0-893a-a8bebdbb5c3e"}, traceId: 215042ae17565393545807050e92cf'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12650
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12650
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized2025-08-30 03:36:19,680 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:20,204 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:20,798 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:20,810 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:20,810 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:20,834 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:20,834 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:20,835 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:21,392 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:21,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:21,840 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:21,861 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:21,861 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:21,888 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:21,888 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:21,888 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:22,825 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:23,355 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:23,874 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:23,875 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:23,875 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:23,885 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:23,886 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:23,907 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:23,907 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:23,907 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools

[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b31b7cc2-2c9c-9ff6-9631-27bafc7cad7f"}, traceId: 2150409517565393532946901eea55'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ba0f2ef3-2131-97e4-9472-7878097a9ad6"}, traceId: 215040aa17565393558476711ee640'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"403f6507-e463-9a67-a983-b04ab77f0721"}, traceId: 2150409517565393566126917eea55'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9bef5f5f-510e-90af-801d-e70961957a4d"}, traceId: 215045b417565393577455789e82ba'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aee0d3d1-ee09-9f4f-bd3e-c97e166d45e2"}, traceId: 2150409517565393581286923eea55'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"687fdacb-26c6-9f07-95c1-d6688d0afd60"}, traceId: 215045b417565393588165797e82ba'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4839
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4839
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c5742d96-6f1b-9087-b519-47754abeb371"}, traceId: 2150409517565393609426929eea55'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dfc5927f-4c51-93fc-8117-4d7b2c245d36"}, traceId: 215045b417565393614685812e82ba'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db699cd0-e803-922a-8e31-02c922d59c40"}, traceId: 215045b417565393635655834e82ba'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"128ee8f2-d276-9d04-a2ae-2faab0c1b65c"}, traceId: 2150409517565393640886943eea55'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dd535060-c495-98a1-88ff-ea67b4052053"}, traceId: 215045b417565393664635844e82ba'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5043
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5043
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"25492cd6-4033-9d33-b558-c3a82bde5e54"}, traceId: 213e06c817565393672671796e82dc'}2025-08-30 03:36:24,236 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:24,401 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:24,923 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:24,949 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:24,961 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:24,961 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:24,986 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:24,986 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:24,986 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:25,476 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:26,070 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:26,259 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:26,559 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:27,037 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:27,049 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:27,050 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:27,075 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:27,075 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:27,075 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:27,801 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:28,070 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:28,108 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:28,113 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:28,599 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:28,811 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:29,116 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:29,126 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:29,126 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:29,148 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:29,148 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:29,148 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:29,644 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:29,796 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12634
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1f12e1e-a848-9326-a6a0-6c993ba46978"}, traceId: 213e006917565393534426209ee19f'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc9f9c28-dff4-9b6c-91dc-580384020e15"}, traceId: 215040c017565393540687839edf9f'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"304d8f15-a07e-926e-a1b5-c7de8ba562f2"}, traceId: 215040c017565393560987851edf9f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"406210ba-cda6-939d-9ccd-45f4f1682a01"}, traceId: 2150416717565393566337057eec05'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"828f53e8-e830-9aea-9995-57c345b6b286"}, traceId: 215040c017565393581257864edf9f'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2ee44bc-ee7f-9edb-b399-cf2e12b8940d"}, traceId: 2150456117565393606276836e8067'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12654
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12654
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"424f2803-0ccf-9eac-b843-ec20d31e29e4"}, traceId: 213e060b17565393628868530e876a'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b1ed2d68-e7f0-9781-8e17-dc464537ad29"}, traceId: 215040c017565393630427901edf9f'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"65bacabc-5d35-933f-a989-72ce32bd5d8a"}, traceId: 215040c017565393646137909edf9f'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e515519d-f828-9e5d-92fe-b8c98da663cc"}, traceId: 213e059717565393651751163e36d7'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ce4eb9a3-e1a2-9b55-ac20-8247d20edf70"}, traceId: 215040c017565393669987919edf9f'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.7
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b32c11d7-6173-9bdc-b426-e89791dfec2a"}, traceId: 213e065417565393685343312e7e53'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cc08ec25-5750-9669-9310-4f05347561fe"}, traceId: 213e062917565393710513632e7df4'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13116
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13116
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f7428f85-b3a3-900f-aeb1-3013da47b3ee"}, traceId: 215040c017565393715347953edf9f'}2025-08-30 03:36:30,166 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:30,580 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:30,690 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:30,724 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:30,884 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:31,326 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:31,872 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:32,354 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:32,917 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:32,952 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:33,744 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:33,835 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:34,754 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:34,766 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:34,767 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:34,791 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:34,791 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:34,791 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:34,796 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:34,885 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:35,288 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:35,310 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:35,320 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:35,320 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:35,344 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:35,344 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:35,345 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:35,834 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:35,858 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct


[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0022df1-3704-900e-ad63-60c1f641c693"}, traceId: 213e06a117565393558546656e8ad1'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7b6550cc-5ab0-93b4-ad59-106a8724a24c"}, traceId: 2150460e17565393561134765e7a3f'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54fe39dd-0d9d-98f3-96a5-db84fadf8328"}, traceId: 2150460e17565393576404775e7a3f'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f036610d-a8c3-9c12-b621-a4ea46953457"}, traceId: 213e059617565393581566136e3dd7'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4dcfd4d-9a2f-971c-a164-884624ebca16"}, traceId: 213e064e17565393598914213e8229'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78f964f0-87ac-9343-be35-9d7b5e6c8ebf"}, traceId: 2150460e17565393603934793e7a3f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e20469e1-11ba-9c9e-9d41-0f29807dfdfb"}, traceId: 2150460e17565393624194804e7a3f'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"24ac94f7-710d-9233-94a1-7ba322f86469"}, traceId: 213e043a17565393635905979e20f0'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"53e43fa4-3469-90ac-9791-e6d60238cced"}, traceId: 213e001317565393654252480e0cba'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c9ff956f-286f-9a62-a483-c637e2f128c8"}, traceId: 2150460e17565393695294840e7a3f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c3bfc16c-e626-957a-bb66-0dbb1829c2a5"}, traceId: 2150415d17565393705136068e10a4'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5f9622a4-cb9c-952d-adb8-808b9c40c1db"}, traceId: 2150460e17565393715514855e7a3f'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"becfc30a-8f89-9f93-a21e-3f74a4b683fb"}, traceId: 2150460e17565393735844881e7a3f'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8fe00a55-8e63-9d5c-a046-af972d6edc02"}, traceId: 2150455217565393741065815e8270'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5266c7cd-d32d-91da-b494-563b0ba93ccb"}, traceId: 215045af17565393763338265e7f42'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3016314f-3573-9b30-afa1-163900fe37ea"}, traceId: 2150460e17565393778424954e7a3f'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1e14f319-2ab2-9cda-9831-d8c3ec96e4d2"}, traceId: 2150457a17565393788777034e0cc7'}2025-08-30 03:36:35,858 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:35,886 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:35,887 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:35,887 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:35,932 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:35,996 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:36,459 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:36,459 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:36,555 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:37,649 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:37,795 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:37,803 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:37,882 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:38,263 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:38,307 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:38,307 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:38,308 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:39,603 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:39,949 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:36:40,129 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:40,129 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:40,840 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:41,061 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:41,913 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:42,406 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0fd849b3-a818-9c0b-9d62-9ec483ae7203"}, traceId: 213e062917565393685311701e80ec'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"83594124-1e75-9a96-a58b-c9ad7083e4e4"}, traceId: 2150409517565393695126966eea55'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"66ebbbdd-4155-930c-aebd-96d8fc017066"}, traceId: 215045b017565393705381980e82a2'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8da15844-2e0d-99b7-b2d9-e647639f99dc"}, traceId: 2150417717565393714747499ed9ac'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1768f0c8-6de1-96e3-8383-1faacacaa019"}, traceId: 213e06b717565393730972718e79e8'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54c66797-c675-9f87-bc11-441be11e0227"}, traceId: 2150417717565393735687518ed9ac'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12990
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12990
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a2c7dacf-1cc8-9cbc-8af2-47c146f88b3b"}, traceId: 2150417717565393757997592ed9ac'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"223eb51d-25f8-9182-a176-0a96ed0a58c3"}, traceId: 213e04ea17565393773048931e352e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"431aa5fc-d7c6-91e0-8e79-0a9d0a6406d6"}, traceId: 2150417717565393783357780ed9ac'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2e8bf889-5586-9af0-b334-fd5d95fdf922"}, traceId: 215041de17565393784271130e363e'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b4b19e73-1232-9778-85e9-612bc2440cc1"}, traceId: 215041de17565393798701140e363e'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3515e5ab-ce42-9cb7-afbf-be5a5f460ae7"}, traceId: 215041de17565393830551155e363e'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1dfaaa11-788a-951e-b965-67ef3fcfa721"}, traceId: 2150417717565393835578062ed9ac'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json2025-08-30 03:36:42,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:42,874 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:43,379 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:43,380 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:43,508 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:43,905 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:44,445 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:45,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:45,457 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:45,953 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"11cc4af3-849c-98d1-97df-8c05ef1ad94a"}, traceId: 215040c017565393725507965edf9f'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ae9e7291-165c-9cab-a8a3-143f300962ed"}, traceId: 2150430c17565393726601755e1fd9'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ff54791-03e8-9853-8ebd-f1f72a944f69"}, traceId: 2150430c17565393746051776e1fd9'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6841becc-cd83-9a83-985d-9fa96cc6aa99"}, traceId: 215040c017565393752258032edf9f'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a583a975-9435-90ca-828e-d0748dc1eac2"}, traceId: 2150430c17565393773381820e1fd9'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fac822f5-d77a-90a3-a64d-cbc7863995bf"}, traceId: 215040c017565393783378119edf9f'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"345178c2-e155-9957-b132-b50b58f54e17"}, traceId: 2150430c17565393793721832e1fd9'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"28e9d7d1-2033-9209-a292-3543ea388d4f"}, traceId: 215040c017565393805188142edf9f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13461
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13461
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d3f91e23-a73c-92f1-8f0e-7ed101fe8235"}, traceId: 213e007317565393812905439ee45c'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3e2630df-6bbf-92b0-abd2-b2ddab525ec0"}, traceId: 2150415d17565393835787401e1292'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44a328ad-2b2b-9718-8223-1e5c52afc03b"}, traceId: 2150430c17565393846961852e1fd9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"719cee45-5087-9a60-86f8-72d69a5b12b6"}, traceId: 2150417517565393857885057edf76'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a266297-fce5-9ad4-b17b-335c0a5133ec"}, traceId: 215040be17565393860032176ee089'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"535b5d29-83c3-9752-a301-524c423971b7"}, traceId: 2150417517565393877895064edf76'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08e9034a-60c6-925d-83d4-bab21edcaf4f"}, traceId: 213e063717565393895636075e8a57'}2025-08-30 03:36:45,964 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:45,965 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:45,981 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:45,992 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:45,992 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:45,992 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:46,012 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:46,013 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:46,041 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:46,041 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:46,041 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:46,731 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:46,742 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:46,742 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:46,766 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:46,766 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:46,766 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:46,989 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:47,003 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:47,003 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:47,030 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:47,030 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:47,030 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:47,211 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:47,488 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:47,499 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:47,499 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:47,525 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:47,525 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:47,525 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:47,712 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:47,732 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:47,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:48,063 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:48,518 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:48,519 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:48,524 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408521753.json
2025-08-30 03:36:48,525 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408524267.json
2025-08-30 03:36:48,525 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408525127.json
2025-08-30 03:36:48,526 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408525769.json
2025-08-30 03:36:48,527 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408526239.json
2025-08-30 03:36:48,528 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408527330.json
2025-08-30 03:36:48,529 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408528625.json
2025-08-30 03:36:48,530 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408529558.json
2025-08-30 03:36:48,531 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408530603.json
2025-08-30 03:36:48,544 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408539959.json
2025-08-30 03:36:48,546 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408545418.json
2025-08-30 03:36:48,547 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408546292.json
2025-08-30 03:36:48,547 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408547273.json
2025-08-30 03:36:48,549 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408548142.json
2025-08-30 03:36:48,552 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408549265.json
2025-08-30 03:36:48,564 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408553684.json
2025-08-30 03:36:48,566 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408565496.json
2025-08-30 03:36:48,567 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408567033.json
2025-08-30 03:36:48,568 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408567967.json
2025-08-30 03:36:48,570 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539408569131.json
2025-08-30 03:36:48,601 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:49,040 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:49,566 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:49,566 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:50,088 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:51,043 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:51,138 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:51,531 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:51,544 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3736cfe4-aa93-9875-84cb-0e1ad4ed38e9"}, traceId: 2150460e17565393815554991e7a3f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13076
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13076
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"78db1ff4-c688-9b78-9402-32e5450ca990"}, traceId: 2150416317565393825762381e14f0'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c724a7c5-62d2-9456-b78a-34ea9ae11977"}, traceId: 2150419d17565393840844453e2d95'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"71b5e678-0776-9c9b-b6ab-785da288fd16"}, traceId: 2150419d17565393862744461e2d95'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e90a9be5-3d3b-987d-a4c0-8491a9a81de2"}, traceId: 213e06b617565393867873835e801f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13319
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13319
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ea8db01d-25ce-950e-9e39-177fa96fdec0"}, traceId: 215045b817565393878481552e804d'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d231c4bf-764a-929c-ad21-8be849a985a4"}, traceId: 2150419d17565393883054469e2d95'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44564d74-51e0-9966-992c-9beead522e85"}, traceId: 215045b817565393893091555e804d'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5fc6d644-374d-9f73-8c40-918549f41f71"}, traceId: 2150419d17565393903454483e2d95'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader json

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"479d365f-9d9e-9e97-9b61-50eb537d6886"}, traceId: 215045b817565393934671584e804d'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"db25c5b2-b9f4-9912-8fa5-1e067522d795"}, traceId: 215045b817565393950201590e804d'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0d583280-b92f-982b-b1da-6072118c8396"}, traceId: 2150419d17565393955604508e2d95'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)2025-08-30 03:36:51,544 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:51,555 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:51,578 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:51,578 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:51,578 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:52,065 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:52,090 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:52,341 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:53,116 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:53,654 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:53,759 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:54,188 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:54,631 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:55,114 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:55,133 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:36:55,406 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:55,621 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:55,632 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:56,792 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:36:57,205 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:57,737 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:57,955 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:58,521 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:59,003 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:59,003 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:36:59,020 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:36:59,020 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:36:59,056 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:36:59,056 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:36:59,056 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:36:59,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:36:59,758 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419758430.json
2025-08-30 03:36:59,759 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419759070.json
2025-08-30 03:36:59,759 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419759420.json
2025-08-30 03:36:59,759 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419759708.json
2025-08-30 03:36:59,760 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419759954.json
2025-08-30 03:36:59,760 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419760229.json
2025-08-30 03:36:59,760 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419760467.json
2025-08-30 03:36:59,760 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419760687.json
2025-08-30 03:36:59,761 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419760903.json
2025-08-30 03:36:59,761 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419761150.json
2025-08-30 03:36:59,761 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419761384.json
2025-08-30 03:36:59,761 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419761603.json
2025-08-30 03:36:59,762 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419761844.json
2025-08-30 03:36:59,762 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419762300.json
2025-08-30 03:36:59,763 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419762893.json
2025-08-30 03:36:59,763 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419763257.json
2025-08-30 03:36:59,764 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419763557.json
2025-08-30 03:36:59,764 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419764078.json
2025-08-30 03:36:59,764 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419764359.json
2025-08-30 03:36:59,764 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539419764570.json
2025-08-30 03:36:59,826 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:00,062 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:00,629 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4892
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4892
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b51e7a20-517a-9f4f-a7c7-41725d624123"}, traceId: 2150413117565393845551621ee911'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d3da3791-3622-9723-bf2d-ed93015f7bbe"}, traceId: 215041de17565393851931165e363e'}
[RETRY] 400 error detected, waiting 2.8s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5461ecab-e342-95fd-8203-a3af9697fe7f"}, traceId: 213e06b617565393885372442e80c4'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e5f23001-e96f-9138-9f74-9c9381e8cdb2"}, traceId: 215041de17565393888031193e363e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3204a1db-1192-9cf6-a6d8-22cdf881257e"}, traceId: 213e06c017565393903247244e7fd7'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bf72388-ae7f-9056-9486-0285c0ef51be"}, traceId: 215045b017565393910461690e8446'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6fcaa69-6fd9-9dc5-bc46-26a567665d50"}, traceId: 2150415b17565393921204250ee3ef'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4402
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4402
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f9a1252b-9ae9-961d-b94f-98650b0c0025"}, traceId: 215045b017565393945121699e8446'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"64ff280a-22a3-91b8-b0ed-b31e0e504f90"}, traceId: 215041e117565393955688642e3565'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6864fce-11c3-99a0-9e77-5376023e425a"}, traceId: 215045b017565393960851703e8446'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"472647cf-9c48-9242-9a8c-d060e81eb1a4"}, traceId: 213e006b17565393980061601eeb85'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ad387b5-b13d-9366-98cd-16e026f72556"}, traceId: 215045b017565393980331712e8446'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"29dcc900-faf2-9b43-a0b4-96be4cb17fdc"}, traceId: 213e06c017565394008203428e8046'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d479d6cf-8da4-9be8-ae2c-e96fdc2740db"}, traceId: 215045b017565394021221729e8446'}2025-08-30 03:37:00,643 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:00,644 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:00,676 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:00,677 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:00,677 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:00,995 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:01,101 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca844384-ca4d-9a5b-9f1b-11146039ecb6"}, traceId: 2150417517565393898285075edf76'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.6
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4839
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4839
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"907ebb05-56d4-98c2-a2ce-7ab639d53f3a"}, traceId: 2150417517565393915965088edf76'}
[RETRY] 400 error detected, waiting 2.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a79285f2-91a2-9e24-8dca-7aff6844dda5"}, traceId: 2150421317565393945264418e3778'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"08f7da92-324f-9613-b922-96fca399f3bc"}, traceId: 2150417517565393950295100edf76'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"979afd60-192c-9be1-9f12-3177bcff3e47"}, traceId: 215040aa17565393961163835ee769'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2945215a-1301-942f-a2db-930693ab1791"}, traceId: 2150457a17565393963273484e0d6d'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5082
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5082
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d41cdc74-729b-921a-bfef-4fde22182f6f"}, traceId: 215040aa17565393975203837ee769'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"911dd44e-5966-9fe8-897a-33ed9da5f81a"}, traceId: 2150456617565393980534157e7f90'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ec49464-076f-9fac-8a3e-aec531acc317"}, traceId: 215040aa17565393993213843ee769'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a1d1b53-c244-9e51-b845-d34c30b4acbe"}, traceId: 213e065017565393998587507e80ba'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b18c0ba-bdf8-9ed4-9994-4f220f750ebf"}, traceId: 215040aa17565394026153858ee769'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8e91c7df-4c09-9a35-8bf6-13ca539781d8"}, traceId: 213e060c17565394031494042e8795'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.62
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4839
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4839
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"59cc4e63-954f-9b04-86fa-1afa747b0dd0"}, traceId: 215041d717565394057193922e361a'}2025-08-30 03:37:01,118 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:01,118 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:01,145 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:01,145 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:01,145 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:01,623 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:01,623 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:02,149 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:02,193 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:02,305 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:03,720 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:03,902 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:04,246 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:04,246 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:04,928 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:05,309 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:05,435 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:05,454 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:05,455 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:05,481 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:05,481 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:05,481 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:05,962 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:06,343 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:06,552 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:06,992 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:07,031 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:07,653 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:07,947 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:07,963 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:07,963 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:07,988 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:07,988 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:07,988 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:08,441 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:08,441 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:08,818 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_call_format_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12749
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12749
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bdd7d9dd-6825-9001-abf8-06c171ae9240"}, traceId: 213e006c17565393976622892e1360'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9c7715de-4fbd-97f3-a731-09b12a3a9d37"}, traceId: 215045b817565393980301602e804d'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"993a7534-c229-9546-b78a-8ccdaeae702a"}, traceId: 215045b817565393998301609e804d'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e52722e-a4d8-9901-b46f-e7be882d6f22"}, traceId: 213e063817565394005865101e7f51'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"43470f8b-b180-9c49-87f6-5cb4b74b7473"}, traceId: 215045b817565394015981615e804d'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"54e294b8-8262-9a6d-9840-337c84575461"}, traceId: 213e065417565394031342384e812b'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.62
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5b1da3ca-2091-9068-9f50-c7216b49d020"}, traceId: 215045b817565394041791622e804d'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"abaa701b-0145-9235-9fef-f51a4f837d40"}, traceId: 213e060a17565394052048632e8a22'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a5ac578-d802-9687-98ab-6f530324cb3a"}, traceId: 215045b817565394067031642e804d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12949
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12949
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6eff3ab4-1b90-9fbf-878f-9631c0a80485"}, traceId: 2150417917565394077403944eeef1'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"03e0562f-c8c6-9633-bee6-e752786ce810"}, traceId: 2150454117565394077877561e7772'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f875f13e-a330-9477-a5f8-9b21e9d735b4"}, traceId: 2150454117565394092497569e7772'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"222210e9-5ca3-989f-af25-f5b44947fbca"}, traceId: 215045c117565394112951743e7fe9'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)2025-08-30 03:37:08,976 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:09,180 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:10,013 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:10,537 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:11,062 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:11,137 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:11,585 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:11,598 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:11,598 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:11,622 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:11,622 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:11,622 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:12,504 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:12,535 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:12,545 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:13,045 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:13,055 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:13,056 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:13,064 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:13,080 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:13,080 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:13,080 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:13,158 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:13,803 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:14,430 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:14,731 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:14,731 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4568
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4568
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7bd4eec-534c-9344-bfaa-3751de5a4143"}, traceId: 213e06c817565394036591310e80cc'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7cf92eea-78d8-98b3-afdd-2d9078f99fb4"}, traceId: 215045b017565394056991734e8446'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"19c5c8ad-7666-9c0a-a4df-01e80d1238a9"}, traceId: 2150455f17565394064488240e7f79'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c923f7cf-baa9-9af1-a236-138c9b9d13af"}, traceId: 215045ee17565394074227729e77d8'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"dfed255d-9185-91b9-b72c-e80616ee3818"}, traceId: 213e007017565394074653737ee96a'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/30 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13706
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13706
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"65bee26a-ba11-91a8-a2c6-612f3c36d3ef"}, traceId: 2150421317565394087594471e3778'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c69b29af-07f5-9256-9f4b-b87b71588092"}, traceId: 215045ee17565394092577738e77d8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68880033-ecb8-9fd8-b5f6-2e5f0b615372"}, traceId: 213e065417565394107977303e8066'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d2250f0f-8779-9e38-8e47-299ef6a410e2"}, traceId: 215045ee17565394112737751e77d8'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"85475879-8300-9e84-b778-bd6532dfeab5"}, traceId: 215045ee17565394138927764e77d8'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a76298ad-2ba3-99e5-87a5-452ae96a00af"}, traceId: 2150416317565394148598693e14ae'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13772
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13772
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c98c5cc1-861a-9f1a-812d-5b9efbbf165e"}, traceId: 2150416017565394203601304ef041'}2025-08-30 03:37:15,112 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:15,802 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:15,989 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:16,805 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:16,805 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:16,805 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:17,204 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:17,220 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:17,232 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:17,233 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:17,264 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:17,264 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:17,264 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:18,164 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:18,770 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b57d48c8-9273-9dc2-80d3-e131de6d81d8"}, traceId: 2150452b17565394069146402e7768'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a75d311e-e668-992e-b28f-a659de8f0252"}, traceId: 215040aa17565394072063928ee769'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"74b44757-0c27-9e20-991d-409426de748c"}, traceId: 2150452b17565394082356410e7768'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"76cf8a71-a33d-96b6-8754-97c69ffcf01f"}, traceId: 215044eb17565394083325127e815e'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ed01214-2632-946c-b983-cb5eeef17a7b"}, traceId: 215044eb17565394097525131e815e'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"49b2b9f0-379e-90fc-82b1-9e79ae22f3b8"}, traceId: 2150452b17565394118076428e7768'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5111
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5111
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a455cf9c-5e5f-96e2-9f89-6b42300b5f52"}, traceId: 215044eb17565394128475140e815e'}
[RETRY] 400 error detected, waiting 2.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7aac30f8-4bf2-90ec-84cc-ad01d9a06ec2"}, traceId: 2150452b17565394133796430e7768'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2f35e5c7-3f0f-9ce7-80ad-3782a7fee5ea"}, traceId: 2150452b17565394153486437e7768'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f96bdde2-aa6e-9ceb-9127-a127db885d68"}, traceId: 215044eb17565394169375156e815e'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb733a3e-8e44-92b9-bcbd-adbcf5e8b504"}, traceId: 2150452b17565394182326453e7768'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b0338294-875a-97d8-ac2c-99d0490c383f"}, traceId: 215044eb17565394187335163e815e'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5034
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5034
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b603ae9b-b9cc-906b-8a18-bedd16599017"}, traceId: 2150452b17565394208106463e7768'}2025-08-30 03:37:18,782 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:18,782 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:18,790 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:18,808 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:18,808 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:18,808 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:19,212 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:19,235 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:19,424 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:19,713 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:20,473 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:20,733 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:20,733 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:21,110 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:21,297 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:21,747 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:21,764 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:21,764 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:21,789 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:21,789 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:21,789 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:22,715 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:22,767 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:22,838 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:23,425 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:23,926 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:23,981 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:24,857 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:24,932 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:25,376 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:25,386 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:25,585 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:25,599 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:25,599 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:25,624 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:25,624 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:25,624 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:25,900 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:26,433 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:26,646 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:26,854 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:26,863 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446861903.json
2025-08-30 03:37:26,864 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446863611.json
2025-08-30 03:37:26,867 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446865116.json
2025-08-30 03:37:26,868 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446867931.json
2025-08-30 03:37:26,868 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446868506.json
2025-08-30 03:37:26,869 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446869107.json
2025-08-30 03:37:26,869 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446869509.json
2025-08-30 03:37:26,870 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446869827.json
2025-08-30 03:37:26,870 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446870164.json
2025-08-30 03:37:26,870 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446870430.json
2025-08-30 03:37:26,870 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446870657.json
2025-08-30 03:37:26,871 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446870865.json
2025-08-30 03:37:26,871 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446871049.json
2025-08-30 03:37:26,871 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446871255.json
2025-08-30 03:37:26,871 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446871530.json
2025-08-30 03:37:26,872 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446871769.json
2025-08-30 03:37:26,877 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446872042.json
2025-08-30 03:37:26,877 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446877394.json
2025-08-30 03:37:26,877 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446877659.json
2025-08-30 03:37:26,878 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539446877913.json

[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e080cd29-7bbb-9186-927e-0349b2f0b668"}, traceId: 2150454117565394117977592e7772'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc1a0cfa-70e5-9d8d-9d9c-a226a07ca385"}, traceId: 2150459f17565394143333919e828e'}
[RETRY] 400 error detected, waiting 0.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"82fcfe31-3291-935a-842d-34606b65bfc4"}, traceId: 2150454117565394148337608e7772'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12749
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12749
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22e1eebf-53a1-9948-905c-37212c17c039"}, traceId: 2150459f17565394153523925e828e'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf193faf-60ee-9759-8dd3-ccb75b9dc033"}, traceId: 2150459f17565394174563933e828e'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0c14b507-41e9-94d2-9edf-7cacbe68ae1f"}, traceId: 2150454117565394187217627e7772'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9363010e-c1ee-9074-9d78-7e90dfabf273"}, traceId: 2150459f17565394197613938e828e'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9002d935-1f1d-971d-85ba-b4de3c728512"}, traceId: 2150415d17565394213205735e1417'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"144f18c8-a1b1-93c6-948e-47ca475fbe77"}, traceId: 215045b817565394236586247e808f'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"44bbe671-6314-9595-99a2-5ade1230f2f4"}, traceId: 2150459f17565394251653953e828e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fc868de3-d4ac-9735-abe1-44baceebffac"}, traceId: 2150449017565394262714552e82a8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"692881ab-d2b4-95a2-b086-8d0c44860a44"}, traceId: 2150436817565394267468201e1e84'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"69dc493c-6888-9a9b-975f-0a0db8f7a0e1"}, traceId: 2150449017565394281914565e82a8'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 50662025-08-30 03:37:27,167 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:27,711 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:27,816 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:28,863 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:28,863 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:29,028 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:29,040 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:29,794 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:29,806 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:29,911 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:30,985 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:31,363 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:31,625 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:31,639 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:31,640 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:31,671 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:31,672 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:31,672 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:31,891 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:31,895 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:31,911 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"348a3de3-17cb-9338-a45a-1bdabb121b3a"}, traceId: 2150438d17565394207426978e2b30'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e15fa8ee-e905-9111-bac9-9f049d91f578"}, traceId: 2150419d17565394218316097e2b41'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d6287eec-dfc6-9da2-bc26-ec7f5bc10bf3"}, traceId: 215040cc17565394219142670ed4de'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88e1f00b-d72a-9775-87e2-5f0be32dd8b2"}, traceId: 215040cc17565394234212673ed4de'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6d30ba38-a784-954c-b289-d21aad55c6d5"}, traceId: 2150417717565394239401006edab4'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4482
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4482
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3d9463e6-184b-9f82-96c0-8af8205e71be"}, traceId: 215040cc17565394256742681ed4de'}
[RETRY] 400 error detected, waiting 2.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3f2bdeb7-8f62-9c25-a244-c08f015b5efb"}, traceId: 215042f917565394282091546e1d04'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"079a7dbe-f0c8-9688-b533-5d9febce3430"}, traceId: 215040cc17565394287102694ed4de'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"87bca295-82f6-9d87-b7fc-d6603742f572"}, traceId: 215040cc17565394312402703ed4de'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6eb9f071-4a2a-99c4-a88a-9a464c925f43"}, traceId: 2150436a17565394327962633e213e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c26fbc4d-deb4-9a12-a3fb-51bb1efff19b"}, traceId: 215045b717565394328823685e821a'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"514ac099-9571-9b66-860d-6314a48b59b7"}, traceId: 213e066417565394335465611e81ae'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0ce03314-b254-9849-a270-ec8e9857e89b"}, traceId: 215045b717565394344203690e821a'}2025-08-30 03:37:32,956 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:32,968 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:32,969 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:32,995 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:32,995 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:32,995 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:33,056 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:33,381 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:33,890 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:34,132 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:34,925 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:35,048 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:35,338 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:35,460 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:35,976 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:36,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e7a362b-7745-90bb-b98f-f63f509c70f2"}, traceId: 215044eb17565394213065178e815e'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bf89f613-8a18-9f08-9c03-bb69c67b987f"}, traceId: 2150416717565394220628392eee15'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a39bcba-ac55-9a07-b702-a70513075d82"}, traceId: 215040cc17565394239351074ed45a'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8efe2a87-f4ec-9d74-b5ce-38aa81436c62"}, traceId: 215044eb17565394246535204e815e'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.8
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13528
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13528
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"977505d3-e3f6-9fcf-ba31-d6096bb6625c"}, traceId: 2150455217565394274172577e8358'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"002cb996-fec8-9a86-93a9-93c4fa71ecc7"}, traceId: 215044eb17565394276855217e815e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3612f851-43e4-9058-99f0-7cec5d2cc12b"}, traceId: 2150415b17565394288917484ee432'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c693359f-be24-974b-83fc-f8745367f730"}, traceId: 2150458717565394296786988e8035'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2a133712-c646-9ffe-af26-3e0655722748"}, traceId: 2150415b17565394307397495ee432'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"416c95ea-b425-9699-b46d-b45a115063b6"}, traceId: 215041a817565394322718838e3542'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6ebc4b6-50cc-9bd4-9c38-ba40595feeff"}, traceId: 2150415b17565394322537503ee432'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e6371016-b5db-90d8-a392-c9cd3a185670"}, traceId: 213e007017565394344403189ee79b'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13547
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13547
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c55f69b6-7320-9692-9271-5435a0e669de"}, traceId: 2150415b17565394364497517ee432'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4ab4c71-38cc-97cf-bc3f-815d0913c2ee"}, traceId: 213e006d17565394385343753e1172'}2025-08-30 03:37:36,483 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:36,504 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:36,577 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:37,811 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:37,873 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:38,301 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:38,303 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:38,313 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:38,313 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:38,338 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:38,340 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:38,340 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:38,341 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:38,893 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:39,393 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:39,446 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:39,998 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:40,180 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:40,663 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:41,214 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:41,225 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:41,226 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:41,272 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:41,272 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:41,272 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:41,706 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:41,713 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:42,277 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:42,739 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:42,778 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:42,790 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:43,241 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:43,751 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:43,823 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:44,325 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:44,692 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:44,757 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:44,783 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:44,807 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:45,292 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:45,293 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:45,796 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:45,801 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:45,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5066
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77ab38ef-91d1-9b83-968a-0d03f72158bf"}, traceId: 2150449017565394302274577e82a8'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0f92028b-9549-9c66-8caa-7773127b36a9"}, traceId: 215041de17565394322731879e3516'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7dc8cb7-353f-98dc-88c8-d3af3f469a66"}, traceId: 2150449017565394327744595e82a8'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0768330e-c2e6-940b-9c0f-8f1f3b10e18b"}, traceId: 213e069217565394341665707e80c7'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c976190c-5e33-9adf-a316-bbd8ff934c72"}, traceId: 213e006a17565394364608276ee153'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"318f5b9a-09d4-9c26-9a23-800c0e3bfd8e"}, traceId: 2150449017565394369444615e82a8'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12827
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12827
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c1e71e1-b73c-9618-81c6-4b0acde455fd"}, traceId: 215044fd17565394391882080e804f'}
[RETRY] 400 error detected, waiting 4.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d656d5d-dd55-98c0-989f-fb1e3b34dd73"}, traceId: 2150459f17565394394433076e7f14'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98b0481d-6101-94ed-b089-2b27482d1e87"}, traceId: 2150459f17565394404663079e7f14'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"257f906d-6162-9f02-971c-66fddbf0934f"}, traceId: 2150459f17565394445823098e7f14'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5d7fd535-36b3-9c28-81e5-71efbfa56e8e"}, traceId: 2150449a17565394453487222e8107'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"63a74747-c7ea-9fc3-851a-1cd1e6a79661"}, traceId: 2150459f17565394460963104e7f14'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
💾 智能Checkpoint: 保存20个结果...
   触发原因: 数量=20, 时间=0.0s, 强制=False
✅ Checkpoint完成: 成功保存 20/20 个结果
Progress: 20/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4349
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True2025-08-30 03:37:46,803 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:46,807 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:46,824 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:46,824 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:46,851 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:46,851 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:46,851 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:46,919 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:37:47,289 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:47,312 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:47,619 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:47,738 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:47,797 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:48,530 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:48,981 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:48,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:49,963 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:50,053 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5111
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5111
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eadc2fbf-3cb2-99ca-a469-344e9420d4d7"}, traceId: 213e043b17565394364664533e2451'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"73622420-0934-955d-80af-ee4bd9b248b7"}, traceId: 215045b717565394369423699e821a'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b6078dc4-80de-96a4-97ac-d6861c62c2f5"}, traceId: 213e06a017565394385375304e7762'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a2e8bc2-1f0c-9beb-8bc2-9ff039a4a112"}, traceId: 215045b717565394389323723e821a'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13528
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13528
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"22987b78-a96a-9b13-8cab-8f3fa7e4ce55"}, traceId: 215045b717565394414753730e821a'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c54bdc2c-bcdf-937f-a511-8f94684b3852"}, traceId: 215045af17565394424571827e8130'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"46866330-b47b-955d-9695-22424ec87b56"}, traceId: 2150460817565394431264484e798c'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"498dfb82-24f5-9dfc-b34d-32cf8eb9e4ca"}, traceId: 2150460817565394450964495e798c'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6506eb3-2e68-9a63-b6a6-5fa61e014c65"}, traceId: 215040be17565394463995133ee191'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4876
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4876
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"07ec9784-a508-9817-9b1f-986117bce394"}, traceId: 2150460817565394495364519e798c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ca742323-cd20-9c5e-b0a5-2788e1f361fd"}, traceId: 213e006a17565394513585260ee04b'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fec42008-0068-9463-a1bb-ef99b24e40ac"}, traceId: 2150460817565394516334522e798c'}2025-08-30 03:37:50,556 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:51,039 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:51,513 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:51,548 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:52,336 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:52,573 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:53,635 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:53,708 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:53,932 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:55,502 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:55,521 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:55,521 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:55,596 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:55,596 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:55,596 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:55,974 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:37:55,981 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:37:56,523 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:56,540 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"532528ff-6c2f-92f1-9d98-fd3c33599a47"}, traceId: 215042ae17565394400911655e90e0'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4ac8e3d-9e8e-934c-a36c-43cee26fee40"}, traceId: 2150415b17565394409797534ee432'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a3542af7-dd9b-91e3-80f0-b8f581301c52"}, traceId: 2150415b17565394424907539ee432'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"bc7fc873-4b55-9529-a763-a1f5d5490a54"}, traceId: 2150415b17565394450887549ee432'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4043bc6-e3f3-988d-bc1d-02e9cbbaa8d5"}, traceId: 215042ae17565394455921694e90e0'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"552c1cfc-6b0d-9825-baa8-b0564e9d3ab1"}, traceId: 2150415b17565394474337562ee432'}
[RETRY] 400 error detected, waiting 4.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13417
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13417
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4a3b22f3-6870-93b6-bfab-c0e4cace7389"}, traceId: 215042ae17565394495241716e90e0'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f3736bd-0f41-9712-ac4a-7a8dddcdc04a"}, traceId: 215042ae17565394510971729e90e0'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0fd6d60d-7994-9da5-a7e1-872c69553540"}, traceId: 2150415b17565394526767578ee432'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"39206ccb-abda-96c0-87de-fb579b027310"}, traceId: 215042ae17565394531051745e90e0'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e596d2fd-ed99-919c-a9ed-123275416bb6"}, traceId: 213e007a17565394538818262ee440'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f8ffe29-17ff-9b23-a704-5f44011c31cc"}, traceId: 213e007917565394557257754ee972'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13457
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=134572025-08-30 03:37:56,541 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:56,574 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:56,574 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:56,574 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:56,658 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:56,675 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:56,675 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:56,700 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:56,700 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:56,700 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:57,065 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:57,175 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:57,699 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:57,803 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:58,111 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:58,124 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:37:58,124 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:37:58,151 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:37:58,151 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:37:58,151 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:37:58,750 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:58,854 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:59,153 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:59,167 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:37:59,368 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:37:59,569 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:00,086 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:00,750 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:01,142 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:01,634 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:01,647 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:01,892 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:03,990 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:03,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:03,991 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

  - ai_classifier=True
  - txt_content_len=4349
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"69c02fdd-60aa-9492-92c4-50cc87168340"}, traceId: 2150409517565394469221645eeb9f'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aea71308-5e53-9a30-8976-413256569420"}, traceId: 2150457917565394487448947e8a60'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8d5e820-4c14-9024-b0c6-c07821b131aa"}, traceId: 2150449a17565394516523255e8200'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e2fc77bf-23f1-9fc0-850c-7016c8748a02"}, traceId: 2150459f17565394516253131e7f14'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6ad1d342-a905-9721-922e-6434d89a432e"}, traceId: 2150459f17565394536173136e7f14'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"537789e8-94af-9162-af7f-2e0f6b597864"}, traceId: 215045b717565394551023415e8154'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7493025-6889-945b-b327-d68c8b9bb0e2"}, traceId: 2150459f17565394562123144e7f14'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12611
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12611
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b6da038b-77d2-92f6-ad6f-6926c00e783d"}, traceId: 2150457917565394580022936e8aa2'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ad67af62-b2ec-956f-a677-a0066941e6b5"}, traceId: 2150459f17565394580243154e7f14'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"df2cf9d7-1382-965e-85e6-2597938ff3b9"}, traceId: 2150455217565394591885276e80a3'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ccbd0a89-8630-9aa7-bb6b-073cece23cc8"}, traceId: 2150455217565394614415288e80a3'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 6/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"01dd95fb-1b7f-9c26-a94a-09aa626d99d9"}, traceId: 2150459f17565394634833173e7f14'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5d26b1c8-dcca-9101-9e94-595e9da8fdb6"}, traceId: 2150455217565394650125373e80a3'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d71413b-c1c9-99c2-8a69-4a7d77049e60"}, traceId: 2150459f17565394655123183e7f14'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.66
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类2025-08-30 03:38:04,175 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:04,514 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:05,564 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:05,661 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:06,894 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:06,908 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:06,910 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:06,934 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:06,934 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:06,934 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:07,137 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:08,076 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:08,184 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:08,446 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:08,458 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:08,460 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:08,489 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:08,489 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:08,489 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:08,952 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:08,962 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:08,962 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:08,984 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:08,984 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:08,984 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:09,480 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:09,933 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:09,943 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3faf56ca-4b1f-9add-a4cc-bb6f96b97e20"}, traceId: 215042ae17565394562061760e90e0'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ae13521a-42dc-9df2-baca-d1c9134631a1"}, traceId: 2150430917565394604386718e1ca7'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"734684a7-adb0-93bc-8206-d1e20e8ef672"}, traceId: 215042ae17565394609241792e90e0'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"57bc1e1f-dfe4-9e60-a8c1-e904757e253a"}, traceId: 215040cc17565394620074779ed6ac'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"b992311a-faf1-966c-84ed-b577c45c9578"}, traceId: 2150416a17565394629987389ee040'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13949
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13949
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cb53547d-df48-9456-bda3-ff720ad33fc4"}, traceId: 215040cc17565394645222904ed4de'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
  [SEARCH] Query: network api fetch

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"021a008e-1d23-9a17-81c4-854fcf3e705a"}, traceId: 2150459f17565394673688539e7ed2'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d1c626d-96bb-9c29-9e65-2eef73cc27f6"}, traceId: 215040cc17565394675314800ed6ac'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4157b931-6af1-932e-8493-1cab14b769ae"}, traceId: 215040cc17565394687224809ed6ac'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe37d4cd-513e-999b-9ee3-93a1a5214d68"}, traceId: 215041d717565394712756778e3554'}
[RETRY] 400 error detected, waiting 4.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"00bf54b8-8487-9de4-a01d-89d7ce2ede31"}, traceId: 215040cc17565394712634815ed6ac'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9b6e805e-a3c9-9528-b065-bd90db45f8b3"}, traceId: 215040cc17565394733564827ed6ac'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.68
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8981ac89-4b8d-9357-954a-ae5629bc9682"}, traceId: 213e066d17565394762828755e7fbd'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13627
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13627
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct2025-08-30 03:38:09,944 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:09,970 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:09,970 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:09,970 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:10,169 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:10,499 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:11,041 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:11,606 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:12,093 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:12,159 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:12,467 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:12,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:13,275 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 200 "
2025-08-30 03:38:13,663 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:14,148 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:14,154 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:15,561 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:16,061 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:16,114 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:17,316 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:18,165 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:19,755 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:19,881 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:20,088 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:20,104 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct

[AI_DEBUG] 生成的txt_content长度: 4482
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4482
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"013270cf-1a46-9d2d-8581-4f5cc312a483"}, traceId: 2150455217565394665295408e80a3'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e3bb1aac-ca8d-9d8c-bd9b-f8a11e7bc029"}, traceId: 2150459f17565394670223188e7f14'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"483f0bae-6e98-98c5-9a8e-73fc6ab67c84"}, traceId: 2150455217565394682315433e80a3'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7f44981f-792b-9325-943e-8166edb36185"}, traceId: 2150455217565394702665460e80a3'}
[RETRY] 400 error detected, waiting 4.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a02d7c2a-db55-9b69-8b8c-0a0c5f957273"}, traceId: 2150459f17565394707643198e7f14'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.68
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"025a4d38-26da-905b-9615-e9060dbd0b2b"}, traceId: 2150459f17565394752213221e7f14'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 14188
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=14188
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"548db162-616e-98a4-8938-d98f8b8bd495"}, traceId: 2150436a17565394763931089e2435'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c0214edb-298d-99ce-bc65-b4dca5778f0e"}, traceId: 2150411617565394768475642ee722'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d97accbc-c764-967a-a2d7-f6680c66c75b"}, traceId: 213e006f17565394775602307ee4dd'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3fd8d664-f0b5-95c3-a235-3457754d24a1"}, traceId: 2150411617565394788855654ee722'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d56a7a51-2bc0-9492-9121-3437f41d00f5"}, traceId: 213e066e17565394793354678e8112'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a6347213-90b0-9b27-b8f1-8e4557cad86c"}, traceId: 2150411617565394808785668ee722'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"68169333-cdb5-9ac6-bbec-1602b71f853c"}, traceId: 215045be17565394814003318e7f8a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5a2166c6-85bf-9d81-8eef-df8f9c084197"}, traceId: 2150460e17565394837297680e7958'}
[RETRY] 400 error detected, waiting 3.9s before retry (not counting as turn)...2025-08-30 03:38:20,104 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:20,131 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:20,131 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:20,131 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:20,467 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:20,472 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500470872.json
2025-08-30 03:38:20,473 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500472896.json
2025-08-30 03:38:20,473 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500473418.json
2025-08-30 03:38:20,474 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500474081.json
2025-08-30 03:38:20,474 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500474439.json
2025-08-30 03:38:20,475 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500474788.json
2025-08-30 03:38:20,475 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500475144.json
2025-08-30 03:38:20,475 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500475500.json
2025-08-30 03:38:20,476 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500475944.json
2025-08-30 03:38:20,476 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500476334.json
2025-08-30 03:38:20,476 - batch_test_runner - INFO - Batch writing 30 records to database (qwen2.5-72b-instruct:30)
2025-08-30 03:38:20,478 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 30 个结果到收集器: qwen2.5-72b-instruct_62491_1756539500477037.json
2025-08-30 03:38:20,478 - batch_test_runner - INFO - Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
2025-08-30 03:38:20,522 - batch_test_runner - INFO - Database saved successfully
2025-08-30 03:38:20,522 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 03:38:20,522 - batch_test_runner - INFO - ============================================================
2025-08-30 03:38:20,522 - batch_test_runner - INFO - Batch test completed at 2025-08-30T03:38:20.522356
2025-08-30 03:38:20,522 - batch_test_runner - INFO - Summary:
2025-08-30 03:38:20,522 - batch_test_runner - INFO -   - Total tests: 30
2025-08-30 03:38:20,522 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 03:38:20,522 - batch_test_runner - INFO -   - Failed: 30
2025-08-30 03:38:20,522 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 03:38:20,522 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_033321.log
2025-08-30 03:38:20,522 - batch_test_runner - INFO - ============================================================
2025-08-30 03:38:20,522 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 03:38:20,522 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 03:38:20,523 - result_merger - INFO - 发现71个新的结果文件
2025-08-30 03:38:20,531 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:20,546 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:20,547 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:20,549 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:38:20,549 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 03:38:20,581 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:20,581 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:20,581 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:21,052 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:21,512 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:21,604 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:21,628 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:21,629 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:21,653 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:21,654 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:21,654 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:21,816 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:22,760 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:23,977 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:38:23,981 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:24,054 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:24,524 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:25,047 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:25,059 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:25,059 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:25,084 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:25,084 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:25,084 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:25,104 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ec69dcba-b53d-933a-9544-d338f660e354"}, traceId: 215041a817565394773765884e3607'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6ef4740a-840d-9d5e-86a3-47a8ddcbb463"}, traceId: 215040cc17565394778334843ed6ac'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e021b61f-f66a-9fe4-8287-e3e8421c3768"}, traceId: 213e006e17565394786195044e1690'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3cdf3501-709a-9da8-be4a-8d643b7b7484"}, traceId: 215041a817565394788895889e3607'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f6075c14-4ba2-9cad-ab19-4d69e7b59685"}, traceId: 215045c117565394798431011e802b'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1c2df93e-2e68-9812-8114-b49d1b1d658b"}, traceId: 215041a817565394804595896e3607'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"6bf3c0e3-b9ec-96a1-961a-4bfeb9a6cc6c"}, traceId: 213e006d17565394816422502e14ac'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e1ed679d-eb18-9778-bd45-90c1faeb7d74"}, traceId: 215041a817565394837085912e3607'}
[RETRY] 400 error detected, waiting 2.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13856
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13856
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1d9709e6-9533-982d-88d3-acea36e4e65e"}, traceId: 213e064717565394854131468e88f7'}
[RETRY] 400 error detected, waiting 3.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0286bcfb-91ab-93c3-b081-98c38c581b40"}, traceId: 215041a817565394866315926e3607'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4323e935-f014-9565-a152-3bfc54bfc880"}, traceId: 2150458117565394878018687e800f'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"55c4ee2b-e42f-9df6-95d3-11566fa31b9f"}, traceId: 2150458117565394891688696e800f'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0e7bbd05-cbf5-95f2-8b3d-7d5a237b454c"}, traceId: 2150449017565394896932138e7f2d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct2025-08-30 03:38:26,054 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:26,204 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:26,568 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:27,071 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:27,129 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:27,130 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error with no tool executions or observable agent decisions; cannot identify a specific agent decision error (no evidence of incorrect tool choice,
2025-08-30 03:38:27,427 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:27,941 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:28,397 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:29,156 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:29,570 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:30,730 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:31,886 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:32,523 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:32,524 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown system-level failure prevented any tool usage or agent decision. No tool_selection/parameter_config/sequence/dependency decisions could be evaluate
2025-08-30 03:38:33,035 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:34,204 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:34,551 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:34,568 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:34,569 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:34,595 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:34,595 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:34,595 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:34,878 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:38:35,303 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:35,717 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:35,791 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"

[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e3dd94cf-6054-9b09-94d2-11481f6dbc00"}, traceId: 2150411617565394842115689ee722'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13601
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13601
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2499e935-b611-998d-aa0a-f7fcf1683edd"}, traceId: 2150417c17565394881813037ef017'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"002ed73d-0df6-96b0-a95d-bb13026e58a5"}, traceId: 2150411617565394886625738ee722'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e7c880f8-e6ee-9009-aec0-e3f1ac550469"}, traceId: 215045f517565394899086257e8220'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8f388cd8-a47e-9fd7-9877-9100fbf589ae"}, traceId: 2150430d17565394902361205e95e1'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5cd4f5dc-fbce-9fb4-91ee-1e6d7be9ab83"}, traceId: 2150430d17565394913281217e95e1'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77772009-f55b-9c57-ac10-a62c3c93809b"}, traceId: 215045f517565394918496269e8220'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.85
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4474
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4474
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"943d6f85-a0cf-9ee6-8493-28814acdc21a"}, traceId: 215045f517565394933836277e8220'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4e6d05f-7f49-93a3-8b2f-689ce6252559"}, traceId: 2150430d17565394938771226e95e1'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"816b65c2-1bde-9d13-8e62-882164938056"}, traceId: 2150430d17565394958011234e95e1'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"633013f4-9987-9a72-99db-d0a118d01e9c"}, traceId: 215045f517565394970136292e8220'}
[RETRY] 400 error detected, waiting 3.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4535
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4535
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ebb92c3f-7921-9d33-bce9-07572f1b5a41"}, traceId: 2150430d17565394997561265e95e1'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct2025-08-30 03:38:36,446 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:36,457 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:36,457 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:36,483 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:36,483 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:36,483 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:36,871 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:37,852 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:37,853 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a misdecision by the agent (no clear tool selection error, parameter config error, sequence order error, or dependency handling iss
2025-08-30 03:38:37,898 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:38,030 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:38,132 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:39,122 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:39,627 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:40,641 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:40,831 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:42,275 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:42,450 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:42,750 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:42,766 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:42,978 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:42,979 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision can be identified. The task shows no required tools and no tool execution trace, so there is insufficient information to attribu
2025-08-30 03:38:43,505 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:44,488 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:44,505 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:44,505 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:44,528 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:44,528 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:44,528 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:45,483 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:46,592 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:47,570 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:47,893 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:48,008 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:48,009 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:48,042 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:48,042 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:48,042 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:48,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:49,673 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:49,831 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:49,894 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"

[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7441598-2964-9534-937c-58b72b2a8d84"}, traceId: 215045c117565394907754848e7f63'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7e858e05-12ee-99c2-9b84-88965122e149"}, traceId: 2150458117565394918328700e800f'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5005
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5005
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"acc19c0c-de5a-99b0-a9ea-04570f30b9d8"}, traceId: 215045c117565394938834861e7f63'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8b1ad9aa-1891-9179-8e92-67f0d7c94a90"}, traceId: 2150458117565394953028717e800f'}
[RETRY] 400 error detected, waiting 4.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"82e0a349-04bf-978e-b7c1-1f5ad7a81a38"}, traceId: 215045c117565394958104870e7f63'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"147d63fb-1bdc-9a30-9ee7-02a3c67fb883"}, traceId: 215045c117565394979084876e7f63'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4789
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4789
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88868ee5-26cf-9e63-b56a-b74b87a0bd40"}, traceId: 2150458117565395002668736e800f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3a94fb07-7874-91bf-9336-40cb8e3d54d4"}, traceId: 215045c117565395007764893e7f63'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77b89d33-7c97-9d35-b020-814b3007bc9e"}, traceId: 213e06b617565395015245002e8126'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"eef40a56-18ae-9573-ad0f-54daa6f25d53"}, traceId: 2150449017565395042773117e7f0b'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8ffb2a2b-753f-9db5-919b-d46f273899e7"}, traceId: 215045c117565395047684905e7f63'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.73
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 48262025-08-30 03:38:50,838 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:52,733 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"46fcd1a9-f877-930d-bb74-d79d54ffccb0"}, traceId: 213e043517565395012606030e2f83'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e55fa94a-29de-9b9a-ac4d-03c1fd80ba19"}, traceId: 215045f517565395012946303e8220'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5038033d-9bc1-9b30-846a-43619a7ac0ff"}, traceId: 2150443817565395024778834e87d6'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"ede04fd0-96e8-9ce3-b11b-6841d39bbbf3"}, traceId: 213e006917565395037427246ee073'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"61b59dd9-5e3c-9611-9ab4-e2934ffacea4"}, traceId: 2150443817565395037478841e87d6'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"acc82f56-8619-9de6-adf4-5ba52d7de752"}, traceId: 215040b917565395063146309ef243'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1871209e-9e00-9fcc-a804-8e833579cc53"}, traceId: 2150443817565395068028862e87d6'}
[RETRY] 400 error detected, waiting 3.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4741
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4741
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"408777b3-b383-95ec-a3f6-eaebb6ba5ceb"}, traceId: 215040aa17565395088901327ee830'}
[RETRY] 400 error detected, waiting 4.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f033a0b5-c4c9-9a05-8979-722a83ba63fe"}, traceId: 2150443817565395104648877e87d6'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5d0f325b-3686-9a6c-82da-b6b49edb6ca8"}, traceId: 2150443817565395142798917e87d6'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.65
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4691
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4691
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d316c043-7654-91b1-acaa-ca9e55242e90"}, traceId: 215041d717565395154471410e346d'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f9b4241a-3f1c-9a76-b6a0-032c49bf6595"}, traceId: 213e007017565395155612409eea30'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...2025-08-30 03:38:53,055 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:38:53,747 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:54,908 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:54,909 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not perform any steps and did not establish a valid execution sequence for a straightforward task; implies a misordering/omission in wor
2025-08-30 03:38:55,186 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:55,525 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:56,141 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:58,584 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:38:58,613 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:38:58,630 - api_client_manager - INFO - Created idealab client for model qwen2.5-72b-instruct
2025-08-30 03:38:58,630 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
2025-08-30 03:38:58,655 - mcp_embedding_manager - INFO - FAISS index loaded
2025-08-30 03:38:58,655 - mcp_embedding_manager - INFO - Updated dimension to 3072
2025-08-30 03:38:58,655 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
2025-08-30 03:38:59,544 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:38:59,544 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tools for the multi_stage_pipeline task; no tool was chosen or executed, effectively omitting required to
2025-08-30 03:38:59,705 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:39:00,867 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:00,871 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540870309.json
2025-08-30 03:39:00,871 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540871120.json
2025-08-30 03:39:00,873 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540871636.json
2025-08-30 03:39:00,876 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540874139.json
2025-08-30 03:39:00,876 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540876342.json
2025-08-30 03:39:00,877 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540876731.json
2025-08-30 03:39:00,878 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540877946.json
2025-08-30 03:39:00,880 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540879005.json
2025-08-30 03:39:00,882 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540880818.json
2025-08-30 03:39:00,886 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540885133.json
2025-08-30 03:39:00,886 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540886199.json
2025-08-30 03:39:00,886 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540886658.json
2025-08-30 03:39:00,887 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540886965.json
2025-08-30 03:39:00,887 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539540887216.json
2025-08-30 03:39:01,102 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:39:01,850 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:39:02,542 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:39:03,400 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:39:03,829 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:04,824 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:39:05,487 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:05,497 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any tool or request clarification to proceed, effectively failing at the initial tool selection step for an unknown task.
2025-08-30 03:39:05,807 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "
2025-08-30 03:39:05,885 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-30 03:39:06,329 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:39:07,452 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:07,453 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62489_1756539547453135.json
2025-08-30 03:39:07,453 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
2025-08-30 03:39:07,457 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 35 个结果到收集器: qwen2.5-72b-instruct_62489_1756539547454360.json
2025-08-30 03:39:07,457 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
2025-08-30 03:39:07,485 - batch_test_runner - INFO - Database saved successfully
2025-08-30 03:39:07,486 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 03:39:07,486 - batch_test_runner - INFO - ============================================================
2025-08-30 03:39:07,486 - batch_test_runner - INFO - Batch test completed at 2025-08-30T03:39:07.486270
2025-08-30 03:39:07,486 - batch_test_runner - INFO - Summary:
2025-08-30 03:39:07,486 - batch_test_runner - INFO -   - Total tests: 35
2025-08-30 03:39:07,486 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 03:39:07,486 - batch_test_runner - INFO -   - Failed: 35
2025-08-30 03:39:07,486 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 03:39:07,486 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_033321.log
2025-08-30 03:39:07,486 - batch_test_runner - INFO - ============================================================
2025-08-30 03:39:07,486 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 03:39:07,486 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 03:39:07,487 - result_merger - INFO - 发现16个新的结果文件
2025-08-30 03:39:07,509 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:39:07,509 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 03:39:07,652 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:39:08,953 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:39:10,001 - httpx - INFO - HTTP Request: POST https://idealab.alibaba-inc.com/api/openai/v1/chat/completions "HTTP/1.1 400 "

[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4058e11f-1e96-9289-abdd-53bb4207a6c4"}, traceId: 215041d717565395165911454e346d'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"faa0ce8e-6eff-95f6-864f-b64d2fccf6e8"}, traceId: 213e059617565395176553800e3db6'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"aaee8a69-0c70-9d2c-8556-97a2f845ed87"}, traceId: 215041d717565395193561503e346d'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"be65cbe0-8b19-99d9-b044-e3ef74ca0c46"}, traceId: 213e006917565395205901506ee0fa'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"c394adb4-ba3c-9359-a042-05cc331c5ad1"}, traceId: 215041d717565395219991511e346d'}
[RETRY] 400 error detected, waiting 1.8s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5111
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5111
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"77e76404-2085-998d-a9c9-35b9947fa3a1"}, traceId: 2150454417565395232636249e81e6'}
[RETRY] 400 error detected, waiting 4.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2d3e3e4c-5be2-90ca-bd5e-dc3a3908d0ce"}, traceId: 215041d717565395242111521e346d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"141f7b72-2fba-9b62-893f-89cfbd9ba6a1"}, traceId: 213e03d917565395252381948e1e66'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d8086017-923f-9660-aad1-127bd4932217"}, traceId: 213e065a17565395273245018e8154'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5d717b01-c485-973b-9275-b1cc2bb00b9f"}, traceId: 2150456617565395276484693e817f'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.82
Progress: 30/35 (Success: 0)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4717
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4717
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2421c69a-9496-912f-ac96-9d0a5d0c2e91"}, traceId: 213e066c17565395293902795e794e'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5678a616-dbbe-93aa-8091-12dbdc87c043"}, traceId: 213e063817565395295975593e7f51'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a1c83be2-cffd-9dd6-ba58-eae6e27a95cb"}, traceId: 213e066c17565395305632798e794e'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fb73cbf6-5016-99e0-916a-cc92790854a3"}, traceId: 213e066c17565395324502806e794e'}2025-08-30 03:39:11,050 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:11,733 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:39:11,851 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:11,853 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool actions were taken and there is no evidence of a wrong tool choice, incorrect parameters, wrong sequence, or unmet dependencies. The error appears 
2025-08-30 03:39:13,217 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:13,217 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool was selected or executed and no agent decision can be identified as incorrect. The failure appears to be a system/unknown error rather than a tool-
2025-08-30 03:39:15,769 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:16,292 - httpx - INFO - HTTP Request: POST http://39.96.211.155:8000/proxy/api/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-30 03:39:18,702 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:18,702 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision (no tools were invoked), so no tool choice, parameter, sequence, or dependency decision can be evaluated. The er

[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"057a07c8-4509-9a4f-9954-5718708c414a"}, traceId: 2150430c17565394527374272e2053'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"473f5a3c-95c6-9681-b6a8-c87ae181ca71"}, traceId: 2150460817565394546334542e798c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"88304797-68e1-97c5-a817-82f1b071fc4d"}, traceId: 2150430c17565394551844286e2053'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d1546f96-4951-9983-af0a-b2bb26650384"}, traceId: 2150430c17565394575154294e2053'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9127242-2069-96a9-b989-00315b174a87"}, traceId: 2150460817565394580324554e798c'}
[RETRY] 400 error detected, waiting 0.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12882
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12882
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d3bdf92-59a3-9d89-bb43-7b4d2ec0598f"}, traceId: 2150460817565394591154557e798c'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fae12ff1-9b50-95c1-b82e-369abadc64d4"}, traceId: 2150430c17565394599114307e2053'}
[RETRY] 400 error detected, waiting 2.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"93c5e271-9707-90f6-bb7b-cb8a5f6645a5"}, traceId: 2150460817565394614454564e798c'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98167472-93e9-96bd-89e6-0db53f16c187"}, traceId: 2150430c17565394624574322e2053'}
[RETRY] 400 error detected, waiting 3.5s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"2fb8e8db-53ad-9350-b340-27cb62fb8ccb"}, traceId: 2150460817565394650154619e798c'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"cf56067a-307c-96ab-95c3-fb15d4b2c9d4"}, traceId: 2150430c17565394665124338e2053'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5406676048)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f8193520-adfa-97d3-a11c-6c25638a1988"}, traceId: 2150460817565394670364639e798c'}
[RETRY] 400 error detected, waiting 2.2s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.75
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12841
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12841
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e0b8967f-d39d-9313-b567-692d351b5468"}, traceId: 213e006b17565394697155403eeae0'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a69e15c7-1b8a-98dc-a996-7287e728e20c"}, traceId: 2150460817565394697564671e798c'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...2025-08-30 03:39:19,504 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:19,504 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for an api_integration task; the agent failed to choose an appropriate tool (or any tool) to proceed, leading to
2025-08-30 03:39:23,896 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:23,896 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task; the agent effectively chose (implicitly) no tool when a data processing tool (e.g., 
2025-08-30 03:39:24,511 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:24,512 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: there is no information showing wrong tool choice, bad parameters, wrong sequence, or unmet dependencies. The failure app
2025-08-30 03:39:25,508 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:25,510 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565509784.json
2025-08-30 03:39:25,510 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565510352.json
2025-08-30 03:39:25,510 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565510684.json
2025-08-30 03:39:25,511 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565510965.json
2025-08-30 03:39:25,511 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565511206.json
2025-08-30 03:39:25,511 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565511414.json
2025-08-30 03:39:25,512 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565511781.json
2025-08-30 03:39:25,512 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565512087.json
2025-08-30 03:39:25,513 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565512359.json
2025-08-30 03:39:25,513 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565513085.json
2025-08-30 03:39:25,515 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565513440.json
2025-08-30 03:39:25,516 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565516074.json
2025-08-30 03:39:25,516 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565516434.json
2025-08-30 03:39:25,517 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565516725.json
2025-08-30 03:39:25,517 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 1 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565517109.json
2025-08-30 03:39:25,517 - batch_test_runner - INFO - Batch writing 35 records to database (qwen2.5-72b-instruct:35)
2025-08-30 03:39:25,520 - result_collector - INFO - 📤 已提交 qwen2.5-72b-instruct 的 35 个结果到收集器: qwen2.5-72b-instruct_62490_1756539565517903.json
2025-08-30 03:39:25,520 - batch_test_runner - INFO - Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
2025-08-30 03:39:25,569 - batch_test_runner - INFO - Database saved successfully
2025-08-30 03:39:25,569 - batch_test_runner - INFO - Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
2025-08-30 03:39:25,569 - batch_test_runner - INFO - ============================================================
2025-08-30 03:39:25,569 - batch_test_runner - INFO - Batch test completed at 2025-08-30T03:39:25.569466
2025-08-30 03:39:25,569 - batch_test_runner - INFO - Summary:
2025-08-30 03:39:25,569 - batch_test_runner - INFO -   - Total tests: 35
2025-08-30 03:39:25,569 - batch_test_runner - INFO -   - Successful: 0
2025-08-30 03:39:25,569 - batch_test_runner - INFO -   - Failed: 35
2025-08-30 03:39:25,569 - batch_test_runner - INFO -   - Success rate: 0.0%
2025-08-30 03:39:25,569 - batch_test_runner - INFO -   - Log file: logs/batch_test_20250830_033321.log
2025-08-30 03:39:25,569 - batch_test_runner - INFO - ============================================================
2025-08-30 03:39:25,569 - batch_test_runner - INFO - 🧹 正在清理存储适配器资源...
2025-08-30 03:39:25,570 - result_merger - INFO - 合并线程已经停止，无需重复操作
2025-08-30 03:39:25,570 - result_merger - INFO - 发现16个新的结果文件
2025-08-30 03:39:25,585 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
2025-08-30 03:39:25,585 - result_merger - INFO - [MERGER_PROTECTION] 使用manager内置的安全合并机制
2025-08-30 03:39:29,201 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:29,202 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any API integration tool, resulting in zero tool execution. This is effectively a wrong or missing initial to
2025-08-30 03:39:30,494 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:30,494 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute to a specific agent decision. No tools were executed, and the error is labeled as 'Unknown error,' suggesting a syste
2025-08-30 03:39:31,227 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:31,227 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps and did not follow the required workflow sequence for the simple_task, effectively skipping the intended steps
2025-08-30 03:39:34,838 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:34,839 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not engage any tools or define steps for an api_integration task, effectively choosing no tool or an inappropriate tooling strategy.
2025-08-30 03:39:35,260 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:35,260 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any appropriate tool or plan for the data_pipeline task (no tool was chosen or executed), indicating an incorrect tool se
2025-08-30 03:39:40,413 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:40,415 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a misstep by the agent (no tool selections, parameters, or sequence decisions to critique). The failure shows as an unknown error w
2025-08-30 03:39:42,350 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:42,351 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any required tools for the multi_stage_pipeline (0% coverage). This indicates a planning/tool-selection failure
2025-08-30 03:39:45,832 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:45,832 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of agent-level decision errors (no tools executed, no parameters provided, and no sequence attempted). The failure is an unknown/syste
2025-08-30 03:39:46,289 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:46,291 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked for the api_integration task; the agent effectively chose not to use any tool (or chose none appropriate). This in
2025-08-30 03:39:51,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:51,066 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified. The task ended with an Unknown error and no tools were executed, providing no basis to attribute the failure to a wrong
2025-08-30 03:39:52,690 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:52,690 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-level decision errors evident: no tools were selected or executed (Executed Tools: blank). The error message 'Unknown error' appears to be a syste
2025-08-30 03:39:55,618 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:55,619 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select any appropriate data_pipeline tooling or initiate the workflow (no tools were executed). This represents a misdecision in too
2025-08-30 03:39:55,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:39:55,959 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision errors can be identified: no tools were selected or executed, no parameters provided, and the error message is unknown. The failure appea
2025-08-30 03:40:01,599 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:01,600 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool to perform the api_integration task (no tools executed). This constitutes a wrong tool choice/omis
2025-08-30 03:40:03,049 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:03,049 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any data_pipeline tools or define a tool-based workflow (no loader/parser/transform steps were invoked), pr
2025-08-30 03:40:09,302 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:09,303 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There are no required tools (0/0) and no explicit agent actions to critique. The provided data lacks any tool usage, parameters, or workflow sequence to ev
2025-08-30 03:40:09,355 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:09,357 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent did not set up or select any API tooling (dependencies) required for the api_integration task; no tools were executed, resulting in 0% cover
2025-08-30 03:40:14,494 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:14,494 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of a concrete agent decision error (no tool selection, parameter misconfiguration, sequence/order, or dependency handling). The error 
2025-08-30 03:40:15,537 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:15,538 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The task requires a precise multi-stage workflow; the failure (with no explicit error) suggests the agent did not follow the correct execution ord
2025-08-30 03:40:20,258 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:20,260 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools, yet the agent opted to use or prepare tool(s), indicating an incorrect tool choice for a tool-less task; this decision
2025-08-30 03:40:22,359 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:22,361 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No clear agent decision error can be identified: there were no tools selected/executed and no parameters set, yet the error reported is 'Unknown error'. Th
2025-08-30 03:40:26,882 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:26,883 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to address the task (0/0 tool coverage). This indicates a poor tool selection/decision in response to 
2025-08-30 03:40:27,460 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:27,461 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and initialize an appropriate toolchain for a multi_stage_pipeline task (0% tool coverage). No required tools were invoked,

[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4826
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f72e6aca-ec6e-9d40-b4da-95c00258d03e"}, traceId: 215042f917565395058148863e1bba'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e30294a8-9db8-903d-ada4-c37440b7df08"}, traceId: 2150415b17565395059305814ee6c5'}
[RETRY] 400 error detected, waiting 1.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d585a51d-ff35-9f0b-9945-93e5201f25d8"}, traceId: 2150415b17565395076185822ee6c5'}
[RETRY] 400 error detected, waiting 1.2s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ca8d4b4-e4a2-99a4-9fa0-995e937e2736"}, traceId: 2150416717565395081463483eed2d'}
[RETRY] 400 error detected, waiting 3.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1b56daec-d4f0-9b8a-901c-ffd3ead81975"}, traceId: 2150415b17565395092945828ee6c5'}
[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"621753c2-1abc-92a4-b516-7799f876f538"}, traceId: 2150416717565395116523593eed3c'}
[RETRY] 400 error detected, waiting 5.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"5409e124-a8a9-93da-972c-2e9dcd04dfe0"}, traceId: 2150415b17565395127515845ee6c5'}
[RETRY] 400 error detected, waiting 2.9s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.66
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12878
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12878
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9ebbfd4c-4afe-97ae-bd51-e43f53a2d114"}, traceId: 2150415b17565395160875883ee6c5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5235106960)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1ed1ee17-d69e-9be9-8d13-ff29b76f0e0c"}, traceId: 2150452b17565395177702139e77d2'}
[RETRY] 400 error detected, waiting 0.7s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"fe0f6b7a-af38-9eb3-81f7-a0d2fc84f46c"}, traceId: 213e065e17565395178841758e813d'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"39330566-a81e-9a35-a16f-525de241b1a3"}, traceId: 2150452b17565395188552160e77d2'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d7e6f18a-17e5-958f-9ccf-016dffa97a4c"}, traceId: 2150452b17565395203742181e77d2'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 4991
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=4991
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e18117db-fd9c-95de-90a2-5ab6be940b23"}, traceId: 2150452b17565395225072192e77d2'}
[RETRY] 400 error detected, waiting 3.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"0a779d83-3ee2-9c53-b640-3e55d97d42e8"}, traceId: 2150452b17565395263212229e77d2'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12883
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12883
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.58
💾 智能Checkpoint: 保存14个结果...
   触发原因: 数量=14, 时间=121.1s, 强制=False
✅ Checkpoint完成: 成功保存 14/14 个结果
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5060
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5060
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
💾 智能Checkpoint: 保存1个结果...
   触发原因: 数量=1, 时间=6.6s, 强制=True
✅ Checkpoint完成: 成功保存 1/1 个结果

[INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_033907.json
[SAVE_ENHANCED] 开始增强保存，时间: 03:39:07
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-72b-instruct的新prompt_type: flawed_parameter_error
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No tool actions were taken and there is no evidenc
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.60) - No tools were selected or invoked for an api_integ
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 2)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision error detected: there is no info
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.68) - No tool was selected or invoked for the api_integr
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.75) - No agent-level decision errors evident: no tools w
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision errors can be identified: no too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: dependency_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.60) - No clear agent decision error can be identified: t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors2025-08-30 03:40:33,039 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:33,039 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were required or executed for this task (Required Tools Coverage: 0%). Consequently, there was no agent decision path (tool selection/parameter/or
2025-08-30 03:40:36,186 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:36,187 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent selected to take no action (no tools invoked, no output produced) on a task that requires at least a minimal workflow result. This repre
2025-08-30 03:40:38,226 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:38,227 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unknown error with no actionable execution trace; no evidence of wrong tool choice, incorrect parameters, mis-sequencing, or unmet dependencies. Insufficie
2025-08-30 03:40:42,507 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:42,508 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select an appropriate starting tool or request clarification for the unknown task, resulting in zero tool usage and no pipeline pr
2025-08-30 03:40:44,048 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:44,048 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or executed for a task presented as a simple_task; the agent effectively refrained from using any tool, which constitutes a w
2025-08-30 03:40:48,049 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:48,051 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or instantiate any tool to execute the multi_stage_pipeline, resulting in no actions being performed. This constitutes an
2025-08-30 03:40:50,144 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:50,145 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tool for a defined task (no tools executed). This indicates a missing/tool initiation decision, effectively st
2025-08-30 03:40:53,420 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:53,421 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No data_pipeline tools were selected or initialized; the agent failed to choose the required data loading/processing tools, resulting in zero tool
2025-08-30 03:40:55,419 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:55,420 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or initialized due to an unknown error; the agent failed to choose an appropriate data_pipeline tool or define a starting act
2025-08-30 03:40:58,125 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:40:58,126 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any appropriate tools for the multi_stage_pipeline; no tools were used and no tool-specific parameters were pro
2025-08-30 03:41:00,294 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:00,294 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or apply any appropriate tool for the given (unknown/simple) task; no tools were invoked and no actionable steps were taken
2025-08-30 03:41:04,646 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:04,646 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select any required tools for the multi-stage pipeline; no tools were executed, leading to zero tool coverage. This indicates 
2025-08-30 03:41:06,267 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:06,268 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable evidence of an agent decision (tool choice, parameters, or sequence). The task shows no tools executed and the error is listed as 'Unknown er
2025-08-30 03:41:12,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:12,022 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No identifiable agent decision error: no tools were selected or configured, and there is an unknown/system-level error preventing progress. Insufficient ev
2025-08-30 03:41:13,214 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:13,216 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error: no tools were selected or executed (0/0 coverage) and there is no displayed wrong tool choice, incorrect pa
2025-08-30 03:41:18,455 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:18,456 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure appears to be a system/tool-level issue (Unknown error) with no tool executions or explicit agent decisions recorded. There is no evidence of i
2025-08-30 03:41:20,566 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:20,566 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or invoke any tool for a task that would require tool action, effectively making no operational decision. This indicate
2025-08-30 03:41:24,029 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:24,029 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initiate the required tools for the api_integration task, resulting in zero tool usage and inability to progress; no too
2025-08-30 03:41:26,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:26,076 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not execute any steps or follow the required multi-stage sequence, effectively breaking the workflow order and preventing downstream
2025-08-30 03:41:28,419 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:28,419 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any required tool for the api_integration task, resulting in 0% tool coverage and complete failure. The absence
2025-08-30 03:41:31,300 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:31,302 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a concrete agent decision error: the failure is reported as Unknown error with no tool executions or parameters provided. Without tool usage
2025-08-30 03:41:32,271 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:32,272 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle TOOL DEPENDENCIES: no prerequisites (e.g., data loading) were executed before downstream stages, indicating the pipeline depend
2025-08-30 03:41:35,901 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:35,902 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-initiated tool usage or decision path was observed; the failure is an unspecified/unknown system error rather than a wrong tool choice, bad parame
2025-08-30 03:41:36,884 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:36,886 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API-integration tool was selected or invoked despite the task requiring tool usage; the agent did not choose or dispatch the appropriate tool, 
2025-08-30 03:41:43,624 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:43,624 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or propose any tool/plan for the multi-stage pipeline (no tools executed). This denotes a wrong tool decision or missing 
2025-08-30 03:41:43,625 - result_merger - INFO - 模型qwen2.5-72b-instruct保存50/50条记录
2025-08-30 03:41:43,625 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-30 03:41:43,625 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 03:41:43,626 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 8)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 10)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 19)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 20)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No tools were required or executed for this task (
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - Unknown error with no actionable execution trace; 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.75) - Agent failed to select an appropriate starting too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 24)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No actionable evidence of an agent decision (tool 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.60) - No identifiable agent decision error: no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 24)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - The failure appears to be a system/tool-level issu
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.72) - No API-integration tool was selected or invoked de
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72) - The agent did not select or propose any tool/plan 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 29)
[INFO] 最终合并完成: 16 个文件
2025-08-30 03:41:43,723 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 03:41:43,723 - smart_result_collector - INFO - SmartResultCollector 已关闭
2025-08-30 03:41:45,396 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:45,397 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool in a multi-stage pipeline (tool coverage 0%), effectively skipping the required starting step. Thi
INFO:__main__:✅ 分片1完成
INFO:__main__:等待分片2完成（20实例×50workers，最多等待50分钟）...
2025-08-30 03:41:53,435 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:53,436 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select and/or invoke any tool for a task that required an action (no tools were executed). This indicates a wrong tool decisio
2025-08-30 03:41:58,076 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:41:58,077 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or activated for the data_pipeline task (the agent did not choose any required tool or sequence), leading to complete failu
2025-08-30 03:42:04,892 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:04,892 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no observable agent decisions (no tools selected or executed, no parameters set, and no sequence defined). The failure appears to be due to inac
2025-08-30 03:42:09,404 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:09,404 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error (tool selection, parameter config, sequence, or dependencies) is available. No tools were executed and there
2025-08-30 03:42:15,107 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:15,107 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or agent decision can be assessed from the provided trace. The error is a generic 'Unknown error' with no information about tool choices, par
2025-08-30 03:42:21,536 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:21,536 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision path could be identified: the task is unknown and no tools were selected or executed (Required Tools Coverage = 0). Consequent
2025-08-30 03:42:28,967 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:28,967 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any actions to complete the basic_task, effectively halting before executing the required workflow. This omission indica
2025-08-30 03:42:36,991 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:36,992 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required no tools (0/0), yet the agent did not take any action or select an appropriate tool, effectively making an incorrect decision ab
2025-08-30 03:42:46,124 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:46,125 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were taken; the agent failed to initiate or follow any workflow sequence (A→B→C). This indicates a misdecision about initiating/orderin
2025-08-30 03:42:51,856 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:51,857 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or apply any appropriate tool for the task; no tools were invoked (0/0 coverage) due to lack of task understanding, indicat
2025-08-30 03:42:57,017 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:42:57,017 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete evidence of a specific agent decision error (tool selection, parameter configuration, sequence, or dependencies) due to lack of executed tools 
2025-08-30 03:43:04,434 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:04,435 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any required tool for the task (0% tool coverage), effectively choosing no tool or an inappropriate starting to
2025-08-30 03:43:09,429 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:09,429 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not initiate any tools or plan steps for the API integration task, effectively selecting no tools and yielding a complete lack of wo
2025-08-30 03:43:16,031 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:16,031 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the basic_task, effectively making no tool choice for execution. This absence of tool usage
2025-08-30 03:43:23,359 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:23,359 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any actionable steps or follow the expected workflow order; there is no sequence executed (no A→B→C or equivalent), resu
2025-08-30 03:43:27,384 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:27,384 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any required tools for the data_pipeline task (tool coverage 0%). No tools were used, indicating a failure to choos

[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4132314c-7dc5-9fe3-9449-40d7ddd0bc36"}, traceId: 213e06a017565394720905894e771f'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4aae7311-6f6a-9d8e-a285-8a107fcfb8a7"}, traceId: 2150460817565394722944679e798c'}
[RETRY] 400 error detected, waiting 4.6s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[AI_DEBUG] AI分类结果: category=max_turns_errors, confidence=0.7
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7c98271d-dd28-970e-82c4-13a9f479a47d"}, traceId: 2150411617565394768102424eeb01'}
[RETRY] 400 error detected, waiting 1.1s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d120c5b0-a642-94d4-9edf-5c437891b71e"}, traceId: 215045af17565394784548022e80cd'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13239
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13239
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"1e7eae98-143a-956e-aff9-b17c05b58e2c"}, traceId: 213e065117565394791377504e8046'}
[RETRY] 400 error detected, waiting 1.5s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"8d4d6ea0-ae7a-9a11-abb4-0bc03a6b1846"}, traceId: 213e007a17565394814034478ee507'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4aaa4988-2efe-902a-97ff-565406ee751a"}, traceId: 213e043b17565394836851361e2493'}
[RETRY] 400 error detected, waiting 3.3s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=sequence_order_errors, confidence=0.65
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"45443bfd-1ea5-94d9-bfc9-dea101e644b1"}, traceId: 213e011517565394878997011e9377'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12965
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12965
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.72
Progress: 30/30 (Success: 0)
💾 智能Checkpoint: 保存10个结果...
   触发原因: 数量=10, 时间=91.9s, 强制=True
✅ Checkpoint完成: 成功保存 10/10 个结果

[INFO] Batch writing 30 records to database (qwen2.5-72b-instruct:30)
[INFO] Successfully wrote 30/30 records (qwen2.5-72b-instruct:30)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_033820.json
[SAVE_ENHANCED] 开始增强保存，时间: 03:38:20
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - Unknown error with no tool executions or observabl
[V3_UPDATE] 创建新prompt类型结构: qwen2.5-72b-instruct -> flawed_parameter_error
[V3_UPDATE] 创建新工具成功率结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8
[V3_UPDATE] 创建新难度结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> basic_task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.68) - Unknown system-level failure prevented any tool us
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> simple_task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - There is no evidence of a misdecision by the agent
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> multi_stage_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 1)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.65) - The agent did not select any tool or request clari
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No tool was selected or executed and no agent deci
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.65) - There is no evidence of any agent decision (no too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 2)2025-08-30 03:43:32,408 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:32,408 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No discernible agent decision error can be identified from the report; no tools were executed and the error is described as 'Unknown error', indicating an 
2025-08-30 03:43:36,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:36,776 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent-made tool decisions could be evaluated because no tools were selected or executed for the task; the error appears to be a system/tool-level issue 
2025-08-30 03:43:42,212 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:42,213 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tools for the data_pipeline task, effectively halting progress. For a data_pipeline task, a proper tool
2025-08-30 03:43:48,904 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:48,904 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or actions initiated; the task required performing steps, but the agent chose to take no action, indicating a suboptimal to
2025-08-30 03:43:56,114 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:43:56,114 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task specifies no required tools, yet the outcome was a complete failure with no output and no explicit error message. This indicates a misste
2025-08-30 03:44:00,308 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:00,309 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected: the task had no required tools and no tools were executed, yet an unknown error occurred. This appears to be an external/
2025-08-30 03:44:05,652 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:05,652 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool to address the api_integration task; no tools were executed, effectively making an omission in tool select
2025-08-30 03:44:11,146 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:11,146 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The task context is unknown and no actionable parameters were provided to configure any tooling. This indicates a failure to supply required par
2025-08-30 03:44:18,761 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:18,762 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were executed and there is no evidence of any required steps or workflow being followed. The task appears to require a specific executi
2025-08-30 03:44:22,569 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:22,569 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and/or use the necessary API integration tool(s); no tools were executed, resulting in 0% coverage for required tools. This
2025-08-30 03:44:27,988 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:27,988 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to handle TOOL DEPENDENCIES: no data_pipeline steps were executed (no loading/processing occurred), indicating prerequisites were not res
2025-08-30 03:44:33,723 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:33,725 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decisions or tool actions were executed due to an unknown task context; there was no tool selection, parameter configuration, sequencing, or depen
2025-08-30 03:44:40,065 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:40,065 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and there is insufficient information to attribute the failure to any specific agent decision. The error appears to be a
2025-08-30 03:44:46,207 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:46,207 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of agent decision making (no tools were executed, no parameters set, and no sequence established). The error message 'Unknown error' suggests a
2025-08-30 03:44:54,530 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:44:54,530 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to initiate or follow the workflow: no actions were executed and no steps/tools were used, effectively breaking the expected task seq
2025-08-30 03:45:01,116 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:01,117 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate or follow the required data_pipeline sequence (no tools were executed). This indicates a failure to establish the corre
2025-08-30 03:45:08,659 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:08,660 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed and no action was taken for the basic_task. The agent failed to select or initiate any appropriate tool/approach to produce
2025-08-30 03:45:12,644 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:12,646 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of an agent decision error (no tool selection, parameter, sequence, or dependency decisions). The error message is 'Unknown error' wit
2025-08-30 03:45:17,479 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:17,479 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any tool, resulting in 0% tool coverage and complete failure. This indicates an omission/incorrect tool dec
2025-08-30 03:45:24,177 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:24,178 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool to handle the unknown task; no tool was chosen, preventing progression and indicating a wrong tool d
2025-08-30 03:45:33,841 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:33,842 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No steps or tools were executed; the task failed to progress, implying the agent did not initiate or follow the required workflow sequence. With 0
2025-08-30 03:45:44,640 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:44,640 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were taken and no workflow sequence was executed for the basic_task. The agent failed to establish or follow any processing sequence (e
2025-08-30 03:45:48,900 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:48,900 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task, indicating an incorrect or missing initial tool choice (the agent failed to pick the
2025-08-30 03:45:55,718 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:45:55,720 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the data_pipeline task, resulting in 0% tool coverage. This indicates the agent failed to identify or choos
2025-08-30 03:46:00,876 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:00,877 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure shows a generic 'Unknown error' with no tools selected or executed, so there is no evidence of a wrong tool choice, incorrect parameters, bad s
2025-08-30 03:46:06,209 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:06,209 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is reported as 'Unknown error'. There is insufficient information to attribute the failure to a wrong tool choice, inc
2025-08-30 03:46:11,761 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:11,762 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the data_pipeline task. The agent did not choose or initialize the required data pipeline tools (e.g., data_
2025-08-30 03:46:22,152 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:22,152 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps or tool actions for the simple_task, effectively halting instead of executing the expected workflow. This cons
2025-08-30 03:46:28,317 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:28,317 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the simple_task, effectively making no decision or action. This constitutes a tool-selectio
2025-08-30 03:46:35,675 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:35,677 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a tool selection, parameter configuration, sequence order, or dependency error. The failure is described as an Unknown error with no execute
2025-08-30 03:46:46,278 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:46,278 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent actions or tool executions are observed; the error message is 'Unknown error' with no evidence of incorrect tool selection, wrong parameters, wron
2025-08-30 03:46:50,415 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:50,415 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision errors: no tools were executed and the error is unknown. Cannot attribute the failure to tool selection, parameter configurati
2025-08-30 03:46:56,538 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:46:56,539 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not perform any steps or produce a result despite the task requiring completion; there were no tools executed, indicating a breakdow
2025-08-30 03:47:06,940 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:06,940 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tool to perform the basic_task, effectively choosing not to act. Despite no explicit error message, the com
2025-08-30 03:47:16,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:16,015 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "For a basic_task with no required tools, the correct approach would be to perform the task without invoking any tools. The agent did not select or
2025-08-30 03:47:21,341 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:21,341 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision errors identifiable because no tools were selected or executed; the error appears to be an unknown/system error (Unknown error
2025-08-30 03:47:28,959 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:28,960 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated because the task context is unknown and no tools or workflow steps were selected or executed. The failure stems from m
2025-08-30 03:47:33,961 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:33,961 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identifiable. The task had no required tools, and there is no evidence of tool misselection, misconfiguration, or incorrect sequenc
2025-08-30 03:47:41,143 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:41,143 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or invoke any tool/action for the basic task, effectively skipping required steps. This represents a wrong decision at the to

[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.68)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.73)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - There is no evidence of a misstep by the agent (no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.75) - There is no evidence of agent-level decision error
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.78) - No agent decision error identified. The task ended
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.78) - There is no evidence of a concrete agent decision 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85) - The task required no tools, yet the agent opted to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 6)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60) - The agent did not select or invoke any tool to add
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.48)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.65) - No tool was selected or initialized due to an unkn
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.65) - Agent failed to select or apply any appropriate to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 9)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - The agent failed to select any required tools for 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.60) - No evidence of a concrete agent decision error: th
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.72) - No agent-initiated tool usage or decision path was
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 11)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62) - The agent did not select or initialize any tool in
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 5)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - No evidence of a specific agent decision error (to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.68) - No tool usage or agent decision can be assessed fr
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 8)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No actionable agent decision path could be identif
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.65) - Agent failed to select or apply any appropriate to
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 1)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No concrete evidence of a specific agent decision 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.60) - The agent did not select or invoke any required to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85) - Agent did not select or invoke any required tools 2025-08-30 03:47:48,038 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:48,038 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not produce or execute any sequence of steps for the data_pipeline task; there was no initiated workflow (A→B→C) or tool usage, effe
2025-08-30 03:47:55,811 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:47:55,811 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task requires no tools, yet the agent did not select or execute any tool/action. This indicates a wrong tool-usage decision (failing to recogn
2025-08-30 03:48:01,226 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:01,227 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Insufficient information to attribute to agent decision. The task shows an 'Unknown error' with 0% tool coverage and no tools executed, making it impossibl
2025-08-30 03:48:07,622 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:07,623 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or decision steps were executed due to an Unknown error; task context/details are insufficient to determine a specific agent decision mistake
2025-08-30 03:48:11,325 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:11,326 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and the error is reported as 'Unknown error' with 0% tool coverage. There is no evidence of incorrect tool selection, parameter conf
2025-08-30 03:48:16,195 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:16,195 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of any agent decision (tool choice, parameterization, sequencing, or dependencies) because no tools were executed and there is no error message
2025-08-30 03:48:23,617 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:23,617 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or invoke any tools for a multi-stage pipeline task (no tools executed). For a multi_stage_pipeline, an appropriate orche
2025-08-30 03:48:28,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:28,409 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or the agent failed to choose the required data_pipeline tool (e.g., expected data_loader/pdf_reader). The complete absence o
2025-08-30 03:48:33,658 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:33,659 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No detectable agent decision error: no tools were selected or executed and the error 'Unknown error' points to a system/tool-level failure rather than a wr
2025-08-30 03:48:38,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:38,749 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error detected. There were no tools selected or executed (Required Tools: none; Executed Tools: none) and the error message is Unknown er
2025-08-30 03:48:43,834 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:43,834 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of any agent tool selection, parameter configuration, or sequence decisions; the failure appears to be an unknown/system-level error without an
2025-08-30 03:48:48,651 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:48,652 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initialize any of the required data-pipeline tools (no tool was executed), effectively making a tool-choice error by n
2025-08-30 03:48:55,468 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:48:55,469 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent did not execute the required API integration workflow steps or initiate actions (no tools invoked), indicating a failure to follow the inten
2025-08-30 03:49:01,764 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:01,765 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or actions taken for a task that requires execution; effectively a no-op, indicating a wrong tool decision (failure to sele
2025-08-30 03:49:08,576 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:08,576 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was chosen or executed; the task required tool usage, but the agent failed to initiate any tool, indicating a tool-selection decision erro
2025-08-30 03:49:13,473 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:13,474 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision path to evaluate: no tools were invoked and no parameters or sequence were executed. The error message 'Unknown error' appears to be a sy
2025-08-30 03:49:19,677 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:19,677 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or execute any tool for a task that requires action; effectively no tool was chosen, indicating a tool-selection decision e
2025-08-30 03:49:26,826 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:26,826 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select any operational tool (i.e., effectively chose a 'no-tool' path) for a task that requires action, representing an incorrect 

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 13)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No discernible agent decision error can be identif
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No agent-made tool decisions could be evaluated be
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - No agent decision error detected: the task had no 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.65) - Agent did not select or invoke any tool to address
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: parameter_config_errors (confidence: 0.70) - The task context is unknown and no actionable para
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 15)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.42)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No agent decisions or tool actions were executed d
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No tools were selected or executed and there is in
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.65) - No evidence of agent decision making (no tools wer
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - There is no evidence of an agent decision error (n
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.85) - The agent did not select or initialize any tool, r
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 20)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85) - Agent failed to select or initialize any tool to h
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75) - No tools were selected or executed for the data_pi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - The failure shows a generic 'Unknown error' with n
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.70) - No tools were executed and the error is reported a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 22)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.70) - No evidence of a tool selection, parameter configu
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60) - No agent actions or tool executions are observed; 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 24)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No observable agent decision errors: no tools were
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.72) - No actionable agent decision errors identifiable b
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 29)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.63) - No agent decision could be evaluated because the t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 23)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - No agent decision error identifiable. The task had
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.72)2025-08-30 03:49:30,506 - openai._base_client - INFO - Retrying request to /chat/completions in 0.431134 seconds
2025-08-30 03:49:32,482 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:32,483 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error identified. The task shows an Unknown error with no tools executed and no evidence of incorrect tool choice, wrong parameters, wron

[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.68) - Insufficient information to attribute to agent dec
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 31)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.62) - No tool usage or decision steps were executed due 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 7)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No tools were executed and the error is reported a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.72)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No detectable agent decision error: no tools were 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.72) - No agent decision error detected. There were no to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 5)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.60) - No evidence of any agent tool selection, parameter
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 27)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.55) - No tool was chosen or executed; the task required 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 33)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.85) - No agent decision path to evaluate: no tools were 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 34)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 29)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.85)
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 31)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 32)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 38)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 37)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 39)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 40)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 41)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 45)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors2025-08-30 03:49:36,484 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:36,486 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated due to complete lack of actionable execution data; error message is Unknown error, indicating a system/tool failure ra
2025-08-30 03:49:40,409 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:40,410 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent failed to handle the pipeline dependencies: no stages were executed, so prerequisite steps (e.g., data loading feeding into subsequent stage
2025-08-30 03:49:43,875 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:43,878 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "In a multi-stage pipeline, full success requires executing stages in the proper order and satisfying dependencies. The report shows no tools were 
2025-08-30 03:49:45,519 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:45,520 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed; there is no agent decision to critique (tool_selection/parameter_config/sequence/dependency errors cannot be determined
2025-08-30 03:49:48,752 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:48,752 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No explicit agent decision error could be identified: there were no tools executed and no parameters or sequence decisions recorded. With 0/0 tool coverage
2025-08-30 03:49:50,520 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:50,521 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no agent tool decisions to evaluate: Executed Tools is empty and Required Tools Coverage is 0 (0/0). The error 'Unknown error' indicates a syste
2025-08-30 03:49:53,332 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:53,332 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "Unable to identify a concrete agent decision error: no tools were selected or executed, and the error is reported as 'Unknown error'. This provides no evid
2025-08-30 03:49:56,423 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:56,423 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision could be evaluated because the task failed at an unknown/system level before any tool was selected or executed; there is no evidence of t
2025-08-30 03:49:58,985 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:49:58,985 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate or execute any steps in the API integration workflow, effectively failing to start the required sequence. No actions we

[RETRY] 400 error detected, waiting 3.0s before retry (not counting as turn)...
  [SEARCH] Query: file reader

[TURN 2/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"3658e681-da98-9926-a194-2ef15592f22f"}, traceId: 213e06c017565395334502993e8248'}
[RETRY] 400 error detected, waiting 0.8s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"743bd034-59fc-9c24-9a6c-5ea7d7cc1607"}, traceId: 213e064e17565395349557843e826a'}
[RETRY] 400 error detected, waiting 1.4s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=timeout_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 12963
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=12963
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"92dca2e3-948f-92cc-b4c2-fdc7ceb5f337"}, traceId: 213e066c17565395358502828e794e'}
[RETRY] 400 error detected, waiting 2.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"e4520c07-0429-9afd-a19d-c9c5ca39a505"}, traceId: 213e068217565395383412847e79b1'}
[RETRY] 400 error detected, waiting 1.6s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"98365c37-c74f-9a3d-b3e2-1f29c4b615f7"}, traceId: 213e066c17565395383272847e794e'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[InteractiveExecutor] Initialized client with model: qwen2.5-72b-instruct
[InteractiveExecutor] Using prompt type: flawed_parameter_error for API key selection
[InteractiveExecutor] API model name: qwen2.5-72b-instruct
[MCPEmbeddingManager] Reusing existing singleton instance (id: 5441232512)
[MCPEmbeddingManager] Current cache size: 30 embeddings
[INFO] Tool embedding index loaded successfully
[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[INFO] Operation semantic index initialized

[TURN 1/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a4c739f2-d6de-9196-ba14-036a35d02f14"}, traceId: 213e060a17565395394282956e8ba5'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a5954e3b-f179-96de-9923-70fb8c61772c"}, traceId: 213e060a17565395408372958e8ba5'}
[RETRY] 400 error detected, waiting 1.9s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 3/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"10a10191-98d9-9ed5-a3e2-428fda891d2f"}, traceId: 213e007a17565395422981848ee252'}
[RETRY] 400 error detected, waiting 1.0s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"f992ba7f-3b56-9cb0-95a1-a298035a1490"}, traceId: 213e060a17565395431342968e8ba5'}
[RETRY] 400 error detected, waiting 1.7s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=other_errors, confidence=0.68
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5100
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5100
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
  [EARLY_EXIT] No actions taken, continuing...

[TURN 4/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"a17a358f-a7cc-9bda-8b1d-75b63eed20b4"}, traceId: 213e060a17565395454812986e8ba5'}
[RETRY] 400 error detected, waiting 3.7s before retry (not counting as turn)...
  [EARLY_EXIT] No actions taken, continuing...

[TURN 5/10]
[LLM_CALL] Using model: qwen2.5-72b-instruct, API name: qwen2.5-72b-instruct
[LLM_ERROR] Attempt 1/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"40371193-06ff-9033-87f5-f90f7cd54562"}, traceId: 213e058a17565395460524282e345a'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 2/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"9412f695-4232-94f9-9858-c3ddd3532603"}, traceId: 213e007617565395474173049e1311'}
[RETRY] 400 error detected, waiting 0.9s before retry (not counting as turn)...
[LLM_ERROR] Attempt 3/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"94ed15e4-3b21-9b0f-94d5-e33155c087ec"}, traceId: 213e060c17565395486933569e8ace'}
[RETRY] 400 error detected, waiting 2.3s before retry (not counting as turn)...
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"7a56eb0e-91e3-9f72-9254-52a3daeee00e"}, traceId: 213e060a17565395496852996e8ba5'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.78
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 5055
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=5055
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[LLM_ERROR] Attempt 4/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"d9d12f77-0e53-901b-9b5a-087db1e4fb90"}, traceId: 213e007417565395514625652ef052'}
[RETRY] 400 error detected, waiting 4.1s before retry (not counting as turn)...
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.7
[LLM_ERROR] Attempt 5/5: Error code: 400 - {'success': False, 'message': '模型提供方限流', 'data': None, 'code': 'MPE-429', 'detailMessage': '{"code":"Throttling.RateQuota","message":"Requests rate limit exceeded, please try again later.","request_id":"4d15d43c-ae59-9d94-90c8-a40d3ce95de6"}, traceId: 213e062917565395560074851e7f51'}
[ERROR] Max retries reached after 5 attempts
[API_FAILURE] All retries exhausted
  [API_FAILURE] API failed (timeout or max retries)
[DEBUG] Got result for task: has_result=True, save_logs=False
[AI_DEBUG] 测试非完全成功(failure)，准备调用AI分类
[AI_DEBUG] 生成的txt_content长度: 13473
[AI_DEBUG] _ai_classify_with_txt_content called:
  - use_ai_classification=True
  - ai_classifier=True
  - txt_content_len=13473
  - task_model=qwen2.5-72b-instruct
[AI_CLASSIFIER] 直接使用AI分析完整交互记录（跳过规则匹配）
[AI_DEBUG] AI分类结果: category=tool_selection_errors, confidence=0.76
💾 智能Checkpoint: 保存15个结果...
   触发原因: 数量=15, 时间=118.6s, 强制=True
✅ Checkpoint完成: 成功保存 15/15 个结果

[INFO] Batch writing 35 records to database (qwen2.5-72b-instruct:35)
[INFO] Successfully wrote 35/35 records (qwen2.5-72b-instruct:35)
[INFO] Runtime error report saved to: runtime_reports/runtime_error_report_20250830_033925.json
[SAVE_ENHANCED] 开始增强保存，时间: 03:39:25
[SAVE_ENHANCED] 使用文件锁机制保存
[SAVE_ENHANCED] 保留qwen2.5-72b-instruct的新prompt_type: flawed_parameter_error
[SAVE_ENHANCED] 文件锁保存成功

📊 Statistics saved to: /Users/ruicheng/Documents/GitHub/WorkflowBench/pilot_bench_cumulative_results/master_database.json
[INFO] 正在停止ResultMerger...
[INFO] 执行最终合并...
[INFO] Enhanced manager: AI错误分类系统已启用
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - Insufficient information to attribute to a specifi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 3)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No agent decision could be evaluated due to comple
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 4)
[INFO] Time-based flush (610.9s since last flush)...
[INFO] Flushing 2 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - Unable to identify a concrete agent decision error
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> api_integration
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.85)
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 14)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 5)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 6)2025-08-30 03:50:01,028 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:01,030 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or invoked for the API integration task; the agent did not choose the required tools, resulting in no workflow steps being 
2025-08-30 03:50:05,869 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:05,869 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No API integration tool was selected or an inappropriate tool was chosen for the api_integration task, resulting in zero tool execution and comple
2025-08-30 03:50:07,795 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:07,798 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select or invoke any required tools for an api_integration task (no tools executed, 0% coverage). This constitutes a wrong too
2025-08-30 03:50:12,113 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:12,114 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or initialize any tools to execute the multi-stage pipeline, leading to zero tool execution and complete failure. This reflec
2025-08-30 03:50:12,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:12,168 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision data available: no tools were executed and the error is labeled Unknown, indicating a possible system-level failure rather tha
2025-08-30 03:50:18,121 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:18,121 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The error is reported as Unknown error with no tools executed or decisions to analyze. There is insufficient information to attribute the failure to a spec
2025-08-30 03:50:18,228 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:18,228 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select any tools or outline a plan for the multi-stage pipeline due to an unknown task. This indicates a tool-selection/plan-for
2025-08-30 03:50:24,028 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:24,029 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or initialized for the API integration task, leading to zero tool execution and thus no progress. The agent failed to choos
2025-08-30 03:50:30,328 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:30,328 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "The agent did not initiate any part of the required data_pipeline, so no tool outputs were produced and dependencies remained unmet. This indicates a 
2025-08-30 03:50:32,227 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:32,228 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent did not initiate or follow any pipeline steps; there is no evidence of tool usage or step sequencing, implying a failure to establish th
2025-08-30 03:50:35,566 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:35,566 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tooling was selected or invoked for the data_pipeline task, resulting in 0% tool coverage and a failure to proceed. The agent effectively skipp
2025-08-30 03:50:38,861 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:38,861 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to initiate or execute the required progression of stages in the multi_stage_pipeline, producing no outputs; effectively ignoring the
2025-08-30 03:50:41,704 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:41,705 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision was made: the task required no tools (0/0 coverage) and no steps were executed. There is no evidence of a wrong tool choice, i
2025-08-30 03:50:48,939 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:48,940 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or invoked to perform the data_pipeline task. The agent did not choose any required tool (e.g., data_loader/pdf_reader) and t
2025-08-30 03:50:49,987 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:49,988 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were executed (0% coverage). The agent did not select or invoke any tool to perform the API integration task, which constitutes a tool se
2025-08-30 03:50:52,873 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:52,874 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or use any of the required data pipeline tools (e.g., data_loader/pdf_reader) needed to perform the task, resulting in comple
2025-08-30 03:50:57,636 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:57,638 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tool usage or task-specific decisions can be evaluated from the provided report; error is labeled Unknown error rather than a concrete agent mistake. Wi
2025-08-30 03:50:57,830 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:50:57,830 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No evidence of a specific agent decision error: no tools were selected or executed (tools coverage 0%), and the error is described as 'Unknown error'. This
2025-08-30 03:51:03,914 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:03,915 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were executed and there is insufficient information to identify a concrete agent decision error (tool selection, parameter configuration, sequence
2025-08-30 03:51:03,963 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:03,964 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No tools were selected or executed and there is insufficient information to attribute the failure to any specific agent decision type (tool selection, para
2025-08-30 03:51:09,120 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:09,121 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The task required using an API/client tool to perform the integration, but the agent did not select or invoke any suitable tool (no tools executed
2025-08-30 03:51:10,473 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:10,474 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There is no evidence of any agent decision or tool usage to cause the failure. The error is reported as Unknown error with 0/0 tools executed, so we cannot
2025-08-30 03:51:12,304 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:12,305 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or initialize any tool appropriate for performing the api_integration task; no tools were executed, indicating a missing or
2025-08-30 03:51:18,114 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:18,115 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No actions were taken by the agent, effectively breaking the expected execution sequence (no steps A→B→C were performed). This omission constitute
2025-08-30 03:51:19,550 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:19,551 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the API integration task. The agent failed to pick the required API client/integration tool, resulting in 0
2025-08-30 03:51:25,013 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:25,018 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "No data_pipeline steps were executed; the agent did not establish or follow the required execution sequence (e.g., load → transform → validate). T
2025-08-30 03:51:30,171 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:30,173 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "There is no evidence of any tools being executed and no steps completed. The failure resembles a breakdown in following the expected data-pipeline
2025-08-30 03:51:33,263 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:33,263 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to take any action by not selecting or invoking any tool for a task that requires a basic action, indicating a wrong tool decision (t
2025-08-30 03:51:37,741 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:37,742 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure seems to be an unknown system-level error that occurred before any tool was engaged, so there is no identifiable agent decision (tool selection
2025-08-30 03:51:38,571 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:38,572 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision error occurred because the task required no tools and no steps were executed. The failure is due to an unknown/system-level error (Unknow
2025-08-30 03:51:44,043 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:44,044 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent did not select or execute any tools to perform the api_integration task, effectively failing to establish the required workflow. This consti
2025-08-30 03:51:46,468 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:46,469 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "The failure lacks any agent-driven decision: no tools were selected/executed and the error is reported as unknown. Since there were no required tools or pa
2025-08-30 03:51:49,164 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:49,164 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No required data_pipeline tools were selected or initiated by the agent (no tools were invoked). This represents a tool-selection/activation decis
2025-08-30 03:51:53,251 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:53,252 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No agent decision can be evaluated because the agent did not select any tools or perform any actions due to an unknown/system-level error. There is no evid
2025-08-30 03:51:53,707 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:53,707 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or execute any of the required tools for the multi-stage pipeline (no pdf_reader/data_loader or equivalent steps were cho
2025-08-30 03:51:59,439 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:51:59,441 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "The agent failed to execute the required API integration workflow in the correct sequence (e.g., skipped or delayed configuration/authentication s
2025-08-30 03:52:00,156 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:00,157 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select and invoke any tool for the simple_task; no actions were taken, representing a wrong decision to skip tool usage when tooli
2025-08-30 03:52:05,095 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:05,096 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "Agent failed to select or execute any required tool for the api_integration task; no tools were used despite the task requiring tooling, indicatin
2025-08-30 03:52:07,969 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:07,970 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or apply any tool (no tools were executed) for a task that requires action, effectively omitting the initial tool choice.
2025-08-30 03:52:13,214 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:13,215 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No concrete agent decision error can be identified from the provided data. The error message is generic ('Unknown error') with 0% tool coverage and no tool
2025-08-30 03:52:15,630 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:15,631 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "sequence_order_errors",
  "reason": "Agent failed to establish or execute the API integration workflow—no tools were selected or invoked, resulting in an incomplete/absent sequence. T
2025-08-30 03:52:19,211 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:19,211 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tools were selected or executed for the unknown multi-stage task, indicating a failure at the tool-selection step (the agent did not pick a sui
2025-08-30 03:52:20,112 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:20,118 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error can be determined from the report. There were no tools executed (0% coverage) and the error is labeled 'Unknown error', 
2025-08-30 03:52:24,661 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:24,661 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "No tool was selected or initialized for the API integration task, indicating a misdecision at the initial tool selection step and preventing any p

[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_call_format_errors
[V3_UPDATE] 创建新任务类型结构: qwen2.5-72b-instruct -> flawed_parameter_error -> 0.8 -> easy -> data_pipeline
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 1)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 2)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 3)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 3)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 4)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 8)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 9)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 13)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 7)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 14)2025-08-30 03:52:26,088 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:26,089 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No observable agent decision error (tool_selection, parameter_config, sequence_order, or dependency) can be identified. The task shows an Unknown error wit
2025-08-30 03:52:29,695 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:29,696 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent failed to select/initialize the appropriate starting tool for a multi-stage pipeline (no tools executed). This constitutes a wrong-tool 
2025-08-30 03:52:33,823 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:33,824 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or identify any tool to handle the data_pipeline task, effectively making a tool-selection decision error by not using an
2025-08-30 03:52:35,798 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:35,799 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "tool_selection_errors",
  "reason": "The agent did not select or initiate any tools for the multi_stage_pipeline task, effectively omitting the required toolchain and sequence. This r
2025-08-30 03:52:35,821 - result_merger - INFO - 模型qwen2.5-72b-instruct保存50/50条记录
2025-08-30 03:52:35,822 - result_merger - INFO - 合并完成，共处理16个文件，保存50条记录
2025-08-30 03:52:35,822 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 03:52:35,824 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: timeout_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'timeout_errors' -> 'timeout_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: timeout_errors -> timeout_errors
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 16)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 17)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.62) - The agent failed to select or invoke any required 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 17)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.65) - No actionable agent decision data available: no to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 21)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85) - The agent did not select any tools or outline a pl
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 22)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.58)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: sequence_order_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.45) - No tools were executed (0% coverage). The agent di
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.72) - No evidence of a specific agent decision error: no
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 20)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.60) - No tools were executed and there is insufficient i
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 21)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.60) - There is no evidence of any tools being executed a
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 15)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.62) - The failure seems to be an unknown system-level er
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 25)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.60) - Agent did not select or execute any tools to perfo
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 25)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.72)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.60)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.03s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.65) - Agent failed to select or execute any required too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.52) - No concrete agent decision error can be identified
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 27)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.60) - No tools were selected or executed for the unknown
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 28)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.66)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[INFO] 最终合并完成: 16 个文件
2025-08-30 03:52:35,953 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 03:52:35,953 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片2完成
INFO:__main__:等待分片3完成（20实例×50workers，最多等待50分钟）...
2025-08-30 03:52:43,168 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:43,169 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "There were no required tools or parameters to select/configure, and no execution sequence to evaluate. Therefore, there is no concrete agent decision (tool
2025-08-30 03:52:50,852 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:50,852 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "other_errors",
  "reason": "No actionable agent decision was possible: the task required no tools, parameters, or sequence steps. The failure cannot be attributed to tool selection, p
2025-08-30 03:52:55,647 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:52:55,648 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "dependency_errors",
  "reason": "Agent failed to initiate required workflow steps / handle dependencies: no tools were executed and no steps performed, indicating missing or unmet pre
2025-08-30 03:53:01,517 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-nano/chat/completions?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
2025-08-30 03:53:01,517 - focused_ai_classifier - INFO - Raw AI response (first 200 chars): {
  "category": "parameter_config_errors",
  "reason": "The agent could not determine or retrieve the task due to missing/incorrect task parameters (Task: Unknown task, Error: Unknown error). This ind
2025-08-30 03:53:01,518 - result_merger - INFO - 模型qwen2.5-72b-instruct保存100/100条记录
2025-08-30 03:53:01,519 - result_merger - INFO - 合并完成，共处理71个文件，保存100条记录
2025-08-30 03:53:01,521 - batch_test_runner - INFO - ✅ 存储适配器资源清理完成
2025-08-30 03:53:01,521 - batch_test_runner - INFO - 🔚 子进程测试完成，主动退出

[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 29)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 46)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_call_format_errors' -> 'tool_call_format_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_call_format_errors -> tool_call_format_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: other_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 31)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 32)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 33)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'other_errors' -> 'sequence_order_errors' (score: 0.78)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: other_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 37)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 38)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 7)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 10)
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 11)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.06s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 15)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 9)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 16)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.07s
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 11)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 12)
[AI-CLASSIFY-EXISTING] Using existing AI classification: max_turns_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 13)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[FUZZY_MATCH] 'max_turns_errors' -> 'max_turns_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: max_turns_errors -> max_turns_errors
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-EXISTING] Using existing AI classification: sequence_order_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 17)
[AI-CLASSIFY-EXISTING] Using existing AI classification: tool_selection_errors
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 18)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.75) - No agent decision error identified. The task shows
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 19)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[FUZZY_MATCH] 'sequence_order_errors' -> 'sequence_order_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: sequence_order_errors -> sequence_order_errors
[FUZZY_MATCH] 'tool_selection_errors' -> 'tool_selection_errors' (score: 1.00)
[TASK-AI-CLASSIFY] Using fuzzy-matched AI classification: tool_selection_errors -> tool_selection_errors
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: dependency_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.65) - No tools were selected or executed; there is no ag
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 19)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.72) - There were no agent tool decisions to evaluate: Ex
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 20)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct multi_stage_pipeline: other_errors (confidence: 0.85) - No agent decision could be evaluated because the t
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> multi_stage_pipeline (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.75)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: tool_selection_errors (confidence: 0.78)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct multi_stage_pipeline: tool_selection_errors (confidence: 0.62)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.04s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.60) - The error is reported as Unknown error with no too
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 49)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.77) - The agent did not initiate any part of the require
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.62) - No tooling was selected or invoked for the data_pi
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 42)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.75)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - No tool usage or task-specific decisions can be ev
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 41)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: other_errors (confidence: 0.85) - No tools were selected or executed and there is in
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - There is no evidence of any agent decision or tool
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 42)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: sequence_order_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: sequence_order_errors (confidence: 0.55)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.65)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No agent decision error occurred because the task 
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 45)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct basic_task: other_errors (confidence: 0.65) - The failure lacks any agent-driven decision: no to
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> basic_task (total: 51)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct api_integration: other_errors (confidence: 0.85) - No agent decision can be evaluated because the age
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> api_integration (total: 23)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: tool_selection_errors (confidence: 0.85)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct basic_task: tool_selection_errors (confidence: 0.65)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct api_integration: sequence_order_errors (confidence: 0.78)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.85) - No observable agent decision error can be determin
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 47)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.72) - No observable agent decision error (tool_selection
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 48)
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct data_pipeline: tool_selection_errors (confidence: 0.55) - The agent did not select or identify any tool to h
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> data_pipeline (total: 47)
[INFO] Buffer full (3 records), triggering flush...
[INFO] Flushing 3 records to database...
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.62)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct simple_task: other_errors (confidence: 0.60)
[AI-CLASSIFY-TASK] qwen2.5-72b-instruct data_pipeline: dependency_errors (confidence: 0.85)
[INFO] All records processed, updating error metrics...
[INFO] Saving database...
[INFO] Database saved successfully in 0.02s
[AI-CLASSIFY-NEW] qwen2.5-72b-instruct simple_task: parameter_config_errors (confidence: 0.85) - The agent could not determine or retrieve the task
[V3_UPDATE] 更新统计完成: qwen2.5-72b-instruct -> flawed_parameter_error -> simple_task (total: 51)
[INFO] 最终合并完成: 71 个文件
2025-08-30 03:53:01,623 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
2025-08-30 03:53:01,624 - smart_result_collector - INFO - SmartResultCollector 已关闭
INFO:__main__:✅ 分片3完成
INFO:__main__:📊 并发执行结果: 3/3 分片成功
INFO:__main__:✅ Key0: 完成 qwen2.5-72b-instruct-easy
INFO:__main__:最终利用率: 1.1%
=== 测试结束时间: 2025年 8月30日 星期六 03时53分03秒 EDT ===
=== 退出码: 0 ===
