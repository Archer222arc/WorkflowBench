===== 分片 qwen2.5-32b-instruct_medium_key1 =====
时间: 2025-08-27T14:34:01.842855
模型: qwen2.5-32b-instruct
实例: qwen-key1
命令: python -u smart_batch_runner.py --model qwen2.5-32b-instruct --deployment qwen-key1 --prompt-types optimal --difficulty medium --task-types all --num-instances 10 --max-workers 50 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[14:34:09.034] 
[14:34:09.049] A module that was compiled using NumPy 1.x cannot be run in
[14:34:09.049] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[14:34:09.050] versions of NumPy, modules must be compiled with NumPy 2.0.
[14:34:09.050] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[14:34:09.050] 
[14:34:09.050] If you are a user of the module, the easiest solution will be to
[14:34:09.052] downgrade to 'numpy<2' or try to upgrade the affected module.
[14:34:09.052] We expect that some modules will need time to support NumPy 2.
[14:34:09.052] 
[14:34:09.052] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[14:34:09.052]     from batch_test_runner import BatchTestRunner, TestTask
[14:34:09.052]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[14:34:09.052]     from mdp_workflow_generator import MDPWorkflowGenerator
[14:34:09.052]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[14:34:09.052]     import torch
[14:34:09.052]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[14:34:09.052]     from .functional import *  # noqa: F403
[14:34:09.052]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[14:34:09.052]     import torch.nn.functional as F
[14:34:09.052]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[14:34:09.052]     from .modules import *  # noqa: F403
[14:34:09.052]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[14:34:09.052]     from .transformer import TransformerEncoder, TransformerDecoder, \
[14:34:09.052]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[14:34:09.053]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:34:09.053] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[14:34:09.059]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:34:13.136] 2025-08-27 14:34:13,117 - faiss.loader - INFO - Loading faiss.
[14:34:13.494] 2025-08-27 14:34:13,487 - faiss.loader - INFO - Successfully loaded faiss.
[14:34:16.719] [INFO] 使用JSON存储格式
[14:34:16.739] [INFO] 使用JSON存储格式
[14:34:19.518] [INFO] 使用JSON存储格式
[14:34:19.535] [INFO] 使用JSON存储格式
[14:34:19.536] 
[14:34:19.536] ============================================================
[14:34:19.536] 智能批测试: qwen2.5-32b-instruct (idealab)
[14:34:19.536] Prompt types: ['optimal']
[14:34:19.536] 难度: medium
[14:34:19.536] 目标: 每种配置 10 个实例
[14:34:19.536] ============================================================
[14:34:19.536] ○ simple_task         :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.537] ○ basic_task          :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.537] ○ data_pipeline       :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.539] ○ api_integration     :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.540] ○ multi_stage_pipeline:   0/ 10 已完成 (需要补充 10 个)
[14:34:19.540] 
[14:34:19.542] ⏳ 需要运行 50 个新测试
[14:34:19.542] 
[14:34:19.542] ▶ 准备 simple_task (10 个实例)...
[14:34:19.542] 
[14:34:19.542] ▶ 准备 basic_task (10 个实例)...
[14:34:19.542] 
[14:34:19.542] ▶ 准备 data_pipeline (10 个实例)...
[14:34:19.542] 
[14:34:19.542] ▶ 准备 api_integration (10 个实例)...
[14:34:19.542] 
[14:34:19.542] ▶ 准备 multi_stage_pipeline (10 个实例)...
[14:34:19.542] 
[14:34:19.542] ▶ 开始执行 50 个测试...
[14:34:19.542] 📊 自适应checkpoint_interval: 20
[14:34:19.542] 📦 批量提交模式：每20个测试保存一次
[14:34:19.542] ⚠️  检测到idealab API，调整并发: workers=2, qps=None
[14:34:19.544] 2025-08-27 14:34:19,542 - smart_result_collector - INFO - 自动保存线程已启动
[14:34:19.545] 2025-08-27 14:34:19,543 - smart_result_collector - INFO - SmartResultCollector初始化完成
[14:34:19.545] 2025-08-27 14:34:19,543 - smart_result_collector - INFO -   - 临时目录: temp_results
[14:34:19.545] 2025-08-27 14:34:19,543 - smart_result_collector - INFO -   - 内存阈值: 20
[14:34:19.545] 2025-08-27 14:34:19,543 - smart_result_collector - INFO -   - 时间阈值: 300秒
[14:34:19.545] 2025-08-27 14:34:19,543 - smart_result_collector - INFO -   - 自动保存: 60秒
[14:34:19.545] 2025-08-27 14:34:19,543 - smart_result_collector - INFO -   - 自适应阈值: True
[14:34:19.545] 2025-08-27 14:34:19,543 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
[14:34:19.545] 2025-08-27 14:34:19,543 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
[14:34:19.545] 🧠 启用SmartResultCollector模式，智能数据管理
[14:34:19.554] 2025-08-27 14:34:19,554 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[14:34:19.879] 2025-08-27 14:34:19,879 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:34:19.879] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7fb6045b5860>
[14:34:19.879] 2025-08-27 14:34:19,879 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[14:34:19.879] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[14:34:19.883] 2025-08-27 14:34:19,882 - batch_test_runner - INFO - ============================================================
[14:34:19.883] 2025-08-27 14:34:19,883 - batch_test_runner - INFO - Batch test runner initialized
[14:34:19.883] 2025-08-27 14:34:19,883 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[14:34:19.883] 2025-08-27 14:34:19,883 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_143419.log
[14:34:19.884] 2025-08-27 14:34:19,883 - batch_test_runner - INFO - ============================================================
[14:34:19.886] 2025-08-27 14:34:19,886 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[14:34:19.886] 2025-08-27 14:34:19,886 - batch_test_runner - INFO - Initializing test components...
[14:35:08.739] 2025-08-27 14:35:08,680 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[14:35:08.756] 2025-08-27 14:35:08,744 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[14:35:08.756] 2025-08-27 14:35:08,744 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[14:35:08.821] [DEBUG] Creating new ToolCapabilityManager instance
[14:35:08.832] [OperationEmbeddingIndex] Initializing with unified API client manager
[14:35:08.843] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[14:35:08.927] 2025-08-27 14:35:08,921 - api_client_manager - INFO - Loaded configuration from config/config.json
[14:35:09.347] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[14:35:09.347] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[14:35:09.347] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[14:35:21.048] 2025-08-27 14:35:21,037 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[14:35:21.231] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[14:35:21.846] [INFO] Loaded 4150 embeddings from persistent cache
[14:35:22.016] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[14:35:22.017] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[14:35:22.102] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[14:35:22.104] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[14:35:22.104] [INFO] Successfully loaded FAISS index with dimension 3072
[14:35:22.104] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[14:35:22.105] [INFO] Loaded 15 operations with dimension 3072
[14:35:22.105] [INFO] Successfully loaded cached index
[14:35:22.105] [INFO] Operation semantic index initialized
[14:35:22.105] [INFO] Using device: cpu
[14:35:22.143] [INFO] Initialized tool success tracking attributes
[14:35:22.144] [INFO] Initializing embedding manager for enhanced tool selection
[14:35:22.145] [MCPEmbeddingManager] Creating new singleton instance
[14:35:22.147] [MCPEmbeddingManager] Initializing with unified API client manager
[14:35:22.347] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[14:35:22.348] [MCPEmbeddingManager] Client initialized successfully
[14:35:22.362] 2025-08-27 14:35:22,349 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:35:26.775] 2025-08-27 14:35:26,741 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:37:10.649] 2025-08-27 14:37:10,363 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[14:37:10.721] 2025-08-27 14:37:10,714 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[14:37:17.011] 2025-08-27 14:37:17,002 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:37:17.439] 2025-08-27 14:37:17,439 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:39:01.394] 2025-08-27 14:39:01,267 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[14:39:02.377] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[14:39:02.399] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[14:39:02.450] 2025-08-27 14:39:02,408 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[14:39:09.846] 2025-08-27 14:39:09,841 - mcp_embedding_manager - INFO - FAISS index loaded
[14:39:09.857] 2025-08-27 14:39:09,854 - mcp_embedding_manager - INFO - Updated dimension to 3072
[14:39:09.857] 2025-08-27 14:39:09,857 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[14:39:11.710] [SUCCESS] Loaded 30 tool embeddings
[14:39:11.815] 2025-08-27 14:39:11,743 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[14:39:11.819] [SUCCESS] Embedding manager initialized with 30 tools
[14:39:11.844] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[14:39:11.857] [INFO] Loading full MCP protocol registry...
[14:39:12.085] 2025-08-27 14:39:12,081 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[14:39:12.091] [INFO] Loaded full tool registry with 30 tools
[14:39:12.093] 2025-08-27 14:39:12,090 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:39:12.093] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:39:12.132] [INFO] Embedding manager ready with 30 tools
[14:39:12.132] [WARNING] Embedding manager exists but has no embeddings
[14:39:12.138] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[14:39:13.209] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:13.252] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:13.252] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:13.273] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[14:39:13.277] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[14:39:13.295] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:13.295] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:13.303] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:13.309] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:13.316] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:13.351] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:13.351] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:13.352] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:13.357] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:13.358] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:13.363] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:13.371] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:13.391] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:13.399] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:13.414] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:13.420] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:13.422] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:13.430] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[14:39:13.438] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[14:39:13.441] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[14:39:13.449] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[14:39:13.452] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[14:39:13.461] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[14:39:13.469] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[14:39:13.472] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[14:39:13.582] 2025-08-27 14:39:13,476 - mdp_workflow_generator - INFO - Loaded 30 tools
[14:39:13.638] [INFO] Setting default state_dim based on loaded tools
[14:39:13.660] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[14:39:13.660] 2025-08-27 14:39:13,651 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[14:39:13.660] [INFO] Setting default action_dim based on loaded tools
[14:39:13.660] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[14:39:13.660] 2025-08-27 14:39:13,660 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[14:39:13.692] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[14:39:13.692] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[14:39:13.692] [INFO] ⚡ Will use pre-generated workflows or random policy
[14:39:13.692] 2025-08-27 14:39:13,692 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[14:39:13.692] [INFO] Initializing TaskManager...
[14:42:15.751] 2025-08-27 14:42:15,672 - unified_training_manager - INFO - Using device: cpu
[14:42:30.479] 2025-08-27 14:42:30,309 - unified_training_manager - INFO - Task filtering results:
[14:42:30.553] 2025-08-27 14:42:30,422 - unified_training_manager - INFO -   Total: 5040 -> 5040
[14:42:30.553] 2025-08-27 14:42:30,450 - unified_training_manager - INFO -   simple_task: 320 -> 320
[14:42:30.553] 2025-08-27 14:42:30,454 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[14:42:30.553] 2025-08-27 14:42:30,463 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[14:42:30.553] 2025-08-27 14:42:30,470 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[14:42:30.553] 2025-08-27 14:42:30,470 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[14:42:30.553] 2025-08-27 14:42:30,507 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[14:42:30.662] 2025-08-27 14:42:30,662 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[14:42:30.670] [TaskManager] Difficulty level 'easy': 1096 tasks
[14:42:30.701] [TaskManager] Difficulty level 'very_easy': 856 tasks
[14:42:30.718] [TaskManager] Difficulty level 'medium': 1136 tasks
[14:42:30.718] [TaskManager] Difficulty level 'hard': 1096 tasks
[14:42:30.718] [TaskManager] Difficulty level 'very_hard': 856 tasks
[14:42:31.371] [INFO] TaskManager initialized with 5040 tasks
[14:42:31.371] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:42:31.378] [INFO] Initializing ToolCallVerifier...
[14:42:31.899] [INFO] ToolCallVerifier initialized with 30 tools
[14:42:31.964] [INFO] Output tools identified: 1
[14:42:31.964] [INFO] Component initialization status:
[14:42:31.964]   - embedding_manager: initialized
[14:42:31.964]   - task_manager: initialized
[14:42:31.964]   - output_verifier: initialized
[14:42:31.965]   - tool_capability_manager: initialized
[14:42:31.965]   - tool_success_rates: initialized with 0 entries
[14:42:31.965] [INFO] MDPWorkflowGenerator initialization complete
[14:42:31.965] 2025-08-27 14:42:31,897 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[14:42:31.967] 2025-08-27 14:42:31,917 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[14:42:31.967] 2025-08-27 14:42:31,932 - batch_test_runner - INFO -   - task_manager: ✓
[14:42:31.967] 2025-08-27 14:42:31,936 - batch_test_runner - INFO -   - output_verifier: ✓
[14:42:31.967] 2025-08-27 14:42:31,937 - batch_test_runner - INFO -   - embedding_manager: ✓
[14:42:31.967] 2025-08-27 14:42:31,939 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[14:42:31.967] 2025-08-27 14:42:31,939 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[14:42:31.996] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140420739862848)
[14:42:31.996] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:31.997] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:42:31.997] [FlawedWorkflowGenerator] RAG support: disabled
[14:42:34.667] 2025-08-27 14:42:34,647 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:42:34.674] [INFO] Enhanced manager: AI错误分类系统已启用
[14:42:34.704] [INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[14:42:35.519] 2025-08-27 14:42:35,505 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
[14:42:35.529] 2025-08-27 14:42:35,516 - result_merger - INFO - ResultMerger初始化完成
[14:42:35.536] 2025-08-27 14:42:35,536 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
[14:42:35.537] [INFO] 后台合并进程已启动（每10秒合并一次）
[14:42:35.538] DEBUG: Checking generator attributes
[14:42:35.539]   - has tool_capabilities: True
[14:42:35.539]   - has tool_capability_manager: True
[14:42:35.539]   - has task_manager: True
[14:42:35.539] [INFO] Loaded 30 tools from generator
[14:42:35.541] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[14:42:35.541] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140420739862848)
[14:42:35.542] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:35.542] [INFO] Initializing LLM client using APIClientManager
[14:42:36.505] [INFO] Using Azure OpenAI client
[14:42:36.510] [DEBUG] Checking if generator has tool_capability_manager attribute
[14:42:36.514] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[14:42:36.521] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140420739862848)
[14:42:36.527] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:36.527] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:42:36.527] [FlawedWorkflowGenerator] RAG support: enabled
[14:42:36.527] [INFO] FlawedWorkflowGenerator initialized successfully
[14:42:36.527] [INFO] Initializing StableScorer for Phase 2 scoring
[14:42:36.527] <tool_capability_manager.ToolCapabilityManager object at 0x7fb6356a4ac0>
[14:42:36.528] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140420739862848)
[14:42:36.528] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:36.528] [INFO] Loaded tool success history for 0 tools
[14:42:36.528] [INFO] StableScorer initialized with semantic capability
[14:42:36.529] [INFO] StableScorer initialized successfully
[14:42:36.551] [INFO] Loading task instances...
[14:42:36.614] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[14:42:37.376] [INFO] Loaded 630 task instances
[14:42:37.383] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:42:37.426] 2025-08-27 14:42:37,409 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[14:42:37.434] 2025-08-27 14:42:37,432 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:46:34.622] 2025-08-27 14:46:34,604 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[14:46:34.637] 2025-08-27 14:46:34,622 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[14:46:38.625] 2025-08-27 14:46:38,602 - batch_test_runner - INFO - Initialization complete
[14:46:44.033] 2025-08-27 14:46:43,942 - batch_test_runner - INFO - Starting batch test with 50 tasks, 2 workers
[14:46:44.063] 2025-08-27 14:46:44,024 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[14:46:44.276] 2025-08-27 14:46:44,271 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:46:44.353] 2025-08-27 14:46:44,321 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:46:44.389] 2025-08-27 14:46:44,384 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:46:44.389] 2025-08-27 14:46:44,388 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:46:44.423] 2025-08-27 14:46:44,400 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:46:44.432] 2025-08-27 14:46:44,432 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
