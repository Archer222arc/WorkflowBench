===== 分片 qwen2.5-14b-instruct_medium_key1 =====
时间: 2025-08-27T14:34:18.294122
模型: qwen2.5-14b-instruct
实例: qwen-key1
命令: python -u smart_batch_runner.py --model qwen2.5-14b-instruct --deployment qwen-key1 --prompt-types optimal --difficulty medium --task-types all --num-instances 10 --max-workers 50 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[14:34:19.338] 
[14:34:19.338] A module that was compiled using NumPy 1.x cannot be run in
[14:34:19.338] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[14:34:19.338] versions of NumPy, modules must be compiled with NumPy 2.0.
[14:34:19.338] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[14:34:19.338] 
[14:34:19.338] If you are a user of the module, the easiest solution will be to
[14:34:19.338] downgrade to 'numpy<2' or try to upgrade the affected module.
[14:34:19.338] We expect that some modules will need time to support NumPy 2.
[14:34:19.338] 
[14:34:19.338] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[14:34:19.338]     from batch_test_runner import BatchTestRunner, TestTask
[14:34:19.338]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[14:34:19.338]     from mdp_workflow_generator import MDPWorkflowGenerator
[14:34:19.338]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[14:34:19.338]     import torch
[14:34:19.338]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[14:34:19.338]     from .functional import *  # noqa: F403
[14:34:19.338]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[14:34:19.338]     import torch.nn.functional as F
[14:34:19.338]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[14:34:19.338]     from .modules import *  # noqa: F403
[14:34:19.338]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[14:34:19.338]     from .transformer import TransformerEncoder, TransformerDecoder, \
[14:34:19.338]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[14:34:19.338]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:34:19.338] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[14:34:19.338]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:34:24.182] 2025-08-27 14:34:24,166 - faiss.loader - INFO - Loading faiss.
[14:34:24.721] 2025-08-27 14:34:24,721 - faiss.loader - INFO - Successfully loaded faiss.
[14:34:29.452] [INFO] 使用JSON存储格式
[14:34:29.464] [INFO] 使用JSON存储格式
[14:34:37.724] [INFO] 使用JSON存储格式
[14:34:37.753] [INFO] 使用JSON存储格式
[14:34:37.757] 
[14:34:37.757] ============================================================
[14:34:37.758] 智能批测试: qwen2.5-14b-instruct (idealab)
[14:34:37.758] Prompt types: ['optimal']
[14:34:37.758] 难度: medium
[14:34:37.758] 目标: 每种配置 10 个实例
[14:34:37.758] ============================================================
[14:34:37.766] ○ simple_task         :   0/ 10 已完成 (需要补充 10 个)
[14:34:37.771] ○ basic_task          :   0/ 10 已完成 (需要补充 10 个)
[14:34:37.776] ○ data_pipeline       :   0/ 10 已完成 (需要补充 10 个)
[14:34:37.783] ○ api_integration     :   0/ 10 已完成 (需要补充 10 个)
[14:34:37.785] ○ multi_stage_pipeline:   0/ 10 已完成 (需要补充 10 个)
[14:34:37.785] 
[14:34:37.785] ⏳ 需要运行 50 个新测试
[14:34:37.785] 
[14:34:37.785] ▶ 准备 simple_task (10 个实例)...
[14:34:37.785] 
[14:34:37.785] ▶ 准备 basic_task (10 个实例)...
[14:34:37.785] 
[14:34:37.785] ▶ 准备 data_pipeline (10 个实例)...
[14:34:37.785] 
[14:34:37.785] ▶ 准备 api_integration (10 个实例)...
[14:34:37.785] 
[14:34:37.785] ▶ 准备 multi_stage_pipeline (10 个实例)...
[14:34:37.785] 
[14:34:37.785] ▶ 开始执行 50 个测试...
[14:34:37.785] 📊 自适应checkpoint_interval: 20
[14:34:37.785] 📦 批量提交模式：每20个测试保存一次
[14:34:37.785] ⚠️  检测到idealab API，调整并发: workers=2, qps=None
[14:34:37.795] 2025-08-27 14:34:37,793 - smart_result_collector - INFO - 自动保存线程已启动
[14:34:37.795] 2025-08-27 14:34:37,795 - smart_result_collector - INFO - SmartResultCollector初始化完成
[14:34:37.795] 2025-08-27 14:34:37,795 - smart_result_collector - INFO -   - 临时目录: temp_results
[14:34:37.795] 2025-08-27 14:34:37,795 - smart_result_collector - INFO -   - 内存阈值: 20
[14:34:37.795] 2025-08-27 14:34:37,795 - smart_result_collector - INFO -   - 时间阈值: 300秒
[14:34:37.795] 2025-08-27 14:34:37,795 - smart_result_collector - INFO -   - 自动保存: 60秒
[14:34:37.795] 2025-08-27 14:34:37,795 - smart_result_collector - INFO -   - 自适应阈值: True
[14:34:37.795] 2025-08-27 14:34:37,795 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
[14:34:37.795] 2025-08-27 14:34:37,795 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
[14:34:37.795] 🧠 启用SmartResultCollector模式，智能数据管理
[14:34:37.805] 2025-08-27 14:34:37,804 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[14:34:38.192] 2025-08-27 14:34:38,192 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:34:38.192] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7fbf1b9af490>
[14:34:38.192] 2025-08-27 14:34:38,192 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[14:34:38.192] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[14:34:38.195] 2025-08-27 14:34:38,195 - batch_test_runner - INFO - ============================================================
[14:34:38.200] 2025-08-27 14:34:38,195 - batch_test_runner - INFO - Batch test runner initialized
[14:34:38.201] 2025-08-27 14:34:38,196 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[14:34:38.201] 2025-08-27 14:34:38,196 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_143437.log
[14:34:38.201] 2025-08-27 14:34:38,198 - batch_test_runner - INFO - ============================================================
[14:34:38.201] 2025-08-27 14:34:38,198 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[14:34:38.201] 2025-08-27 14:34:38,199 - batch_test_runner - INFO - Initializing test components...
[14:35:40.413] 2025-08-27 14:35:40,333 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[14:35:40.457] 2025-08-27 14:35:40,370 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[14:35:40.457] 2025-08-27 14:35:40,378 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[14:35:40.457] [DEBUG] Creating new ToolCapabilityManager instance
[14:35:40.467] [OperationEmbeddingIndex] Initializing with unified API client manager
[14:35:40.491] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[14:35:40.508] 2025-08-27 14:35:40,503 - api_client_manager - INFO - Loaded configuration from config/config.json
[14:35:41.064] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[14:35:41.142] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[14:35:41.171] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[14:35:56.562] 2025-08-27 14:35:56,524 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[14:35:56.953] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[14:35:57.809] [INFO] Loaded 4150 embeddings from persistent cache
[14:35:57.825] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[14:35:57.825] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[14:35:57.913] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[14:35:57.917] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[14:35:58.028] [INFO] Successfully loaded FAISS index with dimension 3072
[14:35:58.030] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[14:35:58.030] [INFO] Loaded 15 operations with dimension 3072
[14:35:58.045] [INFO] Successfully loaded cached index
[14:35:58.085] [INFO] Operation semantic index initialized
[14:35:58.168] [INFO] Using device: cpu
[14:35:58.269] [INFO] Initialized tool success tracking attributes
[14:35:58.272] [INFO] Initializing embedding manager for enhanced tool selection
[14:35:58.272] [MCPEmbeddingManager] Creating new singleton instance
[14:35:58.279] [MCPEmbeddingManager] Initializing with unified API client manager
[14:35:58.686] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[14:35:58.703] [MCPEmbeddingManager] Client initialized successfully
[14:35:58.743] 2025-08-27 14:35:58,699 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:36:06.424] 2025-08-27 14:36:06,402 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:37:47.282] 2025-08-27 14:37:47,222 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[14:37:47.322] 2025-08-27 14:37:47,258 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[14:37:51.794] 2025-08-27 14:37:51,750 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:37:52.193] 2025-08-27 14:37:52,193 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:39:37.529] 2025-08-27 14:39:37,403 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[14:39:38.379] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[14:39:38.401] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[14:39:38.462] 2025-08-27 14:39:38,422 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[14:39:44.212] 2025-08-27 14:39:44,148 - mcp_embedding_manager - INFO - FAISS index loaded
[14:39:44.222] 2025-08-27 14:39:44,187 - mcp_embedding_manager - INFO - Updated dimension to 3072
[14:39:44.226] 2025-08-27 14:39:44,191 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[14:39:45.750] [SUCCESS] Loaded 30 tool embeddings
[14:39:45.799] 2025-08-27 14:39:45,773 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[14:39:45.800] [SUCCESS] Embedding manager initialized with 30 tools
[14:39:45.830] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[14:39:45.832] [INFO] Loading full MCP protocol registry...
[14:39:46.583] 2025-08-27 14:39:46,520 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[14:39:46.588] [INFO] Loaded full tool registry with 30 tools
[14:39:46.589] 2025-08-27 14:39:46,578 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:39:46.590] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:39:46.631] [INFO] Embedding manager ready with 30 tools
[14:39:46.631] [WARNING] Embedding manager exists but has no embeddings
[14:39:46.633] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[14:39:48.489] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:48.847] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:49.191] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:49.216] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[14:39:49.598] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[14:39:49.604] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:49.605] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:49.605] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:49.605] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:49.605] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:49.605] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:49.605] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:49.605] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:49.605] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:49.605] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:49.605] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:49.606] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:49.607] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:49.607] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:49.607] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:49.607] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:49.607] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:49.609] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[14:39:49.609] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[14:39:49.609] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[14:39:49.614] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[14:39:49.614] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[14:39:49.615] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[14:39:49.616] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[14:39:49.616] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[14:39:49.616] 2025-08-27 14:39:48,613 - mdp_workflow_generator - INFO - Loaded 30 tools
[14:39:49.616] [INFO] Setting default state_dim based on loaded tools
[14:39:49.616] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[14:39:49.616] 2025-08-27 14:39:48,624 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[14:39:49.616] [INFO] Setting default action_dim based on loaded tools
[14:39:49.616] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[14:39:49.616] 2025-08-27 14:39:48,625 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[14:39:49.616] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[14:39:49.617] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[14:39:49.617] [INFO] ⚡ Will use pre-generated workflows or random policy
[14:39:49.617] 2025-08-27 14:39:48,633 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[14:39:49.617] [INFO] Initializing TaskManager...
[14:43:51.671] 2025-08-27 14:43:51,573 - unified_training_manager - INFO - Using device: cpu
[14:44:06.156] 2025-08-27 14:44:05,784 - unified_training_manager - INFO - Task filtering results:
[14:44:06.300] 2025-08-27 14:44:05,948 - unified_training_manager - INFO -   Total: 5040 -> 5040
[14:44:06.303] 2025-08-27 14:44:05,977 - unified_training_manager - INFO -   simple_task: 320 -> 320
[14:44:06.307] 2025-08-27 14:44:05,994 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[14:44:06.307] 2025-08-27 14:44:05,994 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[14:44:06.307] 2025-08-27 14:44:05,994 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[14:44:06.307] 2025-08-27 14:44:05,994 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[14:44:06.307] 2025-08-27 14:44:06,084 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[14:44:06.394] 2025-08-27 14:44:06,384 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[14:44:06.413] [TaskManager] Difficulty level 'easy': 1096 tasks
[14:44:06.413] [TaskManager] Difficulty level 'very_easy': 856 tasks
[14:44:06.413] [TaskManager] Difficulty level 'medium': 1136 tasks
[14:44:06.413] [TaskManager] Difficulty level 'hard': 1096 tasks
[14:44:06.413] [TaskManager] Difficulty level 'very_hard': 856 tasks
[14:44:07.089] [INFO] TaskManager initialized with 5040 tasks
[14:44:07.090] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:44:07.090] [INFO] Initializing ToolCallVerifier...
[14:44:07.788] [INFO] ToolCallVerifier initialized with 30 tools
[14:44:07.975] [INFO] Output tools identified: 1
[14:44:07.976] [INFO] Component initialization status:
[14:44:07.990]   - embedding_manager: initialized
[14:44:07.990]   - task_manager: initialized
[14:44:07.990]   - output_verifier: initialized
[14:44:07.990]   - tool_capability_manager: initialized
[14:44:07.990]   - tool_success_rates: initialized with 0 entries
[14:44:07.991] [INFO] MDPWorkflowGenerator initialization complete
[14:44:07.991] 2025-08-27 14:44:07,800 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[14:44:07.991] 2025-08-27 14:44:07,842 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[14:44:07.991] 2025-08-27 14:44:07,909 - batch_test_runner - INFO -   - task_manager: ✓
[14:44:07.991] 2025-08-27 14:44:07,970 - batch_test_runner - INFO -   - output_verifier: ✓
[14:44:07.991] 2025-08-27 14:44:07,972 - batch_test_runner - INFO -   - embedding_manager: ✓
[14:44:07.991] 2025-08-27 14:44:07,972 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[14:44:07.991] 2025-08-27 14:44:07,972 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[14:44:08.030] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140458756986336)
[14:44:08.031] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:44:08.034] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:44:08.034] [FlawedWorkflowGenerator] RAG support: disabled
[14:44:14.022] 2025-08-27 14:44:13,907 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:44:14.474] [INFO] Enhanced manager: AI错误分类系统已启用
[14:44:14.560] [INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[14:44:15.475] 2025-08-27 14:44:15,461 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
[14:44:15.476] 2025-08-27 14:44:15,464 - result_merger - INFO - ResultMerger初始化完成
[14:44:15.498] 2025-08-27 14:44:15,498 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
[14:44:15.573] [INFO] 后台合并进程已启动（每10秒合并一次）
[14:44:15.639] DEBUG: Checking generator attributes
[14:44:15.639]   - has tool_capabilities: True
[14:44:15.639]   - has tool_capability_manager: True
[14:44:15.639]   - has task_manager: True
[14:44:15.639] [INFO] Loaded 30 tools from generator
[14:44:15.639] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[14:44:15.639] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140458756986336)
[14:44:15.639] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:44:15.639] [INFO] Initializing LLM client using APIClientManager
[14:44:16.525] [INFO] Using Azure OpenAI client
[14:44:16.576] [DEBUG] Checking if generator has tool_capability_manager attribute
[14:44:16.578] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[14:44:16.582] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140458756986336)
[14:44:16.583] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:44:16.583] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:44:16.585] [FlawedWorkflowGenerator] RAG support: enabled
[14:44:16.585] [INFO] FlawedWorkflowGenerator initialized successfully
[14:44:16.585] [INFO] Initializing StableScorer for Phase 2 scoring
[14:44:16.585] <tool_capability_manager.ToolCapabilityManager object at 0x7fbf1b9aea30>
[14:44:16.585] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140458756986336)
[14:44:16.585] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:44:16.585] [INFO] Loaded tool success history for 0 tools
[14:44:16.585] [INFO] StableScorer initialized with semantic capability
[14:44:16.585] [INFO] StableScorer initialized successfully
[14:44:16.585] [INFO] Loading task instances...
[14:44:16.585] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[14:44:16.739] [INFO] Loaded 630 task instances
[14:44:16.796] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:44:16.837] 2025-08-27 14:44:16,746 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[14:44:16.837] 2025-08-27 14:44:16,797 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:47:34.982] 2025-08-27 14:47:34,953 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[14:47:35.134] 2025-08-27 14:47:34,970 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[14:47:37.091] 2025-08-27 14:47:37,076 - batch_test_runner - INFO - Initialization complete
[14:47:42.484] 2025-08-27 14:47:42,438 - batch_test_runner - INFO - Starting batch test with 50 tasks, 2 workers
[14:47:42.505] 2025-08-27 14:47:42,482 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[14:47:42.887] 2025-08-27 14:47:42,798 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:47:43.182] 2025-08-27 14:47:43,058 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:47:43.213] 2025-08-27 14:47:43,165 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:47:43.232] 2025-08-27 14:47:43,223 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:47:43.255] 2025-08-27 14:47:43,234 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:47:43.289] 2025-08-27 14:47:43,258 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
