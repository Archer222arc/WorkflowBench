===== 分片 qwen2.5-32b-instruct_medium_key0 =====
时间: 2025-08-27T14:33:56.613714
模型: qwen2.5-32b-instruct
实例: qwen-key0
命令: python -u smart_batch_runner.py --model qwen2.5-32b-instruct --deployment qwen-key0 --prompt-types optimal --difficulty medium --task-types all --num-instances 10 --max-workers 50 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[14:34:09.043] 
[14:34:09.050] A module that was compiled using NumPy 1.x cannot be run in
[14:34:09.050] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[14:34:09.050] versions of NumPy, modules must be compiled with NumPy 2.0.
[14:34:09.052] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[14:34:09.052] 
[14:34:09.052] If you are a user of the module, the easiest solution will be to
[14:34:09.052] downgrade to 'numpy<2' or try to upgrade the affected module.
[14:34:09.052] We expect that some modules will need time to support NumPy 2.
[14:34:09.052] 
[14:34:09.052] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[14:34:09.052]     from batch_test_runner import BatchTestRunner, TestTask
[14:34:09.052]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[14:34:09.052]     from mdp_workflow_generator import MDPWorkflowGenerator
[14:34:09.053]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[14:34:09.055]     import torch
[14:34:09.055]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[14:34:09.055]     from .functional import *  # noqa: F403
[14:34:09.055]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[14:34:09.055]     import torch.nn.functional as F
[14:34:09.055]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[14:34:09.055]     from .modules import *  # noqa: F403
[14:34:09.055]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[14:34:09.055]     from .transformer import TransformerEncoder, TransformerDecoder, \
[14:34:09.055]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[14:34:09.055]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:34:09.055] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[14:34:09.059]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:34:13.133] 2025-08-27 14:34:13,114 - faiss.loader - INFO - Loading faiss.
[14:34:13.498] 2025-08-27 14:34:13,491 - faiss.loader - INFO - Successfully loaded faiss.
[14:34:16.736] [INFO] 使用JSON存储格式
[14:34:16.739] [INFO] 使用JSON存储格式
[14:34:19.523] [INFO] 使用JSON存储格式
[14:34:19.535] [INFO] 使用JSON存储格式
[14:34:19.535] 
[14:34:19.537] ============================================================
[14:34:19.537] 智能批测试: qwen2.5-32b-instruct (idealab)
[14:34:19.537] Prompt types: ['optimal']
[14:34:19.539] 难度: medium
[14:34:19.540] 目标: 每种配置 10 个实例
[14:34:19.540] ============================================================
[14:34:19.540] ○ simple_task         :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.540] ○ basic_task          :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.540] ○ data_pipeline       :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.549] ○ api_integration     :   0/ 10 已完成 (需要补充 10 个)
[14:34:19.552] ○ multi_stage_pipeline:   0/ 10 已完成 (需要补充 10 个)
[14:34:19.552] 
[14:34:19.552] ⏳ 需要运行 50 个新测试
[14:34:19.552] 
[14:34:19.552] ▶ 准备 simple_task (10 个实例)...
[14:34:19.552] 
[14:34:19.552] ▶ 准备 basic_task (10 个实例)...
[14:34:19.552] 
[14:34:19.552] ▶ 准备 data_pipeline (10 个实例)...
[14:34:19.552] 
[14:34:19.552] ▶ 准备 api_integration (10 个实例)...
[14:34:19.552] 
[14:34:19.552] ▶ 准备 multi_stage_pipeline (10 个实例)...
[14:34:19.552] 
[14:34:19.552] ▶ 开始执行 50 个测试...
[14:34:19.552] 📊 自适应checkpoint_interval: 20
[14:34:19.552] 📦 批量提交模式：每20个测试保存一次
[14:34:19.552] ⚠️  检测到idealab API，调整并发: workers=2, qps=None
[14:34:19.561] 2025-08-27 14:34:19,553 - smart_result_collector - INFO - 自动保存线程已启动
[14:34:19.561] 2025-08-27 14:34:19,561 - smart_result_collector - INFO - SmartResultCollector初始化完成
[14:34:19.562] 2025-08-27 14:34:19,561 - smart_result_collector - INFO -   - 临时目录: temp_results
[14:34:19.562] 2025-08-27 14:34:19,562 - smart_result_collector - INFO -   - 内存阈值: 20
[14:34:19.562] 2025-08-27 14:34:19,562 - smart_result_collector - INFO -   - 时间阈值: 300秒
[14:34:19.562] 2025-08-27 14:34:19,562 - smart_result_collector - INFO -   - 自动保存: 60秒
[14:34:19.562] 2025-08-27 14:34:19,562 - smart_result_collector - INFO -   - 自适应阈值: True
[14:34:19.562] 2025-08-27 14:34:19,562 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
[14:34:19.562] 2025-08-27 14:34:19,562 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
[14:34:19.562] 🧠 启用SmartResultCollector模式，智能数据管理
[14:34:19.568] 2025-08-27 14:34:19,568 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[14:34:19.878] 2025-08-27 14:34:19,878 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:34:19.879] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7f8bc61600c0>
[14:34:19.879] 2025-08-27 14:34:19,878 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[14:34:19.879] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[14:34:19.884] 2025-08-27 14:34:19,883 - batch_test_runner - INFO - ============================================================
[14:34:19.884] 2025-08-27 14:34:19,884 - batch_test_runner - INFO - Batch test runner initialized
[14:34:19.884] 2025-08-27 14:34:19,884 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[14:34:19.885] 2025-08-27 14:34:19,885 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_143419.log
[14:34:19.885] 2025-08-27 14:34:19,885 - batch_test_runner - INFO - ============================================================
[14:34:19.886] 2025-08-27 14:34:19,886 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[14:34:19.887] 2025-08-27 14:34:19,886 - batch_test_runner - INFO - Initializing test components...
[14:35:08.415] 2025-08-27 14:35:08,258 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[14:35:08.557] 2025-08-27 14:35:08,333 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[14:35:08.582] 2025-08-27 14:35:08,334 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[14:35:08.583] [DEBUG] Creating new ToolCapabilityManager instance
[14:35:08.599] [OperationEmbeddingIndex] Initializing with unified API client manager
[14:35:08.608] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[14:35:08.622] 2025-08-27 14:35:08,530 - api_client_manager - INFO - Loaded configuration from config/config.json
[14:35:09.337] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[14:35:09.338] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[14:35:09.338] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[14:35:21.017] 2025-08-27 14:35:20,985 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[14:35:21.204] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[14:35:21.856] [INFO] Loaded 4150 embeddings from persistent cache
[14:35:22.017] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[14:35:22.017] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[14:35:22.104] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[14:35:22.104] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[14:35:22.104] [INFO] Successfully loaded FAISS index with dimension 3072
[14:35:22.105] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[14:35:22.105] [INFO] Loaded 15 operations with dimension 3072
[14:35:22.105] [INFO] Successfully loaded cached index
[14:35:22.105] [INFO] Operation semantic index initialized
[14:35:22.105] [INFO] Using device: cpu
[14:35:22.158] [INFO] Initialized tool success tracking attributes
[14:35:22.159] [INFO] Initializing embedding manager for enhanced tool selection
[14:35:22.159] [MCPEmbeddingManager] Creating new singleton instance
[14:35:22.164] [MCPEmbeddingManager] Initializing with unified API client manager
[14:35:22.378] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[14:35:22.378] [MCPEmbeddingManager] Client initialized successfully
[14:35:22.390] 2025-08-27 14:35:22,380 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:35:26.783] 2025-08-27 14:35:26,760 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:37:10.147] 2025-08-27 14:37:09,918 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[14:37:10.403] 2025-08-27 14:37:10,091 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[14:37:16.410] 2025-08-27 14:37:16,377 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:37:18.064] 2025-08-27 14:37:18,053 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:39:02.090] 2025-08-27 14:39:01,947 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[14:39:03.103] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[14:39:03.134] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[14:39:03.149] 2025-08-27 14:39:03,129 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[14:39:11.345] 2025-08-27 14:39:11,331 - mcp_embedding_manager - INFO - FAISS index loaded
[14:39:11.354] 2025-08-27 14:39:11,344 - mcp_embedding_manager - INFO - Updated dimension to 3072
[14:39:11.354] 2025-08-27 14:39:11,351 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[14:39:13.659] [SUCCESS] Loaded 30 tool embeddings
[14:39:13.918] 2025-08-27 14:39:13,796 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[14:39:13.918] [SUCCESS] Embedding manager initialized with 30 tools
[14:39:13.999] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[14:39:14.004] [INFO] Loading full MCP protocol registry...
[14:39:15.078] 2025-08-27 14:39:15,067 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[14:39:15.079] [INFO] Loaded full tool registry with 30 tools
[14:39:15.087] 2025-08-27 14:39:15,087 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:39:15.087] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:39:15.175] [INFO] Embedding manager ready with 30 tools
[14:39:15.175] [WARNING] Embedding manager exists but has no embeddings
[14:39:15.188] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[14:39:15.782] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:15.873] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:15.890] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:15.904] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[14:39:15.935] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[14:39:15.944] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:15.961] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:15.972] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:16.009] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:16.019] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:16.028] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:16.038] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:39:16.039] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:16.056] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:16.056] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[14:39:16.070] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:16.072] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:16.072] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:39:16.076] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:16.076] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:16.076] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:16.082] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[14:39:16.088] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[14:39:16.088] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[14:39:16.092] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[14:39:16.097] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[14:39:16.098] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[14:39:16.118] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[14:39:16.118] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[14:39:16.118] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[14:39:16.144] 2025-08-27 14:39:16,118 - mdp_workflow_generator - INFO - Loaded 30 tools
[14:39:16.155] [INFO] Setting default state_dim based on loaded tools
[14:39:16.155] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[14:39:16.155] 2025-08-27 14:39:16,155 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[14:39:16.155] [INFO] Setting default action_dim based on loaded tools
[14:39:16.155] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[14:39:16.155] 2025-08-27 14:39:16,155 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[14:39:16.191] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[14:39:16.191] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[14:39:16.191] [INFO] ⚡ Will use pre-generated workflows or random policy
[14:39:16.209] 2025-08-27 14:39:16,191 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[14:39:16.209] [INFO] Initializing TaskManager...
[14:42:14.331] 2025-08-27 14:42:14,195 - unified_training_manager - INFO - Using device: cpu
[14:42:18.787] 2025-08-27 14:42:18,691 - unified_training_manager - INFO - Task filtering results:
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO -   Total: 5040 -> 5040
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO -   simple_task: 320 -> 320
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[14:42:18.847] 2025-08-27 14:42:18,760 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[14:42:18.847] 2025-08-27 14:42:18,820 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[14:42:18.847] [TaskManager] Difficulty level 'easy': 1096 tasks
[14:42:18.847] [TaskManager] Difficulty level 'very_easy': 856 tasks
[14:42:18.863] [TaskManager] Difficulty level 'medium': 1136 tasks
[14:42:18.882] [TaskManager] Difficulty level 'hard': 1096 tasks
[14:42:18.882] [TaskManager] Difficulty level 'very_hard': 856 tasks
[14:42:18.887] [INFO] TaskManager initialized with 5040 tasks
[14:42:18.888] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:42:18.888] [INFO] Initializing ToolCallVerifier...
[14:42:19.539] [INFO] ToolCallVerifier initialized with 30 tools
[14:42:19.812] [INFO] Output tools identified: 1
[14:42:19.812] [INFO] Component initialization status:
[14:42:19.812]   - embedding_manager: initialized
[14:42:19.812]   - task_manager: initialized
[14:42:19.812]   - output_verifier: initialized
[14:42:19.812]   - tool_capability_manager: initialized
[14:42:19.812]   - tool_success_rates: initialized with 0 entries
[14:42:19.812] [INFO] MDPWorkflowGenerator initialization complete
[14:42:19.812] 2025-08-27 14:42:19,544 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[14:42:19.812] 2025-08-27 14:42:19,569 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[14:42:19.812] 2025-08-27 14:42:19,590 - batch_test_runner - INFO -   - task_manager: ✓
[14:42:19.812] 2025-08-27 14:42:19,590 - batch_test_runner - INFO -   - output_verifier: ✓
[14:42:19.812] 2025-08-27 14:42:19,590 - batch_test_runner - INFO -   - embedding_manager: ✓
[14:42:19.812] 2025-08-27 14:42:19,590 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[14:42:19.812] 2025-08-27 14:42:19,590 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[14:42:19.812] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140239291370064)
[14:42:19.812] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:19.812] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:42:19.812] [FlawedWorkflowGenerator] RAG support: disabled
[14:42:21.375] 2025-08-27 14:42:21,356 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:42:21.377] [INFO] Enhanced manager: AI错误分类系统已启用
[14:42:21.414] [INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[14:42:21.718] 2025-08-27 14:42:21,718 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
[14:42:21.729] 2025-08-27 14:42:21,718 - result_merger - INFO - ResultMerger初始化完成
[14:42:21.735] 2025-08-27 14:42:21,735 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
[14:42:21.745] [INFO] 后台合并进程已启动（每10秒合并一次）
[14:42:21.753] DEBUG: Checking generator attributes
[14:42:21.753]   - has tool_capabilities: True
[14:42:21.753]   - has tool_capability_manager: True
[14:42:21.753]   - has task_manager: True
[14:42:21.753] [INFO] Loaded 30 tools from generator
[14:42:21.753] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[14:42:21.772] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140239291370064)
[14:42:21.772] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:21.772] [INFO] Initializing LLM client using APIClientManager
[14:42:22.300] [INFO] Using Azure OpenAI client
[14:42:22.301] [DEBUG] Checking if generator has tool_capability_manager attribute
[14:42:22.305] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[14:42:22.330] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140239291370064)
[14:42:22.330] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:22.330] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:42:22.330] [FlawedWorkflowGenerator] RAG support: enabled
[14:42:22.330] [INFO] FlawedWorkflowGenerator initialized successfully
[14:42:22.330] [INFO] Initializing StableScorer for Phase 2 scoring
[14:42:22.330] <tool_capability_manager.ToolCapabilityManager object at 0x7f8c0025f1f0>
[14:42:22.330] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140239291370064)
[14:42:22.330] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:42:22.330] [INFO] Loaded tool success history for 0 tools
[14:42:22.331] [INFO] StableScorer initialized with semantic capability
[14:42:22.331] [INFO] StableScorer initialized successfully
[14:42:22.331] [INFO] Loading task instances...
[14:42:22.331] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[14:42:22.397] [INFO] Loaded 630 task instances
[14:42:22.397] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:42:22.398] 2025-08-27 14:42:22,397 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[14:42:22.398] 2025-08-27 14:42:22,398 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:46:25.734] 2025-08-27 14:46:25,694 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[14:46:25.779] 2025-08-27 14:46:25,713 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[14:46:27.403] 2025-08-27 14:46:27,400 - batch_test_runner - INFO - Initialization complete
[14:46:30.097] 2025-08-27 14:46:29,982 - batch_test_runner - INFO - Starting batch test with 50 tasks, 2 workers
[14:46:30.164] 2025-08-27 14:46:30,085 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[14:46:30.385] 2025-08-27 14:46:30,343 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:46:30.401] 2025-08-27 14:46:30,382 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:46:30.574] 2025-08-27 14:46:30,522 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:46:30.585] 2025-08-27 14:46:30,493 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:46:30.596] 2025-08-27 14:46:30,593 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:46:30.744] 2025-08-27 14:46:30,707 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
