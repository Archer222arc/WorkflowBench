===== 分片 qwen2.5-72b-instruct_medium_key0 =====
时间: 2025-08-27T14:33:40.678653
模型: qwen2.5-72b-instruct
实例: qwen-key0
命令: python -u smart_batch_runner.py --model qwen2.5-72b-instruct --deployment qwen-key0 --prompt-types optimal --difficulty medium --task-types all --num-instances 10 --max-workers 50 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[14:33:42.499] 
[14:33:42.536] A module that was compiled using NumPy 1.x cannot be run in
[14:33:42.536] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[14:33:42.536] versions of NumPy, modules must be compiled with NumPy 2.0.
[14:33:42.536] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[14:33:42.536] 
[14:33:42.536] If you are a user of the module, the easiest solution will be to
[14:33:42.536] downgrade to 'numpy<2' or try to upgrade the affected module.
[14:33:42.536] We expect that some modules will need time to support NumPy 2.
[14:33:42.536] 
[14:33:42.536] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[14:33:42.536]     from batch_test_runner import BatchTestRunner, TestTask
[14:33:42.536]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[14:33:42.536]     from mdp_workflow_generator import MDPWorkflowGenerator
[14:33:42.536]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[14:33:42.536]     import torch
[14:33:42.536]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[14:33:42.536]     from .functional import *  # noqa: F403
[14:33:42.536]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[14:33:42.536]     import torch.nn.functional as F
[14:33:42.536]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[14:33:42.536]     from .modules import *  # noqa: F403
[14:33:42.536]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[14:33:42.536]     from .transformer import TransformerEncoder, TransformerDecoder, \
[14:33:42.536]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[14:33:42.536]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:33:42.538] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[14:33:42.542]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[14:33:46.759] 2025-08-27 14:33:46,716 - faiss.loader - INFO - Loading faiss.
[14:33:47.102] 2025-08-27 14:33:47,098 - faiss.loader - INFO - Successfully loaded faiss.
[14:33:51.816] [INFO] 使用JSON存储格式
[14:33:51.820] [INFO] 使用JSON存储格式
[14:34:02.691] [INFO] 使用JSON存储格式
[14:34:02.725] [INFO] 使用JSON存储格式
[14:34:02.741] 
[14:34:02.746] ============================================================
[14:34:02.750] 智能批测试: qwen2.5-72b-instruct (idealab)
[14:34:02.754] Prompt types: ['optimal']
[14:34:02.754] 难度: medium
[14:34:02.754] 目标: 每种配置 10 个实例
[14:34:02.754] ============================================================
[14:34:02.764] ○ simple_task         :   0/ 10 已完成 (需要补充 10 个)
[14:34:02.768] ○ basic_task          :   0/ 10 已完成 (需要补充 10 个)
[14:34:02.773] ○ data_pipeline       :   0/ 10 已完成 (需要补充 10 个)
[14:34:02.773] ○ api_integration     :   0/ 10 已完成 (需要补充 10 个)
[14:34:02.775] ○ multi_stage_pipeline:   0/ 10 已完成 (需要补充 10 个)
[14:34:02.775] 
[14:34:02.775] ⏳ 需要运行 50 个新测试
[14:34:02.775] 
[14:34:02.775] ▶ 准备 simple_task (10 个实例)...
[14:34:02.775] 
[14:34:02.775] ▶ 准备 basic_task (10 个实例)...
[14:34:02.775] 
[14:34:02.775] ▶ 准备 data_pipeline (10 个实例)...
[14:34:02.775] 
[14:34:02.775] ▶ 准备 api_integration (10 个实例)...
[14:34:02.775] 
[14:34:02.775] ▶ 准备 multi_stage_pipeline (10 个实例)...
[14:34:02.775] 
[14:34:02.775] ▶ 开始执行 50 个测试...
[14:34:02.775] 📊 自适应checkpoint_interval: 20
[14:34:02.775] 📦 批量提交模式：每20个测试保存一次
[14:34:02.775] ⚠️  检测到idealab API，调整并发: workers=2, qps=None
[14:34:02.779] 2025-08-27 14:34:02,778 - smart_result_collector - INFO - 自动保存线程已启动
[14:34:02.779] 2025-08-27 14:34:02,779 - smart_result_collector - INFO - SmartResultCollector初始化完成
[14:34:02.779] 2025-08-27 14:34:02,779 - smart_result_collector - INFO -   - 临时目录: temp_results
[14:34:02.779] 2025-08-27 14:34:02,779 - smart_result_collector - INFO -   - 内存阈值: 20
[14:34:02.779] 2025-08-27 14:34:02,779 - smart_result_collector - INFO -   - 时间阈值: 300秒
[14:34:02.779] 2025-08-27 14:34:02,779 - smart_result_collector - INFO -   - 自动保存: 60秒
[14:34:02.779] 2025-08-27 14:34:02,779 - smart_result_collector - INFO -   - 自适应阈值: True
[14:34:02.779] 2025-08-27 14:34:02,779 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
[14:34:02.779] 2025-08-27 14:34:02,779 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
[14:34:02.779] 🧠 启用SmartResultCollector模式，智能数据管理
[14:34:02.796] 2025-08-27 14:34:02,796 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[14:34:03.201] 2025-08-27 14:34:03,200 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:34:03.201] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7fe14ca4cf60>
[14:34:03.201] 2025-08-27 14:34:03,200 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[14:34:03.201] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - ============================================================
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - Batch test runner initialized
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_143402.log
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - ============================================================
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[14:34:03.203] 2025-08-27 14:34:03,203 - batch_test_runner - INFO - Initializing test components...
[14:34:27.721] 2025-08-27 14:34:27,637 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[14:34:27.770] 2025-08-27 14:34:27,673 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[14:34:27.777] 2025-08-27 14:34:27,673 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[14:34:27.784] [DEBUG] Creating new ToolCapabilityManager instance
[14:34:27.785] [OperationEmbeddingIndex] Initializing with unified API client manager
[14:34:27.787] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[14:34:27.787] 2025-08-27 14:34:27,751 - api_client_manager - INFO - Loaded configuration from config/config.json
[14:34:27.933] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[14:34:27.936] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[14:34:27.936] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[14:34:29.794] 2025-08-27 14:34:29,786 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[14:34:29.931] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[14:34:30.265] [INFO] Loaded 4150 embeddings from persistent cache
[14:34:30.266] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[14:34:30.266] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[14:34:30.316] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[14:34:30.319] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[14:34:30.319] [INFO] Successfully loaded FAISS index with dimension 3072
[14:34:30.319] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[14:34:30.319] [INFO] Loaded 15 operations with dimension 3072
[14:34:30.319] [INFO] Successfully loaded cached index
[14:34:30.320] [INFO] Operation semantic index initialized
[14:34:30.344] [INFO] Using device: cpu
[14:34:30.367] [INFO] Initialized tool success tracking attributes
[14:34:30.367] [INFO] Initializing embedding manager for enhanced tool selection
[14:34:30.372] [MCPEmbeddingManager] Creating new singleton instance
[14:34:30.377] [MCPEmbeddingManager] Initializing with unified API client manager
[14:34:30.411] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[14:34:30.411] [MCPEmbeddingManager] Client initialized successfully
[14:34:30.414] 2025-08-27 14:34:30,412 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:34:30.880] 2025-08-27 14:34:30,877 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:35:56.369] 2025-08-27 14:35:56,264 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[14:35:56.403] 2025-08-27 14:35:56,358 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[14:36:03.773] 2025-08-27 14:36:03,719 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[14:36:08.193] 2025-08-27 14:36:08,177 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[14:37:55.973] 2025-08-27 14:37:55,878 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[14:37:56.035] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[14:37:56.043] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[14:37:56.046] 2025-08-27 14:37:55,995 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[14:37:56.567] 2025-08-27 14:37:56,567 - mcp_embedding_manager - INFO - FAISS index loaded
[14:37:56.570] 2025-08-27 14:37:56,569 - mcp_embedding_manager - INFO - Updated dimension to 3072
[14:37:56.571] 2025-08-27 14:37:56,569 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[14:37:56.594] [SUCCESS] Loaded 30 tool embeddings
[14:37:56.600] 2025-08-27 14:37:56,600 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[14:37:56.605] [SUCCESS] Embedding manager initialized with 30 tools
[14:37:56.606] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[14:37:56.606] [INFO] Loading full MCP protocol registry...
[14:37:56.643] 2025-08-27 14:37:56,643 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[14:37:56.672] [INFO] Loaded full tool registry with 30 tools
[14:37:56.672] 2025-08-27 14:37:56,648 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:37:56.672] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[14:37:56.672] [INFO] Embedding manager ready with 30 tools
[14:37:56.672] [WARNING] Embedding manager exists but has no embeddings
[14:37:56.682] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[14:37:56.881] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[14:37:56.896] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[14:37:56.898] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:37:56.900] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[14:37:56.900] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[14:37:56.900] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:37:56.900] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:37:56.902] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:37:56.902] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:37:56.903] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[14:37:56.903] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:37:56.903] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[14:37:56.903] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[14:37:56.903] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[14:37:56.903] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[14:37:56.908] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:37:56.911] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:37:56.911] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[14:37:56.911] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[14:37:56.911] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[14:37:56.911] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[14:37:56.911] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[14:37:56.913] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[14:37:56.913] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[14:37:56.913] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[14:37:56.917] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[14:37:56.917] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[14:37:56.918] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[14:37:56.919] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[14:37:56.920] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[14:37:56.920] 2025-08-27 14:37:56,920 - mdp_workflow_generator - INFO - Loaded 30 tools
[14:37:56.923] [INFO] Setting default state_dim based on loaded tools
[14:37:56.923] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[14:37:56.923] 2025-08-27 14:37:56,920 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[14:37:56.923] [INFO] Setting default action_dim based on loaded tools
[14:37:56.923] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[14:37:56.923] 2025-08-27 14:37:56,920 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[14:37:56.932] [INFO] ⚡ SKIP_MODEL_LOADING=true - Skipping neural network model loading
[14:37:56.932] [INFO] ⚡ Memory optimization: Saving ~350MB by not loading model
[14:37:56.932] [INFO] ⚡ Will use pre-generated workflows or random policy
[14:37:56.935] 2025-08-27 14:37:56,932 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[14:37:56.935] [INFO] Initializing TaskManager...
[14:40:51.699] 2025-08-27 14:40:51,665 - unified_training_manager - INFO - Using device: cpu
[14:41:01.830] 2025-08-27 14:41:01,798 - unified_training_manager - INFO - Task filtering results:
[14:41:01.847] 2025-08-27 14:41:01,813 - unified_training_manager - INFO -   Total: 5040 -> 5040
[14:41:01.850] 2025-08-27 14:41:01,817 - unified_training_manager - INFO -   simple_task: 320 -> 320
[14:41:01.852] 2025-08-27 14:41:01,817 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[14:41:01.855] 2025-08-27 14:41:01,817 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[14:41:01.857] 2025-08-27 14:41:01,817 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[14:41:01.857] 2025-08-27 14:41:01,819 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[14:41:01.857] 2025-08-27 14:41:01,822 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[14:41:02.903] 2025-08-27 14:41:02,862 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[14:41:02.916] [TaskManager] Difficulty level 'easy': 1096 tasks
[14:41:02.917] [TaskManager] Difficulty level 'very_easy': 856 tasks
[14:41:02.926] [TaskManager] Difficulty level 'medium': 1136 tasks
[14:41:02.927] [TaskManager] Difficulty level 'hard': 1096 tasks
[14:41:02.927] [TaskManager] Difficulty level 'very_hard': 856 tasks
[14:41:03.783] [INFO] TaskManager initialized with 5040 tasks
[14:41:03.793] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:41:03.795] [INFO] Initializing ToolCallVerifier...
[14:41:03.979] [INFO] ToolCallVerifier initialized with 30 tools
[14:41:04.060] [INFO] Output tools identified: 1
[14:41:04.064] [INFO] Component initialization status:
[14:41:04.064]   - embedding_manager: initialized
[14:41:04.065]   - task_manager: initialized
[14:41:04.065]   - output_verifier: initialized
[14:41:04.070]   - tool_capability_manager: initialized
[14:41:04.070]   - tool_success_rates: initialized with 0 entries
[14:41:04.071] [INFO] MDPWorkflowGenerator initialization complete
[14:41:04.072] 2025-08-27 14:41:03,983 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[14:41:04.072] 2025-08-27 14:41:04,002 - batch_test_runner - INFO - ✅ MDPWorkflowGenerator initialized successfully:
[14:41:04.072] 2025-08-27 14:41:04,020 - batch_test_runner - INFO -   - task_manager: ✓
[14:41:04.072] 2025-08-27 14:41:04,020 - batch_test_runner - INFO -   - output_verifier: ✓
[14:41:04.077] 2025-08-27 14:41:04,020 - batch_test_runner - INFO -   - embedding_manager: ✓
[14:41:04.077] 2025-08-27 14:41:04,020 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[14:41:04.077] 2025-08-27 14:41:04,020 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[14:41:04.078] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140606463201680)
[14:41:04.078] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:41:04.078] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:41:04.078] [FlawedWorkflowGenerator] RAG support: disabled
[14:41:05.096] 2025-08-27 14:41:05,071 - focused_ai_classifier - INFO - Focused AI classifier initialized with gpt-5-nano (parameter-filtered)
[14:41:05.112] [INFO] Enhanced manager: AI错误分类系统已启用
[14:41:05.149] [INFO] 检测到并发环境，使用安全存储模式（ResultCollector）
[14:41:05.311] 2025-08-27 14:41:05,310 - result_collector - INFO - ResultCollector初始化，临时目录: temp_results
[14:41:05.368] 2025-08-27 14:41:05,311 - result_merger - INFO - ResultMerger初始化完成
[14:41:05.369] 2025-08-27 14:41:05,318 - result_merger - WARNING - 另一个合并器已在运行 (PID: -1)
[14:41:05.370] [INFO] 后台合并进程已启动（每10秒合并一次）
[14:41:05.370] DEBUG: Checking generator attributes
[14:41:05.370]   - has tool_capabilities: True
[14:41:05.370]   - has tool_capability_manager: True
[14:41:05.370]   - has task_manager: True
[14:41:05.371] [INFO] Loaded 30 tools from generator
[14:41:05.371] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[14:41:05.371] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140606463201680)
[14:41:05.371] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:41:05.371] [INFO] Initializing LLM client using APIClientManager
[14:41:06.246] [INFO] Using Azure OpenAI client
[14:41:06.269] [DEBUG] Checking if generator has tool_capability_manager attribute
[14:41:06.272] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[14:41:06.275] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140606463201680)
[14:41:06.275] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:41:06.279] [FlawedWorkflowGenerator] Initialized with 30 tools
[14:41:06.285] [FlawedWorkflowGenerator] RAG support: enabled
[14:41:06.285] [INFO] FlawedWorkflowGenerator initialized successfully
[14:41:06.285] [INFO] Initializing StableScorer for Phase 2 scoring
[14:41:06.287] <tool_capability_manager.ToolCapabilityManager object at 0x7fe17e332380>
[14:41:06.287] [MCPEmbeddingManager] Reusing existing singleton instance (id: 140606463201680)
[14:41:06.287] [MCPEmbeddingManager] Current cache size: 30 embeddings
[14:41:06.287] [INFO] Loaded tool success history for 0 tools
[14:41:06.287] [INFO] StableScorer initialized with semantic capability
[14:41:06.287] [INFO] StableScorer initialized successfully
[14:41:06.287] [INFO] Loading task instances...
[14:41:06.309] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[14:41:07.237] [INFO] Loaded 630 task instances
[14:41:07.271] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[14:41:07.279] 2025-08-27 14:41:07,256 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[14:41:07.286] 2025-08-27 14:41:07,286 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:45:29.765] 2025-08-27 14:45:29,724 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[14:45:29.797] 2025-08-27 14:45:29,737 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[14:45:31.321] 2025-08-27 14:45:31,307 - batch_test_runner - INFO - Initialization complete
[14:45:35.066] 2025-08-27 14:45:34,911 - batch_test_runner - INFO - Starting batch test with 50 tasks, 2 workers
[14:45:35.094] 2025-08-27 14:45:35,085 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[14:45:35.184] 2025-08-27 14:45:35,181 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:45:35.216] 2025-08-27 14:45:35,214 - batch_test_runner - INFO - Loading task library for difficulty: medium
[14:45:35.220] 2025-08-27 14:45:35,218 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:45:35.246] 2025-08-27 14:45:35,245 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_medium_with_workflows.json
[14:45:35.255] 2025-08-27 14:45:35,255 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[14:45:35.255] 2025-08-27 14:45:35,255 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
