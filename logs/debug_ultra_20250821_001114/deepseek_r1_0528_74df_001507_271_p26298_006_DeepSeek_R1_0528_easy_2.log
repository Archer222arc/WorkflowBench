===== ÂàÜÁâá DeepSeek-R1-0528_easy_2 =====
Êó∂Èó¥: 2025-08-21T00:15:07.272820
Ê®°Âûã: deepseek-r1-0528
ÂÆû‰æã: DeepSeek-R1-0528-3
ÂëΩ‰ª§: python -u smart_batch_runner.py --model deepseek-r1-0528 --deployment DeepSeek-R1-0528-3 --prompt-types optimal --difficulty easy --task-types all --num-instances 3 --max-workers 5 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
ÁéØÂ¢ÉÂèòÈáè:
  STORAGE_FORMAT=parquet
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[00:15:09.129] 2025-08-21 00:15:09,129 - faiss.loader - INFO - Loading faiss.
[00:15:09.142] 2025-08-21 00:15:09,142 - faiss.loader - INFO - Successfully loaded faiss.
[00:15:10.211] [INFO] ‰ΩøÁî®ParquetÂ≠òÂÇ®Ê†ºÂºè
[00:15:10.560] [INFO] ‰ΩøÁî®ParquetÂ≠òÂÇ®Ê†ºÂºè
[00:15:10.569] [INFO] ‰ΩøÁî®PARQUETÂ≠òÂÇ®Ê†ºÂºè
[00:15:10.569] 
[00:15:10.569] ============================================================
[00:15:10.569] Êô∫ËÉΩÊâπÊµãËØï: deepseek-r1-0528 (idealab)
[00:15:10.569] Prompt types: ['optimal']
[00:15:10.569] ÈöæÂ∫¶: easy
[00:15:10.569] ÁõÆÊ†á: ÊØèÁßçÈÖçÁΩÆ 3 ‰∏™ÂÆû‰æã
[00:15:10.569] ============================================================
[00:15:10.570] ‚óã simple_task         :   0/  3 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 3 ‰∏™)
[00:15:10.570] ‚óã basic_task          :   0/  3 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 3 ‰∏™)
[00:15:10.570] ‚óã data_pipeline       :   0/  3 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 3 ‰∏™)
[00:15:10.570] ‚óã api_integration     :   0/  3 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 3 ‰∏™)
[00:15:10.570] ‚óã multi_stage_pipeline:   0/  3 Â∑≤ÂÆåÊàê (ÈúÄË¶ÅË°•ÂÖÖ 3 ‰∏™)
[00:15:10.570] 
[00:15:10.570] ‚è≥ ÈúÄË¶ÅËøêË°å 15 ‰∏™Êñ∞ÊµãËØï
[00:15:10.570] 
[00:15:10.570] ‚ñ∂ ÂáÜÂ§á simple_task (3 ‰∏™ÂÆû‰æã)...
[00:15:10.570] 
[00:15:10.570] ‚ñ∂ ÂáÜÂ§á basic_task (3 ‰∏™ÂÆû‰æã)...
[00:15:10.570] 
[00:15:10.570] ‚ñ∂ ÂáÜÂ§á data_pipeline (3 ‰∏™ÂÆû‰æã)...
[00:15:10.570] 
[00:15:10.570] ‚ñ∂ ÂáÜÂ§á api_integration (3 ‰∏™ÂÆû‰æã)...
[00:15:10.570] 
[00:15:10.570] ‚ñ∂ ÂáÜÂ§á multi_stage_pipeline (3 ‰∏™ÂÆû‰æã)...
[00:15:10.570] 
[00:15:10.570] ‚ñ∂ ÂºÄÂßãÊâßË°å 15 ‰∏™ÊµãËØï...
[00:15:10.570] üì¶ ÊâπÈáèÊèê‰∫§Ê®°ÂºèÔºöÊØè20‰∏™ÊµãËØï‰øùÂ≠ò‰∏ÄÊ¨°
[00:15:10.570] üöÄ Ê£ÄÊµãÂà∞Azure APIÔºå‰ΩøÁî®Ë∂ÖÈ´òÂπ∂Âèë: workers=100, qps=200.0
[00:15:10.571] 2025-08-21 00:15:10,571 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for gpt-5-nano
[00:15:10.740] 2025-08-21 00:15:10,740 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[00:15:10.740] [AI_DEBUG] AIÂàÜÁ±ªÂô®ÂàùÂßãÂåñÊàêÂäü: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x147e7b500>
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - Âü∫‰∫éTXTÊñá‰ª∂ÁöÑAIÈîôËØØÂàÜÁ±ªÁ≥ªÁªüÂ∑≤ÂêØÁî® (‰ΩøÁî®gpt-5-nano)
[00:15:10.740] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=True, use_ai_classification=True, checkpoint_interval=20
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - ============================================================
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - Batch test runner initialized
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - Log file: logs/batch_test_20250821_001510.log
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - ============================================================
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - Running 15 tests with 100 workers, QPS limit: 200.0
[00:15:10.740] 2025-08-21 00:15:10,740 - batch_test_runner - INFO - Initializing test components...
[00:15:11.065] 2025-08-21 00:15:11,065 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[00:15:11.065] 2025-08-21 00:15:11,065 - batch_test_runner - INFO - ‚ö° [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[00:15:11.065] 2025-08-21 00:15:11,065 - batch_test_runner - INFO - ‚ö° This saves ~350MB memory while keeping all functionality intact
[00:15:11.065] [DEBUG] Creating new ToolCapabilityManager instance
[00:15:11.065] [OperationEmbeddingIndex] Initializing with unified API client manager
[00:15:11.065] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[00:15:11.065] 2025-08-21 00:15:11,065 - api_client_manager - INFO - Loaded configuration from config/config.json
[00:15:11.072] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[00:15:11.072] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[00:15:11.072] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[00:15:11.918] 2025-08-21 00:15:11,917 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[00:15:11.919] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[00:15:11.957] [INFO] Loaded 4150 embeddings from persistent cache
[00:15:11.957] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[00:15:11.958] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[00:15:11.958] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[00:15:11.958] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[00:15:11.961] [INFO] Successfully loaded FAISS index with dimension 3072
[00:15:11.961] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[00:15:11.961] [INFO] Loaded 15 operations with dimension 3072
[00:15:11.961] [INFO] Successfully loaded cached index
[00:15:11.961] [INFO] Operation semantic index initialized
[00:15:11.962] [INFO] Using device: cpu
[00:15:11.962] [INFO] Initialized tool success tracking attributes
[00:15:11.962] [INFO] Initializing embedding manager for enhanced tool selection
[00:15:11.962] [MCPEmbeddingManager] Creating new singleton instance
[00:15:11.962] [MCPEmbeddingManager] Initializing with unified API client manager
[00:15:11.969] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[00:15:11.969] [MCPEmbeddingManager] Client initialized successfully
[00:15:11.969] 2025-08-21 00:15:11,969 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[00:15:12.108] 2025-08-21 00:15:12,108 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[00:15:12.344] 2025-08-21 00:15:12,344 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[00:15:12.344] 2025-08-21 00:15:12,344 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[00:15:12.366] 2025-08-21 00:15:12,366 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[00:15:12.425] 2025-08-21 00:15:12,425 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[00:15:12.645] 2025-08-21 00:15:12,645 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[00:15:12.645] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[00:15:12.645] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[00:15:12.645] 2025-08-21 00:15:12,645 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:12.665] 2025-08-21 00:15:12,665 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:12.665] 2025-08-21 00:15:12,665 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:12.665] 2025-08-21 00:15:12,665 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:12.667] [SUCCESS] Loaded 30 tool embeddings
[00:15:12.667] 2025-08-21 00:15:12,667 - mdp_workflow_generator - INFO - Embedding index loaded successfully
[00:15:12.667] [SUCCESS] Embedding manager initialized with 30 tools
[00:15:12.667] [INFO] Initialized task types: ['simple_task', 'data_pipeline', 'api_integration', 'basic_task', 'multi_stage_pipeline']
[00:15:12.667] [INFO] Loading full MCP protocol registry...
[00:15:12.668] 2025-08-21 00:15:12,668 - mdp_workflow_generator - INFO - Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:12.668] [INFO] Loaded full tool registry with 30 tools
[00:15:12.668] 2025-08-21 00:15:12,668 - mdp_workflow_generator - INFO - Loading tools from mcp_generated_library/tool_registry_consolidated.json
[00:15:12.668] [INFO] Loading tools from mcp_generated_library/tool_registry_consolidated.json
[00:15:12.669] [INFO] Embedding manager ready with 30 tools
[00:15:12.669] [WARNING] Embedding manager exists but has no embeddings
[00:15:12.669] [INFO] Consider rebuilding index with: embedding_manager.build_index(tools_path)
[00:15:12.669] [INFO] Tool file_operations_reader: semantic operations = ['read', 'write', 'parse', 'transform']
[00:15:12.670] [INFO] Tool file_operations_scanner: semantic operations = ['read', 'write', 'parse', 'transform']
[00:15:12.670] [INFO] Tool network_fetcher: semantic operations = ['read', 'write', 'validate', 'integrate']
[00:15:12.670] [INFO] Tool integration_authenticator: semantic operations = ['integrate', 'transform', 'validate']
[00:15:12.670] [INFO] Tool utility_logger: semantic operations = ['cache', 'process']
[00:15:12.670] [INFO] Tool data_processing_parser: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[00:15:12.670] [INFO] Tool data_processing_transformer: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[00:15:12.670] [INFO] Tool data_processing_validator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[00:15:12.670] [INFO] Tool network_validator: semantic operations = ['read', 'write', 'validate', 'integrate']
[00:15:12.670] [INFO] Tool computation_calculator: semantic operations = ['compute', 'aggregate', 'transform']
[00:15:12.670] [INFO] Tool data_processing_filter: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[00:15:12.670] [INFO] Tool data_processing_aggregator: semantic operations = ['validate', 'transform', 'filter', 'aggregate']
[00:15:12.670] [INFO] Tool file_operations_converter: semantic operations = ['read', 'write', 'parse', 'transform']
[00:15:12.670] [INFO] Tool file_operations_compressor: semantic operations = ['read', 'write', 'parse', 'transform']
[00:15:12.670] [INFO] Tool file_operations_writer: semantic operations = ['read', 'write', 'parse', 'transform']
[00:15:12.670] [INFO] Tool network_poster: semantic operations = ['read', 'write', 'validate', 'integrate']
[00:15:12.670] [INFO] Tool network_monitor: semantic operations = ['read', 'write', 'validate', 'integrate']
[00:15:12.670] [INFO] Tool network_router: semantic operations = ['read', 'write', 'validate', 'integrate']
[00:15:12.670] [INFO] Tool computation_predictor: semantic operations = ['compute', 'aggregate', 'transform']
[00:15:12.670] [INFO] Tool computation_analyzer: semantic operations = ['compute', 'aggregate', 'transform']
[00:15:12.670] [INFO] Tool computation_simulator: semantic operations = ['compute', 'aggregate', 'transform']
[00:15:12.670] [INFO] Tool computation_optimizer: semantic operations = ['compute', 'aggregate', 'transform']
[00:15:12.670] [INFO] Tool integration_mapper: semantic operations = ['integrate', 'transform', 'validate']
[00:15:12.670] [INFO] Tool integration_queue: semantic operations = ['integrate', 'transform', 'validate']
[00:15:12.670] [INFO] Tool integration_scheduler: semantic operations = ['integrate', 'transform', 'validate']
[00:15:12.670] [INFO] Tool integration_connector: semantic operations = ['integrate', 'transform', 'validate']
[00:15:12.670] [INFO] Tool utility_cache: semantic operations = ['cache', 'process']
[00:15:12.670] [INFO] Tool utility_tracker: semantic operations = ['cache', 'process']
[00:15:12.670] [INFO] Tool utility_helper: semantic operations = ['cache', 'process']
[00:15:12.670] [INFO] Tool utility_notifier: semantic operations = ['cache', 'process']
[00:15:12.670] 2025-08-21 00:15:12,670 - mdp_workflow_generator - INFO - Loaded 30 tools
[00:15:12.670] [INFO] Setting default state_dim based on loaded tools
[00:15:12.670] [INFO] state_dim set to 345 (tools=30, base=340, task_types=5)
[00:15:12.670] 2025-08-21 00:15:12,670 - mdp_workflow_generator - INFO - Default state_dim calculated: 345
[00:15:12.670] [INFO] Setting default action_dim based on loaded tools
[00:15:12.670] [INFO] action_dim set to 31 (tools=30 + NO_OP)
[00:15:12.670] 2025-08-21 00:15:12,670 - mdp_workflow_generator - INFO - Default action_dim calculated: 31
[00:15:12.670] [INFO] ‚ö° SKIP_MODEL_LOADING=true - Skipping neural network model loading
[00:15:12.670] [INFO] ‚ö° Memory optimization: Saving ~350MB by not loading model
[00:15:12.670] [INFO] ‚ö° Will use pre-generated workflows or random policy
[00:15:12.670] 2025-08-21 00:15:12,670 - mdp_workflow_generator - INFO - Model loading skipped for memory optimization (SKIP_MODEL_LOADING=true)
[00:15:12.670] [INFO] Initializing TaskManager...
[00:15:14.254] 2025-08-21 00:15:14,253 - unified_training_manager - INFO - Using device: cpu
[00:15:14.365] 2025-08-21 00:15:14,365 - unified_training_manager - INFO - Task filtering results:
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO -   Total: 5040 -> 5040
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO -   simple_task: 320 -> 320
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO -   data_pipeline: 1520 -> 1520
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO -   api_integration: 1360 -> 1360
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO -   basic_task: 1200 -> 1200
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO -   multi_stage_pipeline: 640 -> 640
[00:15:14.366] 2025-08-21 00:15:14,365 - unified_training_manager - INFO - Loaded 5040 tasks from mcp_generated_library/task_library_all_difficulties.json
[00:15:14.368] 2025-08-21 00:15:14,368 - unified_training_manager - INFO - Organized tasks: 5 types, 3 complexity levels, 5 difficulty levels
[00:15:14.368] [TaskManager] Difficulty level 'easy': 1096 tasks
[00:15:14.368] [TaskManager] Difficulty level 'very_easy': 856 tasks
[00:15:14.368] [TaskManager] Difficulty level 'medium': 1136 tasks
[00:15:14.368] [TaskManager] Difficulty level 'hard': 1096 tasks
[00:15:14.368] [TaskManager] Difficulty level 'very_hard': 856 tasks
[00:15:14.370] [INFO] TaskManager initialized with 5040 tasks
[00:15:14.370] [INFO] Task types available: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[00:15:14.370] [INFO] Initializing ToolCallVerifier...
[00:15:14.371] [INFO] ToolCallVerifier initialized with 30 tools
[00:15:14.371] [INFO] Output tools identified: 1
[00:15:14.371] [INFO] Component initialization status:
[00:15:14.371]   - embedding_manager: initialized
[00:15:14.371]   - task_manager: initialized
[00:15:14.371]   - output_verifier: initialized
[00:15:14.371]   - tool_capability_manager: initialized
[00:15:14.371]   - tool_success_rates: initialized with 0 entries
[00:15:14.371] [INFO] MDPWorkflowGenerator initialization complete
[00:15:14.371] 2025-08-21 00:15:14,371 - mdp_workflow_generator - INFO - MDPWorkflowGenerator initialized successfully
[00:15:14.371] 2025-08-21 00:15:14,371 - batch_test_runner - INFO - ‚úÖ MDPWorkflowGenerator initialized successfully:
[00:15:14.371] 2025-08-21 00:15:14,371 - batch_test_runner - INFO -   - task_manager: ‚úì
[00:15:14.371] 2025-08-21 00:15:14,371 - batch_test_runner - INFO -   - output_verifier: ‚úì
[00:15:14.371] 2025-08-21 00:15:14,371 - batch_test_runner - INFO -   - embedding_manager: ‚úì
[00:15:14.371] 2025-08-21 00:15:14,371 - batch_test_runner - INFO -   - tool_capabilities: 30 tools
[00:15:14.371] 2025-08-21 00:15:14,371 - batch_test_runner - INFO -   - neural network: skipped (saving 350MB)
[00:15:14.371] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.371] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.371] [FlawedWorkflowGenerator] Initialized with 30 tools
[00:15:14.371] [FlawedWorkflowGenerator] RAG support: disabled
[00:15:14.372] DEBUG: Checking generator attributes
[00:15:14.372]   - has tool_capabilities: True
[00:15:14.372]   - has tool_capability_manager: True
[00:15:14.372]   - has task_manager: True
[00:15:14.372] [INFO] Loaded 30 tools from generator
[00:15:14.372] [INFO] Tool names sample: ['computation_analyzer', 'computation_calculator', 'computation_optimizer', 'computation_predictor', 'computation_simulator']...
[00:15:14.372] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.372] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.372] [INFO] Initializing LLM client using APIClientManager
[00:15:14.379] [INFO] Using Azure OpenAI client
[00:15:14.379] [DEBUG] Checking if generator has tool_capability_manager attribute
[00:15:14.379] [DEBUG] Creating FlawedWorkflowGenerator with correct parameters
[00:15:14.379] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.379] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.379] [FlawedWorkflowGenerator] Initialized with 30 tools
[00:15:14.379] [FlawedWorkflowGenerator] RAG support: enabled
[00:15:14.379] [INFO] FlawedWorkflowGenerator initialized successfully
[00:15:14.379] [INFO] Initializing StableScorer for Phase 2 scoring
[00:15:14.379] <tool_capability_manager.ToolCapabilityManager object at 0x147e7ac30>
[00:15:14.379] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.379] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.379] [INFO] Loaded tool success history for 0 tools
[00:15:14.379] [INFO] StableScorer initialized with semantic capability
[00:15:14.379] [INFO] StableScorer initialized successfully
[00:15:14.379] [INFO] Loading task instances...
[00:15:14.379] [INFO] Loading task instances from mcp_generated_library/difficulty_versions/task_library_enhanced_v3_easy.json
[00:15:14.385] [INFO] Loaded 630 task instances
[00:15:14.385] [INFO] Task instances loaded: ['basic_task', 'data_pipeline', 'multi_stage_pipeline', 'simple_task', 'api_integration']
[00:15:14.385] 2025-08-21 00:15:14,385 - batch_test_runner - INFO - Loading task library with pre-generated workflows: task_library_enhanced_v3_easy_with_workflows.json
[00:15:14.385] 2025-08-21 00:15:14,385 - batch_test_runner - INFO - Using partial loading: 20 tasks per type
[00:15:14.787] 2025-08-21 00:15:14,787 - batch_test_runner - INFO - Partially loaded 100 tasks (vs 630 total)
[00:15:14.787] 2025-08-21 00:15:14,787 - batch_test_runner - INFO - Estimated memory saving: 84.1%
[00:15:14.803] 2025-08-21 00:15:14,803 - batch_test_runner - INFO - Initialization complete
[00:15:14.839] 2025-08-21 00:15:14,839 - batch_test_runner - INFO - Detected Azure API, disabling QPS sleep for better performance
[00:15:14.839] 2025-08-21 00:15:14,839 - batch_test_runner - INFO - Starting batch test with 15 tasks, 100 workers
[00:15:14.839] 2025-08-21 00:15:14,839 - batch_test_runner - INFO - Each task timeout: 10 minutes, Total batch timeout: 20 minutes
[00:15:14.840] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.841] 2025-08-21 00:15:14,841 - smart_model_router - INFO - ‚ú® Using USER's Azure endpoint for DeepSeek-R1-0528-3
[00:15:14.842] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.842] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.842] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.843] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.844] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.845] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.846] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.846] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.846] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.846] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.846] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.846] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.847] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.847] [InteractiveExecutor] No LLM client provided, initializing from api_client_manager
[00:15:14.850] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.850] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.852] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.852] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.853] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.853] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.853] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.853] 2025-08-21 00:15:14,853 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.854] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.854] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.883] 
[00:15:14.883] 
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.883] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.883] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.884] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.884] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.884] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.885] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.885] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.885] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.885] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.886] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.886] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.886] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.886] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.886] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.886] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.886] 2025-08-21 00:15:14,886 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.886] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.886] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)[MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.887] 2025-08-21 00:15:14,886 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.887] 
[00:15:14.887] [MCPEmbeddingManager] Current cache size: 30 embeddings2025-08-21 00:15:14,887 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.888] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.888] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.888] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.888] 2025-08-21 00:15:14,888 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.889] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.889] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.889] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.889] 2025-08-21 00:15:14,889 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.889] 2025-08-21 00:15:14,889 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.889] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.889] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.889] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.889] 2025-08-21 00:15:14,889 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.890] 
[00:15:14.891] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3[InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.891] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.891] 
[00:15:14.891] 2025-08-21 00:15:14,891 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.891] [MCPEmbeddingManager] Current cache size: 30 embeddings[InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.891] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.891] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.891] 
[00:15:14.892] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.892] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.893] 2025-08-21 00:15:14,893 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.893] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.893] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.893] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.894] [InteractiveExecutor] Initialized client with model: DeepSeek-R1-0528-3
[00:15:14.894] [InteractiveExecutor] Using prompt type: optimal for API key selection
[00:15:14.897] [InteractiveExecutor] API model name: DeepSeek-R1-0528-32025-08-21 00:15:14,897 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.898] 
[00:15:14.898] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.898] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.899] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.899] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.899] 2025-08-21 00:15:14,899 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.901] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3[MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.901] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.903] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.903] 
[00:15:14.904] [InteractiveExecutor] API model name: DeepSeek-R1-0528-3
[00:15:14.905] 2025-08-21 00:15:14,905 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.905] [MCPEmbeddingManager] Reusing existing singleton instance (id: 13064392384)
[00:15:14.906] [MCPEmbeddingManager] Current cache size: 30 embeddings
[00:15:14.906] 2025-08-21 00:15:14,906 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:14.908] 2025-08-21 00:15:14,908 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
[00:15:15.069] 2025-08-21 00:15:15,069 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.069] 2025-08-21 00:15:15,069 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.069] 2025-08-21 00:15:15,069 - mcp_embedding_manager - INFO - Index loaded successfully: 17 tools
[00:15:15.071] [INFO] Tool embedding index loaded successfully
[00:15:15.083] 2025-08-21 00:15:15,083 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.083] 2025-08-21 00:15:15,083 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.091] 2025-08-21 00:15:15,090 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[00:15:15.113] [INFO] Tool embedding index loaded successfully
[00:15:15.113] 2025-08-21 00:15:15,113 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.113] 2025-08-21 00:15:15,113 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.113] 2025-08-21 00:15:15,113 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.116] [INFO] Tool embedding index loaded successfully
[00:15:15.128] 2025-08-21 00:15:15,128 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.128] 2025-08-21 00:15:15,128 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.128] 2025-08-21 00:15:15,128 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[00:15:15.131] [INFO] Tool embedding index loaded successfully
[00:15:15.145] 2025-08-21 00:15:15,145 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.145] 2025-08-21 00:15:15,145 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.145] 2025-08-21 00:15:15,145 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.147] [INFO] Tool embedding index loaded successfully
[00:15:15.154] 2025-08-21 00:15:15,154 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.154] 2025-08-21 00:15:15,154 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.154] 2025-08-21 00:15:15,154 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[00:15:15.156] [INFO] Tool embedding index loaded successfully
[00:15:15.156] 2025-08-21 00:15:15,156 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.156] 2025-08-21 00:15:15,156 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.156] 2025-08-21 00:15:15,156 - mcp_embedding_manager - INFO - Index loaded successfully: 18 tools
[00:15:15.159] [INFO] Tool embedding index loaded successfully
[00:15:15.159] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.174] [INFO] Operation semantic index initialized2025-08-21 00:15:15,174 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.174] 2025-08-21 00:15:15,174 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.174] 2025-08-21 00:15:15,174 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.178] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.178] [INFO] Operation semantic index initialized
[00:15:15.178] 
[00:15:15.178] [TURN 1/10]
[00:15:15.182] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.184] [INFO] Tool embedding index loaded successfully
[00:15:15.194] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.194] 
[00:15:15.194] 
[00:15:15.194] [TURN 1/10]
[00:15:15.194] 2025-08-21 00:15:15,194 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.194] 2025-08-21 00:15:15,194 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.194] 2025-08-21 00:15:15,194 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.197] [INFO] Tool embedding index loaded successfully
[00:15:15.197] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.197] [INFO] Operation semantic index initialized
[00:15:15.197] 
[00:15:15.197] [TURN 1/10]
[00:15:15.197] 2025-08-21 00:15:15,197 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.198] 2025-08-21 00:15:15,197 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.198] 2025-08-21 00:15:15,197 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.200] [INFO] Tool embedding index loaded successfully
[00:15:15.200] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.220] [INFO] Operation semantic index initialized
[00:15:15.220] 
[00:15:15.220] [TURN 1/10]
[00:15:15.220] 2025-08-21 00:15:15,220 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.220] 2025-08-21 00:15:15,220 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.220] 2025-08-21 00:15:15,220 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.221] [INFO] Operation semantic index initialized
[00:15:15.223] [INFO] Tool embedding index loaded successfully
[00:15:15.223] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.224] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.225] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.225] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.225] [INFO] Operation semantic index initialized
[00:15:15.225] 
[00:15:15.225] [TURN 1/10]
[00:15:15.225] 2025-08-21 00:15:15,221 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.225] 2025-08-21 00:15:15,225 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.225] 2025-08-21 00:15:15,225 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.228] [INFO] Tool embedding index loaded successfully
[00:15:15.228] 2025-08-21 00:15:15,225 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.228] 2025-08-21 00:15:15,228 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.228] 2025-08-21 00:15:15,228 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.231] [INFO] Tool embedding index loaded successfully
[00:15:15.231] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.231] [INFO] Operation semantic index initialized
[00:15:15.231] 2025-08-21 00:15:15,223 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.231] 2025-08-21 00:15:15,231 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.231] 2025-08-21 00:15:15,231 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.234] [INFO] Tool embedding index loaded successfully
[00:15:15.234] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.235] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3[INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.235] [INFO] Operation semantic index initialized
[00:15:15.236] 2025-08-21 00:15:15,236 - mcp_embedding_manager - INFO - FAISS index loaded
[00:15:15.236] 2025-08-21 00:15:15,236 - mcp_embedding_manager - INFO - Updated dimension to 3072
[00:15:15.236] 2025-08-21 00:15:15,236 - mcp_embedding_manager - INFO - Index loaded successfully: 30 tools
[00:15:15.238] [INFO] Tool embedding index loaded successfully
[00:15:15.238] 
[00:15:15.239] 
[00:15:15.239] [TURN 1/10]
[00:15:15.239] [INFO] Operation semantic index initialized
[00:15:15.239] 
[00:15:15.239] [TURN 1/10]
[00:15:15.240] [INFO] Operation semantic index initialized
[00:15:15.240] [TURN 1/10]
[00:15:15.240] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.240] 
[00:15:15.241] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.241] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.241] 
[00:15:15.242] [TURN 1/10][INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.242] 
[00:15:15.242] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.243] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.243] [INFO] Loaded full tool registry from mcp_generated_library/tool_registry_consolidated.json
[00:15:15.243] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.244] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.244] [INFO] Operation semantic index initialized
[00:15:15.244] 
[00:15:15.244] [TURN 1/10]
[00:15:15.244] 
[00:15:15.244] [TURN 1/10]
[00:15:15.245] [INFO] Operation semantic index initialized
[00:15:15.245] [INFO] Operation semantic index initialized
[00:15:15.245] 
[00:15:15.245] [TURN 1/10]
[00:15:15.245] [INFO] Operation semantic index initialized
[00:15:15.245] 
[00:15:15.245] [TURN 1/10]
[00:15:15.245] [INFO] Operation semantic index initialized
[00:15:15.245] 
[00:15:15.245] [TURN 1/10]
[00:15:15.245] 
[00:15:15.245] [TURN 1/10]
[00:15:15.248] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.249] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.250] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3[LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.250] 
[00:15:15.251] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.251] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:15:15.252] [LLM_CALL] Using model: DeepSeek-R1-0528-3, API name: DeepSeek-R1-0528-3
[00:16:51.261] 2025-08-21 00:16:51,261 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 502 Bad Gateway"
[00:16:51.262] 2025-08-21 00:16:51,262 - openai._base_client - INFO - Retrying request to /chat/completions in 0.448614 seconds
[00:17:15.544] 2025-08-21 00:17:15,544 - openai._base_client - INFO - Retrying request to /chat/completions in 0.495629 seconds
[00:17:15.546] 2025-08-21 00:17:15,546 - openai._base_client - INFO - Retrying request to /chat/completions in 0.415226 seconds
[00:17:15.547] 2025-08-21 00:17:15,547 - openai._base_client - INFO - Retrying request to /chat/completions in 0.381183 seconds
[00:17:15.550] 2025-08-21 00:17:15,549 - openai._base_client - INFO - Retrying request to /chat/completions in 0.412298 seconds
[00:17:15.552] 2025-08-21 00:17:15,551 - openai._base_client - INFO - Retrying request to /chat/completions in 0.495077 seconds
[00:17:15.554] 2025-08-21 00:17:15,554 - openai._base_client - INFO - Retrying request to /chat/completions in 0.404351 seconds
[00:17:15.558] 2025-08-21 00:17:15,557 - openai._base_client - INFO - Retrying request to /chat/completions in 0.443146 seconds
[00:17:15.572] 2025-08-21 00:17:15,571 - openai._base_client - INFO - Retrying request to /chat/completions in 0.468273 seconds
[00:17:15.573] 2025-08-21 00:17:15,571 - openai._base_client - INFO - Retrying request to /chat/completions in 0.463248 seconds
[00:17:15.573] 2025-08-21 00:17:15,572 - openai._base_client - INFO - Retrying request to /chat/completions in 0.486449 seconds
[00:17:15.573] 2025-08-21 00:17:15,573 - openai._base_client - INFO - Retrying request to /chat/completions in 0.476817 seconds
[00:17:15.573] 2025-08-21 00:17:15,573 - openai._base_client - INFO - Retrying request to /chat/completions in 0.438814 seconds
[00:17:15.573] 2025-08-21 00:17:15,573 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394905 seconds
[00:17:15.574] 2025-08-21 00:17:15,574 - openai._base_client - INFO - Retrying request to /chat/completions in 0.422826 seconds
[00:17:16.749] 2025-08-21 00:17:16,749 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.750] 2025-08-21 00:17:16,750 - openai._base_client - INFO - Retrying request to /chat/completions in 0.872507 seconds
[00:17:16.757] 2025-08-21 00:17:16,757 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.759] 2025-08-21 00:17:16,758 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.760] 2025-08-21 00:17:16,759 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.760] 2025-08-21 00:17:16,760 - openai._base_client - INFO - Retrying request to /chat/completions in 0.867374 seconds
[00:17:16.761] 2025-08-21 00:17:16,761 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.761] 2025-08-21 00:17:16,761 - openai._base_client - INFO - Retrying request to /chat/completions in 0.758818 seconds
[00:17:16.761] 2025-08-21 00:17:16,761 - openai._base_client - INFO - Retrying request to /chat/completions in 0.948830 seconds
[00:17:16.762] 2025-08-21 00:17:16,762 - openai._base_client - INFO - Retrying request to /chat/completions in 0.781528 seconds
[00:17:16.771] 2025-08-21 00:17:16,770 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.771] 2025-08-21 00:17:16,771 - openai._base_client - INFO - Retrying request to /chat/completions in 0.990976 seconds
[00:17:16.774] 2025-08-21 00:17:16,772 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.774] 2025-08-21 00:17:16,773 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.774] 2025-08-21 00:17:16,774 - openai._base_client - INFO - Retrying request to /chat/completions in 0.900517 seconds
[00:17:16.774] 2025-08-21 00:17:16,774 - openai._base_client - INFO - Retrying request to /chat/completions in 0.957860 seconds
[00:17:16.776] 2025-08-21 00:17:16,776 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.777] 2025-08-21 00:17:16,777 - openai._base_client - INFO - Retrying request to /chat/completions in 0.969526 seconds
[00:17:16.783] 2025-08-21 00:17:16,782 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:16.784] 2025-08-21 00:17:16,784 - openai._base_client - INFO - Retrying request to /chat/completions in 0.887882 seconds
[00:17:17.886] 2025-08-21 00:17:17,885 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:17.886] 2025-08-21 00:17:17,886 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:17.886] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:17.886] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.886] 2025-08-21 00:17:17,886 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:17.886] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.886] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:17.886] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.887] 2025-08-21 00:17:17,886 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:17.887] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.887] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:17.887] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:17.951] 2025-08-21 00:17:17,951 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:17.951] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:17.951] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.951] 2025-08-21 00:17:17,951 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:17.951] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.952] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:17.965] 2025-08-21 00:17:17,965 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:17.965] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:17.965] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.965] 2025-08-21 00:17:17,965 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:17.965] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:17.966] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.007] 2025-08-21 00:17:18,007 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:18.008] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:18.008] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.008] 2025-08-21 00:17:18,008 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:18.008] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.008] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.016] 2025-08-21 00:17:18,016 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:18.017] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:18.017] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.017] 2025-08-21 00:17:18,017 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:18.017] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.017] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.050] 2025-08-21 00:17:18,050 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:18.051] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:18.051] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.051] 2025-08-21 00:17:18,051 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:18.051] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.051] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.106] 2025-08-21 00:17:18,106 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:18.107] 2025-08-21 00:17:18,107 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:18.107] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:18.107] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.107] 2025-08-21 00:17:18,107 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:18.107] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.107] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:18.107] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.107] 2025-08-21 00:17:18,107 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:18.107] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.108] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.108] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.117] 2025-08-21 00:17:18,117 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:17:18.118] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:17:18.118] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.118] 2025-08-21 00:17:18,118 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:17:18.118] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:17:18.118] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:17:18.118] Progress: 10/15 (Success: 0)
[00:18:51.722] 2025-08-21 00:18:51,721 - openai._base_client - INFO - Retrying request to /chat/completions in 0.999190 seconds
[00:18:53.414] 2025-08-21 00:18:53,413 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:18:53.415] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:18:53.415] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:18:53.415] 2025-08-21 00:18:53,415 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:18:53.415] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:18:53.417] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:19:16.405] 2025-08-21 00:19:16,403 - openai._base_client - INFO - Retrying request to /chat/completions in 0.830579 seconds
[00:19:16.406] 2025-08-21 00:19:16,404 - openai._base_client - INFO - Retrying request to /chat/completions in 0.923688 seconds
[00:19:16.406] 2025-08-21 00:19:16,405 - openai._base_client - INFO - Retrying request to /chat/completions in 0.939286 seconds
[00:19:16.447] 2025-08-21 00:19:16,447 - openai._base_client - INFO - Retrying request to /chat/completions in 0.988391 seconds
[00:19:18.020] 2025-08-21 00:19:18,020 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:19:18.022] 2025-08-21 00:19:18,022 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:19:18.022] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:19:18.022] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:19:18.022] 2025-08-21 00:19:18,022 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:19:18.022] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:19:18.024] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:19:18.024] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:19:18.024] 2025-08-21 00:19:18,024 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:19:18.024] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:19:18.024] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:19:18.026] [DEBUG] Got result for task: has_result=True, save_logs=True
[00:19:18.166] 2025-08-21 00:19:18,165 - httpx - INFO - HTTP Request: POST https://85409-me3ofvov-eastus2.services.ai.azure.com/openai/deployments/DeepSeek-R1-0528-3/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 429 Too Many Requests"
[00:19:18.169] [LLM_ERROR] Attempt 1/5: Please check this guide to understand why this error code might have been returned 
[00:19:18.169] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:19:18.169] 2025-08-21 00:19:18,168 - batch_test_runner - ERROR - Test failed with exception: Please check this guide to understand why this error code might have been returned 
[00:19:18.169] https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes
[00:19:18.169] [DEBUG] Got result for task: has_result=True, save_logs=True
