===== 分片 qwen2.5-72b-instruct_very_easy_key0 =====
时间: 2025-08-27T15:05:16.064056
模型: qwen2.5-72b-instruct
实例: qwen-key0
命令: python -u smart_batch_runner.py --model qwen2.5-72b-instruct --deployment qwen-key0 --prompt-types optimal --difficulty very_easy --task-types all --num-instances 10 --max-workers 50 --tool-success-rate 0.8 --batch-commit --checkpoint-interval 20 --ai-classification --no-adaptive --qps 50
环境变量:
  STORAGE_FORMAT=json
  PYTHONFAULTHANDLER=1
  PYTHONUNBUFFERED=1
==================================================

[15:05:18.004] 
[15:05:18.004] A module that was compiled using NumPy 1.x cannot be run in
[15:05:18.004] NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
[15:05:18.004] versions of NumPy, modules must be compiled with NumPy 2.0.
[15:05:18.004] Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
[15:05:18.004] 
[15:05:18.004] If you are a user of the module, the easiest solution will be to
[15:05:18.004] downgrade to 'numpy<2' or try to upgrade the affected module.
[15:05:18.004] We expect that some modules will need time to support NumPy 2.
[15:05:18.004] 
[15:05:18.004] Traceback (most recent call last):  File "/Users/ruicheng/Documents/GitHub/WorkflowBench/smart_batch_runner.py", line 21, in <module>
[15:05:18.004]     from batch_test_runner import BatchTestRunner, TestTask
[15:05:18.004]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/batch_test_runner.py", line 26, in <module>
[15:05:18.004]     from mdp_workflow_generator import MDPWorkflowGenerator
[15:05:18.004]   File "/Users/ruicheng/Documents/GitHub/WorkflowBench/mdp_workflow_generator.py", line 17, in <module>
[15:05:18.004]     import torch
[15:05:18.004]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
[15:05:18.004]     from .functional import *  # noqa: F403
[15:05:18.004]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
[15:05:18.004]     import torch.nn.functional as F
[15:05:18.004]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
[15:05:18.004]     from .modules import *  # noqa: F403
[15:05:18.004]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
[15:05:18.004]     from .transformer import TransformerEncoder, TransformerDecoder, \
[15:05:18.004]   File "/Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
[15:05:18.004]     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[15:05:18.004] /Users/ruicheng/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)
[15:05:18.005]   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
[15:05:19.135] 2025-08-27 15:05:19,135 - faiss.loader - INFO - Loading faiss.
[15:05:19.362] 2025-08-27 15:05:19,361 - faiss.loader - INFO - Successfully loaded faiss.
[15:05:20.245] [INFO] 使用JSON存储格式
[15:05:20.245] [INFO] 使用JSON存储格式
[15:05:21.019] [INFO] 使用JSON存储格式
[15:05:21.021] [INFO] 使用JSON存储格式
[15:05:21.022] 
[15:05:21.022] ============================================================
[15:05:21.022] 智能批测试: qwen2.5-72b-instruct (idealab)
[15:05:21.022] Prompt types: ['optimal']
[15:05:21.022] 难度: very_easy
[15:05:21.022] 目标: 每种配置 10 个实例
[15:05:21.022] ============================================================
[15:05:21.024] ○ simple_task         :   0/ 10 已完成 (需要补充 10 个)
[15:05:21.025] ○ basic_task          :   0/ 10 已完成 (需要补充 10 个)
[15:05:21.027] ○ data_pipeline       :   0/ 10 已完成 (需要补充 10 个)
[15:05:21.028] ○ api_integration     :   0/ 10 已完成 (需要补充 10 个)
[15:05:21.029] ○ multi_stage_pipeline:   0/ 10 已完成 (需要补充 10 个)
[15:05:21.029] 
[15:05:21.029] ⏳ 需要运行 50 个新测试
[15:05:21.029] 
[15:05:21.029] ▶ 准备 simple_task (10 个实例)...
[15:05:21.029] 
[15:05:21.029] ▶ 准备 basic_task (10 个实例)...
[15:05:21.029] 
[15:05:21.029] ▶ 准备 data_pipeline (10 个实例)...
[15:05:21.029] 
[15:05:21.029] ▶ 准备 api_integration (10 个实例)...
[15:05:21.029] 
[15:05:21.029] ▶ 准备 multi_stage_pipeline (10 个实例)...
[15:05:21.029] 
[15:05:21.029] ▶ 开始执行 50 个测试...
[15:05:21.029] 📊 自适应checkpoint_interval: 20
[15:05:21.029] 📦 批量提交模式：每20个测试保存一次
[15:05:21.029] ⚠️  检测到idealab API，调整并发: workers=2, qps=None
[15:05:21.029] 2025-08-27 15:05:21,029 - smart_result_collector - INFO - 自动保存线程已启动
[15:05:21.029] 2025-08-27 15:05:21,029 - smart_result_collector - INFO - SmartResultCollector初始化完成
[15:05:21.029] 2025-08-27 15:05:21,029 - smart_result_collector - INFO -   - 临时目录: temp_results
[15:05:21.029] 2025-08-27 15:05:21,029 - smart_result_collector - INFO -   - 内存阈值: 20
[15:05:21.030] 2025-08-27 15:05:21,029 - smart_result_collector - INFO -   - 时间阈值: 300秒
[15:05:21.030] 2025-08-27 15:05:21,030 - smart_result_collector - INFO -   - 自动保存: 60秒
[15:05:21.030] 2025-08-27 15:05:21,030 - smart_result_collector - INFO -   - 自适应阈值: True
[15:05:21.030] 2025-08-27 15:05:21,030 - result_collector_adapter - INFO - ✅ 使用SmartResultCollector
[15:05:21.030] 2025-08-27 15:05:21,030 - result_collector_adapter - INFO - AdaptiveResultCollector初始化完成，使用: smart
[15:05:21.030] 🧠 启用SmartResultCollector模式，智能数据管理
[15:05:21.032] 2025-08-27 15:05:21,032 - smart_model_router - INFO - ✨ Using USER's Azure endpoint for gpt-5-nano
[15:05:21.087] 2025-08-27 15:05:21,087 - txt_based_ai_classifier - INFO - TXT-based AI classifier initialized with gpt-5-nano (parameter-filtered)
[15:05:21.087] [AI_DEBUG] AI分类器初始化成功: <txt_based_ai_classifier.TxtBasedAIClassifier object at 0x7fb003a5d550>
[15:05:21.087] 2025-08-27 15:05:21,087 - batch_test_runner - INFO - 基于TXT文件的AI错误分类系统已启用 (使用gpt-5-nano)
[15:05:21.087] [DEBUG] BatchTestRunner initialized with save_logs=True, enable_database_updates=False, use_ai_classification=True, checkpoint_interval=20
[15:05:21.088] 2025-08-27 15:05:21,087 - batch_test_runner - INFO - ============================================================
[15:05:21.089] 2025-08-27 15:05:21,088 - batch_test_runner - INFO - Batch test runner initialized
[15:05:21.089] 2025-08-27 15:05:21,088 - batch_test_runner - INFO - Configuration: debug=False, silent=False, adaptive=False
[15:05:21.089] 2025-08-27 15:05:21,088 - batch_test_runner - INFO - Log file: logs/batch_test_20250827_150521.log
[15:05:21.089] 2025-08-27 15:05:21,088 - batch_test_runner - INFO - ============================================================
[15:05:21.089] 2025-08-27 15:05:21,088 - batch_test_runner - INFO - Running 50 tests with 2 workers, QPS limit: None
[15:05:21.089] 2025-08-27 15:05:21,088 - batch_test_runner - INFO - Initializing test components...
[15:05:22.056] 2025-08-27 15:05:22,054 - batch_test_runner - INFO - Found pre-generated workflows, will use them to save memory
[15:05:22.058] 2025-08-27 15:05:22,055 - batch_test_runner - INFO - ⚡ [OPTIMIZATION] Using MDPWorkflowGenerator with SKIP_MODEL_LOADING=true
[15:05:22.058] 2025-08-27 15:05:22,055 - batch_test_runner - INFO - ⚡ This saves ~350MB memory while keeping all functionality intact
[15:05:22.058] [DEBUG] Creating new ToolCapabilityManager instance
[15:05:22.059] [OperationEmbeddingIndex] Initializing with unified API client manager
[15:05:22.059] ['config/config.json', 'config/api_keys.json', 'config/api-keys.json']
[15:05:22.059] 2025-08-27 15:05:22,058 - api_client_manager - INFO - Loaded configuration from config/config.json
[15:05:22.078] [OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini
[15:05:22.078] [OperationEmbeddingIndex] Using embedding model: text-embedding-3-large
[15:05:22.079] [OperationEmbeddingIndex] Detecting actual embedding dimension...
[15:05:22.758] 2025-08-27 15:05:22,757 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview "HTTP/1.1 200 OK"
[15:05:22.766] [OperationEmbeddingIndex] Detected embedding dimension: 3072
[15:05:22.821] [INFO] Loaded 4150 embeddings from persistent cache
[15:05:22.821] [OperationEmbeddingIndex] Initialized with 4150 cached embeddings
[15:05:22.825] [INFO] Loaded 15 LLM-enhanced operation definitions from cache
[15:05:22.826] [INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl
[15:05:22.826] [INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl
[15:05:22.844] [INFO] Successfully loaded FAISS index with dimension 3072
[15:05:22.844] [INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl
[15:05:22.844] [INFO] Loaded 15 operations with dimension 3072
[15:05:22.844] [INFO] Successfully loaded cached index
[15:05:22.844] [INFO] Operation semantic index initialized
[15:05:22.844] [INFO] Using device: cpu
[15:05:22.845] [INFO] Initialized tool success tracking attributes
[15:05:22.845] [INFO] Initializing embedding manager for enhanced tool selection
[15:05:22.845] [MCPEmbeddingManager] Creating new singleton instance
[15:05:22.845] [MCPEmbeddingManager] Initializing with unified API client manager
[15:05:22.860] [MCPEmbeddingManager] Using embedding model: text-embedding-3-large
[15:05:22.860] [MCPEmbeddingManager] Client initialized successfully
[15:05:22.860] 2025-08-27 15:05:22,860 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[15:05:23.317] 2025-08-27 15:05:23,317 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[15:05:24.905] 2025-08-27 15:05:24,905 - smart_result_collector - INFO - 收到信号 2，准备关闭
[15:05:24.906] 2025-08-27 15:05:24,905 - smart_result_collector - INFO - SmartResultCollector 正在关闭...
[15:05:24.906] 2025-08-27 15:05:24,905 - smart_result_collector - INFO - SmartResultCollector 已关闭
[15:05:24.906] 2025-08-27 15:05:24,905 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries
[15:05:24.906] 2025-08-27 15:05:24,906 - mcp_embedding_manager - INFO - Initialized operation mappings with 149 terms
[15:05:25.205] 2025-08-27 15:05:25,205 - mcp_embedding_manager - INFO - Loading embedding cache from .mcp_embedding_cache/embedding_cache.pkl (size: 173790244 bytes)
[15:05:25.412] 2025-08-27 15:05:25,412 - mcp_embedding_manager - INFO - Loaded 7050 cached embeddings
[15:05:28.304] 2025-08-27 15:05:28,299 - mcp_embedding_manager - INFO - [Cache] Loaded 9650 entries from file
[15:05:28.310] [MCPEmbeddingManager] Singleton created with 0 cached embeddings
[15:05:28.314] [INFO] Loading embedding index from .mcp_embedding_cache/tool_index.pkl
[15:05:28.314] 2025-08-27 15:05:28,314 - mcp_embedding_manager - INFO - Loading index from .mcp_embedding_cache/tool_index.pkl (size: 3723608 bytes)
