# æ™ºèƒ½éƒ¨ç½²åˆ‡æ¢åŠŸèƒ½ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æ™ºèƒ½éƒ¨ç½²åˆ‡æ¢åŠŸèƒ½è‡ªåŠ¨å¤„ç†Azure OpenAI APIçš„429 Too Many Requestsé”™è¯¯ï¼Œé€šè¿‡åœ¨å¤šä¸ªéƒ¨ç½²å®ä¾‹é—´åˆ‡æ¢å®ç°è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»ã€‚

## åŠŸèƒ½ç‰¹æ€§

### âœ… è‡ªåŠ¨429é”™è¯¯æ£€æµ‹
- ç›‘æµ‹APIå“åº”ä¸­çš„429é”™è¯¯ç 
- è¯†åˆ«"Too Many Requests"å’Œ"Rate limit"æ¶ˆæ¯
- è‡ªåŠ¨è§¦å‘éƒ¨ç½²åˆ‡æ¢é€»è¾‘

### âœ… æ™ºèƒ½è´Ÿè½½å‡è¡¡
- è½®æ¢ä½¿ç”¨ä¸åŒéƒ¨ç½²å®ä¾‹
- åŸºäºæœ€å°‘ä½¿ç”¨æ—¶é—´çš„è´Ÿè½½å‡è¡¡
- é¿å…é›†ä¸­åœ¨å•ä¸€éƒ¨ç½²ä¸Š

### âœ… å¥åº·çŠ¶æ€ç®¡ç†
- è‡ªåŠ¨æ ‡è®°å¤±è´¥çš„éƒ¨ç½²ä¸ºä¸å¥åº·
- å¤±è´¥è®¡æ•°å’Œæ¢å¤æœºåˆ¶
- å®æ—¶çŠ¶æ€ç›‘æ§å’ŒæŠ¥å‘Š

### âœ… æ— ç¼é›†æˆ
- è‡ªåŠ¨é›†æˆåˆ°ç°æœ‰æµ‹è¯•æµç¨‹
- æ— éœ€ä¿®æ”¹ç°æœ‰å‘½ä»¤æˆ–è„šæœ¬
- é€æ˜çš„æ•…éšœè½¬ç§»æœºåˆ¶

## æ”¯æŒçš„æ¨¡å‹

ç›®å‰æ”¯æŒä»¥ä¸‹å…·æœ‰å¤šéƒ¨ç½²é…ç½®çš„æ¨¡å‹ï¼š

### Azureå¼€æºæ¨¡å‹
- **Llama-3.3-70B-Instruct** (3ä¸ªéƒ¨ç½²)
  - Llama-3.3-70B-Instruct
  - Llama-3.3-70B-Instruct-2
  - Llama-3.3-70B-Instruct-3

- **DeepSeek-V3-0324** (3ä¸ªéƒ¨ç½²)
  - DeepSeek-V3-0324
  - DeepSeek-V3-0324-2
  - DeepSeek-V3-0324-3

- **DeepSeek-R1-0528** (3ä¸ªéƒ¨ç½²)
  - DeepSeek-R1-0528
  - DeepSeek-R1-0528-2
  - DeepSeek-R1-0528-3

## ä½¿ç”¨æ–¹æ³•

### è‡ªåŠ¨å¯ç”¨
æ™ºèƒ½éƒ¨ç½²åˆ‡æ¢åŠŸèƒ½ä¼šåœ¨ä»¥ä¸‹æƒ…å†µä¸‹è‡ªåŠ¨å¯ç”¨ï¼š

```bash
# 5.5æç¤ºæ•æ„Ÿæ€§æµ‹è¯• - Llamaæ¨¡å‹ä¼šè‡ªåŠ¨ä½¿ç”¨éƒ¨ç½²åˆ‡æ¢
./test_5_5_prompt_sensitivity.sh Llama-3.3-70B-Instruct baseline

# 5.4å·¥å…·å¯é æ€§æµ‹è¯• - DeepSeekæ¨¡å‹ä¹Ÿæ”¯æŒ
./test_5_4_tool_reliability.sh DeepSeek-V3-0324 0.9

# ä»»ä½•ä½¿ç”¨æ”¯æŒæ¨¡å‹çš„æµ‹è¯•
./run_systematic_test_final.sh --phase 5.1
```

### æ‰‹åŠ¨æµ‹è¯•
```bash
# æµ‹è¯•éƒ¨ç½²åˆ‡æ¢åŠŸèƒ½
python test_deployment_switching.py

# æŸ¥çœ‹æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨çŠ¶æ€
python test_smart_deployment.py
```

## å·¥ä½œåŸç†

### 1. å®¢æˆ·ç«¯åˆ›å»ºé˜¶æ®µ
```python
# api_client_manager.py ä¸­çš„æ™ºèƒ½éƒ¨ç½²é€‰æ‹©
if model_name in parallel_deployments:
    deployment_manager = get_deployment_manager()
    best_deployment = deployment_manager.get_best_deployment(model_name)
```

### 2. APIè°ƒç”¨é˜¶æ®µ
```python
# interactive_executor.py ä¸­çš„429é”™è¯¯å¤„ç†
if is_429_error:
    deployment_manager.mark_deployment_failed(current_deployment, "429")
    new_deployment = deployment_manager.get_best_deployment(self.model)
    self.llm_client = get_client_for_model(self.model, self.prompt_type, idealab_key_index)
```

### 3. è´Ÿè½½å‡è¡¡ç®—æ³•
- **è½®è½¬é€‰æ‹©**: é€‰æ‹©æœ€å°‘ä½¿ç”¨çš„éƒ¨ç½²
- **å¥åº·æ£€æŸ¥**: è¿‡æ»¤å¤±è´¥æ¬¡æ•°è¿‡å¤šçš„éƒ¨ç½²
- **è‡ªåŠ¨æ¢å¤**: åœ¨æ‰€æœ‰éƒ¨ç½²å¤±è´¥æ—¶é‡ç½®çŠ¶æ€

## ç›‘æ§å’Œè°ƒè¯•

### æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
```python
from smart_deployment_manager import get_deployment_manager

manager = get_deployment_manager()
manager.print_status()
```

### è¾“å‡ºç¤ºä¾‹ï¼š
```
ğŸš€ æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨çŠ¶æ€:
ğŸ“Š Llama-3.3-70B-Instruct:
  â€¢ Llama-3.3-70B-Instruct: âœ… å¥åº· (å¤±è´¥æ¬¡æ•°: 0, ä¸Šæ¬¡ä½¿ç”¨: 15:01:19)
  â€¢ Llama-3.3-70B-Instruct-2: âŒ ä¸å¥åº· (å¤±è´¥æ¬¡æ•°: 1, ä¸Šæ¬¡ä½¿ç”¨: 15:01:20)  
  â€¢ Llama-3.3-70B-Instruct-3: âœ… å¥åº· (å¤±è´¥æ¬¡æ•°: 0, ä¸Šæ¬¡ä½¿ç”¨: 15:01:20)
```

### æ—¥å¿—ç›‘æ§
åœ¨æµ‹è¯•è¿è¡Œæ—¶ï¼ŒæŸ¥çœ‹ä»¥ä¸‹æ—¥å¿—ä¿¡æ¯ï¼š
```bash
tail -f logs/batch_test_*.log | grep "429_ERROR\|deployment"
```

### å…³é”®æ—¥å¿—æ¶ˆæ¯ï¼š
```
[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...
[429_ERROR] Current deployment: Llama-3.3-70B-Instruct-2
[429_ERROR] Marked Llama-3.3-70B-Instruct-2 as failed due to 429 error
[429_ERROR] Switching from Llama-3.3-70B-Instruct-2 to Llama-3.3-70B-Instruct-3
[429_ERROR] Successfully switched to new deployment: Llama-3.3-70B-Instruct-3
```

## å®é™…æµ‹è¯•ç»“æœ

åœ¨å®é™…5.5æµ‹è¯•ä¸­è§‚å¯Ÿåˆ°çš„æˆåŠŸæ¡ˆä¾‹ï¼š

### æµ‹è¯•åœºæ™¯
```bash
./test_5_5_prompt_sensitivity.sh Llama-3.3-70B-Instruct baseline
```

### è§‚å¯Ÿåˆ°çš„è¡Œä¸º
1. **åˆå§‹éƒ¨ç½²**: `Llama-3.3-70B-Instruct-2`
2. **é‡åˆ°429é”™è¯¯**: Rate limit of 400000 per 60s exceeded
3. **è‡ªåŠ¨åˆ‡æ¢åˆ°**: `Llama-3.3-70B-Instruct-3`
4. **å†æ¬¡é‡åˆ°429**: ç»§ç»­åˆ‡æ¢åˆ° `Llama-3.3-70B-Instruct`
5. **æµ‹è¯•ç»§ç»­**: æˆåŠŸå®ŒæˆAPIè°ƒç”¨ï¼Œè¿”å›200 OK

### æ€§èƒ½æ”¹è¿›
- **ä¹‹å‰**: é‡åˆ°429é”™è¯¯åæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ‰‹åŠ¨é‡è¯•
- **ç°åœ¨**: è‡ªåŠ¨åˆ‡æ¢éƒ¨ç½²ï¼Œæµ‹è¯•æ— ç¼ç»§ç»­ï¼ŒæˆåŠŸç‡æ˜¾è‘—æé«˜

## é…ç½®è¯´æ˜

### æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨å‚æ•°
```python
# smart_deployment_manager.py é…ç½®
class SmartDeploymentManager:
    def __init__(self):
        self.failure_count = {}  # å¤±è´¥è®¡æ•°é˜ˆå€¼ï¼š5æ¬¡
        self.deployment_health = {}  # å¥åº·çŠ¶æ€è·Ÿè¸ª
        self.last_used = {}  # è´Ÿè½½å‡è¡¡æ—¶é—´æˆ³
```

### æ¢å¤æœºåˆ¶
- **å¥åº·æ£€æŸ¥**: å¤±è´¥æ¬¡æ•°<5çš„éƒ¨ç½²è¢«è®¤ä¸ºæ˜¯å¥åº·çš„
- **è‡ªåŠ¨é‡ç½®**: å½“æ‰€æœ‰éƒ¨ç½²éƒ½å¤±è´¥æ—¶ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
- **æˆåŠŸæ¢å¤**: æˆåŠŸçš„APIè°ƒç”¨ä¼šé‡ç½®éƒ¨ç½²çš„å¤±è´¥è®¡æ•°

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. éƒ¨ç½²åˆ‡æ¢ä¸ç”Ÿæ•ˆ
**æ£€æŸ¥**: æ¨¡å‹æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­
```bash
python -c "from smart_deployment_manager import SmartDeploymentManager; 
m = SmartDeploymentManager(); print(m.parallel_deployments.keys())"
```

#### 2. æ‰€æœ‰éƒ¨ç½²éƒ½å¤±è´¥
**è§£å†³**: ç­‰å¾…Azureé…é¢æ¢å¤ï¼Œæˆ–æ£€æŸ¥APIå¯†é’¥
```bash
# æ‰‹åŠ¨é‡ç½®éƒ¨ç½²çŠ¶æ€
python -c "from smart_deployment_manager import get_deployment_manager;
m = get_deployment_manager(); [m.mark_deployment_success(d) for d in ['Llama-3.3-70B-Instruct', 'Llama-3.3-70B-Instruct-2', 'Llama-3.3-70B-Instruct-3']]"
```

#### 3. æ—¥å¿—ä¸­æ²¡æœ‰æ˜¾ç¤ºéƒ¨ç½²åˆ‡æ¢
**æ£€æŸ¥**: ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æµ‹è¯•è„šæœ¬
```bash
# æ­£ç¡®ï¼šä½¿ç”¨bashæµ‹è¯•è„šæœ¬
./test_5_5_prompt_sensitivity.sh Llama-3.3-70B-Instruct baseline

# é”™è¯¯ï¼šç›´æ¥è°ƒç”¨Pythonï¼ˆç»•è¿‡äº†æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨ï¼‰
python smart_batch_runner.py --model Llama-3.3-70B-Instruct
```

## æ€»ç»“

æ™ºèƒ½éƒ¨ç½²åˆ‡æ¢åŠŸèƒ½æ˜¾è‘—æé«˜äº†Azureå¼€æºæ¨¡å‹çš„æµ‹è¯•ç¨³å®šæ€§å’ŒæˆåŠŸç‡ã€‚é€šè¿‡è‡ªåŠ¨å¤„ç†429é”™è¯¯å¹¶åœ¨å¤šéƒ¨ç½²é—´è´Ÿè½½å‡è¡¡ï¼Œç³»ç»Ÿèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨Azure APIé…é¢ï¼Œå‡å°‘å› å•ä¸€éƒ¨ç½²é™æµå¯¼è‡´çš„æµ‹è¯•å¤±è´¥ã€‚

**å…³é”®ä¼˜åŠ¿**:
- ğŸš€ **è‡ªåŠ¨åŒ–**: æ— éœ€äººå·¥å¹²é¢„çš„æ•…éšœè½¬ç§»
- ğŸ’ª **ç¨³å®šæ€§**: æ˜¾è‘—æé«˜æµ‹è¯•æˆåŠŸç‡
- ğŸ”„ **è´Ÿè½½å‡è¡¡**: å……åˆ†åˆ©ç”¨æ‰€æœ‰å¯ç”¨éƒ¨ç½²
- ğŸ“Š **é€æ˜åº¦**: è¯¦ç»†çš„çŠ¶æ€ç›‘æ§å’Œæ—¥å¿—è®°å½•