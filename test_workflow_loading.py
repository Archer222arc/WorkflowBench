#!/usr/bin/env python3
"""æµ‹è¯•workflowåŠ è½½é€»è¾‘ï¼Œç¡®ä¿ä½¿ç”¨é¢„ç”Ÿæˆçš„workflowè€Œä¸æ˜¯é‡æ–°ç”Ÿæˆ"""

import os
import sys
import json
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæ¨¡æ‹Ÿrun_systematic_test_final.shçš„è®¾ç½®ï¼‰
os.environ['SKIP_MODEL_LOADING'] = 'true'
os.environ['USE_PARTIAL_LOADING'] = 'true'
os.environ['TASK_LOAD_COUNT'] = '20'
os.environ['USE_RESULT_COLLECTOR'] = 'true'

print("=" * 60)
print("ğŸ” æµ‹è¯•WorkflowåŠ è½½æµç¨‹")
print("=" * 60)

# 1. éªŒè¯ç¯å¢ƒå˜é‡
print("\n1ï¸âƒ£ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
print(f"   SKIP_MODEL_LOADING = {os.environ.get('SKIP_MODEL_LOADING')}")
print(f"   USE_PARTIAL_LOADING = {os.environ.get('USE_PARTIAL_LOADING')}")
print(f"   TASK_LOAD_COUNT = {os.environ.get('TASK_LOAD_COUNT')}")

# 2. éªŒè¯é¢„ç”Ÿæˆworkflowæ–‡ä»¶
print("\n2ï¸âƒ£ é¢„ç”ŸæˆWorkflowæ–‡ä»¶æ£€æŸ¥:")
difficulties = ['easy', 'very_easy', 'medium']
all_exist = True
for diff in difficulties:
    path = Path(f'mcp_generated_library/difficulty_versions/task_library_enhanced_v3_{diff}_with_workflows.json')
    if path.exists():
        with open(path, 'r') as f:
            data = json.load(f)
            tasks = data.get('tasks', data if isinstance(data, list) else [])
            has_workflow = tasks and len(tasks) > 0 and 'workflow' in tasks[0]
            status = "âœ…" if has_workflow else "âš ï¸"
            print(f"   {status} {diff}: {path.name} - {'æœ‰workflow' if has_workflow else 'æ— workflow'}")
            if not has_workflow:
                all_exist = False
    else:
        print(f"   âŒ {diff}: æ–‡ä»¶ä¸å­˜åœ¨")
        all_exist = False

# 3. æ¨¡æ‹ŸBatchTestRunneråˆå§‹åŒ–
print("\n3ï¸âƒ£ æ¨¡æ‹ŸBatchTestRunneråˆå§‹åŒ–:")
from batch_test_runner import BatchTestRunner

# åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•é…ç½®
test_config = {
    'model': 'test-model',
    'prompt_types': 'optimal',
    'difficulty': 'easy',
    'task_types': 'simple_task',
    'num_instances': 2,
    'max_workers': 2,
    'adaptive': False,
    'silent': True,
    'batch_commit': True,
    'checkpoint_interval': 20,
    'enable_ai_classification': False
}

print("   åˆ›å»ºBatchTestRunnerå®ä¾‹...")
runner = BatchTestRunner(**test_config)

# æ£€æŸ¥æ˜¯å¦ä½¿ç”¨é¢„ç”Ÿæˆworkflow
if hasattr(runner, 'use_pregenerated_workflows'):
    print(f"   use_pregenerated_workflows = {runner.use_pregenerated_workflows}")
    if runner.use_pregenerated_workflows:
        print("   âœ… å°†ä½¿ç”¨é¢„ç”Ÿæˆçš„workflow")
    else:
        print("   âš ï¸ å°†é‡æ–°ç”Ÿæˆworkflow")
else:
    print("   âš ï¸ æ— æ³•æ£€æµ‹use_pregenerated_workflowså±æ€§")

# 4. æ£€æŸ¥MDPWorkflowGenerator
print("\n4ï¸âƒ£ æ£€æŸ¥MDPWorkflowGenerator:")
if hasattr(runner, 'generator'):
    if runner.generator:
        if hasattr(runner.generator, 'q_network'):
            if runner.generator.q_network is None:
                print("   âœ… ç¥ç»ç½‘ç»œæ¨¡å‹æœªåŠ è½½ï¼ˆèŠ‚çœ350MBå†…å­˜ï¼‰")
            else:
                print("   âš ï¸ ç¥ç»ç½‘ç»œæ¨¡å‹å·²åŠ è½½")
        print("   âœ… MDPWorkflowGeneratorå·²åˆå§‹åŒ–")
    else:
        print("   âš ï¸ MDPWorkflowGeneratoræœªåˆå§‹åŒ–")
else:
    print("   âš ï¸ æ— generatorå±æ€§")

# 5. æ€»ç»“
print("\n" + "=" * 60)
print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
if all_exist and os.environ.get('SKIP_MODEL_LOADING') == 'true':
    print("âœ… æ‰€æœ‰é…ç½®æ­£ç¡®ï¼Œå°†ä½¿ç”¨é¢„ç”Ÿæˆworkflowï¼Œä¸ä¼šé‡æ–°ç”Ÿæˆ")
    print("âœ… å†…å­˜ä¼˜åŒ–ç”Ÿæ•ˆï¼ŒèŠ‚çœçº¦350MB/è¿›ç¨‹")
else:
    print("âš ï¸ é…ç½®å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥")

print("=" * 60)