#!/usr/bin/env python3
"""
JSONå’ŒParquetæ•°æ®åŒå‘åŒæ­¥å·¥å…·
æ”¯æŒæ•°æ®æ¸…ç†ã€éªŒè¯å’ŒåŒæ­¥
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import argparse
import shutil

class DataSyncManager:
    """ç®¡ç†JSONå’ŒParquetæ•°æ®çš„åŒæ­¥"""
    
    def __init__(self):
        self.json_path = Path('pilot_bench_cumulative_results/master_database.json')
        self.parquet_path = Path('pilot_bench_parquet_data/test_results.parquet')
        self.backup_dir = Path('pilot_bench_cumulative_results/backups')
        self.backup_dir.mkdir(exist_ok=True)
        
    def backup_files(self):
        """å¤‡ä»½å½“å‰æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # å¤‡ä»½JSON
        if self.json_path.exists():
            json_backup = self.backup_dir / f'master_database_{timestamp}.json'
            shutil.copy2(self.json_path, json_backup)
            print(f"âœ… å·²å¤‡ä»½JSON: {json_backup.name}")
            
        # å¤‡ä»½Parquet
        if self.parquet_path.exists():
            parquet_backup = self.backup_dir / f'test_results_{timestamp}.parquet'
            shutil.copy2(self.parquet_path, parquet_backup)
            print(f"âœ… å·²å¤‡ä»½Parquet: {parquet_backup.name}")
    
    def clean_invalid_flawed_records(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†æ— æ•ˆçš„flawedè®°å½•ï¼ˆåªæœ‰flawedè€Œæ²¡æœ‰å…·ä½“ç±»å‹çš„ï¼‰"""
        # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„è®°å½•
        invalid_mask = df['prompt_type'] == 'flawed'
        invalid_count = invalid_mask.sum()
        
        if invalid_count > 0:
            print(f"\nğŸ§¹ å‘ç° {invalid_count} æ¡æ— æ•ˆçš„flawedè®°å½•ï¼ˆç¼ºå°‘å…·ä½“ç±»å‹ï¼‰")
            
            # æ˜¾ç¤ºè¦åˆ é™¤çš„è®°å½•è¯¦æƒ…
            invalid_records = df[invalid_mask]
            for model in invalid_records['model'].unique():
                model_count = len(invalid_records[invalid_records['model'] == model])
                print(f"  - {model}: {model_count} æ¡")
            
            # åˆ é™¤è¿™äº›è®°å½•
            df = df[~invalid_mask].copy()
            print(f"âœ… å·²åˆ é™¤ {invalid_count} æ¡æ— æ•ˆè®°å½•")
        else:
            print("âœ… æ²¡æœ‰å‘ç°æ— æ•ˆçš„flawedè®°å½•")
            
        return df
    
    def validate_flawed_types(self, df: pd.DataFrame) -> bool:
        """éªŒè¯æ‰€æœ‰flawedè®°å½•éƒ½æœ‰å…·ä½“ç±»å‹"""
        valid_flawed_types = [
            'flawed_sequence_disorder',
            'flawed_tool_misuse', 
            'flawed_parameter_error',
            'flawed_missing_step',
            'flawed_redundant_operations',
            'flawed_logical_inconsistency',
            'flawed_semantic_drift'
        ]
        
        # æ£€æŸ¥æ‰€æœ‰åŒ…å«flawedçš„è®°å½•
        flawed_records = df[df['prompt_type'].str.contains('flawed', na=False)]
        
        # éªŒè¯æ¯æ¡è®°å½•
        invalid_types = []
        for prompt_type in flawed_records['prompt_type'].unique():
            if prompt_type == 'flawed' or prompt_type not in valid_flawed_types:
                if prompt_type != 'flawed':  # å·²ç»å¤„ç†è¿‡çš„æƒ…å†µ
                    invalid_types.append(prompt_type)
        
        if invalid_types:
            print(f"âš ï¸ å‘ç°æœªçŸ¥çš„flawedç±»å‹: {invalid_types}")
            return False
        
        print(f"âœ… æ‰€æœ‰ {len(flawed_records)} æ¡flawedè®°å½•ç±»å‹éªŒè¯é€šè¿‡")
        return True
    
    def parquet_to_json(self, clean_data: bool = True) -> Dict:
        """ä»Parquetè½¬æ¢åˆ°JSONæ ¼å¼"""
        if not self.parquet_path.exists():
            print("âŒ Parquetæ–‡ä»¶ä¸å­˜åœ¨")
            return None
            
        print("\nğŸ“– è¯»å–Parquetæ•°æ®...")
        df = pd.read_parquet(self.parquet_path)
        print(f"  è¯»å– {len(df)} æ¡è®°å½•")
        
        # æ¸…ç†æ— æ•ˆæ•°æ®
        if clean_data:
            df = self.clean_invalid_flawed_records(df)
            self.validate_flawed_types(df)
        
        # æ„å»ºJSONç»“æ„
        print("\nğŸ”„ è½¬æ¢ä¸ºJSONæ ¼å¼...")
        json_data = {
            "version": "3.0",
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "models": {},
            "test_groups": {},
            "summary": {
                "total_tests": 0,
                "total_success": 0,
                "total_partial": 0,
                "total_failure": 0,
                "models_tested": [],
                "last_test_time": None
            }
        }
        
        # å¤„ç†æ¯æ¡è®°å½•
        for _, row in df.iterrows():
            model = row['model']
            prompt_type = row['prompt_type']
            tool_rate = str(row['tool_success_rate'])
            difficulty = row['difficulty']
            task_type = row['task_type']
            
            # åˆå§‹åŒ–æ¨¡å‹ç»“æ„
            if model not in json_data['models']:
                json_data['models'][model] = {
                    'overall_stats': {},
                    'experiment_metrics': {},
                    'by_prompt_type': {}
                }
            
            # åˆå§‹åŒ–å±‚æ¬¡ç»“æ„
            model_data = json_data['models'][model]
            if prompt_type not in model_data['by_prompt_type']:
                model_data['by_prompt_type'][prompt_type] = {
                    'by_tool_success_rate': {}
                }
            
            prompt_data = model_data['by_prompt_type'][prompt_type]
            if tool_rate not in prompt_data['by_tool_success_rate']:
                prompt_data['by_tool_success_rate'][tool_rate] = {
                    'by_difficulty': {}
                }
            
            rate_data = prompt_data['by_tool_success_rate'][tool_rate]
            if difficulty not in rate_data['by_difficulty']:
                rate_data['by_difficulty'][difficulty] = {
                    'by_task_type': {}
                }
            
            diff_data = rate_data['by_difficulty'][difficulty]
            
            # å­˜å‚¨ä»»åŠ¡æ•°æ®
            task_data = {
                'total': int(row.get('total', 0)),
                'successful': int(row.get('success', 0)),
                'partial': int(row.get('partial_success', 0)),
                'failed': int(row.get('total', 0) - row.get('success', 0) - row.get('partial_success', 0)),
                'success_rate': float(row.get('success_rate', 0)),
                'partial_rate': float(row.get('partial_rate', 0)),
                'failure_rate': float(row.get('failure_rate', 0)),
                'weighted_success_score': float(row.get('weighted_success_score', 0)),
                'avg_execution_time': float(row.get('avg_execution_time', 0)),
                'avg_turns': float(row.get('avg_turns', 0)),
                'avg_tool_calls': float(row.get('avg_tool_calls', 0)),
                'tool_coverage_rate': float(row.get('tool_coverage_rate', 0))
            }
            
            diff_data['by_task_type'][task_type] = task_data
            
            # æ›´æ–°æ±‡æ€»
            json_data['summary']['total_tests'] += task_data['total']
            json_data['summary']['total_success'] += task_data['successful']
            json_data['summary']['total_partial'] += task_data['partial']
            json_data['summary']['total_failure'] += task_data['failed']
        
        json_data['summary']['models_tested'] = list(json_data['models'].keys())
        json_data['summary']['last_test_time'] = datetime.now().isoformat()
        
        print(f"âœ… è½¬æ¢å®Œæˆ: {len(json_data['models'])} ä¸ªæ¨¡å‹")
        return json_data
    
    def json_to_parquet(self, clean_data: bool = True) -> pd.DataFrame:
        """ä»JSONè½¬æ¢åˆ°Parquetæ ¼å¼"""
        if not self.json_path.exists():
            print("âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨")
            return None
            
        print("\nğŸ“– è¯»å–JSONæ•°æ®...")
        with open(self.json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        records = []
        
        # éå†JSONç»“æ„æå–è®°å½•
        for model_name, model_data in json_data.get('models', {}).items():
            for prompt_type, prompt_data in model_data.get('by_prompt_type', {}).items():
                for tool_rate, rate_data in prompt_data.get('by_tool_success_rate', {}).items():
                    for difficulty, diff_data in rate_data.get('by_difficulty', {}).items():
                        for task_type, task_data in diff_data.get('by_task_type', {}).items():
                            
                            # è·³è¿‡æ— æ•ˆçš„flawedè®°å½•
                            if clean_data and prompt_type == 'flawed':
                                print(f"  è·³è¿‡æ— æ•ˆè®°å½•: {model_name}/{prompt_type}")
                                continue
                            
                            record = {
                                'model': model_name,
                                'prompt_type': prompt_type,
                                'tool_success_rate': float(tool_rate),
                                'difficulty': difficulty,
                                'task_type': task_type,
                                'total': task_data.get('total', 0),
                                'success': task_data.get('successful', 0),
                                'full_success': task_data.get('successful', 0) - task_data.get('partial', 0),
                                'partial_success': task_data.get('partial', 0),
                                'success_rate': task_data.get('success_rate', 0),
                                'partial_rate': task_data.get('partial_rate', 0),
                                'failure_rate': task_data.get('failure_rate', 0),
                                'weighted_success_score': task_data.get('weighted_success_score', 0),
                                'avg_execution_time': task_data.get('avg_execution_time', 0),
                                'avg_turns': task_data.get('avg_turns', 0),
                                'avg_tool_calls': task_data.get('avg_tool_calls', 0),
                                'tool_coverage_rate': task_data.get('tool_coverage_rate', 0),
                                'last_updated': datetime.now().isoformat()
                            }
                            records.append(record)
        
        df = pd.DataFrame(records)
        print(f"âœ… è½¬æ¢å®Œæˆ: {len(df)} æ¡è®°å½•")
        
        if clean_data:
            df = self.clean_invalid_flawed_records(df)
            self.validate_flawed_types(df)
        
        return df
    
    def sync_parquet_to_json(self, clean: bool = True):
        """åŒæ­¥Parquetæ•°æ®åˆ°JSON"""
        print("\n=== åŒæ­¥Parquet â†’ JSON ===")
        
        # å¤‡ä»½
        self.backup_files()
        
        # è½¬æ¢
        json_data = self.parquet_to_json(clean_data=clean)
        if json_data:
            # ä¿å­˜JSON
            with open(self.json_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… å·²ä¿å­˜åˆ°: {self.json_path}")
    
    def sync_json_to_parquet(self, clean: bool = True):
        """åŒæ­¥JSONæ•°æ®åˆ°Parquet"""
        print("\n=== åŒæ­¥JSON â†’ Parquet ===")
        
        # å¤‡ä»½
        self.backup_files()
        
        # è½¬æ¢
        df = self.json_to_parquet(clean_data=clean)
        if df is not None and len(df) > 0:
            # ä¿å­˜Parquet
            df.to_parquet(self.parquet_path, index=False)
            print(f"âœ… å·²ä¿å­˜åˆ°: {self.parquet_path}")
    
    def bidirectional_sync(self, primary: str = 'parquet', clean: bool = True):
        """åŒå‘åŒæ­¥ï¼ŒæŒ‡å®šä¸»æ•°æ®æº"""
        print(f"\n{'='*60}")
        print(f"åŒå‘åŒæ­¥: ä¸»æ•°æ®æº={primary.upper()}")
        print(f"{'='*60}")
        
        if primary == 'parquet':
            self.sync_parquet_to_json(clean=clean)
        elif primary == 'json':
            self.sync_json_to_parquet(clean=clean)
        else:
            print("âŒ æ— æ•ˆçš„ä¸»æ•°æ®æºï¼Œè¯·é€‰æ‹© 'parquet' æˆ– 'json'")
    
    def show_statistics(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        print(f"\n{'='*60}")
        print("æ•°æ®ç»Ÿè®¡")
        print(f"{'='*60}")
        
        # Parquetç»Ÿè®¡
        if self.parquet_path.exists():
            df = pd.read_parquet(self.parquet_path)
            print(f"\nğŸ“Š Parquetæ•°æ®:")
            print(f"  æ€»è®°å½•æ•°: {len(df)}")
            print(f"  æ¨¡å‹æ•°: {df['model'].nunique()}")
            print(f"  Promptç±»å‹æ•°: {df['prompt_type'].nunique()}")
            
            # æ£€æŸ¥æ— æ•ˆè®°å½•
            invalid_flawed = df[df['prompt_type'] == 'flawed']
            if len(invalid_flawed) > 0:
                print(f"  âš ï¸ æ— æ•ˆflawedè®°å½•: {len(invalid_flawed)}")
        
        # JSONç»Ÿè®¡
        if self.json_path.exists():
            with open(self.json_path, 'r') as f:
                json_data = json.load(f)
            
            total_records = 0
            invalid_count = 0
            
            for model_data in json_data.get('models', {}).values():
                for prompt_type, prompt_data in model_data.get('by_prompt_type', {}).items():
                    if prompt_type == 'flawed':
                        invalid_count += 1
                    for rate_data in prompt_data.get('by_tool_success_rate', {}).values():
                        for diff_data in rate_data.get('by_difficulty', {}).values():
                            total_records += len(diff_data.get('by_task_type', {}))
            
            print(f"\nğŸ“Š JSONæ•°æ®:")
            print(f"  æ€»è®°å½•æ•°: {total_records}")
            print(f"  æ¨¡å‹æ•°: {len(json_data.get('models', {}))}")
            if invalid_count > 0:
                print(f"  âš ï¸ æ— æ•ˆflawedè®°å½•: {invalid_count}")

def main():
    parser = argparse.ArgumentParser(description='JSONå’ŒParquetæ•°æ®åŒæ­¥å·¥å…·')
    parser.add_argument('action', choices=['sync', 'clean', 'stats', 'p2j', 'j2p'],
                       help='æ“ä½œ: sync(åŒå‘åŒæ­¥), clean(æ¸…ç†å¹¶åŒæ­¥), stats(ç»Ÿè®¡), p2j(Parquetè½¬JSON), j2p(JSONè½¬Parquet)')
    parser.add_argument('--primary', choices=['parquet', 'json'], default='parquet',
                       help='ä¸»æ•°æ®æº (é»˜è®¤: parquet)')
    parser.add_argument('--no-clean', action='store_true',
                       help='ä¸æ¸…ç†æ— æ•ˆæ•°æ®')
    
    args = parser.parse_args()
    
    manager = DataSyncManager()
    clean = not args.no_clean
    
    if args.action == 'sync':
        manager.bidirectional_sync(primary=args.primary, clean=clean)
    elif args.action == 'clean':
        # å¼ºåˆ¶æ¸…ç†å¹¶åŒæ­¥
        manager.bidirectional_sync(primary=args.primary, clean=True)
    elif args.action == 'stats':
        manager.show_statistics()
    elif args.action == 'p2j':
        manager.sync_parquet_to_json(clean=clean)
    elif args.action == 'j2p':
        manager.sync_json_to_parquet(clean=clean)
    
    print("\nâœ… æ“ä½œå®Œæˆï¼")

if __name__ == "__main__":
    main()