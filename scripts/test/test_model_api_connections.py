#!/usr/bin/env python3
"""
æ¨¡å‹APIè¿æ¥æµ‹è¯•å·¥å…·
å¿«é€ŸéªŒè¯æ‰€æœ‰æ¨¡å‹çš„APIè¿æ¥æ˜¯å¦æ­£å¸¸
"""

import asyncio
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple, Any

def test_model_connections():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å‹çš„APIè¿æ¥"""
    
    # ä»é…ç½®ä¸­è·å–æ¨¡å‹åˆ—è¡¨
    config_path = Path("config/config.json")
    if not config_path.exists():
        print("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: config/config.json")
        return
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    models = config.get("supported_models", [])
    if not models:
        print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨")
        return
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹APIè¿æ¥...")
    print(f"ğŸ“‹ å…± {len(models)} ä¸ªæ¨¡å‹éœ€è¦æµ‹è¯•")
    print("=" * 60)
    
    results = []
    
    for i, model in enumerate(models, 1):
        print(f"\n[{i}/{len(models)}] æµ‹è¯•æ¨¡å‹: {model}")
        print("-" * 40)
        
        try:
            # å¯¼å…¥APIå®¢æˆ·ç«¯ç®¡ç†å™¨
            from api_client_manager import get_client_for_model
            
            # è·å–å®¢æˆ·ç«¯
            start_time = time.time()
            client = get_client_for_model(model)
            
            if not client:
                results.append((model, "âŒ è¿æ¥å¤±è´¥", "æ— æ³•è·å–å®¢æˆ·ç«¯", 0))
                print(f"âŒ {model}: æ— æ³•è·å–å®¢æˆ·ç«¯")
                continue
            
            # æµ‹è¯•ç®€å•çš„APIè°ƒç”¨
            test_prompt = "è¯·ç®€å•å›ç­”ï¼š1+1ç­‰äºå‡ ï¼Ÿ"
            
            try:
                if hasattr(client, 'is_gpt5_nano') and client.is_gpt5_nano:
                    # GPT-5 Nanoå®¢æˆ·ç«¯
                    response = client.chat.completions.create(
                        messages=[{"role": "user", "content": test_prompt}],
                        model=model
                    )
                else:
                    # æ ‡å‡†OpenAIå…¼å®¹å®¢æˆ·ç«¯
                    response = client.chat.completions.create(
                        model=model,
                        messages=[{"role": "user", "content": test_prompt}],
                        max_tokens=50,
                        temperature=0.1
                    )
                
                response_time = time.time() - start_time
                
                if response and response.choices and len(response.choices) > 0:
                    answer = response.choices[0].message.content.strip()
                    results.append((model, "âœ… è¿æ¥æˆåŠŸ", answer[:50], response_time))
                    print(f"âœ… {model}: è¿æ¥æˆåŠŸ ({response_time:.2f}s)")
                    print(f"   å“åº”: {answer[:50]}...")
                else:
                    results.append((model, "âš ï¸  å“åº”å¼‚å¸¸", "ç©ºå“åº”", response_time))
                    print(f"âš ï¸  {model}: å“åº”å¼‚å¸¸ - ç©ºå“åº”")
                    
            except Exception as api_error:
                response_time = time.time() - start_time
                error_msg = str(api_error)
                results.append((model, "âŒ APIé”™è¯¯", error_msg[:50], response_time))
                print(f"âŒ {model}: APIè°ƒç”¨å¤±è´¥")
                print(f"   é”™è¯¯: {error_msg}")
                
        except ImportError as e:
            results.append((model, "âŒ å¯¼å…¥é”™è¯¯", str(e)[:50], 0))
            print(f"âŒ {model}: å¯¼å…¥APIå®¢æˆ·ç«¯å¤±è´¥ - {e}")
            
        except Exception as e:
            results.append((model, "âŒ æœªçŸ¥é”™è¯¯", str(e)[:50], 0))
            print(f"âŒ {model}: æœªçŸ¥é”™è¯¯ - {e}")
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    successful = sum(1 for r in results if "æˆåŠŸ" in r[1])
    failed = len(results) - successful
    
    print(f"âœ… æˆåŠŸ: {successful}/{len(results)} ä¸ªæ¨¡å‹")
    print(f"âŒ å¤±è´¥: {failed}/{len(results)} ä¸ªæ¨¡å‹")
    print()
    
    # è¯¦ç»†ç»“æœè¡¨æ ¼
    print("æ¨¡å‹æµ‹è¯•è¯¦æƒ…:")
    print("-" * 60)
    print(f"{'æ¨¡å‹åç§°':<25} {'çŠ¶æ€':<12} {'å“åº”æ—¶é—´':<10}")
    print("-" * 60)
    
    for model, status, response, time_taken in results:
        time_str = f"{time_taken:.2f}s" if time_taken > 0 else "N/A"
        print(f"{model:<25} {status:<12} {time_str:<10}")
    
    # å¤±è´¥è¯¦æƒ…
    failed_models = [r for r in results if "æˆåŠŸ" not in r[1]]
    if failed_models:
        print("\n" + "=" * 60)
        print("âŒ å¤±è´¥è¯¦æƒ…:")
        print("=" * 60)
        for model, status, error, _ in failed_models:
            print(f"â€¢ {model}: {status}")
            if error and error != "N/A":
                print(f"  â””â”€ {error}")
    
    # æˆåŠŸæ¨¡å‹åˆ—è¡¨ï¼ˆç”¨äºåç»­æµ‹è¯•ï¼‰
    successful_models = [r[0] for r in results if "æˆåŠŸ" in r[1]]
    if successful_models:
        print("\n" + "=" * 60)
        print("âœ… å¯ç”¨æ¨¡å‹åˆ—è¡¨ (å¯ä»¥å¼€å§‹æµ‹è¯•):")
        print("=" * 60)
        for model in successful_models:
            print(f"  â€¢ {model}")
        
        # ä¿å­˜å¯ç”¨æ¨¡å‹åˆ—è¡¨
        available_models_file = Path("available_models.json")
        with open(available_models_file, 'w') as f:
            json.dump({
                "tested_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                "available_models": successful_models,
                "total_tested": len(results),
                "success_rate": f"{successful}/{len(results)}"
            }, f, indent=2)
        
        print(f"\nğŸ“„ å¯ç”¨æ¨¡å‹åˆ—è¡¨å·²ä¿å­˜åˆ°: {available_models_file}")
    
    return results


def test_specific_models(model_names: List[str]):
    """æµ‹è¯•æŒ‡å®šçš„æ¨¡å‹åˆ—è¡¨"""
    print(f"ğŸ¯ æµ‹è¯•æŒ‡å®šæ¨¡å‹: {', '.join(model_names)}")
    
    # ä¸´æ—¶ä¿®æ”¹é…ç½®åªæµ‹è¯•æŒ‡å®šæ¨¡å‹
    config_path = Path("config/config.json")
    if config_path.exists():
        with open(config_path, 'r') as f:
            original_config = json.load(f)
        
        # å¤‡ä»½åŸé…ç½®
        backup_config = original_config.copy()
        backup_config["models"] = model_names
        
        # ä¸´æ—¶å†™å…¥æ–°é…ç½®
        with open(config_path, 'w') as f:
            json.dump(backup_config, f, indent=2)
        
        try:
            # è¿è¡Œæµ‹è¯•
            results = test_model_connections()
        finally:
            # æ¢å¤åŸé…ç½®
            with open(config_path, 'w') as f:
                json.dump(original_config, f, indent=2)
        
        return results
    else:
        print("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶")
        return []


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯•æ¨¡å‹APIè¿æ¥")
    parser.add_argument("--models", nargs="+", help="æŒ‡å®šè¦æµ‹è¯•çš„æ¨¡å‹åç§°")
    parser.add_argument("--baseline-only", action="store_true", help="åªæµ‹è¯•åŸºçº¿æ¨¡å‹")
    
    args = parser.parse_args()
    
    if args.baseline_only:
        # åªæµ‹è¯•å‡ ä¸ªä¸»è¦æ¨¡å‹
        baseline_models = [
            "gpt-4o-mini",
            "qwen2.5-7b-instruct", 
            "DeepSeek-V3-0324",
            "Llama-3.3-70B-Instruct"
        ]
        test_specific_models(baseline_models)
    elif args.models:
        test_specific_models(args.models)
    else:
        test_model_connections()


if __name__ == "__main__":
    main()