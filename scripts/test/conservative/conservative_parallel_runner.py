#!/usr/bin/env python3
"""
Conservative Parallel Runner - ä¿å®ˆå¹¶å‘æ‰§è¡Œå™¨
è®¾è®¡ç›®æ ‡ï¼š
1. æœ‰æ•ˆåˆ©ç”¨å¤šä¸ªAPI keysï¼Œä½†é¿å…ç³»ç»Ÿè¿‡è½½
2. æ¯ä¸ªkeyç‹¬ç«‹è¿è¡Œï¼Œé¿å…å¹¶å‘å†²çª
3. åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
4. å®Œæ•´çš„é”™è¯¯æ¢å¤å’Œè¿›åº¦ä¿å­˜
"""

import os
import sys
import json
import time
import subprocess
import argparse
import psutil
from typing import List, Dict, Optional, Tuple
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ConservativeParallelRunner:
    """ä¿å®ˆå¹¶å‘æ‰§è¡Œå™¨ - ç¨³å®šä¼˜å…ˆï¼Œæ€§èƒ½å…¶æ¬¡"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.checkpoints_dir = self.base_dir / "checkpoints"
        self.checkpoints_dir.mkdir(exist_ok=True)
        
        # ä¿å®ˆçš„é»˜è®¤é…ç½®
        self.default_config = {
            'qwen_models': {
                'max_workers_per_key': 1,  # qwenæ¯ä¸ªkeyçš„max_workerså°±æ˜¯1ï¼ˆé™æµè¦æ±‚ï¼‰
                'num_keys': 3,  # ä½¿ç”¨3ä¸ªkeys (key0, key1, key2)
                'delay_between_keys': 5,  # keysä¹‹é—´å¯åŠ¨å»¶è¿Ÿ(ç§’)
                'qps_limit': 10.0,  # QPSé™åˆ¶ä¸º10
            },
            'azure_models': {
                'max_workers': 50,  # Azureæ¨¡å‹ä¿æŒåŸæœ‰å¹¶å‘æ•°
                'delay_between_shards': 3,  # åˆ†ç‰‡ä¹‹é—´å¯åŠ¨å»¶è¿Ÿ
            },
            'ideallab_closed': {
                'max_workers': 1,  # IdealLabé—­æºæ¨¡å‹ä¹Ÿæ˜¯1ä¸ªworkerï¼ˆé™æµè¦æ±‚ï¼‰
                'qps_limit': 10.0,  # QPSé™åˆ¶ä¸º10
            },
            'system': {
                'memory_threshold': 70,  # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼(%)
                'cpu_threshold': 80,  # CPUä½¿ç”¨ç‡é˜ˆå€¼(%)
                'check_interval': 10,  # ç³»ç»Ÿæ£€æŸ¥é—´éš”(ç§’)
                'max_total_processes': 10,  # æœ€å¤§æ€»è¿›ç¨‹æ•°
            }
        }
        
        self.active_processes = []
        self.completed_shards = set()
        
    def check_system_resources(self) -> Tuple[float, float]:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        memory_percent = psutil.virtual_memory().percent
        cpu_percent = psutil.cpu_percent(interval=1)
        return memory_percent, cpu_percent
    
    def should_wait_for_resources(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç­‰å¾…ç³»ç»Ÿèµ„æºé‡Šæ”¾"""
        memory_percent, cpu_percent = self.check_system_resources()
        
        if memory_percent > self.default_config['system']['memory_threshold']:
            logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_percent:.1f}%")
            return True
            
        if cpu_percent > self.default_config['system']['cpu_threshold']:
            logger.warning(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent:.1f}%")
            return True
            
        active_count = len([p for p in self.active_processes if p.poll() is None])
        if active_count >= self.default_config['system']['max_total_processes']:
            logger.warning(f"âš ï¸ æ´»è·ƒè¿›ç¨‹æ•°è¿‡å¤š: {active_count}")
            return True
            
        return False
    
    def wait_for_resources(self):
        """ç­‰å¾…ç³»ç»Ÿèµ„æºé‡Šæ”¾"""
        logger.info("â³ ç­‰å¾…ç³»ç»Ÿèµ„æºé‡Šæ”¾...")
        while self.should_wait_for_resources():
            time.sleep(self.default_config['system']['check_interval'])
            self.cleanup_finished_processes()
    
    def cleanup_finished_processes(self):
        """æ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹"""
        self.active_processes = [p for p in self.active_processes if p.poll() is None]
    
    def create_qwen_shards(self, model: str, prompt_types: str, difficulty: str,
                          task_types: str, num_instances: int, tool_success_rate: float) -> List[Dict]:
        """ä¸ºqwenæ¨¡å‹åˆ›å»ºä¿å®ˆçš„åˆ†ç‰‡ç­–ç•¥"""
        shards = []
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯5.3çš„å¤šprompt_typesæƒ…å†µ
        if "," in prompt_types and "flawed" in prompt_types:
            # 5.3åœºæ™¯ï¼šå¤šä¸ªflawedç±»å‹
            prompt_list = prompt_types.split(",")
            
            # å°†æ‰€æœ‰promptåˆ†æˆ3ç»„ï¼Œåˆ†é…ç»™3ä¸ªkeys
            group_size = len(prompt_list) // 3
            remainder = len(prompt_list) % 3
            
            groups = []
            start = 0
            for i in range(3):
                size = group_size + (1 if i < remainder else 0)
                if size > 0:
                    groups.append(",".join(prompt_list[start:start+size]))
                    start += size
            
            # åˆ†é…ç»™3ä¸ªkeys
            for key_idx, group in enumerate(groups):
                if group:
                    shards.append({
                        'model': model,
                        'prompt_types': group,
                        'difficulty': difficulty,
                        'task_types': task_types,
                        'num_instances': num_instances,
                        'tool_success_rate': tool_success_rate,
                        'key_index': key_idx,  # 0, 1, 2
                        'max_workers': self.default_config['qwen_models']['max_workers_per_key']
                    })
        else:
            # 5.1/5.2/5.4/5.5åœºæ™¯ï¼šå•ä¸ªprompt_type
            # å¹³å‡åˆ†é…åˆ°3ä¸ªkeys
            instances_per_key = num_instances // 3
            remainder = num_instances % 3
            
            for key_idx in range(3):  # ä½¿ç”¨key0, key1, key2
                shard_instances = instances_per_key + (1 if key_idx < remainder else 0)
                
                if shard_instances > 0:
                    shards.append({
                        'model': model,
                        'prompt_types': prompt_types,
                        'difficulty': difficulty,
                        'task_types': task_types,
                        'num_instances': shard_instances,
                        'tool_success_rate': tool_success_rate,
                        'key_index': key_idx,
                        'max_workers': self.default_config['qwen_models']['max_workers_per_key']
                    })
        
        logger.info(f"ğŸ“¦ Qwenä¿å®ˆåˆ†ç‰‡: {len(shards)}ä¸ªåˆ†ç‰‡ï¼Œæ¯ä¸ªä½¿ç”¨ç‹¬ç«‹çš„API key")
        return shards
    
    def create_azure_shards(self, model: str, prompt_types: str, difficulty: str,
                           task_types: str, num_instances: int, tool_success_rate: float) -> List[Dict]:
        """ä¸ºAzureæ¨¡å‹åˆ›å»ºä¿å®ˆçš„åˆ†ç‰‡ç­–ç•¥"""
        # Azureæ¨¡å‹ä½¿ç”¨å•åˆ†ç‰‡ï¼Œä½†é™ä½å¹¶å‘æ•°
        return [{
            'model': model,
            'prompt_types': prompt_types,
            'difficulty': difficulty,
            'task_types': task_types,
            'num_instances': num_instances,
            'tool_success_rate': tool_success_rate,
            'max_workers': self.default_config['azure_models']['max_workers']
        }]
    
    def execute_shard(self, shard: Dict, phase: str) -> subprocess.Popen:
        """æ‰§è¡Œå•ä¸ªåˆ†ç‰‡"""
        cmd = [
            "python3", "smart_batch_runner.py",
            "--model", shard['model'],
            "--prompt-types", shard['prompt_types'],
            "--difficulty", shard['difficulty'],
            "--task-types", shard['task_types'],
            "--num-instances", str(shard['num_instances']),
            "--tool-success-rate", str(shard['tool_success_rate']),
            "--phase", phase,
            "--workers", str(shard['max_workers']),
            "--batch-commit",
            "--enable-checkpoints"
        ]
        
        # æ·»åŠ qwenç‰¹å®šå‚æ•°
        if 'key_index' in shard:
            cmd.extend(["--idealab-key-index", str(shard['key_index'])])
            cmd.extend(["--qps", str(self.default_config['qwen_models']['qps_limit'])])
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['USE_RESULT_COLLECTOR'] = 'true'
        env['STORAGE_FORMAT'] = 'json'
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.base_dir / "logs" / f"conservative_{shard['model']}_{timestamp}.log"
        
        logger.info(f"ğŸš€ å¯åŠ¨åˆ†ç‰‡: {shard['model']} (workers={shard['max_workers']})")
        
        with open(log_file, 'w') as f:
            process = subprocess.Popen(
                cmd,
                stdout=f,
                stderr=subprocess.STDOUT,
                env=env,
                cwd=str(self.base_dir)
            )
        
        return process
    
    def run_phase(self, phase: str, model: str, prompt_types: str, difficulty: str,
                  task_types: str, num_instances: int, tool_success_rate: float = 0.8):
        """è¿è¡Œå•ä¸ªæµ‹è¯•é˜¶æ®µ"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¯ æ‰§è¡Œé˜¶æ®µ {phase}: {model}")
        logger.info(f"   Prompt: {prompt_types}")
        logger.info(f"   éš¾åº¦: {difficulty}, ä»»åŠ¡ç±»å‹: {task_types}")
        logger.info(f"   å®ä¾‹æ•°: {num_instances}")
        logger.info(f"{'='*60}\n")
        
        # åˆ›å»ºåˆ†ç‰‡
        if "qwen" in model.lower():
            shards = self.create_qwen_shards(model, prompt_types, difficulty,
                                            task_types, num_instances, tool_success_rate)
        elif any(x in model.lower() for x in ['deepseek', 'llama', 'gpt', 'gemini', 'kimi', 'o3']):
            shards = self.create_azure_shards(model, prompt_types, difficulty,
                                             task_types, num_instances, tool_success_rate)
        else:
            logger.error(f"âŒ æœªçŸ¥æ¨¡å‹ç±»å‹: {model}")
            return
        
        # æ‰§è¡Œåˆ†ç‰‡
        for i, shard in enumerate(shards):
            # ç­‰å¾…ç³»ç»Ÿèµ„æº
            self.wait_for_resources()
            
            # å¯åŠ¨åˆ†ç‰‡
            process = self.execute_shard(shard, phase)
            self.active_processes.append(process)
            
            # åˆ†ç‰‡ä¹‹é—´çš„å»¶è¿Ÿ
            if i < len(shards) - 1:
                if "qwen" in model.lower():
                    delay = self.default_config['qwen_models']['delay_between_keys']
                else:
                    delay = self.default_config['azure_models']['delay_between_shards']
                
                logger.info(f"â° ç­‰å¾…{delay}ç§’åå¯åŠ¨ä¸‹ä¸€ä¸ªåˆ†ç‰‡...")
                time.sleep(delay)
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        logger.info(f"\nâ³ ç­‰å¾…æ‰€æœ‰åˆ†ç‰‡å®Œæˆ...")
        while any(p.poll() is None for p in self.active_processes):
            time.sleep(10)
            self.cleanup_finished_processes()
            
            # æ˜¾ç¤ºè¿›åº¦
            active = len([p for p in self.active_processes if p.poll() is None])
            if active > 0:
                logger.info(f"   ä»æœ‰{active}ä¸ªåˆ†ç‰‡åœ¨è¿è¡Œ...")
        
        logger.info(f"âœ… é˜¶æ®µ{phase}å®Œæˆï¼")
    
    def run_5_3_test(self, models: List[str]):
        """è¿è¡Œ5.3æµ‹è¯•ï¼ˆç¼ºé™·å·¥ä½œæµï¼‰"""
        # 5.3çš„7ç§ç¼ºé™·ç±»å‹
        defect_groups = [
            "flawed_sequence_disorder,flawed_partial_execution",  # ç»„1
            "flawed_missing_step,flawed_redundant_step",  # ç»„2
            "flawed_logical_inconsistency,flawed_parameter_mismatch,flawed_ambiguous_instruction"  # ç»„3
        ]
        
        for model in models:
            for defects in defect_groups:
                self.run_phase(
                    phase="5.3",
                    model=model,
                    prompt_types=defects,
                    difficulty="easy",
                    task_types="all",
                    num_instances=30,  # ä¿å®ˆçš„å®ä¾‹æ•°
                    tool_success_rate=0.8
                )
                
                # ç»„ä¹‹é—´çš„å»¶è¿Ÿ
                logger.info("â° ç­‰å¾…30ç§’åå¤„ç†ä¸‹ä¸€ç»„ç¼ºé™·...")
                time.sleep(30)

def main():
    parser = argparse.ArgumentParser(description='Conservative Parallel Runner')
    parser.add_argument('--phase', type=str, help='Test phase (5.1-5.5)')
    parser.add_argument('--models', type=str, help='Comma-separated model list')
    parser.add_argument('--test', action='store_true', help='Run test mode')
    
    args = parser.parse_args()
    
    runner = ConservativeParallelRunner()
    
    if args.test:
        # æµ‹è¯•æ¨¡å¼ï¼šè¿è¡Œå°è§„æ¨¡æµ‹è¯•
        logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šè¿è¡Œå°è§„æ¨¡æµ‹è¯•")
        runner.run_phase(
            phase="5.1",
            model="qwen2.5-7b-instruct",
            prompt_types="optimal",
            difficulty="easy",
            task_types="simple_task",
            num_instances=4,
            tool_success_rate=0.8
        )
    elif args.phase == "5.3":
        # 5.3ç‰¹æ®Šå¤„ç†
        models = args.models.split(",") if args.models else ["qwen2.5-7b-instruct"]
        runner.run_5_3_test(models)
    else:
        logger.info("è¯·æŒ‡å®š --phase å’Œ --models å‚æ•°")

if __name__ == "__main__":
    main()