#!/usr/bin/env python3
"""
è¯¦ç»†APIæµ‹è¯•è„šæœ¬ - æ˜¾ç¤ºå®Œæ•´çš„è¯·æ±‚å’Œå“åº”ä¿¡æ¯å¹¶ä¿å­˜æ—¥å¿—
"""

import time
import json
import traceback
import sys
from datetime import datetime
from pathlib import Path
from api_client_manager import get_client_for_model, get_api_model_name

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)

class DualLogger:
    """åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶çš„æ—¥å¿—å™¨"""
    def __init__(self, log_file):
        self.terminal = sys.stdout
        self.log = open(log_file, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()

def test_model_detailed(model_name: str, prompt_type: str = "baseline"):
    """è¯¦ç»†æµ‹è¯•å•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"Promptç±»å‹: {prompt_type}")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print('-'*60)
    
    try:
        # 1. è·å–å®¢æˆ·ç«¯
        print(f"[1] è·å–APIå®¢æˆ·ç«¯...")
        start = time.time()
        client = get_client_for_model(model_name, prompt_type)
        elapsed = time.time() - start
        print(f"    âœ“ å®¢æˆ·ç«¯è·å–æˆåŠŸ ({elapsed:.3f}s)")
        print(f"    å®¢æˆ·ç«¯ç±»å‹: {type(client).__name__}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯Azureå®¢æˆ·ç«¯
        if hasattr(client, '_base_url'):
            print(f"    Base URL: {client._base_url}")
        
        # 2. è·å–APIæ¨¡å‹å
        print(f"[2] è·å–APIæ¨¡å‹å...")
        api_model_name = get_api_model_name(model_name)
        print(f"    åŸå§‹æ¨¡å‹å: {model_name}")
        print(f"    APIæ¨¡å‹å: {api_model_name}")
        
        # 3. æ„å»ºè¯·æ±‚
        print(f"[3] æ„å»ºAPIè¯·æ±‚...")
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Reply with exactly: Hello World"}
        ]
        
        request_params = {
            "model": api_model_name,
            "messages": messages
        }
        
        print(f"    è¯·æ±‚å‚æ•°:")
        print(f"      model: {api_model_name}")
        print(f"      messages: {len(messages)} æ¡")
        print(f"      timeout: 60ç§’")
        
        # 4. å‘é€è¯·æ±‚
        print(f"[4] å‘é€APIè¯·æ±‚...")
        start = time.time()
        response = client.chat.completions.create(**request_params, timeout=60)
        elapsed = time.time() - start
        print(f"    âœ“ è¯·æ±‚æˆåŠŸ ({elapsed:.3f}s)")
        
        # 5. è§£æå“åº”
        print(f"[5] è§£æå“åº”...")
        content = response.choices[0].message.content
        print(f"    å“åº”å†…å®¹: '{content}'")
        
        # å“åº”å…ƒæ•°æ®
        if hasattr(response, 'usage'):
            print(f"    Tokenä½¿ç”¨:")
            if hasattr(response.usage, 'prompt_tokens'):
                print(f"      Prompt tokens: {response.usage.prompt_tokens}")
            if hasattr(response.usage, 'completion_tokens'):
                print(f"      Completion tokens: {response.usage.completion_tokens}")
            if hasattr(response.usage, 'total_tokens'):
                print(f"      Total tokens: {response.usage.total_tokens}")
        
        if hasattr(response, 'model'):
            print(f"    å®é™…ä½¿ç”¨æ¨¡å‹: {response.model}")
        
        print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼æ€»è€—æ—¶: {elapsed:.3f}ç§’")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥!")
        print(f"    é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"    é”™è¯¯æ¶ˆæ¯: {str(e)}")
        print(f"\n    è¯¦ç»†é”™è¯¯è¿½è¸ª:")
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = LOG_DIR / f"api_test_{timestamp}.log"
    
    # è®¾ç½®åŒé‡è¾“å‡º
    logger = DualLogger(log_file)
    old_stdout = sys.stdout
    sys.stdout = logger
    
    try:
        print("="*80)
        print("è¯¦ç»†APIæµ‹è¯• - å®Œæ•´æ—¥å¿—")
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
        print("="*80)
        
        # æµ‹è¯•bashè„šæœ¬ä¸­å®šä¹‰çš„æ‰€æœ‰æ¨¡å‹
        # ä»run_systematic_test_final.shä¸­æå–çš„æ¨¡å‹åˆ—è¡¨
        
        # å¼€æºæ¨¡å‹ï¼ˆæ¥è‡ªOPENSOURCE_MODELSæ•°ç»„ï¼‰
        opensource_models = [
            "DeepSeek-V3-0324",       # Azure 85409
            "DeepSeek-R1-0528",       # Azure 85409
            "qwen2.5-72b-instruct",   # IdealLab
            "qwen2.5-32b-instruct",   # IdealLab
            "qwen2.5-14b-instruct",   # IdealLab
            "qwen2.5-7b-instruct",    # IdealLab
            "qwen2.5-3b-instruct",    # IdealLab
            "Llama-3.3-70B-Instruct", # Azure 85409
        ]
        
        # é—­æºæ¨¡å‹ï¼ˆæ¥è‡ªCLOSED_SOURCE_MODELSæ•°ç»„ï¼‰
        closed_source_models = [
            "gpt-4o-mini",             # Azure
            "gpt-5-mini",              # Azure 85409
            "o3-0416-global",          # IdealLab
            "gemini-2.5-flash-06-17",  # IdealLab
            "kimi-k2",                 # IdealLab
            "claude_sonnet4",          # IdealLab
        ]
        
        # åˆå¹¶æ‰€æœ‰æ¨¡å‹
        all_bash_models = opensource_models + closed_source_models
        
        print(f"ä»bashè„šæœ¬ä¸­æ‰¾åˆ°çš„æ¨¡å‹:")
        print(f"  - å¼€æºæ¨¡å‹: {len(opensource_models)} ä¸ª")
        print(f"  - é—­æºæ¨¡å‹: {len(closed_source_models)} ä¸ª")
        print(f"  - æ€»è®¡: {len(all_bash_models)} ä¸ªæ¨¡å‹")
        print("-"*80)
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºæµ‹è¯•æ¡ç›®
        test_models = [(model, "baseline") for model in all_bash_models]
        
        success_count = 0
        failed_models = []
        
        for model, prompt_type in test_models:
            if test_model_detailed(model, prompt_type):
                success_count += 1
            else:
                failed_models.append(model)
    
        # æ€»ç»“
        print("\n" + "="*80)
        print("æµ‹è¯•æ€»ç»“")
        print("-"*80)
        print(f"æˆåŠŸ: {success_count}/{len(test_models)}")
        if failed_models:
            print(f"å¤±è´¥çš„æ¨¡å‹: {', '.join(failed_models)}")
        else:
            print("âœ… æ‰€æœ‰æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
        
        print(f"\næ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
        
    finally:
        # æ¢å¤æ ‡å‡†è¾“å‡º
        sys.stdout = old_stdout
        logger.close()
        print(f"\nğŸ“ æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")

if __name__ == "__main__":
    main()