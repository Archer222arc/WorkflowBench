#!/usr/bin/env python3
"""
æŸ¥çœ‹5.4å·¥å…·å¯é æ€§æ•æ„Ÿæ€§æµ‹è¯•ç»“æœ
ä»æ•°æ®åº“æå–å¹¶åˆ†æä¸åŒtool_success_rateä¸‹çš„è¡¨ç°
"""

import json
from pathlib import Path
from typing import Dict, List
import numpy as np

def load_database() -> Dict:
    """åŠ è½½æ•°æ®åº“"""
    db_path = Path("pilot_bench_cumulative_results/master_database.json")
    if not db_path.exists():
        print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {db_path}")
        return {}
    
    with open(db_path, 'r') as f:
        return json.load(f)

def extract_5_4_data(db: Dict) -> Dict:
    """æå–5.4æµ‹è¯•æ•°æ®"""
    results = {}
    
    # è¦åˆ†æçš„æ¨¡å‹
    models = [
        "qwen2.5-72b-instruct",
        "qwen2.5-32b-instruct", 
        "qwen2.5-14b-instruct",
        "qwen2.5-7b-instruct",
        "qwen2.5-3b-instruct",
        "DeepSeek-V3-0324",
        "DeepSeek-R1-0528",
        "Llama-3.3-70B-Instruct"
    ]
    
    # å·¥å…·æˆåŠŸç‡é…ç½®
    tool_rates = ["0.9", "0.8", "0.7", "0.6"]
    
    for model in models:
        if model not in db.get('models', {}):
            continue
            
        model_data = db['models'][model]
        results[model] = {}
        
        # æŸ¥æ‰¾optimal promptä¸‹çš„æ•°æ®
        if 'by_prompt_type' in model_data and 'optimal' in model_data['by_prompt_type']:
            optimal_data = model_data['by_prompt_type']['optimal']
            
            if 'by_tool_success_rate' in optimal_data:
                for rate in tool_rates:
                    if rate in optimal_data['by_tool_success_rate']:
                        rate_data = optimal_data['by_tool_success_rate'][rate]
                        
                        # æŸ¥æ‰¾easyéš¾åº¦ä¸‹çš„æ•°æ®
                        if 'by_difficulty' in rate_data and 'easy' in rate_data['by_difficulty']:
                            easy_data = rate_data['by_difficulty']['easy']
                            
                            # æ±‡æ€»æ‰€æœ‰ä»»åŠ¡ç±»å‹
                            total_tests = 0
                            successful = 0
                            task_results = {}
                            
                            if 'by_task_type' in easy_data:
                                for task_type, task_data in easy_data['by_task_type'].items():
                                    total = task_data.get('total', 0)
                                    success = task_data.get('successful', 0)
                                    
                                    if total > 0:
                                        total_tests += total
                                        successful += success
                                        task_results[task_type] = {
                                            'total': total,
                                            'successful': success,
                                            'rate': success / total if total > 0 else 0
                                        }
                            
                            if total_tests > 0:
                                results[model][float(rate)] = {
                                    'total': total_tests,
                                    'successful': successful,
                                    'success_rate': successful / total_tests,
                                    'tasks': task_results
                                }
    
    return results

def calculate_sensitivity(performance_dict: Dict[float, Dict]) -> Dict:
    """è®¡ç®—æ•æ„Ÿæ€§æŒ‡æ ‡"""
    rates = sorted([r for r in performance_dict.keys() if performance_dict[r]['total'] > 0])
    
    if len(rates) < 2:
        return {
            'sensitivity': None,
            'robustness': None,
            'degradation': None
        }
    
    performances = [performance_dict[r]['success_rate'] for r in rates]
    
    # è®¡ç®—æ•æ„Ÿæ€§ç³»æ•°ï¼ˆæ ‡å‡†å·®/å¹³å‡å€¼ï¼‰
    if np.mean(performances) > 0:
        sensitivity = np.std(performances) / np.mean(performances)
    else:
        sensitivity = None
    
    # è®¡ç®—é²æ£’æ€§å¾—åˆ†
    if sensitivity is not None:
        robustness = np.mean(performances) * 0.6 + (1 - min(sensitivity, 1)) * 0.4
    else:
        robustness = None
    
    # è®¡ç®—é€€åŒ–ç‡
    degradation = {}
    for i in range(len(rates) - 1):
        key = f"{rates[i]:.0%}â†’{rates[i+1]:.0%}"
        if performances[i] > 0:
            degradation[key] = (performances[i] - performances[i+1]) / performances[i]
        else:
            degradation[key] = None
    
    return {
        'sensitivity': sensitivity,
        'robustness': robustness,
        'degradation': degradation,
        'mean_performance': np.mean(performances)
    }

def print_results_table(results: Dict):
    """æ‰“å°ç»“æœè¡¨æ ¼"""
    
    print("\n" + "=" * 100)
    print("5.4 å·¥å…·å¯é æ€§æ•æ„Ÿæ€§æµ‹è¯•ç»“æœ")
    print("=" * 100)
    
    # ä¸»è¡¨æ ¼
    print("\nğŸ“Š æ€§èƒ½æ±‡æ€»è¡¨")
    print("-" * 100)
    print(f"{'æ¨¡å‹åç§°':<30} {'90%':>10} {'80%':>10} {'70%':>10} {'60%':>10} {'æ•æ„Ÿç³»æ•°':>10} {'é²æ£’æ€§':>10}")
    print("-" * 100)
    
    for model, data in results.items():
        row = [model[:28]]
        
        for rate in [0.9, 0.8, 0.7, 0.6]:
            if rate in data and data[rate]['total'] > 0:
                row.append(f"{data[rate]['success_rate']:.1%}")
            else:
                row.append("-")
        
        # è®¡ç®—æ•æ„Ÿæ€§æŒ‡æ ‡
        metrics = calculate_sensitivity(data)
        
        if metrics['sensitivity'] is not None:
            row.append(f"{metrics['sensitivity']:.3f}")
        else:
            row.append("-")
            
        if metrics['robustness'] is not None:
            row.append(f"{metrics['robustness']:.1%}")
        else:
            row.append("-")
        
        print(f"{row[0]:<30} {row[1]:>10} {row[2]:>10} {row[3]:>10} {row[4]:>10} {row[5]:>10} {row[6]:>10}")
    
    print("-" * 100)
    
    # è¯¦ç»†ä»»åŠ¡åˆ†è§£ï¼ˆæ¯ä¸ªå·¥å…·æˆåŠŸç‡ï¼‰
    for rate in [0.9, 0.8, 0.7, 0.6]:
        has_data = any(rate in data and data[rate]['total'] > 0 for data in results.values())
        
        if has_data:
            print(f"\nğŸ“‹ å·¥å…·æˆåŠŸç‡ {rate:.0%} è¯¦ç»†åˆ†è§£")
            print("-" * 100)
            print(f"{'æ¨¡å‹åç§°':<30} {'ç®€å•ä»»åŠ¡':>12} {'åŸºç¡€ä»»åŠ¡':>12} {'æ•°æ®ç®¡é“':>12} {'APIé›†æˆ':>12} {'å¤šé˜¶æ®µ':>12}")
            print("-" * 100)
            
            for model, data in results.items():
                if rate in data and data[rate]['total'] > 0:
                    row = [model[:28]]
                    
                    task_mapping = {
                        'simple_task': 'ç®€å•ä»»åŠ¡',
                        'basic_task': 'åŸºç¡€ä»»åŠ¡',
                        'data_pipeline': 'æ•°æ®ç®¡é“',
                        'api_integration': 'APIé›†æˆ',
                        'multi_stage_pipeline': 'å¤šé˜¶æ®µ'
                    }
                    
                    for task_key in ['simple_task', 'basic_task', 'data_pipeline', 
                                    'api_integration', 'multi_stage_pipeline']:
                        if task_key in data[rate]['tasks']:
                            task_data = data[rate]['tasks'][task_key]
                            rate_str = f"{task_data['rate']:.1%}"
                            count_str = f"({task_data['successful']}/{task_data['total']})"
                            row.append(rate_str)
                        else:
                            row.append("-")
                    
                    print(f"{row[0]:<30} {row[1]:>12} {row[2]:>12} {row[3]:>12} {row[4]:>12} {row[5]:>12}")
            
            print("-" * 100)
    
    # æ€§èƒ½é€€åŒ–åˆ†æ
    print("\nğŸ“‰ æ€§èƒ½é€€åŒ–åˆ†æ")
    print("-" * 100)
    print(f"{'æ¨¡å‹åç§°':<30} {'90%â†’80%':>15} {'80%â†’70%':>15} {'70%â†’60%':>15} {'ç¨³å®šæ€§è¯„çº§':>15}")
    print("-" * 100)
    
    for model, data in results.items():
        metrics = calculate_sensitivity(data)
        row = [model[:28]]
        
        if metrics['degradation']:
            for key in ['90%â†’80%', '80%â†’70%', '70%â†’60%']:
                if key in metrics['degradation'] and metrics['degradation'][key] is not None:
                    deg = metrics['degradation'][key]
                    row.append(f"{deg:.1%}")
                else:
                    row.append("-")
            
            # è¯„çº§
            avg_deg = [d for d in metrics['degradation'].values() if d is not None]
            if avg_deg:
                avg = np.mean(avg_deg)
                if avg < 0.1:
                    rating = "Açº§"
                elif avg < 0.2:
                    rating = "Bçº§"
                elif avg < 0.3:
                    rating = "Cçº§"
                else:
                    rating = "Dçº§"
            else:
                rating = "-"
            row.append(rating)
        else:
            row.extend(["-", "-", "-", "-"])
        
        print(f"{row[0]:<30} {row[1]:>15} {row[2]:>15} {row[3]:>15} {row[4]:>15}")
    
    print("-" * 100)

def print_summary_stats(results: Dict):
    """æ‰“å°æ±‡æ€»ç»Ÿè®¡"""
    print("\nğŸ“Š ç»Ÿè®¡æ±‡æ€»")
    print("-" * 50)
    
    # ç»Ÿè®¡æ•°æ®å®Œæ•´æ€§
    total_models = len(results)
    models_with_data = {}
    
    for rate in [0.9, 0.8, 0.7, 0.6]:
        count = sum(1 for data in results.values() if rate in data and data[rate]['total'] > 0)
        models_with_data[rate] = count
    
    print(f"æ€»æ¨¡å‹æ•°: {total_models}")
    for rate, count in models_with_data.items():
        print(f"  {rate:.0%}å·¥å…·æˆåŠŸç‡: {count}ä¸ªæ¨¡å‹æœ‰æ•°æ®")
    
    # æ‰¾å‡ºæœ€é²æ£’çš„æ¨¡å‹
    best_robustness = None
    best_model = None
    
    for model, data in results.items():
        metrics = calculate_sensitivity(data)
        if metrics['robustness'] is not None:
            if best_robustness is None or metrics['robustness'] > best_robustness:
                best_robustness = metrics['robustness']
                best_model = model
    
    if best_model:
        print(f"\nğŸ† æœ€é²æ£’æ¨¡å‹: {best_model}")
        print(f"   é²æ£’æ€§å¾—åˆ†: {best_robustness:.1%}")
    
    # æ‰¾å‡ºæœ€æ•æ„Ÿçš„æ¨¡å‹
    most_sensitive = None
    sensitive_model = None
    
    for model, data in results.items():
        metrics = calculate_sensitivity(data)
        if metrics['sensitivity'] is not None:
            if most_sensitive is None or metrics['sensitivity'] > most_sensitive:
                most_sensitive = metrics['sensitivity']
                sensitive_model = model
    
    if sensitive_model:
        print(f"\nâš ï¸ æœ€æ•æ„Ÿæ¨¡å‹: {sensitive_model}")
        print(f"   æ•æ„Ÿç³»æ•°: {most_sensitive:.3f}")

def main():
    """ä¸»å‡½æ•°"""
    print("åŠ è½½æ•°æ®åº“...")
    db = load_database()
    
    if not db:
        return
    
    print("æå–5.4æµ‹è¯•æ•°æ®...")
    results = extract_5_4_data(db)
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°5.4æµ‹è¯•æ•°æ®")
        return
    
    # æ‰“å°ç»“æœ
    print_results_table(results)
    print_summary_stats(results)
    
    print("\n" + "=" * 100)
    print("æç¤ºï¼š")
    print("- æ•æ„Ÿç³»æ•° < 0.2: ä½æ•æ„Ÿæ€§ï¼ˆç¨³å®šï¼‰")
    print("- æ•æ„Ÿç³»æ•° 0.2-0.4: ä¸­ç­‰æ•æ„Ÿæ€§")
    print("- æ•æ„Ÿç³»æ•° > 0.4: é«˜æ•æ„Ÿæ€§ï¼ˆæ˜“å—å½±å“ï¼‰")
    print("- é²æ£’æ€§å¾—åˆ†ç»¼åˆè€ƒè™‘æ€§èƒ½å’Œç¨³å®šæ€§")
    print("=" * 100)

if __name__ == "__main__":
    main()