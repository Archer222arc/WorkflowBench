#!/usr/bin/env python3
"""
ä»JSONåŒæ­¥æ•°æ®åˆ°Parquetæ ¼å¼
"""
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import numpy as np

def extract_summaries_from_json(db):
    """ä»JSONæ•°æ®åº“æå–æ±‡æ€»è®°å½•"""
    summaries = []
    
    for model_name, model_data in db.get('models', {}).items():
        if 'by_prompt_type' not in model_data:
            continue
            
        for prompt_type, prompt_data in model_data['by_prompt_type'].items():
            if 'by_tool_success_rate' not in prompt_data:
                continue
                
            for tool_rate, rate_data in prompt_data['by_tool_success_rate'].items():
                if 'by_difficulty' not in rate_data:
                    continue
                    
                for difficulty, diff_data in rate_data['by_difficulty'].items():
                    if 'by_task_type' not in diff_data:
                        continue
                        
                    for task_type, task_data in diff_data['by_task_type'].items():
                        # åˆ›å»ºæ±‡æ€»è®°å½•
                        summary = {
                            'model': model_name,
                            'prompt_type': prompt_type,
                            'difficulty': difficulty,
                            'task_type': task_type,
                            'tool_success_rate': float(tool_rate),
                            'total': task_data.get('total', 0),
                            'success': task_data.get('success', 0),
                            'partial': task_data.get('partial', 0),
                            'failed': task_data.get('failed', 0),
                            'success_rate': task_data.get('success_rate', 0),
                            'partial_rate': task_data.get('partial_rate', 0),
                            'failure_rate': task_data.get('failure_rate', 0),
                            'weighted_success_score': task_data.get('weighted_success_score', 0),
                            'avg_execution_time': task_data.get('avg_execution_time', 0),
                            'avg_turns': task_data.get('avg_turns', 0),
                            'avg_tool_calls': task_data.get('avg_tool_calls', 0),
                            'tool_coverage_rate': task_data.get('tool_coverage_rate', 0),
                            'last_updated': datetime.now().isoformat()
                        }
                        
                        # æ·»åŠ ç¼ºé™·ç±»å‹ï¼ˆå¦‚æœæ˜¯ç¼ºé™·æµ‹è¯•ï¼‰
                        if 'flawed' in prompt_type:
                            summary['is_flawed'] = True
                            summary['flaw_type'] = prompt_type.replace('flawed_', '')
                        else:
                            summary['is_flawed'] = False
                            summary['flaw_type'] = None
                        
                        summaries.append(summary)
    
    return summaries

def main():
    # è¯»å–JSONæ•°æ®åº“
    json_path = Path('pilot_bench_cumulative_results/master_database.json')
    if not json_path.exists():
        print("âŒ JSONæ•°æ®åº“ä¸å­˜åœ¨")
        return
    
    with open(json_path, 'r') as f:
        db = json.load(f)
    
    print("ğŸ“– è¯»å–JSONæ•°æ®åº“...")
    
    # æå–æ±‡æ€»è®°å½•
    summaries = extract_summaries_from_json(db)
    print(f"âœ… æå–äº† {len(summaries)} æ¡æ±‡æ€»è®°å½•")
    
    if not summaries:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ±‡æ€»è®°å½•")
        return
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(summaries)
    
    # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®
    numeric_columns = ['total', 'success', 'partial', 'failed', 'success_rate', 
                      'partial_rate', 'failure_rate', 'weighted_success_score',
                      'avg_execution_time', 'avg_turns', 'avg_tool_calls', 
                      'tool_coverage_rate', 'tool_success_rate']
    
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # åˆ›å»ºParquetç›®å½•
    parquet_dir = Path('pilot_bench_parquet_data')
    parquet_dir.mkdir(exist_ok=True)
    
    # å¤‡ä»½ç°æœ‰çš„Parquetæ–‡ä»¶
    parquet_path = parquet_dir / 'test_results.parquet'
    if parquet_path.exists():
        backup_path = parquet_dir / f"test_results_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet"
        parquet_path.rename(backup_path)
        print(f"âœ… å¤‡ä»½ç°æœ‰Parquetæ–‡ä»¶åˆ°: {backup_path}")
    
    # ä¿å­˜æ–°çš„Parquetæ–‡ä»¶
    df.to_parquet(parquet_path, index=False)
    print(f"âœ… ä¿å­˜äº† {len(df)} æ¡è®°å½•åˆ°Parquetæ–‡ä»¶")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  æ¨¡å‹æ•°: {df['model'].nunique()}")
    print(f"  æç¤ºç±»å‹æ•°: {df['prompt_type'].nunique()}")
    
    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    print("\næŒ‰æ¨¡å‹ç»Ÿè®¡:")
    model_stats = df.groupby('model').agg({
        'total': 'sum',
        'success': 'sum'
    })
    
    for model, row in model_stats.iterrows():
        total = row['total']
        success = row['success']
        rate = (success / total * 100) if total > 0 else 0
        print(f"  {model}: {total}ä¸ªæµ‹è¯•, æˆåŠŸç‡={rate:.1f}%")
    
    # ç»Ÿè®¡ç¼ºé™·æµ‹è¯•
    flawed_df = df[df['is_flawed'] == True]
    if len(flawed_df) > 0:
        print(f"\nç¼ºé™·æµ‹è¯•ç»Ÿè®¡:")
        print(f"  æ€»ç¼ºé™·æµ‹è¯•: {flawed_df['total'].sum()}")
        print(f"  ç¼ºé™·ç±»å‹æ•°: {flawed_df['flaw_type'].nunique()}")
    
    # ä¿å­˜JSONæ ¼å¼çš„Parquetå†…å®¹ï¼ˆç”¨äºæŸ¥çœ‹ï¼‰
    json_preview_path = parquet_dir / 'test_results.parquet.as.json'
    df.to_json(json_preview_path, orient='records', indent=2, force_ascii=False)
    print(f"\nâœ… ä¿å­˜JSONé¢„è§ˆåˆ°: {json_preview_path}")
    
    print("\nâœ… JSONåˆ°ParquetåŒæ­¥å®Œæˆï¼")

if __name__ == "__main__":
    main()