#!/usr/bin/env python3
"""
ResultCollectoråŠŸèƒ½éªŒè¯æµ‹è¯•
æµ‹è¯•å°è§„æ¨¡è¶…å¹¶å‘æ¨¡å¼ä¸‹çš„æ•°æ®æ”¶é›†å®Œæ•´æ€§
"""

import os
import sys
import time
import json
from pathlib import Path
import subprocess
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_result_collector_basic():
    """åŸºç¡€åŠŸèƒ½æµ‹è¯•ï¼šéªŒè¯ResultCollectorçš„æ ¸å¿ƒåŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹ResultCollectoråŸºç¡€åŠŸèƒ½æµ‹è¯•")
    
    # ç¡®ä¿result_collector.pyå¯ä»¥æ­£å¸¸å¯¼å…¥
    try:
        from result_collector import ResultCollector, ResultAggregator
        logger.info("âœ… ResultCollectoræ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ ResultCollectoræ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_results = [
        {
            "model": "test-model-1",
            "task_type": "simple_task", 
            "prompt_type": "optimal",
            "difficulty": "easy",
            "tool_success_rate": 0.8,
            "success": True,
            "execution_time": 25.5,
            "workflow_score": 0.95
        },
        {
            "model": "test-model-1",
            "task_type": "basic_task",
            "prompt_type": "optimal", 
            "difficulty": "easy",
            "tool_success_rate": 0.8,
            "success": False,
            "execution_time": 12.3,
            "workflow_score": 0.45
        }
    ]
    
    # æµ‹è¯•ResultCollector
    collector = ResultCollector("test_temp_results")
    
    # æ·»åŠ æµ‹è¯•ç»“æœ
    result_file = collector.add_batch_result("test-model-1", test_results, 
                                           {"test_batch": "basic_test"})
    logger.info(f"âœ… æˆåŠŸæ·»åŠ æ‰¹æ¬¡ç»“æœï¼Œæ–‡ä»¶: {result_file}")
    
    # æ£€æŸ¥å¾…å¤„ç†æ•°é‡
    pending = collector.get_pending_count()
    logger.info(f"ğŸ“Š å¾…å¤„ç†ç»“æœæ–‡ä»¶æ•°é‡: {pending}")
    
    # æ”¶é›†ç»“æœ
    collected = collector.collect_all_results(cleanup=False)
    logger.info(f"âœ… æ”¶é›†åˆ° {len(collected)} ä¸ªæ‰¹æ¬¡ç»“æœ")
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    if len(collected) == 1:
        batch = collected[0]
        if (batch['model'] == 'test-model-1' and 
            batch['result_count'] == 2 and
            len(batch['results']) == 2):
            logger.info("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        else:
            logger.error("âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥")
            return False
    else:
        logger.error(f"âŒ æœŸæœ›æ”¶é›†åˆ°1ä¸ªæ‰¹æ¬¡ï¼Œå®é™…æ”¶é›†åˆ°{len(collected)}ä¸ª")
        return False
    
    # æµ‹è¯•èšåˆå™¨
    aggregator = ResultAggregator()
    aggregated_db = aggregator.aggregate_results(collected)
    
    if 'test-model-1' in aggregated_db['models']:
        logger.info("âœ… ç»“æœèšåˆéªŒè¯é€šè¿‡")
    else:
        logger.error("âŒ ç»“æœèšåˆéªŒè¯å¤±è´¥")
        return False
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    collector.clear_temp_files()
    test_temp_dir = Path("test_temp_results")
    if test_temp_dir.exists():
        test_temp_dir.rmdir()
    
    logger.info("âœ… ResultCollectoråŸºç¡€åŠŸèƒ½æµ‹è¯•å®Œæˆ")
    return True

def test_ultra_parallel_integration():
    """é›†æˆæµ‹è¯•ï¼šåœ¨çœŸå®çš„è¶…å¹¶å‘ç¯å¢ƒä¸­æµ‹è¯•"""
    logger.info("ğŸ§ª å¼€å§‹è¶…å¹¶å‘é›†æˆæµ‹è¯•")
    
    # åˆ›å»ºå°è§„æ¨¡æµ‹è¯•é…ç½®
    test_env = os.environ.copy()
    test_env['USE_RESULT_COLLECTOR'] = 'true'
    test_env['STORAGE_FORMAT'] = 'json'  # ä½¿ç”¨JSONæ ¼å¼ä¾¿äºéªŒè¯
    
    # é€‰æ‹©ä¸€ä¸ªå¿«é€Ÿçš„æ¨¡å‹è¿›è¡Œå°è§„æ¨¡æµ‹è¯•
    test_model = "DeepSeek-V3-0324"
    
    logger.info(f"ğŸ“‹ å‡†å¤‡æµ‹è¯•é…ç½®:")
    logger.info(f"  æ¨¡å‹: {test_model}")
    logger.info(f"  ä½¿ç”¨ResultCollector: {test_env.get('USE_RESULT_COLLECTOR')}")
    logger.info(f"  å­˜å‚¨æ ¼å¼: {test_env.get('STORAGE_FORMAT')}")
    
    # æ‰§è¡Œå°è§„æ¨¡è¶…å¹¶å‘æµ‹è¯•
    # åªæµ‹è¯•2ä¸ªå®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹2ä¸ªä»»åŠ¡ï¼Œæ€»å…±4ä¸ªä»»åŠ¡
    cmd = [
        'python', 'ultra_parallel_runner.py',
        '--model', test_model,
        '--prompt-types', 'optimal',
        '--difficulty', 'easy', 
        '--task-types', 'simple_task,basic_task',
        '--tool-success-rate', '0.8',
        '--num-instances', '2',  # 2ä¸ªå®ä¾‹å¹¶å‘
        '--max-workers', '10'  # è¾ƒå°‘çš„workeré¿å…èµ„æºå ç”¨è¿‡å¤š
    ]
    
    logger.info(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # æ‰§è¡Œæµ‹è¯•ï¼ˆè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…ï¼‰
        process = subprocess.run(
            cmd, 
            env=test_env,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        logger.info(f"â±ï¸ æµ‹è¯•æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        
        # æ£€æŸ¥æ‰§è¡Œç»“æœ
        if process.returncode == 0:
            logger.info("âœ… è¶…å¹¶å‘æµ‹è¯•æ‰§è¡ŒæˆåŠŸ")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ResultCollectorç›¸å…³çš„æ—¥å¿—è¾“å‡º
            stdout = process.stdout
            if "ResultCollector" in stdout or "å·²æäº¤" in stdout or "ğŸ“¤" in stdout:
                logger.info("âœ… å‘ç°ResultCollectoræ´»åŠ¨æ—¥å¿—")
                # è¾“å‡ºç›¸å…³æ—¥å¿—ç‰‡æ®µ
                lines = stdout.split('\n')
                for line in lines:
                    if any(keyword in line for keyword in ["ResultCollector", "ğŸ“¤", "ğŸ“¥", "æ”¶é›†å™¨"]):
                        logger.info(f"  ğŸ“ {line}")
            else:
                logger.warning("âš ï¸ æœªå‘ç°ResultCollectoræ´»åŠ¨æ—¥å¿—")
            
        else:
            logger.error(f"âŒ è¶…å¹¶å‘æµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
            logger.error(f"STDOUT: {process.stdout}")
            logger.error(f"STDERR: {process.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        logger.error("âŒ æµ‹è¯•è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰")
        return False
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
        return False
    
    # æ£€æŸ¥temp_resultsç›®å½•
    temp_results_dir = Path("temp_results")
    if temp_results_dir.exists():
        temp_files = list(temp_results_dir.glob("*.json"))
        logger.info(f"ğŸ“ å‘ç° {len(temp_files)} ä¸ªä¸´æ—¶ç»“æœæ–‡ä»¶")
        
        if len(temp_files) > 0:
            logger.info("âœ… ResultCollectoræ­£å¸¸å·¥ä½œï¼Œç”Ÿæˆäº†ä¸´æ—¶ç»“æœæ–‡ä»¶")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in temp_files:
                temp_file.unlink()
            if not any(temp_results_dir.iterdir()):
                temp_results_dir.rmdir()
        else:
            logger.warning("âš ï¸ æ²¡æœ‰å‘ç°ä¸´æ—¶ç»“æœæ–‡ä»¶ï¼Œå¯èƒ½ä½¿ç”¨äº†ä¼ ç»Ÿæ¨¡å¼")
    else:
        logger.warning("âš ï¸ æ²¡æœ‰å‘ç°temp_resultsç›®å½•")
    
    # æ£€æŸ¥æœ€ç»ˆæ•°æ®åº“
    db_path = Path("pilot_bench_cumulative_results/master_database.json")
    if db_path.exists():
        try:
            with open(db_path, 'r') as f:
                db = json.load(f)
            
            if test_model in db.get('models', {}):
                model_data = db['models'][test_model]
                total_tests = model_data.get('total_tests', 0)
                logger.info(f"âœ… åœ¨æ•°æ®åº“ä¸­æ‰¾åˆ° {test_model}ï¼Œæ€»æµ‹è¯•æ•°: {total_tests}")
                
                if total_tests > 0:
                    logger.info("âœ… æ•°æ®ä¿å­˜éªŒè¯é€šè¿‡")
                else:
                    logger.warning("âš ï¸ æ¨¡å‹æ•°æ®å­˜åœ¨ä½†æµ‹è¯•æ•°ä¸º0")
            else:
                logger.warning(f"âš ï¸ åœ¨æ•°æ®åº“ä¸­æœªæ‰¾åˆ° {test_model}")
                
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ•°æ®åº“å¤±è´¥: {e}")
    else:
        logger.warning("âš ï¸ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
    
    logger.info("âœ… è¶…å¹¶å‘é›†æˆæµ‹è¯•å®Œæˆ")
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ¯ ResultCollectoråŠŸèƒ½éªŒè¯æµ‹è¯•å¼€å§‹")
    logger.info("=" * 60)
    
    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    logger.info("\nğŸ“‹ é˜¶æ®µ1: åŸºç¡€åŠŸèƒ½æµ‹è¯•")
    basic_test_passed = test_result_collector_basic()
    
    if not basic_test_passed:
        logger.error("âŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡åç»­æµ‹è¯•")
        return False
    
    # é›†æˆæµ‹è¯•
    logger.info("\nğŸ“‹ é˜¶æ®µ2: è¶…å¹¶å‘é›†æˆæµ‹è¯•")
    integration_test_passed = test_ultra_parallel_integration()
    
    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    if basic_test_passed and integration_test_passed:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ResultCollectorå¯ä»¥æ­£å¸¸ä½¿ç”¨")
        logger.info("ğŸ’¡ å»ºè®®ï¼šå¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨ResultCollector")
        logger.info("ğŸ“ ä½¿ç”¨æ–¹æ³•ï¼šexport USE_RESULT_COLLECTOR=true")
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)