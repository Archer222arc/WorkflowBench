#!/usr/bin/env python3
"""
åˆ†æqwenæ¨¡å‹æ•°æ®ï¼Œè¯†åˆ«éœ€è¦æ¸…ç†çš„éƒ¨åˆ†
"""

import json
from pathlib import Path
from collections import defaultdict

def analyze_qwen_data():
    """æ·±å…¥åˆ†æqwenæ¨¡å‹çš„æ•°æ®"""
    
    # æ£€æŸ¥JSONæ•°æ®åº“
    json_db_path = Path("pilot_bench_cumulative_results/master_database.json")
    if json_db_path.exists():
        print("=" * 60)
        print("JSONæ•°æ®åº“åˆ†æ")
        print("=" * 60)
        with open(json_db_path, 'r', encoding='utf-8') as f:
            json_db = json.load(f)
        analyze_database(json_db, "JSON")
    else:
        print("âŒ JSONæ•°æ®åº“ä¸å­˜åœ¨")
    
    # æ£€æŸ¥Parquetæ•°æ®
    parquet_path = Path("pilot_bench_parquet_data/test_results.parquet")
    if parquet_path.exists():
        print("\n" + "=" * 60)
        print("Parquetæ•°æ®åˆ†æ")
        print("=" * 60)
        try:
            import pandas as pd
            df = pd.read_parquet(parquet_path)
            
            # ç­›é€‰qwenæ¨¡å‹
            qwen_models = ["qwen2.5-72b-instruct", "qwen2.5-32b-instruct", 
                          "qwen2.5-14b-instruct", "qwen2.5-7b-instruct", 
                          "qwen2.5-3b-instruct"]
            
            for model in qwen_models:
                model_df = df[df['model'] == model] if 'model' in df.columns else pd.DataFrame()
                if not model_df.empty:
                    print(f"\nğŸ“Š {model}:")
                    print(f"  æ€»è®°å½•æ•°: {len(model_df)}")
                    
                    if 'prompt_type' in model_df.columns:
                        prompt_counts = model_df['prompt_type'].value_counts()
                        print("  æŒ‰promptç±»å‹:")
                        for prompt_type, count in prompt_counts.items():
                            indicator = "âš ï¸" if prompt_type.startswith('flawed_') else "âœ…"
                            print(f"    {indicator} {prompt_type}: {count}")
        except ImportError:
            print("  âš ï¸ pandasæœªå®‰è£…ï¼Œæ— æ³•åˆ†æParquetæ•°æ®")
        except Exception as e:
            print(f"  âŒ åˆ†æParquetå¤±è´¥: {e}")

def analyze_database(db, db_type=""):
    """åˆ†ææ•°æ®åº“ä¸­çš„qwenæ•°æ®"""
    
    qwen_models = [
        "qwen2.5-72b-instruct",
        "qwen2.5-32b-instruct", 
        "qwen2.5-14b-instruct",
        "qwen2.5-7b-instruct",
        "qwen2.5-3b-instruct"
    ]
    
    # ç»Ÿè®¡æ±‡æ€»
    summary = {
        'total_by_model': {},
        'flawed_by_model': {},
        'normal_by_model': {}
    }
    
    for model in qwen_models:
        if model not in db.get('models', {}):
            print(f"\nğŸ“Š {model}: æ— æ•°æ®")
            continue
            
        model_data = db['models'][model]
        total_tests = 0
        flawed_tests = 0
        normal_tests = 0
        
        print(f"\nğŸ“Š {model}:")
        
        # åˆ†æpromptç±»å‹åˆ†å¸ƒ
        if 'by_prompt_type' in model_data:
            print("  æŒ‰promptç±»å‹:")
            for prompt_type in sorted(model_data['by_prompt_type'].keys()):
                prompt_data = model_data['by_prompt_type'][prompt_type]
                
                # è®¡ç®—è¯¥promptç±»å‹çš„æµ‹è¯•æ€»æ•°
                prompt_total = 0
                if 'total_tests' in prompt_data:
                    prompt_total = prompt_data['total_tests']
                elif 'by_tool_success_rate' in prompt_data:
                    # éå†æ‰€æœ‰å±‚çº§è®¡ç®—
                    for rate_data in prompt_data['by_tool_success_rate'].values():
                        if 'by_difficulty' in rate_data:
                            for diff_data in rate_data['by_difficulty'].values():
                                if 'by_task_type' in diff_data:
                                    for task_data in diff_data['by_task_type'].values():
                                        prompt_total += task_data.get('total', 0)
                
                if prompt_total > 0:
                    total_tests += prompt_total
                    
                    if prompt_type.startswith('flawed_'):
                        flawed_tests += prompt_total
                        indicator = "âš ï¸ [5.3-5.5]"
                    else:
                        normal_tests += prompt_total
                        indicator = "âœ… [5.1-5.2]"
                    
                    print(f"    {indicator} {prompt_type}: {prompt_total} ä¸ªæµ‹è¯•")
        
        # æ±‡æ€»
        summary['total_by_model'][model] = total_tests
        summary['flawed_by_model'][model] = flawed_tests
        summary['normal_by_model'][model] = normal_tests
        
        if total_tests > 0:
            print(f"  ğŸ“ˆ æ€»è®¡: {total_tests} (æ­£å¸¸: {normal_tests}, ç–‘ä¼¼é”™è¯¯: {flawed_tests})")
    
    # æ‰“å°æ±‡æ€»
    print("\n" + "=" * 60)
    print(f"{db_type} æ•°æ®æ±‡æ€»")
    print("=" * 60)
    
    print("\nğŸ” éœ€è¦å…³æ³¨çš„æ•°æ®:")
    for model in ["qwen2.5-7b-instruct", "qwen2.5-3b-instruct"]:
        flawed = summary['flawed_by_model'].get(model, 0)
        normal = summary['normal_by_model'].get(model, 0)
        
        if flawed > 0:
            print(f"  âŒ {model}: {flawed} ä¸ªflawedæµ‹è¯•éœ€è¦æ¸…ç†ï¼ˆå®é™…æ˜¯72bçš„ç»“æœï¼‰")
        if normal > 0:
            print(f"  âœ… {model}: {normal} ä¸ªæ­£å¸¸æµ‹è¯•å¯ä»¥ä¿ç•™")
    
    # æ£€æŸ¥72bæ˜¯å¦åŒ…å«äº†é”™è¯¯å½’å±çš„æ•°æ®
    model_72b = "qwen2.5-72b-instruct"
    total_72b = summary['total_by_model'].get(model_72b, 0)
    if total_72b > 0:
        print(f"\n  âš ï¸ {model_72b}: å…±{total_72b}ä¸ªæµ‹è¯•ï¼ˆå¯èƒ½åŒ…å«7b/3bçš„é”™è¯¯æ•°æ®ï¼‰")
    
    # åˆ†ætest_groups
    if 'test_groups' in db:
        print("\nğŸ“‹ Test Groupsåˆ†æ:")
        qwen_groups = defaultdict(list)
        for group_id, group_data in db['test_groups'].items():
            model = group_data.get('model', '')
            if 'qwen' in model.lower():
                prompt_type = group_data.get('prompt_type', '')
                qwen_groups[model].append({
                    'id': group_id,
                    'prompt_type': prompt_type,
                    'total': group_data.get('total_tests', 0)
                })
        
        for model in ["qwen2.5-7b-instruct", "qwen2.5-3b-instruct"]:
            if model in qwen_groups:
                flawed_groups = [g for g in qwen_groups[model] if g['prompt_type'].startswith('flawed_')]
                if flawed_groups:
                    print(f"  âš ï¸ {model}: {len(flawed_groups)} ä¸ªflawed test_groupéœ€è¦æ¸…ç†")

if __name__ == "__main__":
    analyze_qwen_data()