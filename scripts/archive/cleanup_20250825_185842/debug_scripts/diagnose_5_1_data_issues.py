#!/usr/bin/env python3
"""
è¯Šæ–­5.1åŸºå‡†æµ‹è¯•æ•°æ®é—®é¢˜
- DeepSeek-R1ç¼ºå¤±é—®é¢˜
- Qwenæ¨¡å‹æ•°æ®æ··ä¹±é—®é¢˜  
- æµ‹è¯•æ•°é‡å¼‚å¸¸é—®é¢˜
"""

import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict

def analyze_database():
    """åˆ†ææ•°æ®åº“çŠ¶æ€"""
    db_path = Path("pilot_bench_cumulative_results/master_database.json")
    
    if not db_path.exists():
        print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
        return
        
    with open(db_path, 'r', encoding='utf-8') as f:
        db = json.load(f)
    
    print("=" * 60)
    print("ğŸ“Š 5.1åŸºå‡†æµ‹è¯•æ•°æ®å®Œæ•´æ€§åˆ†æ")
    print("=" * 60)
    
    # é¢„æœŸçš„æ¨¡å‹åˆ—è¡¨ï¼ˆæ¥è‡ªè„šæœ¬ï¼‰
    expected_models = [
        "DeepSeek-V3-0324",
        "DeepSeek-R1-0528", 
        "qwen2.5-72b-instruct",
        "qwen2.5-32b-instruct",
        "qwen2.5-14b-instruct", 
        "qwen2.5-7b-instruct",
        "qwen2.5-3b-instruct",
        "Llama-3.3-70B-Instruct"
    ]
    
    # å®é™…æ•°æ®åº“ä¸­çš„æ¨¡å‹
    actual_models = list(db.get('models', {}).keys())
    
    print(f"é¢„æœŸæ¨¡å‹æ•°é‡: {len(expected_models)}")
    print(f"å®é™…æ¨¡å‹æ•°é‡: {len(actual_models)}")
    print()
    
    # æ£€æŸ¥ç¼ºå¤±çš„æ¨¡å‹
    missing_models = set(expected_models) - set(actual_models)
    extra_models = set(actual_models) - set(expected_models)
    
    if missing_models:
        print("âŒ ç¼ºå¤±çš„æ¨¡å‹:")
        for model in missing_models:
            print(f"   - {model}")
    
    if extra_models:
        print("âš ï¸  é¢å¤–çš„æ¨¡å‹:")
        for model in extra_models:
            print(f"   - {model}")
    
    if not missing_models and not extra_models:
        print("âœ… æ¨¡å‹åˆ—è¡¨å®Œæ•´")
    
    print()
    
    # åˆ†ææ¯ä¸ªæ¨¡å‹çš„æµ‹è¯•è¯¦æƒ…
    print("=" * 60)
    print("ğŸ“ˆ å„æ¨¡å‹æµ‹è¯•è¯¦æƒ…åˆ†æ")
    print("=" * 60)
    
    expected_tests_per_model = 10  # 5ç§ä»»åŠ¡ç±»å‹ Ã— 2ä¸ªå®ä¾‹
    task_types = ["simple_task", "basic_task", "data_pipeline", "api_integration", "multi_stage_pipeline"]
    
    for model in actual_models:
        model_data = db['models'][model]
        total_tests = model_data.get('total_tests', 0)
        
        print(f"\nğŸ¯ {model}")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests} (é¢„æœŸ: {expected_tests_per_model})")
        
        if total_tests != expected_tests_per_model:
            print(f"   âŒ æµ‹è¯•æ•°é‡å¼‚å¸¸! å·®å¼‚: {total_tests - expected_tests_per_model}")
        
        # åˆ†æä»»åŠ¡ç±»å‹åˆ†å¸ƒ
        if 'by_prompt_type' in model_data:
            optimal_data = model_data['by_prompt_type'].get('optimal', {})
            if 'by_tool_success_rate' in optimal_data:
                rate_08_data = optimal_data['by_tool_success_rate'].get('0.8', {})
                if 'by_difficulty' in rate_08_data:
                    easy_data = rate_08_data['by_difficulty'].get('easy', {})
                    if 'by_task_type' in easy_data:
                        task_data = easy_data['by_task_type']
                        
                        print("   ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
                        for task_type in task_types:
                            if task_type in task_data:
                                count = task_data[task_type].get('total', 0)
                                expected = 2
                                status = "âœ…" if count == expected else "âŒ"
                                print(f"     {status} {task_type}: {count} (é¢„æœŸ: {expected})")
                            else:
                                print(f"     âŒ {task_type}: 0 (é¢„æœŸ: 2) - å®Œå…¨ç¼ºå¤±")
        
        # åˆ†ææ—¶é—´ä¿¡æ¯
        first_test = model_data.get('first_test_time', 'Unknown')
        last_test = model_data.get('last_test_time', 'Unknown')
        print(f"   æµ‹è¯•æ—¶é—´: {first_test} - {last_test}")

def check_normalize_logic():
    """æ£€æŸ¥æ¨¡å‹åç§°è§„èŒƒåŒ–é€»è¾‘"""
    print("\n" + "=" * 60)
    print("ğŸ”§ æ¨¡å‹åç§°è§„èŒƒåŒ–é€»è¾‘æ£€æŸ¥")
    print("=" * 60)
    
    try:
        from cumulative_test_manager import normalize_model_name
        
        test_cases = [
            # DeepSeekç³»åˆ—
            ("DeepSeek-V3-0324", "DeepSeek-V3-0324"),
            ("DeepSeek-V3-0324-2", "DeepSeek-V3-0324"),
            ("DeepSeek-R1-0528", "DeepSeek-R1-0528"), 
            ("DeepSeek-R1-0528-2", "DeepSeek-R1-0528"),
            
            # Qwenç³»åˆ—ï¼ˆåº”è¯¥ä¿æŒä¸å˜ï¼‰
            ("qwen2.5-72b-instruct", "qwen2.5-72b-instruct"),
            ("qwen2.5-32b-instruct", "qwen2.5-32b-instruct"),
            ("qwen2.5-14b-instruct", "qwen2.5-14b-instruct"),
            ("qwen2.5-7b-instruct", "qwen2.5-7b-instruct"),
            ("qwen2.5-3b-instruct", "qwen2.5-3b-instruct"),
            
            # Llamaç³»åˆ—
            ("Llama-3.3-70B-Instruct", "Llama-3.3-70B-Instruct"),
            ("Llama-3.3-70B-Instruct-2", "Llama-3.3-70B-Instruct"),
        ]
        
        all_correct = True
        for input_name, expected in test_cases:
            actual = normalize_model_name(input_name)
            status = "âœ…" if actual == expected else "âŒ"
            if actual != expected:
                all_correct = False
            print(f"   {status} {input_name} -> {actual} (é¢„æœŸ: {expected})")
        
        if all_correct:
            print("\nâœ… æ¨¡å‹åç§°è§„èŒƒåŒ–é€»è¾‘æ­£ç¡®")
        else:
            print("\nâŒ æ¨¡å‹åç§°è§„èŒƒåŒ–å­˜åœ¨é—®é¢˜")
            
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥normalize_model_nameå‡½æ•°: {e}")

def analyze_log_files():
    """åˆ†ææœ€è¿‘çš„æ—¥å¿—æ–‡ä»¶"""
    print("\n" + "=" * 60)
    print("ğŸ“ æœ€è¿‘æµ‹è¯•æ—¥å¿—åˆ†æ")
    print("=" * 60)
    
    log_dir = Path("logs")
    if not log_dir.exists():
        print("âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æ‰¾åˆ°æœ€æ–°çš„æ‰¹å¤„ç†æ—¥å¿—
    log_files = list(log_dir.glob("batch_test_*.log"))
    if not log_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ‰¹å¤„ç†æ—¥å¿—æ–‡ä»¶")
        return
    
    # æŒ‰æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„5ä¸ª
    log_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    recent_logs = log_files[:5]
    
    print(f"åˆ†ææœ€æ–°çš„ {len(recent_logs)} ä¸ªæ—¥å¿—æ–‡ä»¶:")
    
    model_mentions = defaultdict(int)
    
    for log_file in recent_logs:
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # ç»Ÿè®¡æ¯ä¸ªæ¨¡å‹çš„æåŠæ¬¡æ•°
                for model in ["DeepSeek-V3-0324", "DeepSeek-R1-0528", "qwen2.5-72b-instruct", 
                             "qwen2.5-32b-instruct", "qwen2.5-14b-instruct", "qwen2.5-7b-instruct",
                             "qwen2.5-3b-instruct", "Llama-3.3-70B-Instruct"]:
                    count = content.count(model)
                    if count > 0:
                        model_mentions[model] += count
                        
        except Exception as e:
            print(f"   âŒ è¯»å–æ—¥å¿—å¤±è´¥ {log_file}: {e}")
    
    print("\næ¨¡å‹åœ¨æ—¥å¿—ä¸­çš„æåŠæ¬¡æ•°:")
    for model, count in sorted(model_mentions.items(), key=lambda x: x[1], reverse=True):
        print(f"   {model}: {count} æ¬¡")
    
    if "DeepSeek-R1-0528" not in model_mentions:
        print("\nâŒ DeepSeek-R1-0528 åœ¨æ—¥å¿—ä¸­å®Œå…¨æ²¡æœ‰è¢«æåŠï¼")
        print("   è¿™è¯å®äº†DeepSeek-R1ç¡®å®æ²¡æœ‰è¢«æµ‹è¯•")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¯åŠ¨5.1åŸºå‡†æµ‹è¯•æ•°æ®é—®é¢˜è¯Šæ–­")
    print(f"ğŸ• è¯Šæ–­æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    analyze_database()
    check_normalize_logic()
    analyze_log_files()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“ä¸å»ºè®®")
    print("=" * 60)
    print("1. æ£€æŸ¥ultra_parallel_runner.pyä¸­çš„æ¨¡å‹åˆ†ç‰‡é€»è¾‘")
    print("2. æ£€æŸ¥5.1æµ‹è¯•å®é™…æ‰§è¡Œçš„æ¨¡å‹åˆ—è¡¨") 
    print("3. æ£€æŸ¥APIé…ç½®æ˜¯å¦æ­£ç¡®ï¼ˆç‰¹åˆ«æ˜¯DeepSeek-R1ï¼‰")
    print("4. æ£€æŸ¥å¹¶å‘æ¨¡å¼ä¸‹çš„æ•°æ®ä¿å­˜æœºåˆ¶")
    print("5. éªŒè¯qwenæ¨¡å‹åç§°åœ¨ä¼ é€’è¿‡ç¨‹ä¸­æ˜¯å¦è¢«ç¯¡æ”¹")

if __name__ == "__main__":
    main()