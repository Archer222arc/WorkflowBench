#!/usr/bin/env python3
"""
ResultCollectorç®€å•éªŒè¯æµ‹è¯•
ç›´æ¥æµ‹è¯•smart_batch_runnerçš„ResultCollectoré›†æˆ
"""

import os
import sys
import json
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_smart_batch_runner_integration():
    """æµ‹è¯•smart_batch_runnerä¸ResultCollectorçš„é›†æˆ"""
    logger.info("ğŸ§ª æµ‹è¯•smart_batch_runnerä¸ResultCollectoré›†æˆ")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['USE_RESULT_COLLECTOR'] = 'true'
    os.environ['STORAGE_FORMAT'] = 'json'
    
    try:
        # å¯¼å…¥å¿…è¦æ¨¡å—
        sys.path.insert(0, '/Users/ruicheng/Documents/GitHub/WorkflowBench')
        from smart_batch_runner import run_batch_test_smart
        from result_collector import ResultCollector
        
        logger.info("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æ‰§è¡Œä¸€ä¸ªéå¸¸å°çš„æµ‹è¯•
        logger.info("ğŸš€ å¼€å§‹å°è§„æ¨¡æ‰¹æ¬¡æµ‹è¯•")
        
        # åˆ›å»ºResultCollectorå®ä¾‹éªŒè¯å…¶å·¥ä½œçŠ¶æ€
        collector = ResultCollector()
        initial_count = collector.get_pending_count()
        logger.info(f"ğŸ“Š æµ‹è¯•å‰å¾…å¤„ç†æ–‡ä»¶æ•°: {initial_count}")
        
        # è¿è¡Œå°è§„æ¨¡æµ‹è¯•ï¼ˆåªæµ‹è¯•1ä¸ªå®ä¾‹ï¼‰
        # ä½¿ç”¨ä¸€ä¸ªæ²¡æœ‰æ•°æ®çš„é…ç½®æ¥ç¡®ä¿ä¼šæ‰§è¡Œæµ‹è¯•
        result = run_batch_test_smart(
            model="DeepSeek-V3-0324",
            prompt_types="baseline",  # ä½¿ç”¨baselineæç¤ºç±»å‹ï¼ˆå¯èƒ½æ²¡æœ‰æ•°æ®ï¼‰
            difficulty="medium",  # ä½¿ç”¨mediuméš¾åº¦ï¼ˆå¯èƒ½æ²¡æœ‰æ•°æ®ï¼‰
            task_types="basic_task",  # ä½¿ç”¨basic_taskï¼ˆå¯èƒ½æ²¡æœ‰æ•°æ®ï¼‰
            num_instances=1,  # åªæµ‹è¯•1ä¸ªå®ä¾‹
            tool_success_rate=0.7,  # ä½¿ç”¨ä¸åŒçš„å·¥å…·æˆåŠŸç‡
            use_result_collector=True  # æ˜ç¡®å¯ç”¨ResultCollector
        )
        
        logger.info(f"âœ… æ‰¹æ¬¡æµ‹è¯•å®Œæˆï¼Œç»“æœ: {result}")
        
        # æ£€æŸ¥ResultCollectoræ˜¯å¦æ”¶åˆ°äº†ç»“æœ
        final_count = collector.get_pending_count()
        logger.info(f"ğŸ“Š æµ‹è¯•åå¾…å¤„ç†æ–‡ä»¶æ•°: {final_count}")
        
        if final_count > initial_count:
            logger.info("âœ… ResultCollectoræˆåŠŸæ¥æ”¶åˆ°æµ‹è¯•ç»“æœ")
            
            # æ”¶é›†å¹¶æ˜¾ç¤ºç»“æœ
            collected_results = collector.collect_all_results(cleanup=False)
            logger.info(f"ğŸ“¥ æ”¶é›†åˆ° {len(collected_results)} ä¸ªç»“æœæ‰¹æ¬¡")
            
            for i, batch in enumerate(collected_results):
                model = batch.get('model', 'unknown')
                count = batch.get('result_count', 0)
                logger.info(f"  æ‰¹æ¬¡ {i+1}: {model} - {count} ä¸ªç»“æœ")
            
            return True
        else:
            logger.warning("âš ï¸ ResultCollectoræœªæ¥æ”¶åˆ°æ–°çš„ç»“æœï¼Œå¯èƒ½ä½¿ç”¨äº†ä¼ ç»Ÿæ¨¡å¼")
            return False
            
    except ImportError as e:
        logger.error(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def test_environment_detection():
    """æµ‹è¯•ç¯å¢ƒå˜é‡æ£€æµ‹æœºåˆ¶"""
    logger.info("ğŸ§ª æµ‹è¯•ç¯å¢ƒå˜é‡æ£€æµ‹æœºåˆ¶")
    
    try:
        # å¯¼å…¥ultra_parallel_runneréªŒè¯ç¯å¢ƒå˜é‡æ£€æµ‹
        from ultra_parallel_runner import UltraParallelRunner
        
        # æµ‹è¯•ä¸åŒçš„ç¯å¢ƒå˜é‡é…ç½®
        test_cases = [
            {'USE_RESULT_COLLECTOR': 'true', 'expected': True},
            {'USE_RESULT_COLLECTOR': 'false', 'expected': False},
            {'USE_RESULT_COLLECTOR': '', 'expected': False},
        ]
        
        for case in test_cases:
            # è®¾ç½®ç¯å¢ƒå˜é‡
            os.environ['USE_RESULT_COLLECTOR'] = case['USE_RESULT_COLLECTOR']
            
            # åˆ›å»ºå®ä¾‹ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œåº”è¯¥ä»ç¯å¢ƒå˜é‡æ£€æµ‹ï¼‰
            runner = UltraParallelRunner()
            
            # æ£€æŸ¥æ˜¯å¦æŒ‰é¢„æœŸæ£€æµ‹
            detected = hasattr(runner, 'use_collector_mode') and runner.use_collector_mode
            expected = case['expected']
            
            if detected == expected:
                logger.info(f"âœ… ç¯å¢ƒå˜é‡ '{case['USE_RESULT_COLLECTOR']}' -> {detected} (é¢„æœŸ: {expected})")
            else:
                logger.error(f"âŒ ç¯å¢ƒå˜é‡ '{case['USE_RESULT_COLLECTOR']}' -> {detected} (é¢„æœŸ: {expected})")
                return False
        
        logger.info("âœ… ç¯å¢ƒå˜é‡æ£€æµ‹æœºåˆ¶å·¥ä½œæ­£å¸¸")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç¯å¢ƒå˜é‡æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ¯ ResultCollectorç®€å•éªŒè¯æµ‹è¯•å¼€å§‹")
    logger.info("=" * 50)
    
    # åŸºç¡€ç¯å¢ƒæ£€æµ‹æµ‹è¯•
    logger.info("\nğŸ“‹ é˜¶æ®µ1: ç¯å¢ƒå˜é‡æ£€æµ‹æµ‹è¯•")
    env_test_passed = test_environment_detection()
    
    # smart_batch_runneré›†æˆæµ‹è¯•
    logger.info("\nğŸ“‹ é˜¶æ®µ2: smart_batch_runneré›†æˆæµ‹è¯•")
    integration_test_passed = test_smart_batch_runner_integration()
    
    # æ€»ç»“
    logger.info("\n" + "=" * 50)
    if env_test_passed and integration_test_passed:
        logger.info("ğŸ‰ æ‰€æœ‰ç®€å•éªŒè¯æµ‹è¯•é€šè¿‡ï¼")
        logger.info("âœ… ResultCollectoråŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… ç¯å¢ƒå˜é‡æ£€æµ‹æœºåˆ¶æ­£å¸¸")
        logger.info("âœ… smart_batch_runneré›†æˆæ­£å¸¸")
        logger.info("ğŸ’¡ å¯ä»¥ç»§ç»­è¿›è¡Œå®Œæ•´çš„è¶…å¹¶å‘æµ‹è¯•")
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        if not env_test_passed:
            logger.error("  - ç¯å¢ƒå˜é‡æ£€æµ‹é—®é¢˜")
        if not integration_test_passed:
            logger.error("  - smart_batch_runneré›†æˆé—®é¢˜")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)