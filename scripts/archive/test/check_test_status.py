#!/usr/bin/env python3
"""æ£€æŸ¥æµ‹è¯•çŠ¶æ€å’Œæ•°æ®å­˜å‚¨æƒ…å†µ"""

import os
import json
import subprocess
from pathlib import Path
from datetime import datetime

def check_running_processes():
    """æ£€æŸ¥è¿è¡Œä¸­çš„æµ‹è¯•è¿›ç¨‹"""
    print("\nğŸ” è¿è¡Œä¸­çš„æµ‹è¯•è¿›ç¨‹:")
    result = subprocess.run(
        "ps aux | grep -E '(smart_batch_runner|ultra_parallel|batch_test)' | grep -v grep",
        shell=True, capture_output=True, text=True
    )
    
    processes = result.stdout.strip().split('\n')
    if processes and processes[0]:
        print(f"  æ‰¾åˆ° {len(processes)} ä¸ªè¿›ç¨‹")
        for proc in processes[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            parts = proc.split()
            if len(parts) > 10:
                cmd = ' '.join(parts[10:13])  # å‘½ä»¤çš„å‰å‡ ä¸ªå‚æ•°
                print(f"    PID {parts[1]}: {cmd}...")
    else:
        print("  æ²¡æœ‰æ‰¾åˆ°è¿è¡Œä¸­çš„æµ‹è¯•è¿›ç¨‹")

def check_storage_format():
    """æ£€æŸ¥å­˜å‚¨æ ¼å¼é…ç½®"""
    print("\nğŸ’¾ å­˜å‚¨æ ¼å¼é…ç½®:")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    storage_format = os.environ.get('STORAGE_FORMAT', 'json')
    print(f"  ç¯å¢ƒå˜é‡ STORAGE_FORMAT: {storage_format}")
    
    # æ£€æŸ¥Parquetç›®å½•
    parquet_dir = Path('pilot_bench_cumulative_results/parquet_data')
    if parquet_dir.exists():
        parquet_files = list(parquet_dir.glob('**/*.parquet'))
        print(f"  âœ… Parquetç›®å½•å­˜åœ¨")
        print(f"  Parquetæ–‡ä»¶æ•°: {len(parquet_files)}")
        
        # æ£€æŸ¥æœ€æ–°æ–‡ä»¶
        if parquet_files:
            latest = max(parquet_files, key=lambda p: p.stat().st_mtime)
            mtime = datetime.fromtimestamp(latest.stat().st_mtime)
            print(f"  æœ€æ–°æ–‡ä»¶: {latest.name}")
            print(f"  æ›´æ–°æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print(f"  âŒ Parquetç›®å½•ä¸å­˜åœ¨")
    
    # æ£€æŸ¥JSONæ•°æ®åº“
    json_db = Path('pilot_bench_cumulative_results/master_database.json')
    if json_db.exists():
        mtime = datetime.fromtimestamp(json_db.stat().st_mtime)
        print(f"  âœ… JSONæ•°æ®åº“å­˜åœ¨")
        print(f"  æ›´æ–°æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ç»Ÿè®¡æµ‹è¯•æ•°
        with open(json_db, 'r') as f:
            db = json.load(f)
        
        total_tests = 0
        for model_data in db.get('models', {}).values():
            if 'by_prompt_type' in model_data:
                for prompt_data in model_data['by_prompt_type'].values():
                    if 'by_tool_success_rate' in prompt_data:
                        for rate_data in prompt_data['by_tool_success_rate'].values():
                            if 'by_difficulty' in rate_data:
                                for diff_data in rate_data['by_difficulty'].values():
                                    if 'by_task_type' in diff_data:
                                        for task_data in diff_data['by_task_type'].values():
                                            total_tests += task_data.get('total', 0)
        
        print(f"  æ€»æµ‹è¯•æ•°: {total_tests}")

def check_logs():
    """æ£€æŸ¥æœ€æ–°æ—¥å¿—"""
    print("\nğŸ“ æœ€æ–°æ—¥å¿—:")
    
    log_dir = Path('logs')
    if log_dir.exists():
        # æ‰¾æœ€æ–°çš„batch_testæ—¥å¿—
        batch_logs = list(log_dir.glob('batch_test_*.log'))
        if batch_logs:
            latest = max(batch_logs, key=lambda p: p.stat().st_mtime)
            mtime = datetime.fromtimestamp(latest.stat().st_mtime)
            print(f"  æœ€æ–°æ—¥å¿—: {latest.name}")
            print(f"  æ›´æ–°æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # æ˜¾ç¤ºæœ€åå‡ è¡Œ
            with open(latest, 'r') as f:
                lines = f.readlines()
                last_lines = lines[-5:] if len(lines) > 5 else lines
                print("  æœ€åå‡ è¡Œ:")
                for line in last_lines:
                    print(f"    {line.strip()}")

def suggest_actions():
    """å»ºè®®æ“ä½œ"""
    print("\nğŸ’¡ å»ºè®®æ“ä½œ:")
    
    storage_format = os.environ.get('STORAGE_FORMAT', 'json')
    
    if storage_format != 'parquet':
        print("  1. ä½ é€‰æ‹©äº†Parquetä½†ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("     è§£å†³æ–¹æ³•: åœ¨è¿è¡Œæµ‹è¯•çš„ç»ˆç«¯ä¸­æ‰§è¡Œ:")
        print("     export STORAGE_FORMAT=parquet")
    
    parquet_dir = Path('pilot_bench_cumulative_results/parquet_data')
    if not parquet_dir.exists() and storage_format == 'parquet':
        print("  2. Parquetç›®å½•ä¸å­˜åœ¨")
        print("     è§£å†³æ–¹æ³•: åˆ›å»ºç›®å½•")
        print("     mkdir -p pilot_bench_cumulative_results/parquet_data/incremental")
    
    print("\n  3. æŸ¥çœ‹å®æ—¶è¿›åº¦:")
    print("     tail -f logs/batch_test_*.log | grep -E '(æˆåŠŸ|å¤±è´¥|å®Œæˆ|checkpoint)'")
    
    print("\n  4. å¦‚æœæµ‹è¯•å¡ä½ï¼Œå¯ä»¥:")
    print("     - æŸ¥çœ‹å…·ä½“è¿›ç¨‹: ps aux | grep smart_batch_runner")
    print("     - ç»ˆæ­¢æµ‹è¯•: pkill -f smart_batch_runner")
    print("     - é‡æ–°å¼€å§‹ï¼ˆä¼šä»checkpointæ¢å¤ï¼‰")

if __name__ == "__main__":
    print("=" * 50)
    print("PILOT-Bench æµ‹è¯•çŠ¶æ€æ£€æŸ¥")
    print("=" * 50)
    
    check_running_processes()
    check_storage_format()
    check_logs()
    suggest_actions()
    
    print("\n" + "=" * 50)
