#!/usr/bin/env python3
"""
æ™ºèƒ½æ•°æ®æ”¶é›†å™¨é›†æˆè„šæœ¬
å°†SmartResultCollectoré›†æˆåˆ°ç°æœ‰çš„BatchTestRunnerå’Œsmart_batch_runnerä¸­

é›†æˆç­–ç•¥ï¼š
1. å‘åå…¼å®¹ - ä¿æŒç°æœ‰æ¥å£ä¸å˜
2. æ¸è¿›å‡çº§ - å¯ä»¥é€‰æ‹©æ€§å¯ç”¨æ–°åŠŸèƒ½
3. æ™ºèƒ½æ£€æµ‹ - è‡ªåŠ¨é€‰æ‹©æœ€ä½³é…ç½®
4. æ— ç¼åˆ‡æ¢ - æ— éœ€ä¿®æ”¹è°ƒç”¨ä»£ç 
"""

import os
import shutil
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class SmartCollectorIntegrator:
    """æ™ºèƒ½æ”¶é›†å™¨é›†æˆå™¨"""
    
    def __init__(self, workspace_root: str = "."):
        self.workspace_root = Path(workspace_root)
        self.backup_dir = self.workspace_root / "backups" / f"integration_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # éœ€è¦é›†æˆçš„æ–‡ä»¶
        self.target_files = [
            "smart_batch_runner.py",
            "batch_test_runner.py"
        ]
        
    def integrate_all(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´é›†æˆ"""
        logger.info("ğŸš€ å¼€å§‹é›†æˆæ™ºèƒ½æ•°æ®æ”¶é›†å™¨...")
        
        results = {
            'backup_created': False,
            'files_modified': [],
            'files_failed': [],
            'new_files_created': [],
            'integration_success': False
        }
        
        try:
            # 1. åˆ›å»ºå¤‡ä»½
            results['backup_created'] = self._create_backups()
            
            # 2. é›†æˆåˆ°smart_batch_runner.py
            if self._integrate_smart_batch_runner():
                results['files_modified'].append('smart_batch_runner.py')
            else:
                results['files_failed'].append('smart_batch_runner.py')
            
            # 3. é›†æˆåˆ°batch_test_runner.py
            if self._integrate_batch_test_runner():
                results['files_modified'].append('batch_test_runner.py')
            else:
                results['files_failed'].append('batch_test_runner.py')
            
            # 4. åˆ›å»ºé…ç½®æ–‡ä»¶
            if self._create_integration_config():
                results['new_files_created'].append('smart_collector_config.py')
            
            # 5. åˆ›å»ºä½¿ç”¨æŒ‡å—
            if self._create_usage_guide():
                results['new_files_created'].append('SMART_COLLECTOR_GUIDE.md')
            
            results['integration_success'] = len(results['files_failed']) == 0
            
        except Exception as e:
            logger.error(f"é›†æˆè¿‡ç¨‹å‡ºé”™: {e}")
            results['integration_success'] = False
        
        return results
    
    def _create_backups(self) -> bool:
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
        logger.info("ğŸ“¦ åˆ›å»ºæ–‡ä»¶å¤‡ä»½...")
        
        try:
            for filename in self.target_files:
                source_file = self.workspace_root / filename
                if source_file.exists():
                    backup_file = self.backup_dir / filename
                    shutil.copy2(source_file, backup_file)
                    logger.info(f"  å¤‡ä»½: {filename} -> {backup_file}")
            
            logger.info(f"âœ… å¤‡ä»½å®Œæˆ: {self.backup_dir}")
            return True
            
        except Exception as e:
            logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def _integrate_smart_batch_runner(self) -> bool:
        """é›†æˆåˆ°smart_batch_runner.py"""
        logger.info("ğŸ”§ é›†æˆåˆ° smart_batch_runner.py...")
        
        target_file = self.workspace_root / "smart_batch_runner.py"
        if not target_file.exists():
            logger.warning("smart_batch_runner.py ä¸å­˜åœ¨")
            return False
        
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # 1. æ·»åŠ æ™ºèƒ½æ”¶é›†å™¨å¯¼å…¥
            import_section = '''# å¯é€‰æ”¯æŒResultCollector
try:
    from result_collector import ResultCollector
    from result_collector_adapter import AdaptiveResultCollector
    RESULT_COLLECTOR_AVAILABLE = True
except ImportError:
    RESULT_COLLECTOR_AVAILABLE = False'''
            
            # æ›¿æ¢ç°æœ‰çš„importéƒ¨åˆ†
            old_import_pattern = r'# å¯é€‰æ”¯æŒResultCollector\ntry:\s*\n\s*from result_collector import ResultCollector\n\s*RESULT_COLLECTOR_AVAILABLE = True\nexcept ImportError:\s*\n\s*RESULT_COLLECTOR_AVAILABLE = False'
            
            if re.search(old_import_pattern, content, re.MULTILINE):
                content = re.sub(old_import_pattern, import_section, content, flags=re.MULTILINE)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œåœ¨å¯¼å…¥éƒ¨åˆ†åæ·»åŠ 
                content = content.replace(
                    '# å¯é€‰æ”¯æŒResultCollector',
                    import_section
                )
            
            # 2. ä¿®æ”¹ç»“æœæ”¶é›†å™¨åˆ›å»ºé€»è¾‘
            new_collector_creation = '''    # åˆ›å»ºæ™ºèƒ½ç»“æœæ”¶é›†å™¨
    result_collector = None
    if use_collector:
        try:
            # å°è¯•ä½¿ç”¨è‡ªé€‚åº”æ”¶é›†å™¨
            from result_collector_adapter import create_adaptive_collector
            
            # è·å–æ•°æ®åº“ç®¡ç†å™¨
            database_manager = getattr(runner, 'manager', None) if hasattr(runner, 'manager') else None
            
            # æ™ºèƒ½é…ç½®
            collector_config = {
                'temp_dir': 'temp_results',
                'max_memory_results': max(5, checkpoint_interval or 5),  # è‡ªé€‚åº”é˜ˆå€¼
                'max_time_seconds': 300,  # 5åˆ†é’Ÿè¶…æ—¶
                'auto_save_interval': 60,  # 1åˆ†é’Ÿè‡ªåŠ¨ä¿å­˜
                'adaptive_threshold': True,
                'database_manager': database_manager
            }
            
            result_collector = create_adaptive_collector(**collector_config)
            
            if not silent:
                print("ğŸ§  å¯ç”¨SmartResultCollectoræ¨¡å¼ï¼Œæ™ºèƒ½æ•°æ®ç®¡ç†")
        except ImportError:
            # å›é€€åˆ°åŸå§‹ResultCollector
            try:
                result_collector = ResultCollector()
                if not silent:
                    print("ğŸ†• å¯ç”¨ResultCollectoræ¨¡å¼ï¼Œæµ‹è¯•å®Œæˆåç»Ÿä¸€å†™å…¥")
            except:
                result_collector = None
                if not silent:
                    print("âš ï¸ ResultCollectorä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
        except Exception as e:
            logger.warning(f"æ™ºèƒ½æ”¶é›†å™¨åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼: {e}")
            result_collector = None'''
            
            # æ›¿æ¢ç°æœ‰çš„æ”¶é›†å™¨åˆ›å»ºé€»è¾‘
            old_collector_pattern = r'# åˆ›å»ºResultCollectorï¼ˆå¦‚æœéœ€è¦ï¼‰[\s\S]*?print\("âš ï¸ ResultCollectorä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼"\)'
            
            if re.search(old_collector_pattern, content):
                content = re.sub(old_collector_pattern, new_collector_creation, content)
            else:
                # å¦‚æœæ‰¾ä¸åˆ°ç²¾ç¡®æ¨¡å¼ï¼Œå¯»æ‰¾æ›´ç®€å•çš„æ¨¡å¼è¿›è¡Œæ›¿æ¢
                simple_pattern = r'result_collector = ResultCollector\(\)[\s\S]*?print\("âš ï¸ ResultCollectorä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼"\)'
                if re.search(simple_pattern, content):
                    content = re.sub(simple_pattern, new_collector_creation, content)
            
            # 3. æ”¹è¿›checkpoint_intervalçš„é»˜è®¤å¤„ç†
            checkpoint_improvement = '''    # æ™ºèƒ½checkpoint_intervalå¤„ç†
    if checkpoint_interval is None:
        # æ ¹æ®æµ‹è¯•è§„æ¨¡è‡ªåŠ¨è°ƒæ•´
        if num_instances <= 5:
            checkpoint_interval = max(1, num_instances)  # å°è§„æ¨¡æµ‹è¯•ä½¿ç”¨å°é˜ˆå€¼
        else:
            checkpoint_interval = min(10, num_instances // 2)  # å¤§è§„æ¨¡æµ‹è¯•ä½¿ç”¨é€‚ä¸­é˜ˆå€¼
        
        if not silent:
            print(f"ğŸ“Š è‡ªé€‚åº”checkpoint_interval: {checkpoint_interval}")'''
            
            # åœ¨å‚æ•°å¤„ç†éƒ¨åˆ†æ·»åŠ æ™ºèƒ½é€»è¾‘
            if 'if checkpoint_interval > 0:' in content:
                content = content.replace(
                    'if checkpoint_interval > 0:',
                    checkpoint_improvement + '\n    \n    if checkpoint_interval > 0:'
                )
            
            # å†™å…¥ä¿®æ”¹åçš„å†…å®¹
            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info("âœ… smart_batch_runner.py é›†æˆå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"smart_batch_runner.py é›†æˆå¤±è´¥: {e}")
            # æ¢å¤å¤‡ä»½
            backup_file = self.backup_dir / "smart_batch_runner.py"
            if backup_file.exists():
                shutil.copy2(backup_file, target_file)
            return False
    
    def _integrate_batch_test_runner(self) -> bool:
        """é›†æˆåˆ°batch_test_runner.py"""
        logger.info("ğŸ”§ é›†æˆåˆ° batch_test_runner.py...")
        
        target_file = self.workspace_root / "batch_test_runner.py"
        if not target_file.exists():
            logger.warning("batch_test_runner.py ä¸å­˜åœ¨")
            return False
        
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # 1. æ·»åŠ æ™ºèƒ½checkpointé€»è¾‘
            smart_checkpoint_method = '''
    def _smart_checkpoint_save(self, results, task_model=None, force=False):
        """æ™ºèƒ½checkpointä¿å­˜ - æ”¯æŒå¤šé‡è§¦å‘æ¡ä»¶"""
        if not self.checkpoint_interval or self.enable_database_updates:
            return
        
        # å°†ç»“æœæ·»åŠ åˆ°pendingç¼“å­˜
        if results:
            if isinstance(results, list):
                self.pending_results.extend(results)
            else:
                self.pending_results.append(results)
        
        # å¤šé‡è§¦å‘æ¡ä»¶æ£€æŸ¥
        current_time = time.time()
        time_since_last_save = current_time - getattr(self, '_last_checkpoint_time', current_time)
        result_count = len(self.pending_results)
        
        # è‡ªé€‚åº”é˜ˆå€¼
        effective_threshold = self.checkpoint_interval
        if hasattr(self, '_adaptive_checkpoint') and self._adaptive_checkpoint:
            if result_count > 0 and time_since_last_save > 300:  # 5åˆ†é’Ÿå¼ºåˆ¶ä¿å­˜
                effective_threshold = 1
            elif time_since_last_save > 180:  # 3åˆ†é’Ÿé™ä½é˜ˆå€¼
                effective_threshold = max(1, self.checkpoint_interval // 2)
        
        # è§¦å‘æ¡ä»¶
        should_save = (force or 
                      result_count >= effective_threshold or
                      (result_count > 0 and time_since_last_save > 600) or  # 10åˆ†é’Ÿå¼ºåˆ¶ä¿å­˜
                      (result_count >= 3 and time_since_last_save > 120))   # 2åˆ†é’Ÿéƒ¨åˆ†ä¿å­˜
        
        if should_save and self.pending_results:
            print(f"\\nğŸ’¾ æ™ºèƒ½Checkpoint: ä¿å­˜{len(self.pending_results)}ä¸ªç»“æœ...")
            print(f"   è§¦å‘åŸå› : æ•°é‡={result_count}, æ—¶é—´={time_since_last_save:.1f}s, å¼ºåˆ¶={force}")
            
            # ç¡®ä¿å·²åˆå§‹åŒ–manager
            self._lazy_init()
            
            # ä¿å­˜é€»è¾‘ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            try:
                from cumulative_test_manager import TestRecord
                saved_count = 0
                
                for result in self.pending_results:
                    if result and not result.get('_saved', False):
                        record = TestRecord(
                            model=result.get('model', task_model or 'unknown'),
                            task_type=result.get('task_type', 'unknown'),
                            prompt_type=result.get('prompt_type', 'baseline'),
                            difficulty=result.get('difficulty', 'easy')
                        )
                        
                        # è®¾ç½®å…¶ä»–å­—æ®µï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                        for field in ['timestamp', 'success', 'success_level', 'execution_time', 'turns',
                                    'tool_calls', 'workflow_score', 'phase2_score', 'quality_score',
                                    'final_score', 'error_type', 'tool_success_rate', 'is_flawed',
                                    'flaw_type', 'format_error_count', 'api_issues', 'executed_tools',
                                    'required_tools', 'tool_coverage_rate', 'task_instance', 'execution_history',
                                    'ai_error_category', '_ai_error_category']:
                            if field in result:
                                if field == '_ai_error_category':
                                    setattr(record, 'ai_error_category', result[field])
                                else:
                                    setattr(record, field, result[field])
                        
                        # ä¿å­˜è®°å½•
                        try:
                            self.manager.append_test_result(record.__dict__)
                            result['_saved'] = True
                            saved_count += 1
                        except Exception as e:
                            print(f"ä¿å­˜è®°å½•å¤±è´¥: {e}")
                
                print(f"âœ… Checkpointå®Œæˆ: æˆåŠŸä¿å­˜ {saved_count}/{len(self.pending_results)} ä¸ªç»“æœ")
                
                # æ¸…ç©ºå·²ä¿å­˜çš„ç»“æœ
                self.pending_results = [r for r in self.pending_results if not r.get('_saved', False)]
                self._last_checkpoint_time = current_time
                
            except Exception as e:
                print(f"âŒ Checkpointå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
'''
            
            # 2. æ·»åŠ é€€å‡ºå¤„ç†å™¨
            exit_handler_code = '''
    def _setup_exit_handlers(self):
        """è®¾ç½®è¿›ç¨‹é€€å‡ºå¤„ç†å™¨"""
        import atexit
        import signal
        
        def cleanup_handler():
            if hasattr(self, 'pending_results') and self.pending_results:
                print(f"\\nğŸš¨ è¿›ç¨‹é€€å‡ºï¼Œå¼ºåˆ¶ä¿å­˜ {len(self.pending_results)} ä¸ªæœªä¿å­˜ç»“æœ...")
                self._smart_checkpoint_save([], force=True)
        
        def signal_handler(signum, frame):
            print(f"\\nğŸš¨ æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡é€€å‡º...")
            cleanup_handler()
        
        atexit.register(cleanup_handler)
        try:
            signal.signal(signal.SIGTERM, signal_handler)
            signal.signal(signal.SIGINT, signal_handler)
        except:
            pass  # æŸäº›ç¯å¢ƒä¸‹å¯èƒ½ä¸æ”¯æŒä¿¡å·å¤„ç†
'''
            
            # 3. ä¿®æ”¹åˆå§‹åŒ–æ–¹æ³•
            init_modification = '''        # å¯ç”¨æ™ºèƒ½checkpointå’Œé€€å‡ºå¤„ç†
        self._adaptive_checkpoint = True
        self._last_checkpoint_time = time.time()
        self._setup_exit_handlers()
        
        print(f"[DEBUG] BatchTestRunner initialized with save_logs={save_logs}, enable_database_updates={enable_database_updates}, use_ai_classification={use_ai_classification}, checkpoint_interval={checkpoint_interval}")
        print(f"[DEBUG] æ™ºèƒ½checkpointå·²å¯ç”¨: è‡ªé€‚åº”é˜ˆå€¼={self._adaptive_checkpoint}")'''
            
            # åº”ç”¨ä¿®æ”¹
            # æ·»åŠ import timeå¦‚æœä¸å­˜åœ¨
            if 'import time' not in content:
                content = 'import time\n' + content
            
            # æ·»åŠ æ™ºèƒ½checkpointæ–¹æ³•
            if '_smart_checkpoint_save' not in content:
                # åœ¨ç±»å®šä¹‰ä¸­æ‰¾ä¸ªåˆé€‚çš„ä½ç½®æ’å…¥
                class_pattern = r'(class BatchTestRunner:[\s\S]*?def __init__[\s\S]*?def _lazy_init\(self\):[\s\S]*?def )'
                if re.search(class_pattern, content):
                    content = re.sub(
                        r'(def _lazy_init\(self\):[\s\S]*?)(\n    def )',
                        r'\1' + smart_checkpoint_method + r'\2',
                        content
                    )
                else:
                    # ç®€å•æ’å…¥åˆ°ç±»çš„æœ«å°¾
                    content = content.replace(
                        'class BatchTestRunner:',
                        'class BatchTestRunner:' + smart_checkpoint_method
                    )
            
            # æ·»åŠ é€€å‡ºå¤„ç†å™¨æ–¹æ³•
            if '_setup_exit_handlers' not in content:
                content = content.replace(
                    smart_checkpoint_method,
                    smart_checkpoint_method + exit_handler_code
                )
            
            # ä¿®æ”¹åˆå§‹åŒ–éƒ¨åˆ†
            old_debug_pattern = r'print\(f"\[DEBUG\] BatchTestRunner initialized.*?\)"'
            if re.search(old_debug_pattern, content):
                content = re.sub(old_debug_pattern, init_modification.strip().split('\n')[-2], content)
                # åœ¨åˆå§‹åŒ–çš„åˆé€‚ä½ç½®æ·»åŠ å…¶ä»–ä»£ç 
                init_pattern = r'(self\.pending_results = \[\].*?\n)'
                content = re.sub(
                    init_pattern,
                    init_modification,
                    content,
                    flags=re.DOTALL
                )
            
            # æ›¿æ¢åŸæœ‰çš„_checkpoint_saveä¸ºæ™ºèƒ½ç‰ˆæœ¬
            if '_checkpoint_save' in content and '_smart_checkpoint_save' in content:
                content = content.replace('self._checkpoint_save(', 'self._smart_checkpoint_save(')
            
            # å†™å…¥ä¿®æ”¹åçš„å†…å®¹
            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info("âœ… batch_test_runner.py é›†æˆå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"batch_test_runner.py é›†æˆå¤±è´¥: {e}")
            # æ¢å¤å¤‡ä»½
            backup_file = self.backup_dir / "batch_test_runner.py"
            if backup_file.exists():
                shutil.copy2(backup_file, target_file)
            return False
    
    def _create_integration_config(self) -> bool:
        """åˆ›å»ºé›†æˆé…ç½®æ–‡ä»¶"""
        logger.info("ğŸ“„ åˆ›å»ºé›†æˆé…ç½®æ–‡ä»¶...")
        
        config_content = '''#!/usr/bin/env python3
"""
æ™ºèƒ½æ•°æ®æ”¶é›†å™¨é…ç½®æ–‡ä»¶
ä¸ºä¸åŒçš„ä½¿ç”¨åœºæ™¯æä¾›é¢„è®¾é…ç½®
"""

import os
from pathlib import Path

# åŸºç¡€é…ç½®
BASE_CONFIG = {
    'temp_dir': 'temp_results',
    'adaptive_threshold': True,
    'auto_save_interval': 60,  # 1åˆ†é’Ÿ
}

# å°è§„æ¨¡æµ‹è¯•é…ç½®ï¼ˆ<10ä¸ªæµ‹è¯•ï¼‰
SMALL_SCALE_CONFIG = {
    **BASE_CONFIG,
    'max_memory_results': 3,
    'max_time_seconds': 120,  # 2åˆ†é’Ÿ
    'checkpoint_interval': 1,  # æ¯ä¸ªæµ‹è¯•éƒ½ä¿å­˜
}

# ä¸­ç­‰è§„æ¨¡æµ‹è¯•é…ç½®ï¼ˆ10-50ä¸ªæµ‹è¯•ï¼‰
MEDIUM_SCALE_CONFIG = {
    **BASE_CONFIG,
    'max_memory_results': 10,
    'max_time_seconds': 300,  # 5åˆ†é’Ÿ
    'checkpoint_interval': 5,
}

# å¤§è§„æ¨¡æµ‹è¯•é…ç½®ï¼ˆ>50ä¸ªæµ‹è¯•ï¼‰
LARGE_SCALE_CONFIG = {
    **BASE_CONFIG,
    'max_memory_results': 25,
    'max_time_seconds': 600,  # 10åˆ†é’Ÿ
    'checkpoint_interval': 20,
}

# è¶…å¹¶å‘é…ç½®ï¼ˆå¤šè¿›ç¨‹ç¯å¢ƒï¼‰
ULTRA_PARALLEL_CONFIG = {
    **BASE_CONFIG,
    'max_memory_results': 5,   # æ›´å°çš„å†…å­˜é˜ˆå€¼
    'max_time_seconds': 180,   # 3åˆ†é’Ÿ
    'auto_save_interval': 30,  # 30ç§’æ›´é¢‘ç¹æ£€æŸ¥
    'checkpoint_interval': 3,
}

# ç¯å¢ƒå˜é‡é…ç½®æ˜ å°„
ENV_CONFIG_MAP = {
    'small': SMALL_SCALE_CONFIG,
    'medium': MEDIUM_SCALE_CONFIG,
    'large': LARGE_SCALE_CONFIG,
    'ultra': ULTRA_PARALLEL_CONFIG,
}

def get_smart_collector_config(scale: str = None, num_tests: int = None) -> dict:
    """
    è·å–æ™ºèƒ½æ”¶é›†å™¨é…ç½®
    
    Args:
        scale: è§„æ¨¡ç±»å‹ ('small', 'medium', 'large', 'ultra')
        num_tests: é¢„æœŸæµ‹è¯•æ•°é‡
    
    Returns:
        é…ç½®å­—å…¸
    """
    # ä»ç¯å¢ƒå˜é‡è·å–
    if scale is None:
        scale = os.environ.get('COLLECTOR_SCALE', '').lower()
    
    # æ ¹æ®æµ‹è¯•æ•°é‡è‡ªåŠ¨åˆ¤æ–­è§„æ¨¡
    if scale == '' and num_tests:
        if num_tests <= 10:
            scale = 'small'
        elif num_tests <= 50:
            scale = 'medium'
        elif num_tests <= 200:
            scale = 'large'
        else:
            scale = 'ultra'
    
    # è·å–é…ç½®
    config = ENV_CONFIG_MAP.get(scale, MEDIUM_SCALE_CONFIG)
    
    # å¦‚æœæœ‰å…·ä½“çš„æµ‹è¯•æ•°é‡ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–
    if num_tests:
        config = config.copy()
        config['max_memory_results'] = min(config['max_memory_results'], max(1, num_tests // 5))
        config['checkpoint_interval'] = min(config['checkpoint_interval'], max(1, num_tests // 3))
    
    return config

def get_current_config() -> dict:
    """è·å–å½“å‰ç¯å¢ƒçš„æ¨èé…ç½®"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    scale = os.environ.get('COLLECTOR_SCALE', '').lower()
    num_tests = os.environ.get('NUM_TESTS')
    
    if num_tests:
        try:
            num_tests = int(num_tests)
        except:
            num_tests = None
    
    return get_smart_collector_config(scale, num_tests)

# å¯¼å‡ºé…ç½®æ£€æŸ¥åŠŸèƒ½
def validate_config(config: dict) -> list:
    """éªŒè¯é…ç½®çš„åˆç†æ€§"""
    issues = []
    
    if config.get('max_memory_results', 0) <= 0:
        issues.append("max_memory_results å¿…é¡»å¤§äº0")
    
    if config.get('checkpoint_interval', 0) > config.get('max_memory_results', 0) * 2:
        issues.append("checkpoint_interval è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¿å­˜")
    
    if config.get('max_time_seconds', 0) <= 0:
        issues.append("max_time_seconds å¿…é¡»å¤§äº0")
    
    return issues

if __name__ == "__main__":
    # æ˜¾ç¤ºå½“å‰æ¨èé…ç½®
    config = get_current_config()
    print("å½“å‰æ¨èé…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # éªŒè¯é…ç½®
    issues = validate_config(config)
    if issues:
        print("\\né…ç½®é—®é¢˜:")
        for issue in issues:
            print(f"  âš ï¸ {issue}")
    else:
        print("\\nâœ… é…ç½®éªŒè¯é€šè¿‡")
'''
        
        try:
            config_file = self.workspace_root / "smart_collector_config.py"
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(config_content)
            
            logger.info(f"âœ… é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ: {config_file}")
            return True
            
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def _create_usage_guide(self) -> bool:
        """åˆ›å»ºä½¿ç”¨æŒ‡å—"""
        guide_content = '''# æ™ºèƒ½æ•°æ®æ”¶é›†å™¨ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æ™ºèƒ½æ•°æ®æ”¶é›†å™¨å·²é›†æˆåˆ°ç°æœ‰çš„æµ‹è¯•ç³»ç»Ÿä¸­ï¼Œæä¾›äº†æ›´çµæ´»ã€å¯é çš„æ•°æ®ç®¡ç†æœºåˆ¶ã€‚

## å…³é”®æ”¹è¿›

### 1. å¤šé‡è§¦å‘æ¡ä»¶
ä¸å†ä¾èµ–å•ä¸€çš„æ•°é‡é˜ˆå€¼ï¼Œæ”¯æŒï¼š
- **æ•°é‡è§¦å‘**: è¾¾åˆ°æŒ‡å®šæ•°é‡çš„ç»“æœ
- **æ—¶é—´è§¦å‘**: è¶…è¿‡æŒ‡å®šæ—¶é—´é—´éš”
- **æ™ºèƒ½è§¦å‘**: æ ¹æ®æƒ…å†µåŠ¨æ€è°ƒæ•´é˜ˆå€¼
- **å¼ºåˆ¶è§¦å‘**: è¿›ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ä¿å­˜

### 2. è‡ªé€‚åº”é…ç½®
ç³»ç»Ÿä¼šæ ¹æ®å®é™…æµ‹è¯•è§„æ¨¡è‡ªåŠ¨è°ƒæ•´å‚æ•°ï¼š
- å°è§„æ¨¡æµ‹è¯•ï¼ˆ<10ä¸ªï¼‰ï¼šä½é˜ˆå€¼ï¼Œå¿«é€Ÿä¿å­˜
- ä¸­ç­‰è§„æ¨¡æµ‹è¯•ï¼ˆ10-50ä¸ªï¼‰ï¼šå¹³è¡¡é˜ˆå€¼
- å¤§è§„æ¨¡æµ‹è¯•ï¼ˆ>50ä¸ªï¼‰ï¼šé«˜é˜ˆå€¼ï¼Œæ‰¹é‡ä¼˜åŒ–

### 3. å®¹é”™æœºåˆ¶
- **è¿›ç¨‹é€€å‡ºä¿æŠ¤**: å¼‚å¸¸é€€å‡ºæ—¶è‡ªåŠ¨ä¿å­˜æœªå¤„ç†æ•°æ®
- **å¤šçº§å›é€€**: æ™ºèƒ½æ”¶é›†å™¨ â†’ åŸå§‹æ”¶é›†å™¨ â†’ ç®€å•æ¨¡å¼
- **æ•°æ®æ¢å¤**: ä»ä¸´æ—¶æ–‡ä»¶æ¢å¤ä¸¢å¤±çš„æ•°æ®

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨ï¼ˆæ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç ï¼‰
```bash
# ç°æœ‰çš„æµ‹è¯•å‘½ä»¤å°†è‡ªåŠ¨ä½¿ç”¨æ™ºèƒ½æ”¶é›†å™¨
./run_systematic_test_final.sh --phase 5.1

# æˆ–
python3 smart_batch_runner.py --model test_model --num-instances 10
```

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# è®¾ç½®æ”¶é›†å™¨è§„æ¨¡
export COLLECTOR_SCALE=small    # å°è§„æ¨¡æµ‹è¯•
export COLLECTOR_SCALE=medium   # ä¸­ç­‰è§„æ¨¡æµ‹è¯•  
export COLLECTOR_SCALE=large    # å¤§è§„æ¨¡æµ‹è¯•
export COLLECTOR_SCALE=ultra    # è¶…å¹¶å‘æµ‹è¯•

# è®¾ç½®é¢„æœŸæµ‹è¯•æ•°é‡ï¼ˆè‡ªåŠ¨ä¼˜åŒ–é…ç½®ï¼‰
export NUM_TESTS=15

# å¯ç”¨æ™ºèƒ½æ”¶é›†å™¨
export USE_SMART_COLLECTOR=true
```

### æ‰‹åŠ¨é…ç½®
å¦‚æœéœ€è¦ç²¾ç¡®æ§åˆ¶ï¼Œå¯ä»¥ä¿®æ”¹é…ç½®ï¼š

```python
# åœ¨ smart_collector_config.py ä¸­
CUSTOM_CONFIG = {
    'max_memory_results': 5,    # 5ä¸ªç»“æœè§¦å‘ä¿å­˜
    'max_time_seconds': 180,    # 3åˆ†é’Ÿè¶…æ—¶ä¿å­˜
    'auto_save_interval': 60,   # 1åˆ†é’Ÿè‡ªåŠ¨æ£€æŸ¥
    'adaptive_threshold': True, # å¯ç”¨è‡ªé€‚åº”
    'checkpoint_interval': 3,   # æ¯3ä¸ªæµ‹è¯•ä¿å­˜
}
```

## æ•…éšœæ’é™¤

### 1. æ•°æ®æ²¡æœ‰ä¿å­˜
æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- ç¡®è®¤ `temp_results` ç›®å½•å­˜åœ¨
- æ£€æŸ¥æ˜¯å¦æœ‰æƒé™å†™å…¥æ–‡ä»¶
- æŸ¥çœ‹æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯
- è¿è¡Œ `python3 smart_collector_config.py` æ£€æŸ¥é…ç½®

### 2. æ€§èƒ½é—®é¢˜
å¦‚æœä¿å­˜è¿‡äºé¢‘ç¹ï¼š
- å¢åŠ  `max_memory_results`
- å¢åŠ  `max_time_seconds`
- è®¾ç½® `COLLECTOR_SCALE=large`

å¦‚æœä¿å­˜ä¸å¤ŸåŠæ—¶ï¼š
- å‡å°‘ `max_memory_results`
- å‡å°‘ `max_time_seconds`  
- è®¾ç½® `COLLECTOR_SCALE=small`

### 3. æ¢å¤ä¸¢å¤±çš„æ•°æ®
```python
# ä»ä¸´æ—¶æ–‡ä»¶æ¢å¤
from result_collector_adapter import create_adaptive_collector

collector = create_adaptive_collector()
recovered_data = collector.collect_all_results()
print(f"æ¢å¤äº† {len(recovered_data)} æ¡è®°å½•")
```

### 4. è°ƒè¯•ä¿¡æ¯
å¢åŠ è¯¦ç»†æ—¥å¿—ï¼š
```bash
export DEBUG_COLLECTOR=true
python3 smart_batch_runner.py --model test_model
```

## é…ç½®å‚è€ƒ

| å‚æ•° | å°è§„æ¨¡ | ä¸­ç­‰è§„æ¨¡ | å¤§è§„æ¨¡ | è¶…å¹¶å‘ |
|------|--------|----------|--------|--------|
| max_memory_results | 3 | 10 | 25 | 5 |
| max_time_seconds | 120 | 300 | 600 | 180 |
| checkpoint_interval | 1 | 5 | 20 | 3 |
| auto_save_interval | 60 | 60 | 60 | 30 |

## ç›‘æ§å’Œç»Ÿè®¡

æ£€æŸ¥æ”¶é›†å™¨çŠ¶æ€ï¼š
```python
from result_collector_adapter import create_adaptive_collector

collector = create_adaptive_collector()
stats = collector.get_stats()
print(f"å½“å‰çŠ¶æ€: {stats}")
```

## æ³¨æ„äº‹é¡¹

1. **å‘åå…¼å®¹**: ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯ä½¿ç”¨æ–°åŠŸèƒ½
2. **æ¸è¿›å‡çº§**: å¯ä»¥é€‰æ‹©æ€§å¯ç”¨æ–°ç‰¹æ€§
3. **å®‰å…¨ç¬¬ä¸€**: æ‰€æœ‰ä¿®æ”¹éƒ½æœ‰å¤‡ä»½ï¼Œå¯ä»¥éšæ—¶å›æ»š
4. **ç›‘æ§é‡è¦**: å®šæœŸæ£€æŸ¥æ•°æ®å®Œæ•´æ€§å’Œç³»ç»Ÿæ€§èƒ½

## è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æ£€æŸ¥å¤‡ä»½ç›®å½•ä¸­çš„åŸå§‹æ–‡ä»¶
2. æŸ¥çœ‹ `data_collection_diagnosis_report.md`
3. è¿è¡Œ `python3 fix_data_collection.py` è¿›è¡Œè¯Šæ–­
4. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
'''
        
        try:
            guide_file = self.workspace_root / "SMART_COLLECTOR_GUIDE.md"
            with open(guide_file, 'w', encoding='utf-8') as f:
                f.write(guide_content)
            
            logger.info(f"âœ… ä½¿ç”¨æŒ‡å—åˆ›å»ºå®Œæˆ: {guide_file}")
            return True
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æŒ‡å—åˆ›å»ºå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½æ•°æ®æ”¶é›†å™¨é›†æˆå·¥å…·")
    print("=" * 60)
    
    integrator = SmartCollectorIntegrator()
    
    print("ğŸ“‹ é›†æˆè®¡åˆ’:")
    print("  1. å¤‡ä»½ç°æœ‰æ–‡ä»¶")
    print("  2. é›†æˆæ™ºèƒ½æ”¶é›†å™¨åˆ° smart_batch_runner.py")
    print("  3. é›†æˆæ™ºèƒ½checkpointåˆ° batch_test_runner.py") 
    print("  4. åˆ›å»ºé…ç½®æ–‡ä»¶å’Œä½¿ç”¨æŒ‡å—")
    print()
    
    # æ‰§è¡Œé›†æˆ
    results = integrator.integrate_all()
    
    # æ˜¾ç¤ºç»“æœ
    print("ğŸ¯ é›†æˆç»“æœ:")
    print(f"  å¤‡ä»½åˆ›å»º: {'âœ…' if results['backup_created'] else 'âŒ'}")
    print(f"  æ–‡ä»¶ä¿®æ”¹: {len(results['files_modified'])} ä¸ª")
    for file in results['files_modified']:
        print(f"    âœ… {file}")
    
    if results['files_failed']:
        print(f"  å¤±è´¥æ–‡ä»¶: {len(results['files_failed'])} ä¸ª")
        for file in results['files_failed']:
            print(f"    âŒ {file}")
    
    print(f"  æ–°å¢æ–‡ä»¶: {len(results['new_files_created'])} ä¸ª")
    for file in results['new_files_created']:
        print(f"    ğŸ“„ {file}")
    
    print(f"\nğŸ‰ é›†æˆ{'æˆåŠŸ' if results['integration_success'] else 'å¤±è´¥'}!")
    
    if results['integration_success']:
        print("\nâœ… ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. æŸ¥çœ‹ SMART_COLLECTOR_GUIDE.md äº†è§£ä½¿ç”¨æ–¹æ³•")
        print("2. è¿è¡Œ python3 smart_collector_config.py æ£€æŸ¥é…ç½®")
        print("3. æµ‹è¯•ç°æœ‰çš„æ‰¹å¤„ç†è„šæœ¬ç¡®è®¤åŠŸèƒ½æ­£å¸¸")
        print("4. æ ¹æ®éœ€è¦è°ƒæ•´ç¯å¢ƒå˜é‡ (COLLECTOR_SCALE, NUM_TESTS)")
    else:
        print("\nâŒ é›†æˆå¤±è´¥ï¼Œå¯ä»¥ä»å¤‡ä»½ç›®å½•æ¢å¤:")
        print(f"   {integrator.backup_dir}")


if __name__ == "__main__":
    main()