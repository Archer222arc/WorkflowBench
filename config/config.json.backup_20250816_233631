{
  "use_azure_openai": true,
  "azure_openai_api_key": "9wiSC2YySp6iDFL45NIPuoJ9Ynm2CcEjPw4FDjGAeCOpRdZjdetdJQQJ99BGACYeBjFXJ3w3AAABACOGqpWV",
  "azure_openai_api_base": "https://archer222arc.openai.azure.com/",
  "azure_openai_api_version": "2024-12-01-preview",
  "azure_openai_deployment_name": "gpt-4o-mini",
  "azure_openai_model": "gpt-4o-mini",
  "openai_api_key": "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",
  "model": "gpt-4o-mini",
  "_comment": "=== \u591a\u6a21\u578b\u6279\u6d4b\u8bd5\u914d\u7f6e ===",
  "idealab_api_key": "956c41bd0f31beaf68b871d4987af4bb",
  "idealab_api_base": "https://idealab.alibaba-inc.com/api/openai/v1",
  "batch_testing": {
    "enabled": true,
    "max_parallel_models": 3,
    "timeout_per_model": 300,
    "retry_attempts": 3,
    "save_individual_results": true
  },
  "_comment_supported": "\u6240\u6709\u6a21\u578b\u90fd\u5df2\u9a8c\u8bc1\u53ef\u7528",
  "supported_models": [
    "gpt-4o-mini",
    "gpt-5-nano",
    "gpt-41-0414-global",
    "o1-1217-global",
    "o3-0416-global",
    "o4-mini-0416-global",
    "claude37_sonnet",
    "claude_sonnet4",
    "claude_opus4",
    "gemini-2.5-pro-06-17",
    "gemini-2.5-flash-06-17",
    "gemini-1.5-pro",
    "gemini-2.0-flash",
    "DeepSeek-V3-671B",
    "DeepSeek-R1-671B",
    "deepseek-v3-671b",
    "deepseek-r1-671b",
    "qwen2.5-max",
    "qwen2.5-72b-instruct",
    "qwen2.5-32b-instruct",
    "qwen2.5-14b-instruct",
    "qwen2.5-7b-instruct",
    "qwen2.5-3b-instruct",
    "kimi-k2"
  ],
  "_comment_model_configs": "\u6240\u6709\u6a21\u578b\u7684\u914d\u7f6e",
  "model_configs": {
    "gpt-4o-mini": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "azure"
    },
    "gpt-5-nano": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "user_azure",
      "azure_endpoint": "https://85409-me3ofvov-eastus2.cognitiveservices.azure.com/",
      "api_version": "2024-12-01-preview",
      "deployment_name": "gpt-5-nano"
    },
    "gpt-41-0414-global": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "o1-1217-global": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "o3-0416-global": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "o4-mini-0416-global": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "claude37_sonnet": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "claude_sonnet4": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "claude_opus4": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "gemini-2.5-pro-06-17": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "gemini-2.5-flash-06-17": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "gemini-1.5-pro": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "gemini-2.0-flash": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "deepseek-v3-671b": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "deepseek-r1-671b": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "DeepSeek-V3-671B": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "DeepSeek-R1-671B": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "qwen2.5-max": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "qwen2.5-72b-instruct": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "qwen2.5-32b-instruct": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "qwen2.5-14b-instruct": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "qwen2.5-7b-instruct": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "qwen2.5-3b-instruct": {
      "max_tokens": 2048,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "kimi-k2": {
      "max_tokens": 4096,
      "temperature": 0.1,
      "provider": "idealab"
    },
    "DeepSeek-V3-0324": {
      "provider": "user_azure",
      "azure_endpoint": "https://85409-me3ofvov-eastus2.services.ai.azure.com",
      "api_version": "2024-02-15-preview",
      "deployment_name": "DeepSeek-V3-0324",
      "max_tokens": 4096,
      "temperature": 0.1
    },
    "DeepSeek-R1-0528": {
      "provider": "user_azure",
      "azure_endpoint": "https://85409-me3ofvov-eastus2.services.ai.azure.com",
      "api_version": "2024-02-15-preview",
      "deployment_name": "DeepSeek-R1-0528",
      "max_tokens": 4096,
      "temperature": 0.1
    },
    "Llama-3.3-70B-Instruct": {
      "provider": "user_azure",
      "azure_endpoint": "https://aixplore-france.openai.azure.com/",
      "api_version": "2024-12-01-preview",
      "deployment_name": "meta-llama-3-3-70b-instruct"
    }
  },
  "experiment_presets": {
    "available_models_test": {
      "models": "all",
      "task_types": [
        "basic_task",
        "simple_task",
        "data_pipeline",
        "api_integration",
        "multi_stage_pipeline"
      ],
      "prompt_types": [
        "baseline",
        "cot",
        "optimal",
        "flawed"
      ],
      "num_tests_per_combination": 5,
      "description": "\u6d4b\u8bd5\u6240\u6709\u53ef\u7528\u6a21\u578b"
    },
    "qwen_scale_analysis": {
      "models": [
        "qwen2.5-3b-instruct",
        "qwen2.5-7b-instruct",
        "qwen2.5-14b-instruct",
        "qwen2.5-32b-instruct"
      ],
      "task_types": [
        "simple_task",
        "data_pipeline",
        "api_integration"
      ],
      "focus": "scale_effects",
      "description": "Qwen\u7cfb\u5217\u89c4\u6a21\u6548\u5e94\u5206\u6790"
    },
    "available_top_models": {
      "models": [
        "gpt-4o-mini",
        "DeepSeek-V3-671B",
        "DeepSeek-R1-671B",
        "qwen2.5-32b-instruct"
      ],
      "task_types": "all",
      "focus": "performance_comparison",
      "description": "\u53ef\u7528\u9876\u7ea7\u6a21\u578b\u5bf9\u6bd4"
    },
    "deepseek_comparison": {
      "models": [
        "DeepSeek-V3-671B",
        "DeepSeek-R1-671B",
        "deepseek-v3-671b",
        "deepseek-r1-671b"
      ],
      "task_types": [
        "simple_task",
        "data_pipeline"
      ],
      "focus": "deepseek_variants",
      "description": "DeepSeek\u4e0d\u540c\u547d\u540d\u683c\u5f0f\u5bf9\u6bd4"
    }
  },
  "models": [
    "o1-1217-global",
    "o3-0416-global",
    "gpt-oss-120b",
    "claude_opus4",
    "claude_sonnet4",
    "claude37_sonnet",
    "claude_haiku35",
    "gemini-2.5-pro-06-17",
    "gemini-2.5-flash-06-17"
  ],
  "user_azure_api_key": "6Qc2Oxuf0oVtGutYCTSHOGbm1Dmn4kESwrDYeytkJsHWv3xqrnEMJQQJ99BHACHYHv6XJ3w3AAAAACOGXWza",
  "model_routing": {
    "Llama-3.3-70B-Instruct": "user_azure"
  },
  "user_azure": {
    "Llama-3.3-70B-Instruct": {
      "endpoint": "https://aixplore-france.openai.azure.com/",
      "api_key": "xbt45cddcefbb0843439f36c6fb48af8e",
      "deployment_name": "meta-llama-3-3-70b-instruct",
      "api_version": "2024-12-01-preview"
    }
  }
}