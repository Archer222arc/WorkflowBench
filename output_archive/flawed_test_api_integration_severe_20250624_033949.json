{
  "task_type": "api_integration",
  "severity": "severe",
  "timestamp": "20250624_033949",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "severe",
        "description": "Adjacent steps swapped (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.248541283607483,
          "tool_accuracy": 0.2,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6425345373153686,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.2109910249710083,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "severe",
        "description": "Dependency order violated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.407065134048462,
          "tool_accuracy": 0.16666666666666666,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6727820873260497,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9511988306045531,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "severe",
        "description": "Tools replaced with similar but incorrect ones (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.2622759294509889,
          "tool_accuracy": 0.2222222222222222,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5096966743469238,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3352118492126466,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "severe",
        "description": "Tools replaced with wrong category (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.3005483150482178,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4591722774505616,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8896354818344117,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "severe",
        "description": "Required parameters missing (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.1967646503448486,
          "tool_accuracy": 0.11428571428571428,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.337467441558838,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.336434621810913,
          "tool_accuracy": 0.02666666666666667,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "severe",
        "description": "Wrong parameter types (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.12,
          "avg_execution_time": 1.3240969276428223,
          "tool_accuracy": 0.3939393939393939,
          "error_rate": 0.88,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6744540739059448,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.12712486743927,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "severe",
        "description": "Middle steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.5397234487533569,
          "tool_accuracy": 0.14285714285714285,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8400648260116577,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.2140095472335815,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "missing_validation",
        "severity": "severe",
        "description": "Validation steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.5819465112686157,
          "tool_accuracy": 0.2,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.952736587524414,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0385334968566893,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "severe",
        "description": "Steps duplicated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.3681103658676148,
          "tool_accuracy": 0.15625,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9906843709945679,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.5500258588790894,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "severe",
        "description": "Unnecessary steps added (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.4318562650680542,
          "tool_accuracy": 0.1388888888888889,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4335802125930786,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.098623356819153,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "severe",
        "description": "Format mismatches between steps (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.3383695316314697,
          "tool_accuracy": 0.17073170731707318,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.038898572921753,
          "tool_accuracy": 0.019230769230769232,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.6781035375595095,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "severe",
        "description": "Unrelated steps inserted (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.2885157728195191,
          "tool_accuracy": 0.058823529411764705,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7914935207366944,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.453959197998047,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}