{
  "task_type": "multi_stage_pipeline",
  "severity": "medium",
  "timestamp": "20250624_030138",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "medium",
        "description": "Adjacent steps swapped (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.7,
          "avg_execution_time": 2.3476008939743043,
          "tool_accuracy": 0.9426751592356688,
          "error_rate": 0.30000000000000004,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.52,
          "avg_execution_time": 1.9732048559188842,
          "tool_accuracy": 0.5350877192982456,
          "error_rate": 0.48,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.7025487852096557,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "medium",
        "description": "Dependency order violated (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.36,
          "avg_execution_time": 1.9798513174057006,
          "tool_accuracy": 0.7978723404255319,
          "error_rate": 0.64,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.54,
          "avg_execution_time": 2.050001401901245,
          "tool_accuracy": 0.5474137931034483,
          "error_rate": 0.45999999999999996,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 2.564438271522522,
          "tool_accuracy": 0.07936507936507936,
          "error_rate": 0.94,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "medium",
        "description": "Tools replaced with similar but incorrect ones (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.46,
          "avg_execution_time": 2.0985138034820556,
          "tool_accuracy": 0.8672566371681416,
          "error_rate": 0.54,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 1.6399748754501342,
          "tool_accuracy": 0.4890829694323144,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.208525447845459,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "medium",
        "description": "Tools replaced with wrong category (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 2.389148488044739,
          "tool_accuracy": 0.8145161290322581,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 1.7800837469100952,
          "tool_accuracy": 0.5627705627705628,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.738981075286865,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "medium",
        "description": "Required parameters missing (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.64,
          "avg_execution_time": 2.176666660308838,
          "tool_accuracy": 0.9078947368421053,
          "error_rate": 0.36,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 1.8484467315673827,
          "tool_accuracy": 0.463519313304721,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.4530192613601685,
          "tool_accuracy": 0.025510204081632654,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "medium",
        "description": "Wrong parameter types (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.64,
          "avg_execution_time": 2.57990065574646,
          "tool_accuracy": 0.9536423841059603,
          "error_rate": 0.36,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.62,
          "avg_execution_time": 2.071593279838562,
          "tool_accuracy": 0.6170212765957447,
          "error_rate": 0.38,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3511092615127565,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "medium",
        "description": "Middle steps removed (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 2.2497373628616333,
          "tool_accuracy": 0.823943661971831,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.52,
          "avg_execution_time": 1.9964485883712768,
          "tool_accuracy": 0.5188284518828452,
          "error_rate": 0.48,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.7905860710144044,
          "tool_accuracy": 0.025,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "unknown",
        "severity": "medium",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 2.065883688926697,
          "tool_accuracy": 0.8512396694214877,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.46,
          "avg_execution_time": 2.2810175037384033,
          "tool_accuracy": 0.47368421052631576,
          "error_rate": 0.54,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.412375445365906,
          "tool_accuracy": 0.02617801047120419,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "medium",
        "description": "Steps duplicated (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.52,
          "avg_execution_time": 2.2111723470687865,
          "tool_accuracy": 0.8702290076335878,
          "error_rate": 0.48,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.52,
          "avg_execution_time": 2.128528380393982,
          "tool_accuracy": 0.5271966527196653,
          "error_rate": 0.48,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.538629961013794,
          "tool_accuracy": 0.030120481927710843,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "medium",
        "description": "Unnecessary steps added (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 2.3259776782989503,
          "tool_accuracy": 0.8759124087591241,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.6,
          "avg_execution_time": 2.0698879861831667,
          "tool_accuracy": 0.5948275862068966,
          "error_rate": 0.4,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.256683559417725,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "medium",
        "description": "Format mismatches between steps (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.54,
          "avg_execution_time": 2.2337803077697753,
          "tool_accuracy": 0.8832116788321168,
          "error_rate": 0.45999999999999996,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 2.1973828411102296,
          "tool_accuracy": 0.5758928571428571,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.5343289518356324,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "medium",
        "description": "Unrelated steps inserted (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.58,
          "avg_execution_time": 2.485773453712463,
          "tool_accuracy": 0.8827586206896552,
          "error_rate": 0.42000000000000004,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.54,
          "avg_execution_time": 2.14803138256073,
          "tool_accuracy": 0.5316455696202531,
          "error_rate": 0.45999999999999996,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3320672273635865,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}