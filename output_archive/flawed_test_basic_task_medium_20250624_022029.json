{
  "task_type": "basic_task",
  "severity": "medium",
  "timestamp": "20250624_022029",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "medium",
        "description": "Adjacent steps swapped (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.6239331769943237,
          "tool_accuracy": 0.08888888888888889,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6569914150238036,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.217319955825806,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "medium",
        "description": "Dependency order violated (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7754949188232423,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.655037417411804,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.425783977508545,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "medium",
        "description": "Tools replaced with similar but incorrect ones (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.788882040977478,
          "tool_accuracy": 0.03076923076923077,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4917672967910767,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7280927896499634,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "medium",
        "description": "Tools replaced with wrong category (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 2.6391364192962645,
          "tool_accuracy": 0.07272727272727272,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.599600133895874,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8959860372543336,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "medium",
        "description": "Required parameters missing (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.7563366842269899,
          "tool_accuracy": 0.07272727272727272,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5972271585464477,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.312320141792297,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "medium",
        "description": "Wrong parameter types (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.6768779230117798,
          "tool_accuracy": 0.09836065573770492,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6922491073608399,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.997116332054138,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "medium",
        "description": "Middle steps removed (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.5185709285736084,
          "tool_accuracy": 0.08,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.65053062915802,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1174019384384155,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "missing_validation",
        "severity": "medium",
        "description": "Validation steps removed (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.466312108039856,
          "tool_accuracy": 0.046511627906976744,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4887845706939697,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.4113175535202025,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "medium",
        "description": "Steps duplicated (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4913873863220215,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.774848885536194,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7209285688400269,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "medium",
        "description": "Unnecessary steps added (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.6665083503723144,
          "tool_accuracy": 0.125,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6679133701324462,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5132552146911622,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "medium",
        "description": "Format mismatches between steps (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.4126747703552247,
          "tool_accuracy": 0.10714285714285714,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.835878119468689,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5891973066329956,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "medium",
        "description": "Unrelated steps inserted (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.4033060932159425,
          "tool_accuracy": 0.10256410256410256,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6339753437042237,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8205839157104493,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}