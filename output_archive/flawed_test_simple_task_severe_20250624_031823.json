{
  "task_type": "simple_task",
  "severity": "severe",
  "timestamp": "20250624_031823",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "severe",
        "description": "Adjacent steps swapped (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.6013313341140747,
          "tool_accuracy": 0.203125,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.485015730857849,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.202632637023926,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "severe",
        "description": "Dependency order violated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.710634126663208,
          "tool_accuracy": 0.18055555555555555,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.3807294273376465,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7783822298049927,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "severe",
        "description": "Tools replaced with similar but incorrect ones (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.1,
          "avg_execution_time": 2.7670575380325317,
          "tool_accuracy": 0.27419354838709675,
          "error_rate": 0.9,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.2967340326309205,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.334593629837036,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "severe",
        "description": "Tools replaced with wrong category (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.393930320739746,
          "tool_accuracy": 0.2,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.268286566734314,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9642298936843872,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "severe",
        "description": "Required parameters missing (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.14,
          "avg_execution_time": 1.7554420042037964,
          "tool_accuracy": 0.3333333333333333,
          "error_rate": 0.86,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5023718118667602,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.385627489089966,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "severe",
        "description": "Wrong parameter types (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.4933838558197021,
          "tool_accuracy": 0.14285714285714285,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.6883402633666993,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0079881143569946,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "severe",
        "description": "Middle steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.7750527954101563,
          "tool_accuracy": 0.08108108108108109,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.3730551481246949,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8305871677398682,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "missing_validation",
        "severity": "severe",
        "description": "Validation steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.5742287731170654,
          "tool_accuracy": 0.1724137931034483,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6980620431900024,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.298892493247986,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "severe",
        "description": "Steps duplicated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.5475990629196168,
          "tool_accuracy": 0.21818181818181817,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.643845329284668,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1352445316314697,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "severe",
        "description": "Unnecessary steps added (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.1,
          "avg_execution_time": 1.4798755598068238,
          "tool_accuracy": 0.22388059701492538,
          "error_rate": 0.9,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4319053840637208,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.134147439002991,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "severe",
        "description": "Format mismatches between steps (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.6068237209320069,
          "tool_accuracy": 0.24074074074074073,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4602636814117431,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0329791736602782,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "severe",
        "description": "Unrelated steps inserted (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.7138406944274902,
          "tool_accuracy": 0.12857142857142856,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4910282278060913,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.2995533990859984,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}