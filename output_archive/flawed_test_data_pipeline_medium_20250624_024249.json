{
  "task_type": "data_pipeline",
  "severity": "medium",
  "timestamp": "20250624_024249",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "medium",
        "description": "Adjacent steps swapped (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.22,
          "avg_execution_time": 2.663751835823059,
          "tool_accuracy": 0.22,
          "error_rate": 0.78,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.15576340675354,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.0994863080978394,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "medium",
        "description": "Dependency order violated (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.16,
          "avg_execution_time": 2.932191557884216,
          "tool_accuracy": 0.17098445595854922,
          "error_rate": 0.84,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.191856818199158,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.7124227476119995,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "medium",
        "description": "Tools replaced with similar but incorrect ones (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.2,
          "avg_execution_time": 2.988056163787842,
          "tool_accuracy": 0.21164021164021163,
          "error_rate": 0.8,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0891391754150392,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.6110187482833864,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "medium",
        "description": "Tools replaced with wrong category (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 2.6926134395599366,
          "tool_accuracy": 0.08,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1844313192367553,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.0511407375335695,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "medium",
        "description": "Required parameters missing (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.24,
          "avg_execution_time": 2.8815802907943726,
          "tool_accuracy": 0.25,
          "error_rate": 0.76,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9448596000671388,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.613108777999878,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "medium",
        "description": "Wrong parameter types (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.16,
          "avg_execution_time": 2.827987985610962,
          "tool_accuracy": 0.15920398009950248,
          "error_rate": 0.84,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9911034774780274,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.1824843454360963,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "medium",
        "description": "Middle steps removed (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.22,
          "avg_execution_time": 2.89356493473053,
          "tool_accuracy": 0.22388059701492538,
          "error_rate": 0.78,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0325096225738526,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.01783100605011,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "missing_validation",
        "severity": "medium",
        "description": "Validation steps removed (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.26,
          "avg_execution_time": 3.165257520675659,
          "tool_accuracy": 0.26,
          "error_rate": 0.74,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3156571912765505,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.6301504611968993,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "medium",
        "description": "Steps duplicated (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.12,
          "avg_execution_time": 2.692231831550598,
          "tool_accuracy": 0.125,
          "error_rate": 0.88,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.147899923324585,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.8962688732147215,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "medium",
        "description": "Unnecessary steps added (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.2,
          "avg_execution_time": 3.354561128616333,
          "tool_accuracy": 0.20408163265306123,
          "error_rate": 0.8,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0380892181396484,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.816121768951416,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "medium",
        "description": "Format mismatches between steps (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.24,
          "avg_execution_time": 4.6459696054458615,
          "tool_accuracy": 0.24,
          "error_rate": 0.76,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.07837863445282,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2832227897644044,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "medium",
        "description": "Unrelated steps inserted (medium severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.24,
          "avg_execution_time": 3.322157897949219,
          "tool_accuracy": 0.24489795918367346,
          "error_rate": 0.76,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.956789240837097,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2321101379394532,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}