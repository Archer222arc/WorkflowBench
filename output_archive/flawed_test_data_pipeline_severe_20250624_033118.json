{
  "task_type": "data_pipeline",
  "severity": "severe",
  "timestamp": "20250624_033118",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "severe",
        "description": "Adjacent steps swapped (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.1457841777801514,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9614899682998657,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2747040367126465,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "severe",
        "description": "Dependency order violated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.401699032783508,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.74998348236084,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.144925231933594,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "severe",
        "description": "Tools replaced with similar but incorrect ones (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2923460006713867,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1650380754470824,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2485310554504396,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "severe",
        "description": "Tools replaced with wrong category (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.9268052053451536,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1616274547576904,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.847035813331604,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "severe",
        "description": "Required parameters missing (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 3.3334401845932007,
          "tool_accuracy": 0.04519774011299435,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.894133105278015,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.0929839849472045,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "severe",
        "description": "Wrong parameter types (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 3.1951691770553587,
          "tool_accuracy": 0.09550561797752809,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.386246709823608,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.181629056930542,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "severe",
        "description": "Middle steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 3.631177878379822,
          "tool_accuracy": 0.06382978723404255,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3434632921218874,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.083849534988403,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "missing_validation",
        "severity": "severe",
        "description": "Validation steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.854568181037903,
          "tool_accuracy": 0.027472527472527472,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7539030599594116,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.118327522277832,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "severe",
        "description": "Steps duplicated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 3.3390124893188475,
          "tool_accuracy": 0.022222222222222223,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.455698890686035,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.117694406509399,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "severe",
        "description": "Unnecessary steps added (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.450213980674744,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1963514614105226,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.8808792877197265,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "severe",
        "description": "Format mismatches between steps (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 6.427736654281616,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2280282258987425,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.5582464027404783,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "severe",
        "description": "Unrelated steps inserted (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 3.9872050952911375,
          "tool_accuracy": 0.02824858757062147,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 4.688500585556031,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.139451780319214,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}