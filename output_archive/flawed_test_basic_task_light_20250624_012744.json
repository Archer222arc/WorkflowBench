{
  "task_type": "basic_task",
  "severity": "light",
  "timestamp": "20250624_012744",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "light",
        "description": "Adjacent steps swapped (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.668798804283142,
          "tool_accuracy": 0.11594202898550725,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3685679483413695,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9818315935134887,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "light",
        "description": "Dependency order violated (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.18,
          "avg_execution_time": 1.597245831489563,
          "tool_accuracy": 0.25,
          "error_rate": 0.8200000000000001,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8371341848373413,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3734160804748536,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "light",
        "description": "Tools replaced with similar but incorrect ones (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.14,
          "avg_execution_time": 1.4338666915893554,
          "tool_accuracy": 0.1917808219178082,
          "error_rate": 0.86,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6350566148757935,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.837995834350586,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "light",
        "description": "Tools replaced with wrong category (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.22,
          "avg_execution_time": 1.473296504020691,
          "tool_accuracy": 0.3142857142857143,
          "error_rate": 0.78,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.787384910583496,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5032972717285156,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "light",
        "description": "Required parameters missing (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.1,
          "avg_execution_time": 1.4419737005233764,
          "tool_accuracy": 0.13333333333333333,
          "error_rate": 0.9,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.857512927055359,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1929263925552367,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "light",
        "description": "Wrong parameter types (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.12,
          "avg_execution_time": 1.515847373008728,
          "tool_accuracy": 0.16666666666666666,
          "error_rate": 0.88,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.2013839864730835,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.3797677612304686,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "unknown",
        "severity": "light",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.12,
          "avg_execution_time": 1.5022738599777221,
          "tool_accuracy": 0.16901408450704225,
          "error_rate": 0.88,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6204580307006835,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.47467077255249,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "unknown",
        "severity": "light",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.26,
          "avg_execution_time": 1.3706334352493286,
          "tool_accuracy": 0.35135135135135137,
          "error_rate": 0.74,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6991177463531495,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 3.0325017023086547,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "light",
        "description": "Steps duplicated (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.16,
          "avg_execution_time": 1.8704513359069823,
          "tool_accuracy": 0.22535211267605634,
          "error_rate": 0.84,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.771408247947693,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.195389232635498,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "light",
        "description": "Unnecessary steps added (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.6663877487182617,
          "tool_accuracy": 0.03225806451612903,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.671145462989807,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.157923855781555,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "light",
        "description": "Format mismatches between steps (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.12,
          "avg_execution_time": 1.8534439086914063,
          "tool_accuracy": 0.15789473684210525,
          "error_rate": 0.88,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7573332977294922,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7988307666778565,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "light",
        "description": "Unrelated steps inserted (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.2,
          "avg_execution_time": 1.4195402002334594,
          "tool_accuracy": 0.29411764705882354,
          "error_rate": 0.8,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.8583139371871948,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4648928880691527,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}