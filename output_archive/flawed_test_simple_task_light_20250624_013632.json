{
  "task_type": "simple_task",
  "severity": "light",
  "timestamp": "20250624_013632",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "unknown",
        "severity": "light",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.3974316453933715,
          "tool_accuracy": 0.16666666666666666,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7145884323120117,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6486225080490113,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "unknown",
        "severity": "light",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.3303556108474732,
          "tool_accuracy": 0.05660377358490566,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.3741475248336792,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6231184530258178,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "light",
        "description": "Tools replaced with similar but incorrect ones (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.116325325965881,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.363165669441223,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.193986916542053,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "light",
        "description": "Tools replaced with wrong category (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 2.015605993270874,
          "tool_accuracy": 0.13636363636363635,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.3211482858657835,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.5696525382995605,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "light",
        "description": "Required parameters missing (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 1.5365482664108276,
          "tool_accuracy": 0.14285714285714285,
          "error_rate": 0.96,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.007340588569641,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9436107778549194,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "light",
        "description": "Wrong parameter types (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.4313231468200684,
          "tool_accuracy": 0.05555555555555555,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.9760596132278443,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7930562210083008,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "unknown",
        "severity": "light",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 2.7774389791488647,
          "tool_accuracy": 0.15517241379310345,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4991461896896363,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6779740858078003,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "unknown",
        "severity": "light",
        "description": "Unknown flaw type: unknown"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.1,
          "avg_execution_time": 1.171062822341919,
          "tool_accuracy": 0.3409090909090909,
          "error_rate": 0.9,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5786332559585572,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.6234817600250244,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "light",
        "description": "Steps duplicated (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.06,
          "avg_execution_time": 1.2990185546875,
          "tool_accuracy": 0.16666666666666666,
          "error_rate": 0.94,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.3823342370986937,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.2730286931991577,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "light",
        "description": "Unnecessary steps added (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.7300348901748657,
          "tool_accuracy": 0.08333333333333333,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4068285417556763,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.1136130237579347,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "light",
        "description": "Format mismatches between steps (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 1.484856095314026,
          "tool_accuracy": 0.075,
          "error_rate": 0.98,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.4492910528182983,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.0156125593185426,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "light",
        "description": "Unrelated steps inserted (light severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.08,
          "avg_execution_time": 1.0958568668365478,
          "tool_accuracy": 0.24489795918367346,
          "error_rate": 0.92,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.5553984451293945,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 1.7377914047241212,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}