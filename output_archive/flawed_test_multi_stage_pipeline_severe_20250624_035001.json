{
  "task_type": "multi_stage_pipeline",
  "severity": "severe",
  "timestamp": "20250624_035001",
  "flaw_test_results": {
    "order_flaw_swap": {
      "flaw_info": {
        "type": "order_swap",
        "severity": "severe",
        "description": "Adjacent steps swapped (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.54,
          "avg_execution_time": 2.7449922513961793,
          "tool_accuracy": 0.7837837837837838,
          "error_rate": 0.45999999999999996,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 1.7417646312713624,
          "tool_accuracy": 0.5627705627705628,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.5531457614898683,
          "tool_accuracy": 0.02717391304347826,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "order_flaw_dependency": {
      "flaw_info": {
        "type": "order_dependency",
        "severity": "severe",
        "description": "Dependency order violated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.54,
          "avg_execution_time": 2.409793133735657,
          "tool_accuracy": 0.9083969465648855,
          "error_rate": 0.45999999999999996,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.52,
          "avg_execution_time": 1.8899359321594238,
          "tool_accuracy": 0.5274261603375527,
          "error_rate": 0.48,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.759924807548523,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_similar": {
      "flaw_info": {
        "type": "tool_similar",
        "severity": "severe",
        "description": "Tools replaced with similar but incorrect ones (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.6,
          "avg_execution_time": 2.751279215812683,
          "tool_accuracy": 0.8954248366013072,
          "error_rate": 0.4,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 1.9249759769439698,
          "tool_accuracy": 0.5633187772925764,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.162277855873108,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "tool_misuse_wrong_category": {
      "flaw_info": {
        "type": "tool_wrong_category",
        "severity": "severe",
        "description": "Tools replaced with wrong category (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 2.040245084762573,
          "tool_accuracy": 0.8536585365853658,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.6,
          "avg_execution_time": 1.7925851440429688,
          "tool_accuracy": 0.6016949152542372,
          "error_rate": 0.4,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.756621069908142,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "param_missing": {
      "flaw_info": {
        "type": "parameter_missing",
        "severity": "severe",
        "description": "Required parameters missing (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.6,
          "avg_execution_time": 2.6418155336380007,
          "tool_accuracy": 0.8571428571428571,
          "error_rate": 0.4,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.46,
          "avg_execution_time": 1.8539320611953736,
          "tool_accuracy": 0.46255506607929514,
          "error_rate": 0.54,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 2.3446215057373045,
          "tool_accuracy": 0.05,
          "error_rate": 0.96,
          "total_tests": 50
        }
      }
    },
    "param_wrong_type": {
      "flaw_info": {
        "type": "parameter_wrong_type",
        "severity": "severe",
        "description": "Wrong parameter types (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.72,
          "avg_execution_time": 2.530637192726135,
          "tool_accuracy": 0.9176470588235294,
          "error_rate": 0.28,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 2.0024221754074096,
          "tool_accuracy": 0.5588235294117647,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 3.0116798210144045,
          "tool_accuracy": 0.025380710659898477,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "missing_middle": {
      "flaw_info": {
        "type": "missing_middle",
        "severity": "severe",
        "description": "Middle steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.58,
          "avg_execution_time": 2.3197725296020506,
          "tool_accuracy": 0.9020979020979021,
          "error_rate": 0.42000000000000004,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 1.7279449605941772,
          "tool_accuracy": 0.48739495798319327,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.04,
          "avg_execution_time": 2.8043754959106444,
          "tool_accuracy": 0.04950495049504951,
          "error_rate": 0.96,
          "total_tests": 50
        }
      }
    },
    "missing_validation": {
      "flaw_info": {
        "type": "missing_validation",
        "severity": "severe",
        "description": "Validation steps removed (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.66,
          "avg_execution_time": 3.0618046283721925,
          "tool_accuracy": 0.948051948051948,
          "error_rate": 0.33999999999999997,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.52,
          "avg_execution_time": 1.8654450798034667,
          "tool_accuracy": 0.5540540540540541,
          "error_rate": 0.48,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.506620850563049,
          "tool_accuracy": 0.025380710659898477,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "redundant_duplicate": {
      "flaw_info": {
        "type": "redundancy_duplicate",
        "severity": "severe",
        "description": "Steps duplicated (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.42,
          "avg_execution_time": 3.0734814167022706,
          "tool_accuracy": 0.6524822695035462,
          "error_rate": 0.5800000000000001,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.58,
          "avg_execution_time": 2.08788507938385,
          "tool_accuracy": 0.5982532751091703,
          "error_rate": 0.42000000000000004,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.3634055280685424,
          "tool_accuracy": 0.032679738562091505,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "redundant_unnecessary": {
      "flaw_info": {
        "type": "redundancy_unnecessary",
        "severity": "severe",
        "description": "Unnecessary steps added (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.64,
          "avg_execution_time": 2.594991421699524,
          "tool_accuracy": 0.9324324324324325,
          "error_rate": 0.36,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.66,
          "avg_execution_time": 1.896044044494629,
          "tool_accuracy": 0.6609442060085837,
          "error_rate": 0.33999999999999997,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.8398128652572634,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    },
    "logic_break_format": {
      "flaw_info": {
        "type": "logic_format",
        "severity": "severe",
        "description": "Format mismatches between steps (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.44,
          "avg_execution_time": 2.3595878314971923,
          "tool_accuracy": 0.7886178861788617,
          "error_rate": 0.56,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.44,
          "avg_execution_time": 2.1076518535614013,
          "tool_accuracy": 0.4396551724137931,
          "error_rate": 0.56,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.02,
          "avg_execution_time": 2.2356944561004637,
          "tool_accuracy": 0.0273224043715847,
          "error_rate": 0.98,
          "total_tests": 50
        }
      }
    },
    "logic_break_unrelated": {
      "flaw_info": {
        "type": "logic_unrelated",
        "severity": "severe",
        "description": "Unrelated steps inserted (severe severity)"
      },
      "performance_comparison": {
        "optimal_prompt": {
          "success_rate": 0.48,
          "avg_execution_time": 1.8851354932785034,
          "tool_accuracy": 0.8790322580645161,
          "error_rate": 0.52,
          "total_tests": 50
        },
        "baseline_prompt": {
          "success_rate": 0.56,
          "avg_execution_time": 2.198727555274963,
          "tool_accuracy": 0.5682819383259912,
          "error_rate": 0.43999999999999995,
          "total_tests": 50
        },
        "flawed_optimal_prompt": {
          "success_rate": 0.0,
          "avg_execution_time": 2.357087645530701,
          "tool_accuracy": 0.0,
          "error_rate": 1.0,
          "total_tests": 50
        }
      }
    }
  }
}