#!/usr/bin/env python3
"""
æµ‹è¯•run_systematic_test_final.shä¸­å®šä¹‰çš„æ‰€æœ‰æ¨¡å‹
å®Œæ•´æµ‹è¯•æ‰€æœ‰å¼€æºå’Œé—­æºæ¨¡å‹çš„APIè¿æ¥
"""

import time
import json
import traceback
import sys
from datetime import datetime
from pathlib import Path
from api_client_manager import get_client_for_model, get_api_model_name

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)

# ä»bashè„šæœ¬ä¸­æå–çš„å®Œæ•´æ¨¡å‹åˆ—è¡¨
OPENSOURCE_MODELS = [
    "DeepSeek-V3-0324",       # Azure 85409
    "DeepSeek-R1-0528",       # Azure 85409
    "qwen2.5-72b-instruct",   # IdealLab
    "qwen2.5-32b-instruct",   # IdealLab
    "qwen2.5-14b-instruct",   # IdealLab
    "qwen2.5-7b-instruct",    # IdealLab
    "qwen2.5-3b-instruct",    # IdealLab
    "Llama-3.3-70B-Instruct", # Azure 85409
]

CLOSED_SOURCE_MODELS = [
    "gpt-4o-mini",             # Azure
    "gpt-5-mini",              # Azure 85409
    "o3-0416-global",          # IdealLab
    "gemini-2.5-flash-06-17",  # IdealLab
    "kimi-k2",                 # IdealLab
    "claude_sonnet4",          # IdealLab
]

# Azure 85409ç«¯ç‚¹çš„é¢å¤–æ¨¡å‹ï¼ˆä»config.jsonä¸­å‘ç°ä½†æœªåœ¨bashè„šæœ¬ä¸»åˆ—è¡¨ä¸­ï¼‰
ADDITIONAL_AZURE_MODELS = [
    "gpt-4o",                  # Azure 85409
    "gpt-5-nano",              # Azure 85409
    "gpt-oss-120b",            # Azure 85409
    "grok-3",                  # Azure 85409
    "grok-3-mini",             # Azure 85409 (åœ¨bashä¸­è¢«æ³¨é‡Šä½†é…ç½®å­˜åœ¨)
    "o3-mini",                 # Azure 85409
    "DeepSeek-R1",             # Azure 85409
    # å¹¶å‘å®ä¾‹
    "DeepSeek-V3-0324-2",      # Azure 85409
    "DeepSeek-V3-0324-3",      # Azure 85409
    "DeepSeek-R1-0528-2",      # Azure 85409
    "DeepSeek-R1-0528-3",      # Azure 85409
    "Llama-3.3-70B-Instruct-2", # Azure 85409
    "Llama-3.3-70B-Instruct-3", # Azure 85409
]

# IdealLabçš„é¢å¤–æ¨¡å‹
ADDITIONAL_IDEALAB_MODELS = [
    "gpt-41-0414-global",      # IdealLab
    "o1-1217-global",          # IdealLab
    "o4-mini-0416-global",     # IdealLab
    "claude37_sonnet",         # IdealLab
    "claude_opus4",            # IdealLab
    "gemini-2.5-pro-06-17",    # IdealLab
    "gemini-1.5-pro",          # IdealLab
    "gemini-2.0-flash",        # IdealLab
    "deepseek-v3-671b",        # IdealLab
    "deepseek-r1-671b",        # IdealLab
    "DeepSeek-V3-671B",        # IdealLab
    "DeepSeek-R1-671B",        # IdealLab
    "qwen2.5-max",             # IdealLab
]

class DualLogger:
    """åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶çš„æ—¥å¿—å™¨"""
    def __init__(self, log_file):
        self.terminal = sys.stdout
        self.log = open(log_file, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()

def test_model_api(model_name: str, prompt_type: str = "baseline", timeout: int = 30):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„APIè¿æ¥"""
    result = {
        "model": model_name,
        "status": "unknown",
        "response_time": None,
        "error": None,
        "provider": None,
        "response": None
    }
    
    start = time.time()
    try:
        # è·å–å®¢æˆ·ç«¯
        client = get_client_for_model(model_name, prompt_type)
        api_model_name = get_api_model_name(model_name)
        
        # åˆ¤æ–­provider
        if hasattr(client, '_base_url'):
            base_url = str(client._base_url)
            if '85409' in base_url:
                result["provider"] = "Azure (85409)"
            elif 'aixplore' in base_url:
                result["provider"] = "Azure (France)"
            elif 'archer222' in base_url:
                result["provider"] = "Azure (Archer)"
            elif 'idealab' in base_url:
                result["provider"] = "IdealLab"
            else:
                result["provider"] = f"Unknown ({base_url[:30]}...)"
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": api_model_name,
            "messages": [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Reply with exactly: Hello World"}
            ],
            "timeout": timeout
        }
        
        # ç‰¹æ®Šå¤„ç†ï¼šgpt-5ç³»åˆ—ä¸æ”¯æŒæŸäº›å‚æ•°
        if 'gpt-5' not in model_name.lower():
            request_params["temperature"] = 0.1
            request_params["max_tokens"] = 100
        
        # å‘é€è¯·æ±‚
        response = client.chat.completions.create(**request_params)
        
        elapsed = time.time() - start
        result["status"] = "âœ… Success"
        result["response_time"] = round(elapsed, 2)
        
        # è·å–å“åº”å†…å®¹
        if response.choices and len(response.choices) > 0:
            result["response"] = response.choices[0].message.content[:50]
        
    except Exception as e:
        elapsed = time.time() - start
        result["status"] = "âŒ Failed"
        result["response_time"] = round(elapsed, 2)
        result["error"] = str(e)[:100]  # æˆªæ–­é”™è¯¯ä¿¡æ¯
    
    return result

def main():
    """ä¸»å‡½æ•°"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = LOG_DIR / f"all_models_test_{timestamp}.log"
    report_file = LOG_DIR / f"all_models_report_{timestamp}.md"
    
    # è®¾ç½®åŒé‡è¾“å‡º
    logger = DualLogger(log_file)
    old_stdout = sys.stdout
    sys.stdout = logger
    
    try:
        print("="*80)
        print("å®Œæ•´æ¨¡å‹APIæµ‹è¯•")
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
        print("="*80)
        
        all_results = []
        
        # 1. æµ‹è¯•bashè„šæœ¬ä¸­çš„å¼€æºæ¨¡å‹
        print("\n## 1. Bashè„šæœ¬å¼€æºæ¨¡å‹æµ‹è¯•")
        print("-"*60)
        for model in OPENSOURCE_MODELS:
            print(f"æµ‹è¯• {model}...", end=" ")
            result = test_model_api(model)
            print(f"{result['status']} ({result['response_time']}s)")
            all_results.append(("Bashå¼€æº", model, result))
        
        # 2. æµ‹è¯•bashè„šæœ¬ä¸­çš„é—­æºæ¨¡å‹
        print("\n## 2. Bashè„šæœ¬é—­æºæ¨¡å‹æµ‹è¯•")
        print("-"*60)
        for model in CLOSED_SOURCE_MODELS:
            print(f"æµ‹è¯• {model}...", end=" ")
            result = test_model_api(model)
            print(f"{result['status']} ({result['response_time']}s)")
            all_results.append(("Bashé—­æº", model, result))
        
        # 3. æµ‹è¯•é¢å¤–çš„Azureæ¨¡å‹
        print("\n## 3. é¢å¤–Azureæ¨¡å‹æµ‹è¯•")
        print("-"*60)
        for model in ADDITIONAL_AZURE_MODELS:
            print(f"æµ‹è¯• {model}...", end=" ")
            result = test_model_api(model)
            print(f"{result['status']} ({result['response_time']}s)")
            all_results.append(("é¢å¤–Azure", model, result))
        
        # 4. æµ‹è¯•é¢å¤–çš„IdealLabæ¨¡å‹
        print("\n## 4. é¢å¤–IdealLabæ¨¡å‹æµ‹è¯•")
        print("-"*60)
        for model in ADDITIONAL_IDEALAB_MODELS:
            print(f"æµ‹è¯• {model}...", end=" ")
            result = test_model_api(model)
            print(f"{result['status']} ({result['response_time']}s)")
            all_results.append(("é¢å¤–IdealLab", model, result))
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# å®Œæ•´æ¨¡å‹APIæµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # æŒ‰ç±»åˆ«æ•´ç†ç»“æœ
            categories = {}
            for category, model, result in all_results:
                if category not in categories:
                    categories[category] = []
                categories[category].append((model, result))
            
            # ç»Ÿè®¡
            total_models = len(all_results)
            success_count = sum(1 for _, _, r in all_results if "Success" in r["status"])
            
            f.write("## æµ‹è¯•ç»Ÿè®¡\n\n")
            f.write(f"- æ€»æ¨¡å‹æ•°: {total_models}\n")
            f.write(f"- æˆåŠŸ: {success_count}\n")
            f.write(f"- å¤±è´¥: {total_models - success_count}\n")
            f.write(f"- æˆåŠŸç‡: {success_count/total_models*100:.1f}%\n\n")
            
            # è¯¦ç»†ç»“æœ
            for category, models in categories.items():
                f.write(f"## {category}\n\n")
                f.write("| æ¨¡å‹ | çŠ¶æ€ | å“åº”æ—¶é—´(ç§’) | Provider | é”™è¯¯ä¿¡æ¯ |\n")
                f.write("|------|------|-------------|----------|----------|\n")
                
                for model, result in models:
                    error_msg = result['error'] if result['error'] else "-"
                    provider = result['provider'] if result['provider'] else "Unknown"
                    f.write(f"| {model} | {result['status']} | {result['response_time']} | {provider} | {error_msg} |\n")
                f.write("\n")
        
        # æ€»ç»“
        print("\n" + "="*80)
        print("æµ‹è¯•æ€»ç»“")
        print("-"*80)
        print(f"æ€»è®¡æµ‹è¯•: {total_models} ä¸ªæ¨¡å‹")
        print(f"æˆåŠŸ: {success_count} ä¸ª")
        print(f"å¤±è´¥: {total_models - success_count} ä¸ª")
        print(f"æˆåŠŸç‡: {success_count/total_models*100:.1f}%")
        
        # å¤±è´¥çš„æ¨¡å‹åˆ—è¡¨
        failed_models = [model for _, model, r in all_results if "Failed" in r["status"]]
        if failed_models:
            print(f"\nå¤±è´¥çš„æ¨¡å‹:")
            for model in failed_models:
                print(f"  - {model}")
        
        print(f"\nğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    finally:
        # æ¢å¤æ ‡å‡†è¾“å‡º
        sys.stdout = old_stdout
        logger.close()
        print(f"ğŸ“ å®Œæ•´æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    main()