#!/usr/bin/env python3
"""
æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨ - å¤„ç†429é”™è¯¯å’Œå¤šéƒ¨ç½²è´Ÿè½½å‡è¡¡
=============================================
å½“é‡åˆ°429 Too Many Requestsé”™è¯¯æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨çš„éƒ¨ç½²å®ä¾‹
"""

import json
import time
import random
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from openai import OpenAI, AzureOpenAI
import httpx

logger = logging.getLogger(__name__)

class SmartDeploymentManager:
    """æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config/config.json"):
        self.config = self._load_config(config_path)
        self.deployment_health = {}  # è®°å½•éƒ¨ç½²å¥åº·çŠ¶æ€
        self.last_used = {}  # è®°å½•ä¸Šæ¬¡ä½¿ç”¨æ—¶é—´ï¼Œç”¨äºè´Ÿè½½å‡è¡¡
        self.failure_count = {}  # è®°å½•å¤±è´¥æ¬¡æ•°
        
        # ä»é…ç½®ä¸­è·å–å¹¶è¡Œéƒ¨ç½²æ˜ å°„
        self.parallel_deployments = self.config.get("azure_parallel_deployments", {})
        
        # åˆå§‹åŒ–éƒ¨ç½²å¥åº·çŠ¶æ€
        for model, deployments in self.parallel_deployments.items():
            for deployment in deployments:
                self.deployment_health[deployment] = True
                self.last_used[deployment] = 0
                self.failure_count[deployment] = 0
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load config from {config_path}: {e}")
            return {}
    
    def get_best_deployment(self, model_name: str) -> Optional[str]:
        """è·å–æœ€ä½³å¯ç”¨éƒ¨ç½²
        
        Args:
            model_name: åŸºç¡€æ¨¡å‹åç§°ï¼ˆå¦‚ Llama-3.3-70B-Instructï¼‰
            
        Returns:
            æœ€ä½³å¯ç”¨éƒ¨ç½²åç§°ï¼Œå¦‚æœæ²¡æœ‰å¯ç”¨éƒ¨ç½²åˆ™è¿”å›None
        """
        # è·å–è¯¥æ¨¡å‹çš„æ‰€æœ‰éƒ¨ç½²
        deployments = self.parallel_deployments.get(model_name, [model_name])
        
        # è¿‡æ»¤å¥åº·çš„éƒ¨ç½²
        healthy_deployments = [
            d for d in deployments 
            if self.deployment_health.get(d, True) and self.failure_count.get(d, 0) < 5
        ]
        
        if not healthy_deployments:
            logger.warning(f"No healthy deployments available for {model_name}")
            # é‡ç½®å¤±è´¥è®¡æ•°ï¼Œç»™æ‰€æœ‰éƒ¨ç½²ä¸€ä¸ªæœºä¼š
            for d in deployments:
                self.failure_count[d] = 0
                self.deployment_health[d] = True
            healthy_deployments = deployments
        
        # è´Ÿè½½å‡è¡¡ï¼šé€‰æ‹©æœ€å°‘ä½¿ç”¨çš„éƒ¨ç½²
        current_time = time.time()
        best_deployment = min(healthy_deployments, key=lambda d: self.last_used.get(d, 0))
        
        # æ›´æ–°ä½¿ç”¨æ—¶é—´
        self.last_used[best_deployment] = current_time
        
        logger.info(f"Selected deployment for {model_name}: {best_deployment}")
        return best_deployment
    
    def mark_deployment_failed(self, deployment_name: str, error_type: str = "429"):
        """æ ‡è®°éƒ¨ç½²å¤±è´¥
        
        Args:
            deployment_name: éƒ¨ç½²åç§°
            error_type: é”™è¯¯ç±»å‹ï¼ˆ429, timeoutç­‰ï¼‰
        """
        self.failure_count[deployment_name] = self.failure_count.get(deployment_name, 0) + 1
        
        if error_type == "429":
            # 429é”™è¯¯ï¼šæš‚æ—¶æ ‡è®°ä¸ºä¸å¥åº·ï¼Œ10åˆ†é’Ÿåæ¢å¤
            self.deployment_health[deployment_name] = False
            logger.warning(f"Deployment {deployment_name} marked as unhealthy due to 429 error")
            
            # è®¾ç½®æ¢å¤æ—¶é—´ï¼ˆ10åˆ†é’Ÿåï¼‰
            recovery_time = time.time() + 600  # 10åˆ†é’Ÿ
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®šæ—¶å™¨æ¥æ¢å¤å¥åº·çŠ¶æ€
            
        elif self.failure_count[deployment_name] >= 5:
            # å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œæ ‡è®°ä¸ºä¸å¥åº·
            self.deployment_health[deployment_name] = False
            logger.warning(f"Deployment {deployment_name} marked as unhealthy due to repeated failures")
    
    def mark_deployment_success(self, deployment_name: str):
        """æ ‡è®°éƒ¨ç½²æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°"""
        if deployment_name in self.failure_count:
            self.failure_count[deployment_name] = 0
        self.deployment_health[deployment_name] = True
    
    def get_client_with_fallback(self, model_name: str, max_retries: int = 3) -> Optional[OpenAI]:
        """è·å–å¸¦æœ‰æ•…éšœè½¬ç§»çš„å®¢æˆ·ç«¯
        
        Args:
            model_name: æ¨¡å‹åç§°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            OpenAIå®¢æˆ·ç«¯å®ä¾‹
        """
        for attempt in range(max_retries):
            deployment = self.get_best_deployment(model_name)
            if not deployment:
                logger.error(f"No available deployments for {model_name}")
                return None
            
            try:
                client = self._create_client_for_deployment(deployment)
                logger.info(f"Successfully created client for deployment: {deployment}")
                return client
                
            except Exception as e:
                logger.warning(f"Failed to create client for deployment {deployment}: {e}")
                self.mark_deployment_failed(deployment, "connection")
                continue
        
        logger.error(f"Failed to create client for {model_name} after {max_retries} attempts")
        return None
    
    def _create_client_for_deployment(self, deployment_name: str) -> OpenAI:
        """ä¸ºç‰¹å®šéƒ¨ç½²åˆ›å»ºå®¢æˆ·ç«¯"""
        # ä»é…ç½®ä¸­è·å–éƒ¨ç½²ä¿¡æ¯
        model_config = self.config.get("model_configs", {}).get(deployment_name, {})
        
        if not model_config:
            raise ValueError(f"No configuration found for deployment: {deployment_name}")
        
        provider = model_config.get("provider", "user_azure")
        
        if provider == "user_azure":
            return AzureOpenAI(
                api_key=self.config.get("user_azure_api_key"),
                api_version=model_config.get("api_version", "2024-02-15-preview"),
                azure_endpoint=model_config.get("azure_endpoint"),
                timeout=httpx.Timeout(150.0, read=150.0, write=30.0, connect=30.0)
            )
        else:
            raise ValueError(f"Unsupported provider: {provider}")
    
    def execute_with_retry_and_fallback(self, model_name: str, api_call_func, *args, **kwargs):
        """æ‰§è¡ŒAPIè°ƒç”¨ï¼ŒåŒ…å«é‡è¯•å’Œæ•…éšœè½¬ç§»é€»è¾‘
        
        Args:
            model_name: æ¨¡å‹åç§°
            api_call_func: APIè°ƒç”¨å‡½æ•°
            *args, **kwargs: ä¼ é€’ç»™APIè°ƒç”¨å‡½æ•°çš„å‚æ•°
            
        Returns:
            APIè°ƒç”¨ç»“æœ
        """
        deployments = self.parallel_deployments.get(model_name, [model_name])
        
        for deployment in deployments:
            if not self.deployment_health.get(deployment, True):
                continue
                
            try:
                client = self._create_client_for_deployment(deployment)
                result = api_call_func(client, *args, **kwargs)
                
                # æˆåŠŸï¼Œæ ‡è®°éƒ¨ç½²ä¸ºå¥åº·
                self.mark_deployment_success(deployment)
                return result
                
            except Exception as e:
                error_str = str(e).lower()
                if "429" in error_str or "too many requests" in error_str:
                    logger.warning(f"429 error with deployment {deployment}, trying next...")
                    self.mark_deployment_failed(deployment, "429")
                    continue
                elif "timeout" in error_str:
                    logger.warning(f"Timeout with deployment {deployment}, trying next...")
                    self.mark_deployment_failed(deployment, "timeout")
                    continue
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œä¹Ÿå°è¯•ä¸‹ä¸€ä¸ªéƒ¨ç½²
                    logger.warning(f"Error with deployment {deployment}: {e}")
                    self.mark_deployment_failed(deployment, "other")
                    continue
        
        raise Exception(f"All deployments failed for model {model_name}")
    
    def get_deployment_status(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰éƒ¨ç½²çš„çŠ¶æ€ä¿¡æ¯"""
        status = {}
        for model, deployments in self.parallel_deployments.items():
            status[model] = {}
            for deployment in deployments:
                status[model][deployment] = {
                    "healthy": self.deployment_health.get(deployment, True),
                    "failure_count": self.failure_count.get(deployment, 0),
                    "last_used": self.last_used.get(deployment, 0)
                }
        return status
    
    def print_status(self):
        """æ‰“å°éƒ¨ç½²çŠ¶æ€"""
        print("ğŸš€ æ™ºèƒ½éƒ¨ç½²ç®¡ç†å™¨çŠ¶æ€:")
        print("=" * 50)
        
        for model, deployments in self.parallel_deployments.items():
            print(f"\nğŸ“Š {model}:")
            for deployment in deployments:
                health = "âœ… å¥åº·" if self.deployment_health.get(deployment, True) else "âŒ ä¸å¥åº·"
                failures = self.failure_count.get(deployment, 0)
                last_used = self.last_used.get(deployment, 0)
                last_used_str = time.strftime("%H:%M:%S", time.localtime(last_used)) if last_used > 0 else "ä»æœªä½¿ç”¨"
                
                print(f"  â€¢ {deployment}: {health} (å¤±è´¥æ¬¡æ•°: {failures}, ä¸Šæ¬¡ä½¿ç”¨: {last_used_str})")


# å…¨å±€å®ä¾‹
_deployment_manager = None

def get_deployment_manager() -> SmartDeploymentManager:
    """è·å–å…¨å±€éƒ¨ç½²ç®¡ç†å™¨å®ä¾‹"""
    global _deployment_manager
    if _deployment_manager is None:
        _deployment_manager = SmartDeploymentManager()
    return _deployment_manager


def create_smart_client(model_name: str) -> Optional[OpenAI]:
    """åˆ›å»ºæ™ºèƒ½å®¢æˆ·ç«¯ï¼ŒåŒ…å«æ•…éšœè½¬ç§»åŠŸèƒ½"""
    manager = get_deployment_manager()
    return manager.get_client_with_fallback(model_name)


def execute_with_smart_retry(model_name: str, api_call_func, *args, **kwargs):
    """æ‰§è¡Œå¸¦æœ‰æ™ºèƒ½é‡è¯•çš„APIè°ƒç”¨"""
    manager = get_deployment_manager()
    return manager.execute_with_retry_and_fallback(model_name, api_call_func, *args, **kwargs)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    manager = SmartDeploymentManager()
    manager.print_status()
    
    # æµ‹è¯•è·å–æœ€ä½³éƒ¨ç½²
    print(f"\nğŸ¯ Llama-3.3-70B-Instructæœ€ä½³éƒ¨ç½²: {manager.get_best_deployment('Llama-3.3-70B-Instruct')}")
    print(f"ğŸ¯ DeepSeek-V3-0324æœ€ä½³éƒ¨ç½²: {manager.get_best_deployment('DeepSeek-V3-0324')}")