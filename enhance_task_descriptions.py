#!/usr/bin/env python3
"""
Enhanced Task Description Generator with Multiple Difficulty Levels
==================================================================
Generates compelling task descriptions that make tool selection challenging but fair.
Now supports 5 difficulty levels: very_easy, easy, medium, hard, very_hard
"""

import json
import time
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Set
from collections import defaultdict
from openai import OpenAI
from pathlib import Path  # <- ä¿®æ”¹äº†è¿™ä¸€è¡Œï¼šæ·»åŠ äº†ç¼ºå¤±çš„ Path å¯¼å…¥
import os
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
import random


class DifficultyLevel(Enum):
    """Task description difficulty levels"""
    VERY_EASY = "very_easy"
    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"
    VERY_HARD = "very_hard"


@dataclass
class DifficultyConfig:
    """Configuration for each difficulty level"""
    level: DifficultyLevel
    abstraction_level: float  # 0.0 (concrete) to 1.0 (abstract)
    business_language_ratio: float  # 0.0 to 1.0
    tool_hint_clarity: float  # 1.0 (obvious) to 0.0 (obscure)
    complexity_target: int  # target word count
    ambiguity_level: float  # 0.0 (clear) to 1.0 (ambiguous)
    use_misleading_terms: bool
    include_direct_keywords: bool
    
    @property
    def temperature(self) -> float:
        """LLM temperature based on difficulty"""
        temp_map = {
            DifficultyLevel.VERY_EASY: 0.3,
            DifficultyLevel.EASY: 0.5,
            DifficultyLevel.MEDIUM: 0.7,
            DifficultyLevel.HARD: 0.8,
            DifficultyLevel.VERY_HARD: 0.9
        }
        return temp_map.get(self.level, 0.7)


class TaskEnhancer:
    """Enhanced task description generator with multiple difficulty levels"""
    
    # Difficulty level configurations
    DIFFICULTY_CONFIGS = {
        DifficultyLevel.VERY_EASY: DifficultyConfig(
            level=DifficultyLevel.VERY_EASY,
            abstraction_level=0.0,
            business_language_ratio=0.0,
            tool_hint_clarity=1.0,
            complexity_target=15,
            ambiguity_level=0.0,
            use_misleading_terms=False,
            include_direct_keywords=True
        ),
        DifficultyLevel.EASY: DifficultyConfig(
            level=DifficultyLevel.EASY,
            abstraction_level=0.2,
            business_language_ratio=0.1,
            tool_hint_clarity=0.8,
            complexity_target=20,
            ambiguity_level=0.1,
            use_misleading_terms=False,
            include_direct_keywords=True
        ),
        DifficultyLevel.MEDIUM: DifficultyConfig(
            level=DifficultyLevel.MEDIUM,
            abstraction_level=0.5,
            business_language_ratio=0.3,
            tool_hint_clarity=0.5,
            complexity_target=25,
            ambiguity_level=0.3,
            use_misleading_terms=False,
            include_direct_keywords=False
        ),
        DifficultyLevel.HARD: DifficultyConfig(
            level=DifficultyLevel.HARD,
            abstraction_level=0.7,
            business_language_ratio=0.6,
            tool_hint_clarity=0.3,
            complexity_target=30,
            ambiguity_level=0.5,
            use_misleading_terms=True,
            include_direct_keywords=False
        ),
        DifficultyLevel.VERY_HARD: DifficultyConfig(
            level=DifficultyLevel.VERY_HARD,
            abstraction_level=0.9,
            business_language_ratio=0.8,
            tool_hint_clarity=0.1,
            complexity_target=35,
            ambiguity_level=0.7,
            use_misleading_terms=True,
            include_direct_keywords=False
        )
    }
    
    # Task categories (from existing code)
    TASK_CATEGORIES = {
        'basic_task': {
            'description': 'Simple single-tool operations',
            'keywords': ['process', 'handle', 'execute', 'perform'],
            'tool_count': (1, 1),
            'patterns': ['direct', 'simple']
        },
        'simple_task': {
            'description': 'Basic multi-tool workflows',
            'keywords': ['coordinate', 'combine', 'integrate', 'workflow'],
            'tool_count': (2, 3),
            'patterns': ['sequential', 'pipeline']
        },
        'data_pipeline': {
            'description': 'Data processing pipelines',
            'keywords': ['transform', 'pipeline', 'stream', 'flow'],
            'tool_count': (3, 5),
            'patterns': ['pipeline', 'streaming', 'batch']
        },
        'api_integration': {
            'description': 'API and service integrations',
            'keywords': ['integrate', 'connect', 'synchronize', 'federate'],
            'tool_count': (2, 4),
            'patterns': ['request-response', 'event-driven', 'polling']
        },
        'multi_stage_pipeline': {
            'description': 'Complex multi-stage workflows',
            'keywords': ['orchestrate', 'coordinate', 'manage', 'complex'],
            'tool_count': (4, 7),
            'patterns': ['parallel', 'conditional', 'iterative', 'recursive']
        }
    }

    
    def __init__(self, api_key: Optional[str] = None,
                tool_registry_path: str = 'mcp_generated_library/tool_registry.json',
                tool_registry_consolidated_path: str = 'mcp_generated_library/tool_registry_consolidated.json',
                max_workers: int = 10,
                rate_limit: float = 0.5):
        """Initialize the task enhancer with semantic components"""
        self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        self.max_workers = max_workers
        self.rate_limit = rate_limit
        
        # Load tool registry
        print(f"ğŸ“ Loading tool registry from {tool_registry_path}...")
        with open(tool_registry_path, 'r') as f:
            self.tool_registry = json.load(f)
        
        # Load consolidated registry with differentiation info
        self.tool_registry_consolidated = {}
        consolidated_path = Path(tool_registry_consolidated_path)
        print(f"ğŸ“ Loading consolidated registry with differentiation...")
        with open(consolidated_path, 'r') as f:
            self.tool_registry_consolidated = json.load(f)
        print(f"âœ… Loaded differentiation info for {len(self.tool_registry_consolidated)} tools")

        
        # Statistics tracking - å¿…é¡»åœ¨å…¶ä»–ç»„ä»¶åˆå§‹åŒ–ä¹‹å‰
        self.enhancement_stats = self._initialize_stats()
        self.fallback_tasks = []
        
        # Initialize components - ç°åœ¨å¯ä»¥å®‰å…¨è®¿é—®enhancement_stats
        self.tool_mapping = self._create_tool_mapping()
        self.tool_analysis = self._analyze_tools()
        self.template_cache = self._generate_task_templates()
        
        # Current difficulty level
        self.current_difficulty = DifficultyLevel.MEDIUM
        
        # Initialize semantic components
        self.embedding_manager = None
        self.operation_index = None
        self._initialize_semantic_components()
    

    def _initialize_semantic_components(self):
        """åˆå§‹åŒ–è¯­ä¹‰ç»„ä»¶ç”¨äºå¢å¼ºæè¿°ç”Ÿæˆ"""
        print("[TaskEnhancer] Initializing semantic components...")
        
        # ä½¿ç”¨å•ä¾‹æ¨¡å¼è·å–MCPEmbeddingManager
        from mcp_embedding_manager import get_embedding_manager
        self.embedding_manager = get_embedding_manager()
        
        # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
        index_path = Path(".mcp_embedding_cache/tool_index.pkl")
        if index_path.exists():
            print(f"[TaskEnhancer] Found existing tool index at {index_path}")
            self.embedding_manager.load_index(index_path)
            print(f"[TaskEnhancer] Loaded {len(self.embedding_manager.tool_embeddings)} tool embeddings")
        else:
            print(f"[TaskEnhancer] No existing index found at {index_path}")
            # å¦‚æœæ²¡æœ‰ç´¢å¼•ï¼Œéœ€è¦æ„å»º
            tool_registry_path = Path("mcp_generated_library/tool_registry_consolidated.json")
            if not tool_registry_path.exists():
                tool_registry_path = Path("mcp_generated_library/tool_registry.json")
            
            if tool_registry_path.exists():
                print(f"[TaskEnhancer] Building index from {tool_registry_path}")
                build_stats = self.embedding_manager.build_index(tool_registry_path, force_rebuild=True)
                print(f"[TaskEnhancer] Built index: {build_stats}")
        
        # åˆå§‹åŒ–æ“ä½œç´¢å¼•
        from operation_embedding_index import get_operation_index
        self.operation_index = get_operation_index()
        print(f"[TaskEnhancer] Operation index loaded with {len(self.operation_index.operation_embeddings)} operations")
        
    def _initialize_stats(self) -> Dict[str, Any]:
        """Initialize statistics tracking"""
        return {
            'total': 0,
            'enhanced': 0,
            'failed': 0,
            'api_errors': 0,
            'validation_failed': 0,
            'retries': 0,
            'fallbacks': 0,
            'max_retries_reached': 0,
            'total_attempts': 0,
            'successful': 0,
            'validation_failures': 0,
            'tool_consolidations': 0,
            'new_templates_used': 0,
            'difficulty_distribution': {
                level.value: 0 for level in DifficultyLevel
            }
        }
    
    def set_difficulty_level(self, level: DifficultyLevel):
        """Set the current difficulty level"""
        self.current_difficulty = level
        print(f"ğŸ¯ Difficulty level set to: {level.value}")
    
    def enhance_single_task(self, task: Dict) -> str:
        """å¢å¼ºå•ä¸ªä»»åŠ¡çš„æè¿°"""
        self.enhancement_stats['total_attempts'] += 1
        
        # ç¡®ä¿ä»»åŠ¡æœ‰æ­£ç¡®çš„åˆ†ç±»
        if 'task_type' not in task or task['task_type'] not in self.TASK_CATEGORIES:
            task['task_type'] = self._categorize_task(task)
        
        try:
            # æ ¹æ®å½“å‰éš¾åº¦è®¾ç½®é€‰æ‹©éš¾åº¦
            if hasattr(self, 'challenge_mode') and self.challenge_mode:
                # æŒ‘æˆ˜æ¨¡å¼ï¼šæ›´å¤šå›°éš¾ä»»åŠ¡
                difficulty = random.choices(
                    list(DifficultyLevel),
                    weights=[0.05, 0.15, 0.30, 0.35, 0.15]
                )[0]
            else:
                # æ™®é€šæ¨¡å¼ï¼šæ›´å¤šç®€å•ä»»åŠ¡
                difficulty = random.choices(
                    list(DifficultyLevel),
                    weights=[0.15, 0.35, 0.35, 0.10, 0.05]
                )[0]
            
            # ç”Ÿæˆå¢å¼ºæè¿°
            enhanced = self.enhance_with_difficulty(task, difficulty)
            
            self.enhancement_stats['successful'] += 1
            self.enhancement_stats['difficulty_distribution'][difficulty.value] += 1
            
            return enhanced
            
        except Exception as e:
            print(f"Error enhancing task {task.get('id')}: {e}")
            self.enhancement_stats['failed'] += 1
            return self._create_fallback_description(task, DifficultyLevel.MEDIUM)
    
    def enhance_description(self, task: Dict) -> str:
        """å¢å¼ºä»»åŠ¡æè¿°ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self.enhance_single_task(task)
    
    def _update_single_description(self, task: Dict, idx: int, total: int) -> Dict:
        """æ›´æ–°å•ä¸ªä»»åŠ¡çš„æè¿°"""
        self.enhancement_stats['total'] += 1
        
        try:
            # é™åˆ¶è¯·æ±‚é€Ÿç‡
            time.sleep(self.rate_limit)
            
            # ä¿å­˜åŸå§‹æè¿°
            original_desc = task.get('description', '')
            task['original_description'] = original_desc
            
            # ç”Ÿæˆæ–°æè¿°
            enhanced_desc = self.enhance_single_task(task)
            
            # æ›´æ–°æè¿°
            task['description'] = enhanced_desc
            task['enhanced'] = True
            task['enhancement_timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S')
            
            self.enhancement_stats['enhanced'] += 1
            
            print(f"  âœ“ Task {idx+1}/{total} updated: {task.get('id', 'unknown')}")
            
            return task
            
        except Exception as e:
            print(f"  âœ— Task {idx+1}/{total} failed: {e}")
            self.enhancement_stats['failed'] += 1
            return task
    
    def _handle_fallback(self, task: Dict, reason: str, error: str = None) -> str:
        """å¤„ç†fallbackå¹¶è®°å½•ä¿¡æ¯"""
        self.enhancement_stats['fallbacks'] += 1
        
        # ä½¿ç”¨é»˜è®¤éš¾åº¦åˆ›å»ºfallback
        fallback_desc = self._create_fallback_description(task, DifficultyLevel.MEDIUM)
        
        fallback_info = {
            'task_id': task.get('id', 'unknown'),
            'task_type': task.get('task_type', 'unknown'),
            'original_description': task.get('description', ''),
            'required_tools': task.get('required_tools', []),
            'fallback_description': fallback_desc,
            'fallback_reason': reason,
            'error': error,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self.fallback_tasks.append(fallback_info)
        
        return fallback_desc
    
    def _generate_subtle_hints(self, tools: List[str]) -> List[str]:
        """ä¸ºå·¥å…·ç”Ÿæˆéšå«çš„åŠŸèƒ½æè¿°"""
        hints = []
        
        for tool in tools:
            if 'read' in tool or 'file' in tool:
                hints.append("extract information from sources")
            elif 'validate' in tool or 'check' in tool:
                hints.append("ensure data integrity")
            elif 'transform' in tool or 'convert' in tool:
                hints.append("restructure information")
            elif 'aggregate' in tool or 'combine' in tool:
                hints.append("consolidate multiple inputs")
            elif 'write' in tool or 'save' in tool:
                hints.append("persist processed results")
            elif 'fetch' in tool or 'api' in tool:
                hints.append("retrieve external data")
            else:
                # ä»å·¥å…·åæå–åŠ¨ä½œ
                parts = tool.split('_')
                if len(parts) > 1:
                    hints.append(f"perform {parts[1]} operations")
        
        return hints


    def enhance_with_difficulty(self, task: Dict, difficulty: DifficultyLevel, 
                            max_retries: int = 3) -> str:
        """Enhance a task description with specific difficulty level"""
        config = self.DIFFICULTY_CONFIGS[difficulty]
        
        for retry in range(max_retries):
            # è·å–ä»»åŠ¡çš„å®Œæ•´ä¸Šä¸‹æ–‡
            required_tools = task.get('required_tools', [])
            task_type = task.get('task_type', 'simple_task')
            test_input = task.get('test_input', {})
            expected_output = task.get('expected_output', {})
            pipeline_config = test_input.get('pipeline_config', {})
            category_config = self.TASK_CATEGORIES.get(task_type, self.TASK_CATEGORIES['simple_task'])
            
            # åˆ†æè¾“å…¥æ•°æ®ç»“æ„
            input_analysis = self._analyze_input_data(test_input)
            output_analysis = self._analyze_output_data(expected_output)
            
            # ä½¿ç”¨ RAG æœç´¢å¢å¼ºå·¥å…·æè¿°
            rag_enhanced_tools = []
            if self.embedding_manager and hasattr(self.embedding_manager, 'search'):
                for tool in required_tools:
                    # åŸºäºä»»åŠ¡ä¸Šä¸‹æ–‡æœç´¢è¯­ä¹‰ç›¸å…³çš„å·¥å…·
                    search_query = f"{tool} {input_analysis['data_type']} {output_analysis['format']}"
                    try:
                        search_results = self.embedding_manager.search(
                            query=search_query,
                            k=5,
                            return_scores=True
                        )
                        
                        # æå–è¯­ä¹‰ç›¸å…³çš„æ“ä½œæè¿°
                        semantic_hints = []
                        for result in search_results[:3]:
                            if hasattr(result, 'tool_name') and result.tool_name in self.tool_registry_consolidated:
                                tool_data = self.tool_registry_consolidated[result.tool_name]
                                if 'differentiation' in tool_data:
                                    hints = tool_data['differentiation'].get('key_differentiators', [])
                                    semantic_hints.extend(hints[:2])
                        
                        tool_desc = self._generate_contextual_tool_description(
                            tool, semantic_hints, input_analysis, output_analysis, config
                        )
                        rag_enhanced_tools.append(tool_desc)
                        
                    except Exception as e:
                        print(f"[DEBUG] RAG search failed for {tool}: {e}")
                        # Fallback to original tool description
                        tool_desc = self._generate_tool_description_for_difficulty(tool, difficulty, config)
                        if tool_desc:
                            rag_enhanced_tools.append(tool_desc)
            else:
                # Fallback: use original tool descriptions
                for tool in required_tools:
                    tool_desc = self._generate_tool_description_for_difficulty(tool, difficulty, config)
                    if tool_desc:
                        rag_enhanced_tools.append(tool_desc)
            
            # æ„å»ºåŸºäºæ•°æ®çš„ prompt
            prompt = f"""Create a task description based on the following data context:

    DIFFICULTY LEVEL: {difficulty.value}
    - Abstraction: {config.abstraction_level:.0%} abstract language
    - Business terminology: {config.business_language_ratio:.0%}
    - Target length: ~{config.complexity_target} words
    - Clarity: {100 - config.ambiguity_level * 100:.0f}% clear

    TASK CONTEXT:
    - Task Type: {task_type} ({category_config['description']})
    - Input Data: {input_analysis['description']}
    - Expected Output: {output_analysis['description']}
    - Processing Steps: {len(required_tools)} operations required
    {f"- Pipeline Stages: {pipeline_config.get('stages', 'N/A')}" if pipeline_config else ""}

    DATA FLOW:
    - Input: {input_analysis['data_type']} with {input_analysis['complexity']} structure
    - Processing: Transform through {len(required_tools)} tools
    - Output: {output_analysis['format']} format with {output_analysis['fields']} fields

    TOOL OPERATIONS (with semantic hints):
    {chr(10).join(rag_enhanced_tools)}

    GENERATION RULES:
    """
            
            if config.include_direct_keywords:
                prompt += """
    - DESCRIBE the specific data transformations based on input/output
    - MENTION how the data flows through the tools
    - INCLUDE references to the data structure and format"""
            else:
                prompt += """
    - FOCUS on the business value of transforming the input to output
    - AVOID technical details about data structures
    - USE abstract language about the process outcomes"""
            
            if config.use_misleading_terms:
                prompt += """
    - INCLUDE some plausible but irrelevant technical terms
    - ADD complexity through domain-specific jargon"""
            
            if config.abstraction_level > 0.6:
                prompt += """
    - FOCUS on high-level business objectives
    - DESCRIBE the value of the data transformation"""
            else:
                prompt += """
    - DESCRIBE the concrete data processing steps
    - MENTION specific transformations from input to output"""
            
            prompt += f"""

    Create a task description that:
    1. Reflects the actual data being processed ({input_analysis['data_type']} â†’ {output_analysis['format']})
    2. Explains the transformation journey through the {len(required_tools)} tools
    3. Matches the difficulty specifications above

    Return ONLY the description, no explanations."""
            
            # è°ƒç”¨ API ç”Ÿæˆæè¿°
            print(f"[DEBUG] Generating data-driven description for {difficulty.value} (attempt {retry + 1}/{max_retries})")
            
            # API è°ƒç”¨å’Œé”™è¯¯å¤„ç†ä¿æŒä¸å˜
            api_error = None
            enhanced = None
            
            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=config.temperature,
                    max_completion_tokens=250
                )
                enhanced = response.choices[0].message.content.strip()
                
            except Exception as e:
                print(f"[ERROR] API call failed: {e}")
                api_error = str(e)
                if retry < max_retries - 1:
                    time.sleep(self.rate_limit * (retry + 1))
                    continue
            
            if enhanced:
                # éªŒè¯ç”Ÿæˆçš„æè¿°
                validation = self._validate_difficulty_description(enhanced, task, difficulty)
                
                if validation['is_valid']:
                    self.enhancement_stats['successful'] += 1
                    self.enhancement_stats['difficulty_distribution'][difficulty.value] += 1
                    return enhanced
                
                if retry < max_retries - 1:
                    print(f"  Retry {retry + 1}: {validation['reason']}")
                    time.sleep(self.rate_limit)
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨åŸºäºæ•°æ®çš„ fallback
        print(f"[FALLBACK] All retries failed for {task.get('id', 'unknown')}. Using data-driven fallback.")
        return self._create_data_driven_fallback(task, difficulty)

    def _analyze_input_data(self, test_input: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æè¾“å…¥æ•°æ®çš„ç»“æ„å’Œç±»å‹"""
        analysis = {
            'data_type': 'unknown',
            'complexity': 'simple',
            'description': 'unspecified input',
            'has_structure': False
        }
        
        if not test_input:
            return analysis
        
        # åˆ†ææ•°æ®ç±»å‹
        if 'data' in test_input:
            data = test_input['data']
            if isinstance(data, list):
                analysis['data_type'] = f"list of {len(data)} items"
                if data and isinstance(data[0], (int, float)):
                    analysis['data_type'] = f"numeric array ({len(data)} values)"
                elif data and isinstance(data[0], dict):
                    analysis['data_type'] = f"structured records ({len(data)} entries)"
                    analysis['complexity'] = 'complex'
            elif isinstance(data, dict):
                analysis['data_type'] = f"structured object with {len(data)} fields"
                analysis['complexity'] = 'moderate'
            elif isinstance(data, str):
                analysis['data_type'] = "text data"
        
        # åˆ†æå…¶ä»–è¾“å…¥å­—æ®µ
        if 'input_file' in test_input:
            analysis['data_type'] = f"file input ({test_input['input_file']})"
        elif 'source' in test_input:
            analysis['data_type'] = f"data from {test_input['source']}"
        elif 'api_endpoints' in test_input:
            endpoints = test_input['api_endpoints']
            analysis['data_type'] = f"API data from {len(endpoints) if isinstance(endpoints, list) else 1} endpoints"
        
        # æ„å»ºæè¿°
        if 'pipeline_config' in test_input:
            stages = test_input['pipeline_config'].get('stages', 'multiple')
            analysis['description'] = f"{analysis['data_type']} to be processed through {stages} stages"
        else:
            analysis['description'] = f"{analysis['data_type']} requiring transformation"
        
        analysis['has_structure'] = analysis['complexity'] != 'simple'
        
        return analysis

    def _analyze_output_data(self, expected_output: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææœŸæœ›è¾“å‡ºçš„æ ¼å¼å’Œç»“æ„"""
        analysis = {
            'format': 'unspecified',
            'fields': 0,
            'description': 'processed result',
            'has_validation': False
        }
        
        if not expected_output:
            return analysis
        
        # åˆ†æè¾“å‡ºæ ¼å¼
        if 'final_output' in expected_output:
            output = expected_output['final_output']
            if isinstance(output, dict):
                analysis['fields'] = len(output)
                if 'success' in output:
                    analysis['format'] = 'status report'
                    analysis['has_validation'] = True
                elif 'data' in output:
                    analysis['format'] = 'data container'
                else:
                    analysis['format'] = f"structured result with {analysis['fields']} fields"
        
        elif 'pipeline_result' in expected_output:
            result = expected_output['pipeline_result']
            if 'stages_completed' in result:
                analysis['format'] = 'pipeline execution report'
                analysis['description'] = f"completion status of {result.get('stages_completed', 'all')} stages"
        
        elif 'result' in expected_output:
            analysis['format'] = 'simple result'
            analysis['description'] = 'transformed data output'
        
        # æ„å»ºæè¿°
        if analysis['has_validation']:
            analysis['description'] = f"{analysis['format']} with validation status"
        elif analysis['fields'] > 0:
            analysis['description'] = f"{analysis['format']} containing {analysis['fields']} data fields"
        
        return analysis

    def _generate_contextual_tool_description(self, tool: str, semantic_hints: List[str], 
                                            input_analysis: Dict, output_analysis: Dict,
                                            config: DifficultyConfig) -> str:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå·¥å…·æè¿°"""
        if config.tool_hint_clarity > 0.7:
            # æ¸…æ™°æè¿°ï¼šåŒ…å«è¯­ä¹‰æç¤ºå’Œæ•°æ®æµä¿¡æ¯
            hints_str = ", ".join(semantic_hints[:2]) if semantic_hints else f"process {input_analysis['data_type']}"
            return f"- {tool}: {hints_str} to support {output_analysis['format']} generation"
        
        elif config.tool_hint_clarity > 0.4:
            # ä¸­ç­‰æ¸…æ™°åº¦ï¼šåªæåŠæ•°æ®ç±»å‹
            return f"- Operation for handling {input_analysis['data_type']}"
        
        else:
            # æ¨¡ç³Šæè¿°ï¼šåªæåŠä¸€èˆ¬å¤„ç†
            return f"- Some form of data manipulation step"

    def _create_data_driven_fallback(self, task: Dict, difficulty: DifficultyLevel) -> str:
        """åˆ›å»ºåŸºäºæ•°æ®çš„ fallback æè¿°"""
        config = self.DIFFICULTY_CONFIGS[difficulty]
        test_input = task.get('test_input', {})
        expected_output = task.get('expected_output', {})
        required_tools = task.get('required_tools', [])
        
        # åˆ†ææ•°æ®
        input_analysis = self._analyze_input_data(test_input)
        output_analysis = self._analyze_output_data(expected_output)
        
        # æ ¹æ®éš¾åº¦æ„å»ºæè¿°
        if difficulty in [DifficultyLevel.VERY_EASY, DifficultyLevel.EASY]:
            description = (
                f"Process {input_analysis['description']} through {len(required_tools)} steps "
                f"to produce {output_analysis['description']}. "
                f"Each tool handles a specific part of the transformation."
            )
        elif difficulty == DifficultyLevel.MEDIUM:
            description = (
                f"Coordinate a workflow that transforms {input_analysis['data_type']} "
                f"into {output_analysis['format']} through {len(required_tools)} processing stages."
            )
        else:  # HARD or VERY_HARD
            description = (
                f"Orchestrate an enterprise solution leveraging {len(required_tools)} components "
                f"to ensure optimal transformation of business-critical data "
                f"while maintaining compliance and performance standards."
            )
        
        # è®°å½• fallback
        self.enhancement_stats['fallbacks'] += 1
        self.fallback_tasks.append({
            'task_id': task.get('id', 'unknown'),
            'difficulty': difficulty.value,
            'reason': 'data-driven fallback',
            'input_type': input_analysis['data_type'],
            'output_type': output_analysis['format'],
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        })
        
        return description

    def _generate_tool_description_for_difficulty(self, tool: str, difficulty: DifficultyLevel, config: DifficultyConfig) -> str:
        """Generate tool description based on difficulty using semantic information"""
        
        # é¦–å…ˆæ£€æŸ¥consolidated registryä¸­çš„differentiationä¿¡æ¯
        if tool in self.tool_registry_consolidated:
            tool_data = self.tool_registry_consolidated[tool]
            differentiation = tool_data.get('differentiation', {})
            
            if config.tool_hint_clarity > 0.7:
                # Very clear hints - ä½¿ç”¨key_differentiators
                key_diffs = differentiation.get('key_differentiators', [])
                usage_keywords = differentiation.get('usage_keywords', [])
                
                if key_diffs:
                    # ä½¿ç”¨å…·ä½“çš„å·®å¼‚åŒ–ç‰¹å¾
                    features = key_diffs[:2]  # æœ€å¤š2ä¸ªç‰¹å¾
                    keywords = usage_keywords[:3] if usage_keywords else []
                    if keywords:
                        return f"- {tool}: {', '.join(features)} (keywords: {', '.join(keywords)})"
                    else:
                        return f"- {tool}: {', '.join(features)}"
                else:
                    # Fallbackåˆ°åŸºç¡€æè¿°
                    desc = tool_data.get('description', '')
                    return f"- {tool}: {desc[:50]}..." if len(desc) > 50 else f"- {tool}: {desc}"
                    
            elif config.tool_hint_clarity > 0.4:
                # Moderate hints - ä½¿ç”¨è¯­ä¹‰æœç´¢æ‰¾ç›¸ä¼¼æ“ä½œ
                if self.operation_index:
                    # ä½¿ç”¨æ“ä½œç´¢å¼•æŸ¥æ‰¾ç›¸ä¼¼æ“ä½œ
                    operation = differentiation.get('unique_purpose', tool.split('_')[-1])
                    similar_ops = self.operation_index.get_similar_operations(operation, k=2)
                    if similar_ops:
                        hint = similar_ops[0] if similar_ops[0] != operation else (similar_ops[1] if len(similar_ops) > 1 else operation)
                        return f"- Operation involving: {hint}"
                
                # Fallback
                unique_purpose = differentiation.get('unique_purpose', 'data processing')
                return f"- Operation involving: {unique_purpose}"
                
            else:
                # Obscure hints - åªç»™å‡ºç±»åˆ«ä¿¡æ¯
                category = tool_data.get('metadata', {}).get('category', 'processing')
                return f"- Some form of {category} operation"
        
        # å¦‚æœæ²¡æœ‰åœ¨consolidated registryä¸­æ‰¾åˆ°ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
        if tool in self.tool_analysis:
            analysis = self.tool_analysis[tool]
            
            if config.tool_hint_clarity > 0.7:
                hints = analysis.get('unique_features', [])[:2]
                keywords = analysis.get('usage_keywords', [])[:3]
                return f"- {tool}: {', '.join(hints)} (keywords: {', '.join(keywords)})"
            elif config.tool_hint_clarity > 0.4:
                hints = analysis.get('distinguishing_hints', [])[:1]
                return f"- Operation involving: {hints[0] if hints else 'data processing'}"
            else:
                category = self.tool_registry.get(tool, {}).get('category', 'processing')
                return f"- Some form of {category} operation"
        
        # æœ€ç»ˆfallback
        return f"- Tool: {tool}"


    def _validate_difficulty_description(self, description: str, task: Dict, 
                                    difficulty: DifficultyLevel) -> Dict[str, Any]:
        """Validate if description matches target difficulty using very relaxed criteria"""
        config = self.DIFFICULTY_CONFIGS[difficulty]
        issues = []
        
        # æåº¦æ”¾å®½çš„é•¿åº¦æ£€æŸ¥ - åªæ£€æŸ¥æç«¯æƒ…å†µ
        word_count = len(description.split())
        if word_count < 5:  # å¤ªçŸ­
            issues.append(f"Description too short: {word_count} words")
        elif word_count > 200:  # å¤ªé•¿
            issues.append(f"Description too long: {word_count} words")
        
        # ä½¿ç”¨embeddingè¿›è¡Œè¯­ä¹‰éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.embedding_manager and len(issues) == 0:  # åªæœ‰åœ¨æ²¡æœ‰å…¶ä»–é—®é¢˜æ—¶æ‰æ£€æŸ¥
            print(f"[DEBUG] Using embedding validation for {difficulty.value}")
            
            # è·å–éš¾åº¦çº§åˆ«çš„å‚è€ƒæ¨¡æ¿
            reference_templates = self._get_difficulty_reference_templates(difficulty)
            
            # è®¡ç®—ç”Ÿæˆæè¿°çš„embedding
            description_embedding = self.embedding_manager._get_embedding(description)
            
            # è®¡ç®—ä¸å‚è€ƒæ¨¡æ¿çš„ç›¸ä¼¼åº¦
            max_similarity = 0.0
            
            for template in reference_templates:
                template_embedding = self.embedding_manager._get_embedding(template)
                
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                similarity = self._calculate_cosine_similarity(
                    description_embedding, 
                    template_embedding
                )
                
                if similarity > max_similarity:
                    max_similarity = similarity
            
            print(f"[DEBUG] Max similarity: {max_similarity:.3f}")
            
            # å¤§å¹…é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ - è®©å¤§éƒ¨åˆ†æè¿°éƒ½èƒ½é€šè¿‡
            similarity_thresholds = {
                DifficultyLevel.VERY_EASY: 0.4,     # ä»0.7é™åˆ°0.4
                DifficultyLevel.EASY: 0.35,         # ä»0.65é™åˆ°0.35
                DifficultyLevel.MEDIUM: 0.3,        # ä»0.6é™åˆ°0.3
                DifficultyLevel.HARD: 0.25,         # ä»0.55é™åˆ°0.25
                DifficultyLevel.VERY_HARD: 0.2      # ä»0.5é™åˆ°0.2
            }
            
            threshold = similarity_thresholds.get(difficulty, 0.3)
            
            # åªæœ‰æä½çš„ç›¸ä¼¼åº¦æ‰ç®—å¤±è´¥
            if max_similarity < threshold:
                # å³ä½¿ä½äºé˜ˆå€¼ï¼Œä¹Ÿç»™ä¸€ä¸ªè­¦å‘Šè€Œä¸æ˜¯å¤±è´¥
                print(f"[WARNING] Similarity {max_similarity:.3f} below threshold {threshold}, but accepting anyway")
                # ä¸æ·»åŠ åˆ°issuesï¼Œè®©å®ƒé€šè¿‡
            
            # å®Œå…¨ç§»é™¤å·¥å…·è¦†ç›–ç‡æ£€æŸ¥ - å¤ªä¸¥æ ¼äº†
            
        elif not self.embedding_manager and len(issues) == 0:
            # æ²¡æœ‰embedding manageræ—¶çš„æç®€éªŒè¯
            print("[INFO] No embedding manager, using minimal validation")
            
            # åªåšæœ€åŸºæœ¬çš„åˆç†æ€§æ£€æŸ¥
            if difficulty in [DifficultyLevel.VERY_EASY, DifficultyLevel.EASY]:
                # å¯¹äºç®€å•éš¾åº¦ï¼Œåªè¦ä¸æ˜¯å®Œå…¨çš„å•†ä¸šæœ¯è¯­å°±è¡Œ
                business_jargon = ['leverage', 'synergize', 'optimize', 'enterprise', 'stakeholder']
                jargon_count = sum(1 for term in business_jargon if term in description.lower())
                if jargon_count > 3:  # åªæœ‰è¿‡å¤šå•†ä¸šæœ¯è¯­æ‰ç®—é—®é¢˜
                    print(f"[WARNING] Too much business jargon ({jargon_count}), but accepting")
                    # ä¾ç„¶ä¸æ·»åŠ åˆ°issues
            
            elif difficulty in [DifficultyLevel.HARD, DifficultyLevel.VERY_HARD]:
                # å¯¹äºå›°éš¾éš¾åº¦ï¼ŒåŸºæœ¬ä¸Šä»»ä½•æè¿°éƒ½æ¥å—
                print(f"[INFO] Hard difficulty - accepting any reasonable description")
        
        # æœ€ç»ˆåˆ¤æ–­ - æåº¦å®½æ¾
        validation_result = {
            'is_valid': len(issues) == 0,  # åªæœ‰çœŸæ­£çš„é—®é¢˜æ‰ä¼šå¤±è´¥
            'reason': '; '.join(issues) if issues else 'Valid',
            'issues': issues
        }
        
        # å³ä½¿æœ‰issuesï¼Œå¦‚æœä¸æ˜¯å¤ªä¸¥é‡ï¼Œä¹Ÿè®©å®ƒé€šè¿‡
        if issues and all('too short' not in issue and 'too long' not in issue for issue in issues):
            print(f"[INFO] Minor issues found but accepting: {issues}")
            validation_result['is_valid'] = True
            validation_result['reason'] = 'Valid (minor issues ignored)'
        
        return validation_result

    def _get_difficulty_reference_templates(self, difficulty: DifficultyLevel) -> List[str]:
        """Get reference templates for each difficulty level"""
        # ç®€åŒ–æ¨¡æ¿ï¼Œè®©åŒ¹é…æ›´å®¹æ˜“
        templates = {
            DifficultyLevel.VERY_EASY: [
                "Read data, validate, transform, and write results",
                "Process files through multiple steps",
                "Load, check, convert, save data"
            ],
            DifficultyLevel.EASY: [
                "Process data through validation and transformation",
                "Handle file operations with format conversion",
                "Execute data pipeline with processing stages"
            ],
            DifficultyLevel.MEDIUM: [
                "Coordinate multi-stage data processing workflow",
                "Implement data pipeline with various stages",
                "Manage workflow combining multiple operations"
            ],
            DifficultyLevel.HARD: [
                "Orchestrate data transformation pipeline",
                "Design solution integrating multiple stages",
                "Architect workflow ensuring data integrity"
            ],
            DifficultyLevel.VERY_HARD: [
                "Engineer data orchestration framework",
                "Implement enterprise solution with components",
                "Architect sophisticated data ecosystem"
            ]
        }
        
        return templates.get(difficulty, templates[DifficultyLevel.MEDIUM])

    def _calculate_cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calculate cosine similarity between two vectors"""
        # é¿å…é™¤é›¶é”™è¯¯
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        # å½’ä¸€åŒ–å‘é‡
        vec1_norm = vec1 / norm1
        vec2_norm = vec2 / norm2
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(vec1_norm, vec2_norm)
        
        return float(similarity)

    def _check_tool_semantic_coverage(self, description: str, required_tools: List[str]) -> float:
        """Check how well the description covers the semantic meaning of required tools"""
        if not self.embedding_manager or not required_tools:
            return 1.0
        
        covered_count = 0
        description_lower = description.lower()
        
        for tool in required_tools:
            # ä»tool registryè·å–å·¥å…·çš„è¯­ä¹‰ä¿¡æ¯
            tool_info = self.tool_registry_consolidated.get(tool, {})
            
            # æ£€æŸ¥å·¥å…·çš„è¯­ä¹‰æ“ä½œæ˜¯å¦åœ¨æè¿°ä¸­æœ‰ä½“ç°
            semantic_ops = tool_info.get('semantic_operations', [])
            differentiation = tool_info.get('differentiation', {})
            keywords = differentiation.get('usage_keywords', [])
            
            # æ£€æŸ¥è¯­ä¹‰æ“ä½œ
            tool_covered = False
            for op in semantic_ops:
                # æå–æ“ä½œçš„æ ¸å¿ƒè¯
                op_words = op.lower().split('_')
                if any(word in description_lower for word in op_words if len(word) > 3):
                    tool_covered = True
                    break
            
            # æ£€æŸ¥å…³é”®è¯
            if not tool_covered and keywords:
                if any(kw.lower() in description_lower for kw in keywords):
                    tool_covered = True
            
            if tool_covered:
                covered_count += 1
        
        coverage = covered_count / len(required_tools) if required_tools else 1.0
        return coverage
        
    def _create_fallback_description(self, task: Dict, difficulty: DifficultyLevel) -> str:
        """Create a fallback description for given difficulty"""
        config = self.DIFFICULTY_CONFIGS[difficulty]
        task_type = task.get('task_type', 'simple_task')
        required_tools = task.get('required_tools', [])
        category_config = self.TASK_CATEGORIES.get(task_type, self.TASK_CATEGORIES['simple_task'])
        
        # Base description
        base_parts = []
        
        if difficulty in [DifficultyLevel.VERY_EASY, DifficultyLevel.EASY]:
            # Direct and clear
            operations = []
            for tool in required_tools:
                if 'read' in tool or 'file' in tool:
                    operations.append("read data from files")
                elif 'validate' in tool or 'check' in tool:
                    operations.append("validate data integrity")
                elif 'transform' in tool or 'process' in tool:
                    operations.append("transform data format")
                elif 'write' in tool or 'save' in tool:
                    operations.append("save processed results")
                else:
                    operations.append(f"process with {tool.split('_')[0]} operations")
            
            base_parts.append(f"This task requires you to {' and '.join(operations)}.")
            
        elif difficulty == DifficultyLevel.MEDIUM:
            # Moderate abstraction
            base_parts.append(f"Coordinate a {task_type.replace('_', ' ')} workflow that ")
            base_parts.append(f"processes data through {len(required_tools)} stages ")
            base_parts.append("to achieve the desired output format.")
            
        else:  # HARD or VERY_HARD
            # High abstraction with business language
            base_parts.append("Orchestrate an enterprise-grade solution that ")
            base_parts.append(f"leverages {len(required_tools)} integrated components ")
            base_parts.append("to ensure compliance with stakeholder requirements ")
            base_parts.append("while optimizing for scalability and performance.")
        
        description = ''.join(base_parts)
        
        # Add complexity for harder difficulties
        if config.use_misleading_terms:
            description += " Consider real-time constraints and security implications."
        
        # Record fallback
        self.enhancement_stats['fallbacks'] += 1
        self.fallback_tasks.append({
            'task_id': task.get('id', 'unknown'),
            'difficulty': difficulty.value,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        })
        
        return description
    
    def update_descriptions_with_difficulty(self, task_library_path: str, 
                                          output_path: str = None,
                                          difficulty_distribution: Dict[str, float] = None) -> None:
        """
        Update task descriptions with specified difficulty distribution
        
        Args:
            task_library_path: Path to input task library
            output_path: Path to output (None = overwrite input)
            difficulty_distribution: Dict mapping difficulty levels to percentages
                                   e.g., {"very_easy": 0.1, "easy": 0.2, "medium": 0.4, "hard": 0.2, "very_hard": 0.1}
        """
        if difficulty_distribution is None:
            # Default distribution
            difficulty_distribution = {
                "very_easy": 0.1,
                "easy": 0.2,
                "medium": 0.4,
                "hard": 0.2,
                "very_hard": 0.1
            }
        
        # Normalize distribution
        total = sum(difficulty_distribution.values())
        if total > 0:
            difficulty_distribution = {k: v/total for k, v in difficulty_distribution.items()}
        
        print(f"\nğŸ“ Updating descriptions with difficulty distribution:")
        for level, ratio in difficulty_distribution.items():
            print(f"  {level}: {ratio:.1%}")
        
        # Load task library
        with open(task_library_path, 'r') as f:
            task_data = json.load(f)
        
        tasks = task_data.get('tasks', task_data if isinstance(task_data, list) else [])
        total_tasks = len(tasks)
        
        # Calculate number of tasks per difficulty
        difficulty_counts = {}
        cumulative = 0
        for level, ratio in difficulty_distribution.items():
            count = int(total_tasks * ratio)
            difficulty_counts[level] = count
            cumulative += count
        
        # Adjust for rounding errors
        if cumulative < total_tasks:
            difficulty_counts['medium'] += total_tasks - cumulative
        
        print(f"\nğŸ“Š Task distribution:")
        for level, count in difficulty_counts.items():
            print(f"  {level}: {count} tasks")
        
        # Assign difficulties to tasks
        task_difficulties = []
        for level, count in difficulty_counts.items():
            task_difficulties.extend([DifficultyLevel(level)] * count)
        
        # Shuffle to randomize distribution
        import random
        random.shuffle(task_difficulties)
        
        # Process tasks
        print(f"\nğŸ”„ Processing {total_tasks} tasks...")
        updated_tasks = []
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            
            for idx, (task, difficulty) in enumerate(zip(tasks, task_difficulties)):
                future = executor.submit(
                    self._update_single_with_difficulty,
                    task.copy(), idx, total_tasks, difficulty
                )
                futures.append((future, idx))
            
            # Collect results in order
            results = [None] * total_tasks
            completed = 0
            
            for future, idx in futures:
                try:
                    result = future.result()
                    results[idx] = result
                    completed += 1
                    
                    # Progress update
                    if completed % 10 == 0 or completed == total_tasks:
                        elapsed = time.time() - start_time
                        rate = completed / elapsed if elapsed > 0 else 0
                        eta = (total_tasks - completed) / rate if rate > 0 else 0
                        print(f"  Progress: {completed}/{total_tasks} ({completed/total_tasks*100:.1f}%) "
                              f"Rate: {rate:.1f} tasks/s, ETA: {eta:.0f}s")
                        
                except Exception as e:
                    print(f"  Error processing task {idx}: {e}")
                    results[idx] = tasks[idx]  # Keep original
        
        # Update task data
        updated_tasks = [t for t in results if t is not None]
        if 'tasks' in task_data:
            task_data['tasks'] = updated_tasks
        else:
            task_data = updated_tasks
        
        # Add metadata
        if isinstance(task_data, dict):
            if 'metadata' not in task_data:
                task_data['metadata'] = {}
            
            task_data['metadata']['difficulty_update'] = {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'distribution': difficulty_distribution,
                'stats': self.enhancement_stats
            }
        
        # Save output
        output_path = output_path or task_library_path
        with open(output_path, 'w') as f:
            json.dump(task_data, f, indent=2)
        
        print(f"\nâœ… Successfully updated {len(updated_tasks)} tasks")
        print(f"ğŸ“„ Saved to: {output_path}")
        
        # Print statistics
        self._print_enhancement_statistics()
        
        # Save fallback information if any
        self._save_fallback_info(output_path)
    
    def _update_single_with_difficulty(self, task: Dict, idx: int, 
                                     total: int, difficulty: DifficultyLevel) -> Dict:
        """Update a single task with specified difficulty"""
        self.enhancement_stats['total'] += 1
        
        try:
            # Rate limiting
            time.sleep(self.rate_limit)
            
            # Save original description
            task['original_description'] = task.get('description', '')
            task['difficulty_level'] = difficulty.value
            
            # Generate new description
            enhanced_desc = self.enhance_with_difficulty(task, difficulty)
            
            # Update task
            task['description'] = enhanced_desc
            task['enhanced'] = True
            task['enhancement_timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S')
            
            self.enhancement_stats['enhanced'] += 1
            
            print(f"  âœ“ Task {idx+1}/{total} updated with {difficulty.value} difficulty")
            
            return task
            
        except Exception as e:
            print(f"  âœ— Task {idx+1}/{total} failed: {e}")
            self.enhancement_stats['failed'] += 1
            return task
    
    def _print_enhancement_statistics(self):
        """Print detailed enhancement statistics"""
        print(f"\nğŸ“Š Enhancement Statistics:")
        print(f"  â€¢ Total processed: {self.enhancement_stats['total']}")
        print(f"  â€¢ Successfully enhanced: {self.enhancement_stats['enhanced']}")
        print(f"  â€¢ Failed: {self.enhancement_stats['failed']}")
        print(f"  â€¢ API errors: {self.enhancement_stats['api_errors']}")
        print(f"  â€¢ Fallbacks used: {self.enhancement_stats['fallbacks']}")
        
        print(f"\nğŸ“Š Difficulty Distribution:")
        dist = self.enhancement_stats['difficulty_distribution']
        total = sum(dist.values())
        if total > 0:
            for level in DifficultyLevel:
                count = dist.get(level.value, 0)
                percentage = (count / total) * 100 if total > 0 else 0
                print(f"  â€¢ {level.value}: {count} ({percentage:.1f}%)")
    
    # ========== Existing methods (kept for compatibility) ==========
    
    def _create_tool_mapping(self) -> Dict[str, str]:
        """Create mapping of tool variations to canonical names"""
        tool_mapping = {}
        base_tools = defaultdict(list)
        
        for tool_name in self.tool_registry.keys():
            # Extract base name and number
            match = re.match(r'^(.+?)_(\d+)$', tool_name)
            if match:
                base_name = match.group(1)
                number = int(match.group(2))
                base_tools[base_name].append((number, tool_name))
            else:
                base_tools[tool_name] = [(0, tool_name)]
        
        for base_name, versions in base_tools.items():
            versions.sort()
            canonical_tool = versions[0][1]
            
            for _, tool_name in versions:
                if tool_name != canonical_tool:
                    tool_mapping[tool_name] = canonical_tool
                    self.enhancement_stats['tool_consolidations'] += 1
        
        return tool_mapping
    
    def _normalize_tool_name(self, tool_name: str) -> str:
        """Get normalized tool name"""
        return self.tool_mapping.get(tool_name, tool_name)
    
    def _analyze_tools(self) -> Dict[str, Dict[str, Any]]:
        """Analyze tools to extract unique features"""
        tool_analysis = {}
        
        for tool_name, tool_info in self.tool_registry.items():
            analysis = {'tool_name': tool_name}
            
            if isinstance(tool_info, dict):
                description = tool_info.get('description', '')
                parameters = tool_info.get('parameters', [])
                returns = tool_info.get('returns', [])
                dependencies = tool_info.get('dependencies', [])
                
                analysis['unique_features'] = self._extract_unique_features(
                    tool_name, description, parameters, returns
                )
                
                analysis['distinguishing_hints'] = self._generate_distinguishing_hints(
                    tool_name, analysis['unique_features'], dependencies
                )
                
                # Extract usage keywords for difficulty adjustment
                analysis['usage_keywords'] = self._extract_usage_keywords(tool_name, description)
            
            tool_analysis[tool_name] = analysis
        
        return tool_analysis
    
    def _extract_unique_features(self, tool_name: str, description: str, 
                                parameters: List, returns: List) -> List[str]:
        """Extract unique features of a tool"""
        features = []
        
        # Extract from tool name
        parts = tool_name.split('_')
        if len(parts) > 2:
            features.append(f"{parts[1]} {parts[2]}")
        
        # Extract from description
        if description:
            key_phrases = re.findall(r'(\w+ \w+ \w+)', description.lower())
            features.extend(key_phrases[:2])
        
        # Extract from parameters
        for param in parameters[:2]:
            if isinstance(param, dict) and 'name' in param:
                features.append(f"uses {param['name']}")
        
        return features[:3]
    
    def _generate_distinguishing_hints(self, tool_name: str, 
                                     features: List[str], 
                                     dependencies: List[str]) -> List[str]:
        """Generate hints that distinguish this tool from others"""
        hints = []
        
        # Hint based on operation type
        if 'validate' in tool_name or 'check' in tool_name:
            hints.append("verification and quality assurance")
        elif 'transform' in tool_name or 'convert' in tool_name:
            hints.append("data transformation and formatting")
        elif 'aggregate' in tool_name or 'combine' in tool_name:
            hints.append("data consolidation and summarization")
        
        # Hint based on dependencies
        if dependencies:
            hints.append(f"requires {len(dependencies)} supporting operations")
        
        # Use features
        if features:
            hints.append(f"specialized in {features[0]}")
        
        return hints[:2]
    
    def _extract_usage_keywords(self, tool_name: str, description: str) -> List[str]:
        """Extract keywords that indicate tool usage"""
        keywords = []
        
        # From tool name
        name_parts = tool_name.lower().split('_')
        keywords.extend([p for p in name_parts if len(p) > 3])
        
        # From description
        if description:
            action_words = re.findall(r'\b(read|write|parse|validate|transform|analyze|compute)\b', 
                                    description.lower())
            keywords.extend(action_words)
        
        return list(set(keywords))[:5]
    
    def _extract_conceptual_requirements(self, task: Dict) -> List[str]:
        """æå–ä»»åŠ¡çš„æ¦‚å¿µæ€§éœ€æ±‚"""
        desc = task.get('description', '').lower()
        concepts = []
        
        # ä»æè¿°ä¸­æå–å…³é”®æ¦‚å¿µ
        important_words = [
            'ensure', 'maintain', 'optimize', 'secure', 'validate',
            'synchronize', 'coordinate', 'integrate', 'transform',
            'aggregate', 'distribute', 'monitor', 'analyze'
        ]
        
        words = desc.split()
        for word in words:
            if word in important_words or len(word) > 6:
                concepts.append(word)
        
        return concepts
    
    def _generate_misleading_requirements(self, task_type: str) -> List[str]:
        """ç”Ÿæˆå…·æœ‰è¯¯å¯¼æ€§çš„ä¸šåŠ¡éœ€æ±‚"""
        misleading_map = {
            'basic_task': [
                "ensure ACID compliance",
                "maintain backward compatibility",
                "support multi-tenancy"
            ],
            'simple_task': [
                "enable real-time synchronization",
                "provide audit trail",
                "ensure idempotency"
            ],
            'data_pipeline': [
                "support CDC mechanisms",
                "enable exactly-once semantics",
                "provide lineage tracking"
            ],
            'api_integration': [
                "implement circuit breaker pattern",
                "enable OAuth2 authentication",
                "maintain SLA guarantees"
            ],
            'multi_stage_pipeline': [
                "support horizontal scaling",
                "enable blue-green deployments",
                "maintain zero-downtime operations",
                "support event sourcing"
            ]
        }
        
        requirements = misleading_map.get(task_type, misleading_map['basic_task'])
        return random.sample(requirements, min(2, len(requirements)))
    
    def _generate_task_templates(self) -> Dict[str, List[Dict]]:
        """Generate task templates for different types"""
        templates = defaultdict(list)
        
        for task_type, config in self.TASK_CATEGORIES.items():
            # Create multiple template patterns
            patterns = [
                {
                    'pattern': 'sequential',
                    'description': f"{config['description']} with sequential execution",
                    'tool_pattern': 'input->process->output'
                },
                {
                    'pattern': 'conditional',
                    'description': f"{config['description']} with conditional branches",
                    'tool_pattern': 'validate->branch->merge'
                }
            ]
            
            if config['tool_count'][1] > 2:
                patterns.append({
                    'pattern': 'parallel',
                    'description': f"{config['description']} with parallel processing",
                    'tool_pattern': 'split->parallel_process->aggregate'
                })
            
            templates[task_type] = patterns
        
        return templates
    
    def _categorize_task(self, task: Dict) -> str:
        """Categorize a task based on its properties"""
        required_tools = task.get('required_tools', [])
        num_tools = len(required_tools)
        
        # Categorize by tool count
        if num_tools <= 1:
            return 'basic_task'
        elif num_tools <= 3:
            # Check for specific patterns
            if any('api' in tool or 'network' in tool for tool in required_tools):
                return 'api_integration'
            elif any('file' in tool or 'data' in tool for tool in required_tools):
                return 'data_pipeline'
            else:
                return 'simple_task'
        elif num_tools <= 5:
            return 'data_pipeline'
        else:
            return 'multi_stage_pipeline'
    
    def _validate_tool_differentiation(self, description: str, 
                                     required_tools: List[str]) -> Dict[str, Any]:
        """Validate if description differentiates tools well"""
        issues = []
        tool_indicators = {}
        
        for tool in required_tools:
            indicators = []
            
            # Check for tool-specific keywords
            if tool in self.tool_analysis:
                keywords = self.tool_analysis[tool].get('usage_keywords', [])
                found_keywords = [kw for kw in keywords if kw in description.lower()]
                
                if found_keywords:
                    indicators.extend(found_keywords)
            
            tool_indicators[tool] = indicators
        
        # Check if each tool has unique indicators
        all_indicators = []
        for tool, indicators in tool_indicators.items():
            if not indicators:
                issues.append(f"{tool} has no clear indicators")
            all_indicators.extend(indicators)
        
        # Check for ambiguity
        if len(set(all_indicators)) < len(required_tools) * 0.7:
            issues.append("Insufficient unique indicators for tools")
        
        return {
            'is_well_differentiated': len(issues) == 0,
            'issues': issues,
            'tool_indicators': tool_indicators
        }
    
    def enhance_tool_differentiation(self) -> Dict[str, Any]:
        """Enhance tool differentiation information using LLM"""
        print("\nğŸ” Enhancing tool differentiation...")
        
        # Group similar tools
        tool_groups = self._group_similar_tools()
        enhanced_differentiations = {}
        
        for group_name, tools in tool_groups.items():
            if len(tools) < 2:
                continue
                
            # Create differentiation prompt
            tools_desc = []
            for tool in tools[:5]:  # Limit to 5 tools per group
                tool_info = self.tool_registry.get(tool, {})
                if isinstance(tool_info, dict):
                    desc = tool_info.get('description', 'No description')
                    tools_desc.append(f"{tool}: {desc}")
            
            prompt = f"""These tools are often confused with each other:
{chr(10).join(tools_desc)}

For EACH tool, provide:
1. **Usage Keywords**: 3-4 words that should trigger this tool
2. **Avoid Keywords**: 2-3 words that should NOT trigger this tool

Format as JSON:
{{
    "tool_name": {{
        "usage_keywords": ["keyword1", "keyword2"],
        "avoid_keywords": ["keyword1", "keyword2"]
    }}
}}"""
            
            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3
                )
                
                diff_data = json.loads(response.choices[0].message.content)
                
                # Update tool analysis
                for tool_name, diff_info in diff_data.items():
                    if tool_name in self.tool_analysis:
                        self.tool_analysis[tool_name].update(diff_info)
                    enhanced_differentiations[tool_name] = diff_info
                    
            except Exception as e:
                print(f"  Error enhancing differentiation for {group_name}: {e}")
        
        return enhanced_differentiations
    
    def _group_similar_tools(self) -> Dict[str, List[str]]:
        """Group tools that might be confused with each other"""
        groups = defaultdict(list)
        
        for tool_name in self.tool_registry.keys():
            # Group by base operation
            if 'validate' in tool_name or 'check' in tool_name:
                groups['validation'].append(tool_name)
            elif 'transform' in tool_name or 'convert' in tool_name:
                groups['transformation'].append(tool_name)
            elif 'read' in tool_name or 'load' in tool_name:
                groups['input'].append(tool_name)
            elif 'write' in tool_name or 'save' in tool_name:
                groups['output'].append(tool_name)
            elif 'aggregate' in tool_name or 'combine' in tool_name:
                groups['aggregation'].append(tool_name)
            else:
                # Group by prefix
                prefix = tool_name.split('_')[0]
                groups[prefix].append(tool_name)
        
        return dict(groups)
    
    # ========== Task Generation Methods (from original) ==========
    
    def _generate_additional_tasks(self, existing_categorized: Dict[str, List], 
                                 count: int) -> List[Dict]:
        """ç”Ÿæˆé¢å¤–çš„ä»»åŠ¡ä»¥å¹³è¡¡åˆ†å¸ƒ"""
        new_tasks = []
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«éœ€è¦çš„é¢å¤–ä»»åŠ¡æ•°
        target_distribution = {
            'basic_task': 0.20,
            'simple_task': 0.25,
            'data_pipeline': 0.20,
            'api_integration': 0.20,
            'multi_stage_pipeline': 0.15
        }
        
        current_total = sum(len(tasks) for tasks in existing_categorized.values())
        target_total = current_total + count
        
        for task_type, target_ratio in target_distribution.items():
            current_count = len(existing_categorized.get(task_type, []))
            target_count = int(target_total * target_ratio)
            needed = max(0, target_count - current_count)
            
            # ç”Ÿæˆè¯¥ç±»åˆ«çš„æ–°ä»»åŠ¡
            for i in range(needed):
                new_task = self._create_new_task(task_type, i)
                new_tasks.append(new_task)
        
        # å¦‚æœè¿˜éœ€è¦æ›´å¤šä»»åŠ¡ï¼Œéšæœºåˆ†é…
        while len(new_tasks) < count:
            task_type = self._weighted_random_choice(target_distribution)
            new_task = self._create_new_task(task_type, len(new_tasks))
            new_tasks.append(new_task)
        
        return new_tasks[:count]
    
    def _create_new_task(self, task_type: str, index: int) -> Dict:
        """åˆ›å»ºæ–°çš„ä»»åŠ¡å®ä¾‹"""
        import uuid
        
        config = self.TASK_CATEGORIES[task_type]
        template = self._select_template(task_type)
        
        # é€‰æ‹©åˆé€‚çš„å·¥å…·
        tool_count = self._random_in_range(config['tool_count'])
        selected_tools = self._select_tools_for_pattern(
            template['tool_pattern'], 
            tool_count
        )
        
        # ç”Ÿæˆä»»åŠ¡æ•°æ®
        task_id = f"task_{uuid.uuid4().hex[:8]}"
        
        return {
            'id': task_id,
            'task_type': task_type,
            'complexity': self._select_complexity(task_type),
            'description': f"{template['description']} - Instance {task_id}",
            'required_tools': selected_tools,
            'test_input': self._generate_test_input(task_type),
            'expected_output': self._generate_expected_output(task_type),
            'metadata': {
                'template': template['pattern'],
                'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                'auto_generated': True
            }
        }
    
    def _select_template(self, task_type: str) -> Dict:
        """é€‰æ‹©åˆé€‚çš„ä»»åŠ¡æ¨¡æ¿"""
        templates = self.template_cache.get(task_type, [])
        if not templates:
            # åˆ›å»ºé»˜è®¤æ¨¡æ¿
            return {
                'pattern': 'sequential',
                'description': f"Execute {task_type}",
                'tool_pattern': 'input->process->output'
            }
        return random.choice(templates)
    
    def _random_in_range(self, range_tuple: Tuple[int, int]) -> int:
        """åœ¨èŒƒå›´å†…éšæœºé€‰æ‹©"""
        return random.randint(range_tuple[0], range_tuple[1])
    
    def _weighted_random_choice(self, weights: Dict[str, float]) -> str:
        """æ ¹æ®æƒé‡éšæœºé€‰æ‹©"""
        choices = list(weights.keys())
        weights_list = list(weights.values())
        return random.choices(choices, weights=weights_list)[0]
    
    def _select_complexity(self, task_type: str) -> str:
        """æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©å¤æ‚åº¦"""
        if task_type == 'basic_task':
            return 'easy'
        elif task_type == 'multi_stage_pipeline':
            return random.choice(['medium', 'hard'])
        else:
            return random.choice(['easy', 'medium', 'hard'])
    
    def _select_tools_for_pattern(self, pattern: str, count: int) -> List[str]:
        """æ ¹æ®æ¨¡å¼é€‰æ‹©åˆé€‚çš„å·¥å…·ç»„åˆ"""
        available_tools = list(set(
            self._normalize_tool_name(tool) 
            for tool in self.tool_registry.keys()
        ))
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©å·¥å…·
        if 'input->process->output' in pattern:
            readers = [t for t in available_tools if any(k in t for k in ['read', 'fetch', 'get'])]
            processors = [t for t in available_tools if any(k in t for k in ['process', 'transform', 'analyze'])]
            writers = [t for t in available_tools if any(k in t for k in ['write', 'save', 'export'])]
            
            selected = []
            if readers and count > 0:
                selected.append(random.choice(readers))
                count -= 1
            if processors and count > 0:
                selected.extend(random.sample(processors, min(count - 1, len(processors))))
                count -= len(selected) - 1
            if writers and count > 0:
                selected.append(random.choice(writers))
            
            return selected[:count]
        else:
            # é»˜è®¤éšæœºé€‰æ‹©
            return random.sample(available_tools, min(count, len(available_tools)))
    
    def _generate_test_input(self, task_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•è¾“å…¥"""
        input_templates = {
            'basic_task': {"data": "sample_input", "format": "json"},
            'simple_task': {"input_file": "data.csv", "config": {"mode": "batch"}},
            'data_pipeline': {"source": "database", "query": "SELECT * FROM table", "batch_size": 100},
            'api_integration': {"endpoint": "https://api.example.com", "method": "GET", "auth": "bearer"},
            'multi_stage_pipeline': {"stages": 5, "data_sources": ["file", "api", "db"], "parallel": True}
        }
        return input_templates.get(task_type, {"input": "generic_data"})
    
    def _generate_expected_output(self, task_type: str) -> Dict[str, Any]:
        """ç”ŸæˆæœŸæœ›è¾“å‡º"""
        output_templates = {
            'basic_task': {"status": "success", "data": "processed"},
            'simple_task': {"result": "completed", "records_processed": 100},
            'data_pipeline': {"pipeline_status": "complete", "stages_completed": 3, "output_location": "/output"},
            'api_integration': {"response_code": 200, "data": {}, "latency_ms": 150},
            'multi_stage_pipeline': {"all_stages_complete": True, "final_output": {}, "performance_metrics": {}}
        }
        return output_templates.get(task_type, {"output": "result"})
    
    def _save_fallback_info(self, output_path: str):
        """ä¿å­˜fallbackä»»åŠ¡ä¿¡æ¯"""
        if self.fallback_tasks:
            fallback_path = output_path.replace('.json', '_fallbacks.json')
            with open(fallback_path, 'w') as f:
                json.dump(self.fallback_tasks, f, indent=2)
            print(f"\nğŸ’¾ Saved {len(self.fallback_tasks)} fallback tasks to: {fallback_path}")
    
    def _update_tool_registry_if_needed(self, update_tool_registry: bool, tool_registry_path: str):
        """å¦‚æœéœ€è¦ï¼Œæ›´æ–°å·¥å…·æ³¨å†Œè¡¨"""
        if update_tool_registry and self.enhancement_stats['tool_consolidations'] > 0:
            # åˆ›å»ºå»é‡çš„å·¥å…·åº“
            consolidated_registry = {}
            for tool_name, tool_info in self.tool_registry.items():
                canonical_name = self._normalize_tool_name(tool_name)
                if canonical_name not in consolidated_registry:
                    consolidated_registry[canonical_name] = tool_info
            
            # ä¿å­˜
            output_path = tool_registry_path.replace('.json', '_consolidated.json')
            with open(output_path, 'w') as f:
                json.dump(consolidated_registry, f, indent=2)
            print(f"\nğŸ”§ Tool Registry Update:")
            print(f"  â€¢ Original tools: {len(self.tool_registry)}")
            print(f"  â€¢ Consolidated tools: {len(consolidated_registry)}")
            print(f"  â€¢ Saved to: {output_path}")
    
    # ========== Complete backward compatibility methods ==========
    
    def enhance_task_library(self, task_library_path: str, output_path: str,
                            sample_size: Optional[int] = None,
                            expand_tasks: bool = True,
                            target_total: int = 500,
                            update_tool_registry: bool = True,
                            challenge_mode: bool = False,
                            enhance_differentiation: bool = False):
        """å¢å¼ºä»»åŠ¡åº“ï¼Œæ”¯æŒæ‰©å±•ä»»åŠ¡æ•°é‡å’Œæ›´æ–°å·¥å…·åº“ï¼ˆå®Œæ•´å®ç°ï¼‰"""
        
        print("\n" + "="*60)
        print("ğŸš€ Task Enhancement Process Starting")
        print("="*60)
        
        # åŠ è½½ç°æœ‰ä»»åŠ¡
        print("\nğŸ“ Loading task library...")
        with open(task_library_path, 'r') as f:
            data = json.load(f)
        
        tasks = data if isinstance(data, list) else data.get('tasks', [])
        
        if sample_size:
            tasks = tasks[:sample_size]
        
        print(f"âœ… Loaded {len(tasks)} tasks from library")
        
        # å¢å¼ºå·¥å…·åŒºåˆ†åº¦
        if enhance_differentiation:
            print("\nğŸ” Enhancing tool differentiation...")
            self.enhance_tool_differentiation()
        
        # æ­¥éª¤1ï¼šè§„èŒƒåŒ–å’Œåˆ†ç±»ç°æœ‰ä»»åŠ¡
        print("\nğŸ·ï¸  Categorizing tasks...")
        categorized_tasks = defaultdict(list)
        for task in tasks:
            # è§„èŒƒåŒ–å·¥å…·åç§°
            original_tools = task.get('required_tools', [])
            normalized_tools = [self._normalize_tool_name(tool) for tool in original_tools]
            task['required_tools'] = normalized_tools
            
            # åˆ†ç±»ä»»åŠ¡
            category = self._categorize_task(task)
            task['task_type'] = category
            categorized_tasks[category].append(task)
        
        print("\nğŸ“Š Task distribution after categorization:")
        for cat, cat_tasks in sorted(categorized_tasks.items()):
            print(f"  â€¢ {cat}: {len(cat_tasks)} tasks")
        
        # æ­¥éª¤2ï¼šæ›´æ–°ç°æœ‰ä»»åŠ¡çš„æè¿°
        difficulty_distribution = {
            "very_easy": 0.05 if challenge_mode else 0.15,
            "easy": 0.15 if challenge_mode else 0.35,
            "medium": 0.30,
            "hard": 0.35 if challenge_mode else 0.10,
            "very_hard": 0.15 if challenge_mode else 0.05
        }
        
        print("\nâœ¨ Enhancing task descriptions...")
        self.update_descriptions_with_difficulty(
            task_library_path,
            output_path if not expand_tasks else output_path + '.tmp',
            difficulty_distribution
        )
        
        # æ­¥éª¤3ï¼šå¦‚æœéœ€è¦ï¼Œç”Ÿæˆé¢å¤–çš„ä»»åŠ¡
        if expand_tasks and len(tasks) < target_total:
            print(f"\nğŸ”§ Expanding task library from {len(tasks)} to {target_total} tasks...")
            
            # é‡æ–°åŠ è½½æ›´æ–°åçš„ä»»åŠ¡
            tmp_path = output_path + '.tmp' if expand_tasks else output_path
            with open(tmp_path, 'r') as f:
                updated_data = json.load(f)
            
            enhanced_tasks = updated_data.get('tasks', updated_data)
            
            # ç”Ÿæˆæ–°ä»»åŠ¡
            additional_needed = target_total - len(enhanced_tasks)
            new_tasks = self._generate_additional_tasks(categorized_tasks, additional_needed)
            
            # å¢å¼ºæ–°ä»»åŠ¡çš„æè¿°
            print(f"âœ¨ Enhancing {len(new_tasks)} new tasks...")
            for i, task in enumerate(new_tasks):
                if i % 10 == 0:
                    print(f"  Progress: {i}/{len(new_tasks)}")
                
                # åˆ†é…éš¾åº¦
                difficulty = random.choices(
                    list(DifficultyLevel),
                    weights=[difficulty_distribution.get(d.value, 0.2) for d in DifficultyLevel]
                )[0]
                
                # å¢å¼ºæè¿°
                task['description'] = self.enhance_with_difficulty(task, difficulty)
                task['difficulty_level'] = difficulty.value
                task['enhanced'] = True
                task['enhancement_timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S')
            
            # åˆå¹¶ä»»åŠ¡
            all_tasks = enhanced_tasks + new_tasks
            
            # ä¿å­˜æœ€ç»ˆç»“æœ
            final_data = {
                'tasks': all_tasks,
                'metadata': updated_data.get('metadata', {})
            }
            final_data['metadata'].update({
                'total_tasks': len(all_tasks),
                'enhanced_count': len(enhanced_tasks),
                'generated_count': len(new_tasks),
                'task_distribution': dict(categorized_tasks),
                'generation_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            })
            
            with open(output_path, 'w') as f:
                json.dump(final_data, f, indent=2)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        
        # æ­¥éª¤4ï¼šæ›´æ–°å·¥å…·æ³¨å†Œè¡¨
        self._update_tool_registry_if_needed(update_tool_registry, tool_registry_path)
        
        # æ­¥éª¤5ï¼šä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        self._print_enhancement_statistics()
        self._save_fallback_info(output_path)
        
        print(f"\nâœ… Task enhancement complete!")
        print(f"ğŸ“„ Enhanced task library saved to: {output_path}")
    
    def update_descriptions_only(self, task_library_path: str, output_path: str = None,
                               challenge_mode: bool = False,
                               enhance_differentiation: bool = False):
        """ä»…æ›´æ–°ç°æœ‰ä»»åŠ¡åº“ä¸­çš„æè¿°ï¼Œä¿ç•™å…¶ä»–æ‰€æœ‰å†…å®¹"""
        
        # åˆ›å»ºå¤‡ä»½
        if output_path is None:
            output_path = task_library_path
            backup_path = task_library_path.replace('.json', '_backup.json')
            import shutil
            shutil.copy2(task_library_path, backup_path)
            print(f"  Backup created: {backup_path}")
        
        # è®¾ç½®éš¾åº¦åˆ†å¸ƒ
        distribution = {
            "very_easy": 0.05 if challenge_mode else 0.20,
            "easy": 0.15 if challenge_mode else 0.35,
            "medium": 0.30,
            "hard": 0.35 if challenge_mode else 0.10,
            "very_hard": 0.15 if challenge_mode else 0.05
        }
        
        if enhance_differentiation:
            self.enhance_tool_differentiation()
        
        self.update_descriptions_with_difficulty(
            task_library_path, output_path, distribution
        )


def main():
    """Main entry point with enhanced CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Enhanced Task Description Generator with Multiple Difficulty Levels'
    )
    parser.add_argument('--api-key', help='OpenAI API key')
    parser.add_argument('--tool-registry', default='mcp_generated_library/tool_registry.json')
    parser.add_argument('--task-library', default='mcp_generated_library/task_library.json')
    parser.add_argument('--output', default='mcp_generated_library/task_library_enhanced.json')
    parser.add_argument('--sample', type=int, help='Sample size for testing')
    parser.add_argument('--expand', action='store_true', help='Expand task library to target size')
    parser.add_argument('--target-total', type=int, default=500, help='Target total number of tasks')
    parser.add_argument('--workers', type=int, default=10, help='Number of parallel workers')
    parser.add_argument('--rate-limit', type=float, default=0.5, help='Rate limit between requests')
    parser.add_argument('--update-tools', action='store_true', default=True, 
                       help='Update tool registry with consolidations')
    parser.add_argument('--no-update-tools', dest='update_tools', action='store_false',
                       help='Do not update tool registry')
    parser.add_argument('--verbose', action='store_true', help='Show detailed debug information')
    
    # Difficulty options
    difficulty_group = parser.add_argument_group('difficulty options')
    difficulty_group.add_argument('--difficulty-mode', choices=['single', 'distribution', 'custom'],
                                default='distribution', help='Difficulty generation mode')
    difficulty_group.add_argument('--difficulty-level', 
                                choices=['very_easy', 'easy', 'medium', 'hard', 'very_hard'],
                                default='medium', help='Single difficulty level (for single mode)')
    difficulty_group.add_argument('--difficulty-distribution', type=str,
                                help='Custom distribution as JSON, e.g., \'{"easy":0.3,"medium":0.5,"hard":0.2}\'')
    
    # Legacy compatibility
    parser.add_argument('--challenge', action='store_true', 
                       help='Enable challenge mode (legacy - sets hard distribution)')
    parser.add_argument('--difficulty-report', action='store_true',
                       help='Generate difficulty analysis report')
    parser.add_argument('--update-descriptions-only', action='store_true',
                       help='Only update descriptions in existing task library')
    parser.add_argument('--input-enhanced', type=str,
                       help='Path to existing enhanced task library')
    parser.add_argument('--enhance-differentiation', action='store_true',
                       help='Enhance tool differentiation using LLM')
    parser.add_argument('--differentiation-only', action='store_true',
                       help='Only enhance tool differentiation')
    
    args = parser.parse_args()
    
    # Setup logging
    if args.verbose:
        import logging
        logging.basicConfig(level=logging.DEBUG, 
                          format='%(asctime)s - %(levelname)s - %(message)s')
    
    # Get API key
    api_key = args.api_key or os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ Error: OpenAI API key required!")
        print("  Set via --api-key or OPENAI_API_KEY environment variable")
        return 1
    
    # Create enhancer
    enhancer = TaskEnhancer(
        api_key=api_key,
        tool_registry_path=args.tool_registry,
        max_workers=args.workers,
        rate_limit=args.rate_limit
    )
    
    # Handle differentiation-only mode
    if args.differentiation_only:
        print("\nğŸ” Running tool differentiation enhancement only...")
        enhanced = enhancer.enhance_tool_differentiation()
        
        output_path = args.output.replace('.json', '_differentiations.json')
        with open(output_path, 'w') as f:
            json.dump(enhanced, f, indent=2)
        
        print(f"âœ… Enhanced differentiations for {len(enhanced)} tools")
        print(f"ğŸ“„ Saved to: {output_path}")
        return 0
    
    # Determine difficulty distribution
    if args.difficulty_mode == 'single':
        # Single difficulty level for all tasks
        distribution = {level: 0.0 for level in ['very_easy', 'easy', 'medium', 'hard', 'very_hard']}
        distribution[args.difficulty_level] = 1.0
        
    elif args.difficulty_mode == 'custom' and args.difficulty_distribution:
        # Custom distribution from JSON
        try:
            distribution = json.loads(args.difficulty_distribution)
        except json.JSONDecodeError as e:
            print(f"âŒ Error parsing difficulty distribution: {e}")
            return 1
            
    elif args.challenge:
        # Legacy challenge mode
        distribution = {
            "very_easy": 0.05,
            "easy": 0.15,
            "medium": 0.30,
            "hard": 0.35,
            "very_hard": 0.15
        }
    else:
        # Default balanced distribution
        distribution = {
            "very_easy": 0.10,
            "easy": 0.25,
            "medium": 0.30,
            "hard": 0.25,
            "very_hard": 0.10
        }
    
    # Enhance differentiation if requested
    if args.enhance_differentiation:
        enhancer.enhance_tool_differentiation()
    
    # Determine input file
    if args.update_descriptions_only:
        input_file = args.input_enhanced or args.task_library
    else:
        input_file = args.task_library
    
    # Run enhancement
    print("\nğŸš€ Starting task enhancement process...")
    print(f"  Mode: {args.difficulty_mode}")
    print(f"  Distribution: {distribution}")
    
    enhancer.update_descriptions_with_difficulty(
        task_library_path=input_file,
        output_path=args.output,
        difficulty_distribution=distribution
    )
    
    # Generate report if requested
    if args.difficulty_report:
        report_path = args.output.replace('.json', '_difficulty_report.json')
        report = {
            'configuration': {
                'mode': args.difficulty_mode,
                'distribution': distribution,
                'enhanced_differentiation': args.enhance_differentiation
            },
            'statistics': enhancer.enhancement_stats,
            'fallback_tasks': enhancer.fallback_tasks
        }
        
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nğŸ“Š Difficulty report saved to: {report_path}")
    
    print("\nâœ… Task enhancement complete!")
    return 0


if __name__ == "__main__":
    exit(main())