#!/bin/bash

# å¤±è´¥æµ‹è¯•ç®¡ç†å™¨ - è¯»å–å’Œå¤„ç†å¤±è´¥æµ‹è¯•é…ç½®

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# è·å–å¤±è´¥æµ‹è¯•é…ç½®æ–‡ä»¶åï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹ï¼‰
get_failed_tests_config_file() {
    if [ "$MODEL_TYPE" = "closed_source" ]; then
        echo "failed_tests_config_closed_source.json"
    else
        echo "failed_tests_config_opensource.json"
    fi
}

# æ£€æŸ¥å¤±è´¥æµ‹è¯•é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
check_failed_tests_config() {
    local config_file=$(get_failed_tests_config_file)
    if [ ! -f "$config_file" ]; then
        return 1
    fi
    return 0
}

# æ˜¾ç¤ºå¤±è´¥æµ‹è¯•æ¦‚è¦
show_failed_tests_summary() {
    if ! check_failed_tests_config; then
        echo -e "${YELLOW}ğŸ“ æ²¡æœ‰å‘ç°å¤±è´¥æµ‹è¯•è®°å½•${NC}"
        return 1
    fi
    
    echo -e "${CYAN}========================================${NC}"
    echo -e "${CYAN}ğŸ“‹ å¤±è´¥æµ‹è¯•ä¼šè¯æ¦‚è¦${NC}"
    echo -e "${CYAN}========================================${NC}"
    
    # ä½¿ç”¨pythonè§£æJSONé…ç½®
    local config_file=$(get_failed_tests_config_file)
    python3 -c "
import json
import sys

try:
    import sys
    config_file = sys.argv[1] if len(sys.argv) > 1 else 'failed_tests_config.json'
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    session = config['failed_tests_session']
    print(f\"ğŸ“… ä¼šè¯æ—¥æœŸ: {session['session_date']}\")
    print(f\"ğŸ“„ æè¿°: {session['session_description']}\")
    print(f\"âŒ å¤±è´¥æ¨¡å‹æ•°: {session['total_failed_models']}\")
    
    print('\nå¤±è´¥çš„æ¨¡å‹å’Œæµ‹è¯•ç»„:')
    for i, model_data in enumerate(session['failed_groups'], 1):
        model = model_data['model']
        status = model_data['status']
        failed_count = len(model_data['failed_groups'])
        remaining_count = len(model_data['remaining_groups'])
        
        print(f'  {i}. {model} ({status})')
        print(f'     âŒ å¤±è´¥ç»„æ•°: {failed_count}')
        print(f'     â³ å‰©ä½™ç»„æ•°: {remaining_count}')
    
    cleanup = session['cleanup_status']
    if cleanup['database_cleaned']:
        print(f\"\nâœ… æ•°æ®åº“å·²æ¸…ç† (åˆ é™¤äº† {len(cleanup['deleted_models'])} ä¸ªåˆ†ç‰‡æ¨¡å‹)\")
    
except Exception as e:
    print(f'âŒ è§£æé…ç½®æ–‡ä»¶å¤±è´¥: {e}', file=sys.stderr)
    sys.exit(1)
" "$config_file"
    
    return 0
}

# æ˜¾ç¤ºè¯¦ç»†çš„å¤±è´¥æµ‹è¯•åˆ—è¡¨
show_failed_tests_details() {
    if ! check_failed_tests_config; then
        echo -e "${RED}âŒ æ²¡æœ‰æ‰¾åˆ°å¤±è´¥æµ‹è¯•é…ç½®æ–‡ä»¶${NC}"
        return 1
    fi
    
    echo -e "${PURPLE}========================================${NC}"
    echo -e "${PURPLE}ğŸ” å¤±è´¥æµ‹è¯•è¯¦ç»†ä¿¡æ¯${NC}"  
    echo -e "${PURPLE}========================================${NC}"
    
    local config_file=$(get_failed_tests_config_file)
    python3 -c "
import json
import sys

config_file = sys.argv[1] if len(sys.argv) > 1 else 'failed_tests_config.json'
with open(config_file, 'r', encoding='utf-8') as f:
    config = json.load(f)

session = config['failed_tests_session']
params = session['test_parameters']

print(f\"æµ‹è¯•å‚æ•°: éš¾åº¦={params['difficulty']}, ä»»åŠ¡ç±»å‹={params['task_types']}, å®ä¾‹æ•°={params['num_instances']}\")
print()

for i, model_data in enumerate(session['failed_groups'], 1):
    model = model_data['model']
    print(f'{i}. ğŸ”´ {model}')
    
    print('   å¤±è´¥çš„æµ‹è¯•ç»„:')
    for failed in model_data['failed_groups']:
        print(f'     âŒ {failed[\"group_name\"]}')
        print(f'        Promptç±»å‹: {failed[\"prompt_types\"]}')
        print(f'        å¤±è´¥åŸå› : {failed[\"reason\"]}')
    
    print('   éœ€è¦é‡æµ‹çš„æµ‹è¯•ç»„:')
    for remaining in model_data['remaining_groups']:
        print(f'     â³ {remaining[\"group_name\"]}')
        print(f'        Promptç±»å‹: {remaining[\"prompt_types\"]}')
    print()
" "$config_file"
    
    return 0
}

# ç”Ÿæˆé‡æµ‹å‘½ä»¤åˆ—è¡¨
generate_retest_commands() {
    if ! check_failed_tests_config; then
        echo -e "${RED}âŒ æ²¡æœ‰æ‰¾åˆ°å¤±è´¥æµ‹è¯•é…ç½®æ–‡ä»¶${NC}"
        return 1
    fi
    
    echo -e "${GREEN}========================================${NC}"
    echo -e "${GREEN}ğŸ”„ ç”Ÿæˆé‡æµ‹å‘½ä»¤${NC}"
    echo -e "${GREEN}========================================${NC}"
    
    local config_file=$(get_failed_tests_config_file)
    python3 -c "
import json
import sys

config_file = sys.argv[1] if len(sys.argv) > 1 else 'failed_tests_config.json'
with open(config_file, 'r', encoding='utf-8') as f:
    config = json.load(f)

session = config['failed_tests_session']
params = session['test_parameters']

print('# é‡æ–°æµ‹è¯•å¤±è´¥çš„æµ‹è¯•ç»„å‘½ä»¤')
print('# ç”Ÿæˆæ—¶é—´: $(date)')
print()

for model_data in session['failed_groups']:
    model = model_data['model']
    print(f'# === {model} ===')
    
    # é‡æµ‹å¤±è´¥çš„ç»„
    for failed in model_data['failed_groups']:
        prompt_types = failed['prompt_types']
        group_name = failed['group_name']
        print(f'# é‡æµ‹ {group_name} (ä¹‹å‰å¤±è´¥)')
        print(f'run_smart_test \"{model}\" \"{prompt_types}\" \"{params[\"difficulty\"]}\" \"{params[\"task_types\"]}\" \"{params[\"num_instances\"]}\" \"{model}-{group_name}\" \"\"')
        print()
    
    # å®Œæˆå‰©ä½™çš„ç»„
    for remaining in model_data['remaining_groups']:
        prompt_types = remaining['prompt_types']
        group_name = remaining['group_name']
        print(f'# å®Œæˆ {group_name} (æœªå®Œæˆ)')
        print(f'run_smart_test \"{model}\" \"{prompt_types}\" \"{params[\"difficulty\"]}\" \"{params[\"task_types\"]}\" \"{params[\"num_instances\"]}\" \"{model}-{group_name}\" \"\"')
        print()
    
    print()
" "$config_file"
}

# æ£€æŸ¥æŸä¸ªæ¨¡å‹æ˜¯å¦åœ¨å¤±è´¥åˆ—è¡¨ä¸­
is_model_in_failed_list() {
    local model_name="$1"
    
    if ! check_failed_tests_config; then
        return 1
    fi
    
    local config_file=$(get_failed_tests_config_file)
    python3 -c "
import json
import sys

config_file = sys.argv[1] if len(sys.argv) > 1 else 'failed_tests_config.json'
with open(config_file, 'r', encoding='utf-8') as f:
    config = json.load(f)

failed_models = [model_data['model'] for model_data in config['failed_tests_session']['failed_groups']]
sys.exit(0 if '$model_name' in failed_models else 1)
" "$config_file"
    
    return $?
}

# è·å–æŸä¸ªæ¨¡å‹çš„å¤±è´¥æµ‹è¯•ä¿¡æ¯
get_model_failed_info() {
    local model_name="$1"
    
    if ! check_failed_tests_config; then
        return 1
    fi
    
    local config_file=$(get_failed_tests_config_file)
    python3 -c "
import json
import sys

config_file = sys.argv[1] if len(sys.argv) > 1 else 'failed_tests_config.json'
with open(config_file, 'r', encoding='utf-8') as f:
    config = json.load(f)

for model_data in config['failed_tests_session']['failed_groups']:
    if model_data['model'] == '$model_name':
        print('FAILED_GROUPS:')
        for failed in model_data['failed_groups']:
            print(f'{failed[\"group_name\"]}:{failed[\"prompt_types\"]}')
        
        print('REMAINING_GROUPS:')
        for remaining in model_data['remaining_groups']:
            print(f'{remaining[\"group_name\"]}:{remaining[\"prompt_types\"]}')
        
        break
" "$config_file"
}

# æ ‡è®°å¤±è´¥æµ‹è¯•ä¸ºå·²å®Œæˆ
mark_failed_test_completed() {
    local model_name="$1"
    local group_name="$2"
    
    # è¿™é‡Œå¯ä»¥å®ç°æ›´æ–°é…ç½®æ–‡ä»¶çš„é€»è¾‘
    # æš‚æ—¶åªæ˜¯æ˜¾ç¤ºæ¶ˆæ¯
    echo -e "${GREEN}âœ… æ ‡è®° ${model_name} çš„ ${group_name} ä¸ºå·²å®Œæˆ${NC}"
}

# ä¸»è¦å¯¼å‡ºçš„å‡½æ•°
export -f check_failed_tests_config
export -f show_failed_tests_summary
export -f show_failed_tests_details
export -f generate_retest_commands
export -f is_model_in_failed_list
export -f get_model_failed_info
export -f mark_failed_test_completed