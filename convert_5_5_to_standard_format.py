#!/usr/bin/env python3
"""
å°†5.5æç¤ºæ•æ„Ÿæ€§æµ‹è¯•ç»“æœè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
åŸºäºconvert_5_4_to_standard_format.pyä¿®æ”¹
"""

import pandas as pd
from datetime import datetime

def convert_5_5_to_standard():
    """è½¬æ¢5.5æ•°æ®åˆ°æ ‡å‡†æ ¼å¼"""
    print("ğŸ”„ è½¬æ¢5.5æç¤ºæ•æ„Ÿæ€§æµ‹è¯•æ•°æ®åˆ°æ ‡å‡†æ ¼å¼...")
    
    # è¯»å–åŸå§‹æ•°æ®
    df = pd.read_csv('5_5_prompt_sensitivity_results.csv')
    
    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    standard_data = []
    
    for _, row in df.iterrows():
        # è®¡ç®—å®Œå…¨æˆåŠŸæ•°å’Œéƒ¨åˆ†æˆåŠŸæ•°
        full_success = max(0, row['successful'] - row['partial'])
        
        record = {
            'experiment': '5.5',
            'experiment_name': 'æç¤ºæ•æ„Ÿæ€§æµ‹è¯•',
            'model': row['model'],
            'prompt_type': row['prompt_type'],
            'tool_success_rate': row['tool_success_rate'],
            'difficulty': row['difficulty'],
            'total_tests': row['total_tests'],
            'effective_total': row['effective_total'],
            'full_success': full_success,
            'partial_success': row['partial'],
            'total_success': row['successful'],
            'failed': row['failed'],
            'timeout_failures': row['timeout_failures'],
            'full_success_rate': full_success / row['effective_total'] if row['effective_total'] > 0 else 0,
            'partial_success_rate': row['partial'] / row['effective_total'] if row['effective_total'] > 0 else 0,
            'total_success_rate': row['successful'] / row['effective_total'] if row['effective_total'] > 0 else 0,
            'failure_rate': (row['failed'] - row['timeout_failures']) / row['effective_total'] if row['effective_total'] > 0 else 0,
            'avg_execution_time': row['avg_execution_time'],
            'timeout_errors': row['timeout_errors'],
            'tool_selection_errors': row['tool_selection_errors'],
            'parameter_errors': row['parameter_errors'],
            'execution_errors': row['execution_errors'],
            'other_errors': row['other_errors'],
            'test_date': '2025-08-31',
            'notes': f"æç¤ºç±»å‹: {row['prompt_type']}"
        }
        
        standard_data.append(record)
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜
    standard_df = pd.DataFrame(standard_data)
    
    # ä¿å­˜æ ‡å‡†æ ¼å¼CSV
    output_file = '5_5_prompt_sensitivity_standard_format.csv'
    standard_df.to_csv(output_file, index=False)
    
    print(f"âœ… æ ‡å‡†æ ¼å¼æ•°æ®å·²ä¿å­˜: {output_file}")
    print(f"ğŸ“Š è½¬æ¢äº† {len(standard_df)} æ¡è®°å½•")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"  å®éªŒ: 5.5 æç¤ºæ•æ„Ÿæ€§æµ‹è¯•")
    print(f"  æ¨¡å‹æ•°: {len(standard_df['model'].unique())}")
    print(f"  æç¤ºç±»å‹: {list(standard_df['prompt_type'].unique())}")
    print(f"  æ€»æµ‹è¯•æ•°: {standard_df['total_tests'].sum()}")
    print(f"  æœ‰æ•ˆæµ‹è¯•æ•°: {standard_df['effective_total'].sum()}")
    print(f"  å¹³å‡æˆåŠŸç‡: {standard_df['total_success_rate'].mean()*100:.1f}%")
    
    return output_file

def main():
    """ä¸»å‡½æ•°"""
    try:
        convert_5_5_to_standard()
        print("\nğŸ‰ 5.5æ•°æ®æ ‡å‡†åŒ–è½¬æ¢å®Œæˆï¼")
    except Exception as e:
        print(f"âŒè½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")
        raise

if __name__ == "__main__":
    main()