{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b67e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 17:40:16,822 - mcp_embedding_manager - INFO - Loaded search cache with 3 entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MCPEmbeddingManager] Initializing with unified API client manager\n",
      "[MCPEmbeddingManager] Using embedding model: text-embedding-3-large\n",
      "[MCPEmbeddingManager] Client initialized successfully\n",
      "[OperationEmbeddingIndex] Initializing with unified API client manager\n",
      "[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini\n",
      "[OperationEmbeddingIndex] Using embedding model: text-embedding-3-large\n",
      "[OperationEmbeddingIndex] Detecting actual embedding dimension...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 17:40:17,110 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:17,201 - mcp_embedding_manager - INFO - Initialized operation mappings with 142 terms\n",
      "2025-07-11 17:40:17,278 - mcp_embedding_manager - INFO - Building tool embedding index...\n",
      "2025-07-11 17:40:17,280 - mcp_embedding_manager - INFO - Creating embeddings for 30 tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OperationEmbeddingIndex] Detected embedding dimension: 3072\n",
      "[INFO] Loaded 6050 embeddings from persistent cache\n",
      "[OperationEmbeddingIndex] Initialized with 6050 cached embeddings\n",
      "[INFO] Loaded 14 LLM-enhanced operation definitions from cache\n",
      "[INFO] Found cached operation index at .mcp_operation_cache/operation_index.pkl\n",
      "[INFO] Loading operation index from .mcp_operation_cache/operation_index.pkl\n",
      "[INFO] Successfully loaded FAISS index with dimension 3072\n",
      "[INFO] Operation index loaded successfully from .mcp_operation_cache/operation_index.pkl\n",
      "[INFO] Loaded 14 operations with dimension 3072\n",
      "[INFO] Successfully loaded cached index\n",
      "[Cache] Loaded 4010 entries from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]2025-07-11 17:40:17,393 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:17,480 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:17,615 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:17,704 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 1/30 [00:00<00:12,  2.38it/s]2025-07-11 17:40:17,784 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:17,871 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:17,952 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "  7%|▋         | 2/30 [00:00<00:08,  3.13it/s]2025-07-11 17:40:18,028 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,132 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,206 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,274 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 3/30 [00:00<00:08,  3.12it/s]2025-07-11 17:40:18,402 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,475 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,572 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,651 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 13%|█▎        | 4/30 [00:01<00:08,  2.92it/s]2025-07-11 17:40:18,729 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,832 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:18,905 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 17%|█▋        | 5/30 [00:01<00:07,  3.22it/s]2025-07-11 17:40:18,975 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,060 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,189 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 6/30 [00:01<00:07,  3.31it/s]2025-07-11 17:40:19,270 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,349 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,430 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,535 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 7/30 [00:02<00:07,  3.16it/s]2025-07-11 17:40:19,610 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,724 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,813 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:19,917 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 27%|██▋       | 8/30 [00:02<00:07,  2.97it/s]2025-07-11 17:40:19,979 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,059 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,135 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,226 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 9/30 [00:02<00:06,  3.05it/s]2025-07-11 17:40:20,290 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,373 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,460 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,550 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 10/30 [00:03<00:06,  3.06it/s]2025-07-11 17:40:20,628 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,720 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,797 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s]2025-07-11 17:40:20,856 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:20,970 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,073 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 12/30 [00:03<00:05,  3.40it/s]2025-07-11 17:40:21,230 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,328 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,445 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 43%|████▎     | 13/30 [00:04<00:05,  3.14it/s]2025-07-11 17:40:21,510 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,624 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,716 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s]2025-07-11 17:40:21,811 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,891 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:21,952 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,014 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 15/30 [00:04<00:04,  3.31it/s]2025-07-11 17:40:22,123 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,275 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,388 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,478 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 16/30 [00:05<00:04,  2.85it/s]2025-07-11 17:40:22,599 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,683 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,782 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:22,869 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 57%|█████▋    | 17/30 [00:05<00:04,  2.76it/s]2025-07-11 17:40:22,968 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,046 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,146 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 18/30 [00:05<00:04,  2.97it/s]2025-07-11 17:40:23,210 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,372 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,456 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 63%|██████▎   | 19/30 [00:06<00:03,  3.04it/s]2025-07-11 17:40:23,627 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,704 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,775 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 20/30 [00:06<00:03,  3.07it/s]2025-07-11 17:40:23,857 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:23,936 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,011 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 21/30 [00:06<00:02,  3.34it/s]2025-07-11 17:40:24,102 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,204 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,309 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 73%|███████▎  | 22/30 [00:07<00:02,  3.35it/s]2025-07-11 17:40:24,391 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,482 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,584 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 77%|███████▋  | 23/30 [00:07<00:02,  3.43it/s]2025-07-11 17:40:24,675 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,771 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:24,884 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 24/30 [00:07<00:01,  3.40it/s]2025-07-11 17:40:24,966 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,041 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,122 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 83%|████████▎ | 25/30 [00:07<00:01,  3.61it/s]2025-07-11 17:40:25,213 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,291 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,416 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 87%|████████▋ | 26/30 [00:08<00:01,  3.54it/s]2025-07-11 17:40:25,491 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,599 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,694 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 27/30 [00:08<00:00,  3.56it/s]2025-07-11 17:40:25,780 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,852 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:25,941 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 93%|█████████▎| 28/30 [00:08<00:00,  3.69it/s]2025-07-11 17:40:26,006 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:26,096 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:26,216 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 29/30 [00:08<00:00,  3.68it/s]2025-07-11 17:40:26,292 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:26,356 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 17:40:26,438 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2025-07-11 17:40:26,542 - mcp_embedding_manager - INFO - Search cache saved with 4010 entries\n",
      "2025-07-11 17:40:26,570 - mcp_embedding_manager - INFO - Index saved to .mcp_embedding_cache/tool_index.pkl\n",
      "2025-07-11 17:40:26,574 - mcp_embedding_manager - INFO - Index built: {'status': 'built', 'tools': 30, 'categories': 6, 'index_type': 'faiss', 'embedding_dimension': 3072}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MCPEmbeddingManager] Expected dimension: 3072\n",
      "[MCPEmbeddingManager] Actual embedding dimension: 3072\n",
      "[INFO] Saved 4010 search cache entries\n",
      "📊 Cache Statistics:\n",
      "  - Embedding cache: 100 entries (2.35 MB)\n",
      "  - Search cache: 4010 entries\n",
      "  - Total size: 6.02 MB\n",
      "🗑️ Clearing cache (keep_embeddings=True)...\n",
      "  - Cleared search cache\n",
      "  - Kept 100 embeddings\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 1. 基础重建（保留所有embedding缓存）\n",
    "from mcp_embedding_manager import MCPEmbeddingManager\n",
    "from collections import OrderedDict\n",
    "\n",
    "manager = MCPEmbeddingManager()\n",
    "manager.build_index(\n",
    "    tool_registry_path=\"mcp_generated_library/tool_registry_consolidated.json\",\n",
    "    force_rebuild=True\n",
    ")\n",
    "\n",
    "# 2. 查看缓存统计\n",
    "stats = manager.get_cache_stats()\n",
    "print(f\"📊 Cache Statistics:\")\n",
    "print(f\"  - Embedding cache: {stats['embedding_cache']['entries']} entries ({stats['embedding_cache']['size_mb']:.2f} MB)\")\n",
    "print(f\"  - Search cache: {stats['search_cache']['entries']} entries\")\n",
    "print(f\"  - Total size: {stats['total_size_mb']:.2f} MB\")\n",
    "\n",
    "# 3. 清理搜索缓存但保留embedding\n",
    "manager.clear_cache(keep_embeddings=True)\n",
    "\n",
    "# 4. 完全清理（仅在必要时）\n",
    "# manager.clear_cache(keep_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf320eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint目录: checkpoints\n",
      "目录是否存在: True\n",
      "\n",
      "找到 6 个checkpoint文件:\n",
      "  - best_model.pt\n",
      "  - checkpoint_episode_0.pt\n",
      "  - checkpoint_episode_100.pt\n",
      "  - final_cpu_optimized.pt\n",
      "  - final_gpu_model.pt\n",
      "  - final_model.pt\n",
      "\n",
      "分析checkpoint: best_model.pt\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199909/167464570.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(target_checkpoint, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 基本信息:\n",
      "  ⚠️ 没有metadata信息\n",
      "\n",
      "📈 训练历史:\n",
      "  总Episodes: 200\n",
      "  最后10个episode成功率: 0.00%\n",
      "  最高成功率: 0.00%\n",
      "  成功的episodes数: 0.0\n",
      "\n",
      "  最后20个episode成功情况:\n",
      "  ✗✗✗✗✗✗✗✗✗✗✗✗✗✗✗✗✗✗✗✗\n",
      "\n",
      "  平均奖励: -286.05\n",
      "  最后10个episode平均奖励: -315.50\n",
      "  最高奖励: -60.00\n",
      "\n",
      "⚙️ 训练配置:\n",
      "  算法: ppo\n",
      "  学习率: 0.0005\n",
      "  批大小: 1024\n",
      "  最大episode长度: 100\n",
      "  课程学习: True\n",
      "\n",
      "📦 其他信息:\n",
      "  Checkpoint包含的所有键: ['algorithm', 'state_dim', 'action_dim', 'episode', 'config', 'timestamp', 'use_task_aware_state', 'enforce_workflow', 'use_phase2_scoring', 'cpu_optimized', 'network_state_dict', 'model_state_dict', 'optimizer_state_dict', 'training_steps', 'training_history', 'best_success_rate']\n",
      "\n",
      "🔍 可能的问题诊断:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# 设置checkpoint路径\n",
    "checkpoint_dir = Path(\"checkpoints\")  # 根据你的实际路径修改\n",
    "print(f\"Checkpoint目录: {checkpoint_dir}\")\n",
    "print(f\"目录是否存在: {checkpoint_dir.exists()}\")\n",
    "\n",
    "# 列出所有checkpoint文件\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob(\"*.pt\"))\n",
    "    print(f\"\\n找到 {len(checkpoints)} 个checkpoint文件:\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        print(f\"  - {ckpt.name}\")\n",
    "else:\n",
    "    print(\"❌ Checkpoint目录不存在!\")\n",
    "    checkpoints = []\n",
    "\n",
    "# 分析最新的checkpoint\n",
    "if checkpoints:\n",
    "    # 选择要分析的checkpoint\n",
    "    # 可以选择 best_model.pt 或最新的 checkpoint_episode_xxx.pt\n",
    "    best_model = checkpoint_dir / \"best_model.pt\"\n",
    "    # best_model = checkpoint_dir / \"checkpoint_episode_400.pt\"\n",
    "    if best_model.exists():\n",
    "        target_checkpoint = best_model\n",
    "    else:\n",
    "        # 获取最新的checkpoint\n",
    "        target_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)\n",
    "    \n",
    "    print(f\"\\n分析checkpoint: {target_checkpoint.name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 加载checkpoint\n",
    "    checkpoint = torch.load(target_checkpoint, map_location='cpu')\n",
    "    \n",
    "    # 1. 打印基本信息\n",
    "    print(\"\\n📊 基本信息:\")\n",
    "    if 'metadata' in checkpoint:\n",
    "        metadata = checkpoint['metadata']\n",
    "        print(f\"  Episode: {metadata.get('episode', 'N/A')}\")\n",
    "        print(f\"  Success Rate: {metadata.get('success_rate', 0):.2%}\")\n",
    "        print(f\"  Timestamp: {metadata.get('timestamp', 'N/A')}\")\n",
    "        print(f\"  Best Success Rate: {metadata.get('best_success_rate', 0):.2%}\")\n",
    "    else:\n",
    "        print(\"  ⚠️ 没有metadata信息\")\n",
    "    \n",
    "    # 2. 训练历史\n",
    "    print(\"\\n📈 训练历史:\")\n",
    "    if 'training_history' in checkpoint:\n",
    "        history = checkpoint['training_history']\n",
    "        if 'success' in history and history['success']:\n",
    "            success_rates = history['success']\n",
    "            print(f\"  总Episodes: {len(success_rates)}\")\n",
    "            print(f\"  最后10个episode成功率: {np.mean(success_rates[-10:]):.2%}\")\n",
    "            print(f\"  最高成功率: {max(success_rates):.2%}\")\n",
    "            print(f\"  成功的episodes数: {sum(success_rates)}\")\n",
    "            \n",
    "            # 打印最后几个episode的成功情况\n",
    "            print(f\"\\n  最后20个episode成功情况:\")\n",
    "            last_20 = success_rates[-20:] if len(success_rates) >= 20 else success_rates\n",
    "            success_str = \"\".join([\"✓\" if s else \"✗\" for s in last_20])\n",
    "            print(f\"  {success_str}\")\n",
    "        else:\n",
    "            print(\"  ⚠️ 没有成功率记录\")\n",
    "            \n",
    "        if 'rewards' in history and history['rewards']:\n",
    "            rewards = history['rewards']\n",
    "            print(f\"\\n  平均奖励: {np.mean(rewards):.2f}\")\n",
    "            print(f\"  最后10个episode平均奖励: {np.mean(rewards[-10:]):.2f}\")\n",
    "            print(f\"  最高奖励: {max(rewards):.2f}\")\n",
    "    else:\n",
    "        print(\"  ⚠️ 没有训练历史\")\n",
    "    \n",
    "    # 3. 配置信息\n",
    "    print(\"\\n⚙️ 训练配置:\")\n",
    "    if 'config' in checkpoint:\n",
    "        config = checkpoint['config']\n",
    "        print(f\"  算法: {config.get('algorithm', 'N/A')}\")\n",
    "        print(f\"  学习率: {config.get('learning_rate', 'N/A')}\")\n",
    "        print(f\"  批大小: {config.get('batch_size', 'N/A')}\")\n",
    "        print(f\"  最大episode长度: {config.get('max_episode_length', 'N/A')}\")\n",
    "        print(f\"  课程学习: {config.get('use_curriculum', False)}\")\n",
    "    \n",
    "    # 4. 额外信息\n",
    "    print(\"\\n📦 其他信息:\")\n",
    "    all_keys = list(checkpoint.keys())\n",
    "    print(f\"  Checkpoint包含的所有键: {all_keys}\")\n",
    "    \n",
    "    # 检查任务统计\n",
    "    if 'task_statistics' in checkpoint:\n",
    "        print(\"\\n  任务统计:\")\n",
    "        task_stats = checkpoint['task_statistics']\n",
    "        for task_type, stats in task_stats.items():\n",
    "            print(f\"    {task_type}: 成功率 {stats.get('success_rate', 0):.2%}\")\n",
    "    \n",
    "    # 检查课程阶段\n",
    "    if 'curriculum_stage' in checkpoint:\n",
    "        print(f\"\\n  课程阶段: Stage {checkpoint['curriculum_stage']}\")\n",
    "    \n",
    "    # 检查是否有工具关键性数据\n",
    "    criticality_file = checkpoint_dir / \"tool_criticality.json\"\n",
    "    if criticality_file.exists():\n",
    "        print(\"\\n  ✓ 找到tool_criticality.json文件\")\n",
    "        with open(criticality_file, 'r') as f:\n",
    "            criticality_data = json.load(f)\n",
    "            print(f\"    记录的工具数: {len(criticality_data.get('tool_criticality', {}))}\")\n",
    "    \n",
    "    # 5. 诊断信息\n",
    "    print(\"\\n🔍 可能的问题诊断:\")\n",
    "    if 'metadata' in checkpoint:\n",
    "        success_rate = checkpoint['metadata'].get('success_rate', 0)\n",
    "        if success_rate == 0:\n",
    "            print(\"  ❌ 成功率为0，可能的原因：\")\n",
    "            print(\"    1. 任务太难或奖励设计有问题\")\n",
    "            print(\"    2. 探索不足，陷入局部最优\")\n",
    "            print(\"    3. required_tools定义可能有问题\")\n",
    "            print(\"    4. 最大步数限制太严格\")\n",
    "            print(\"    5. 课程学习进度太快\")\n",
    "            \n",
    "            # 检查episode长度\n",
    "            if 'training_history' in checkpoint and 'lengths' in checkpoint['training_history']:\n",
    "                avg_length = np.mean(checkpoint['training_history']['lengths'])\n",
    "                max_allowed = config.get('max_episode_length', 100)\n",
    "                if avg_length > max_allowed * 0.9:\n",
    "                    print(f\"\\n    ⚠️ 平均episode长度({avg_length:.1f})接近最大限制({max_allowed})!\")\n",
    "                    print(\"       可能需要增加max_episode_length\")\n",
    "else:\n",
    "    print(\"\\n❌ 没有找到任何checkpoint文件!\")\n",
    "    print(\"请检查:\")\n",
    "    print(\"1. checkpoint路径是否正确\")\n",
    "    print(\"2. 训练是否正常保存了checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095732e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "A key should be provided to invoke the endpoint",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mAZURE_INFERENCE_CREDENTIAL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA key should be provided to invoke the endpoint\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m client = ChatCompletionsClient(\n\u001b[32m     11\u001b[39m     endpoint=\u001b[33m'\u001b[39m\u001b[33mhttps://archer222arc.openai.azure.com/openai/deployments/gpt-4o-mini\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     credential=AzureKeyCredential(api_key),\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m payload = {\n\u001b[32m     17\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     18\u001b[39m     {\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m     35\u001b[39m }\n",
      "\u001b[31mException\u001b[39m: A key should be provided to invoke the endpoint"
     ]
    }
   ],
   "source": [
    "# pip install azure-ai-inference\n",
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# api_key = os.getenv(\"AZURE_INFERENCE_CREDENTIAL\", '')\n",
    "api_key = \"9wiSC2YySp6iDFL45NIPuoJ9Ynm2CcEjPw4FDjGAeCOpRdZjdetdJQQJ99BGACYeBjFXJ3w3AAABACOGqpWV\"\n",
    "if not api_key:\n",
    "  raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint='https://archer222arc.openai.azure.com/openai/deployments/gpt-4o-mini',\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    \n",
    ")\n",
    "\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I am going to Paris, what should I see?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\\n\\n1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\\n2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\\n3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\\n\\nThese are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is so great about #1?\"\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 4096,\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 1,\n",
    "  \"stop\": []\n",
    "}\n",
    "response = client.complete(payload)\n",
    "\n",
    "print(\"Response:\", response.choices[0].message.content)\n",
    "print(\"Model:\", response.model)\n",
    "print(\"Usage:\")\n",
    "print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "print(\"\tCompletion tokens:\", response.usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd99a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:23:21,469 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is a vibrant city with a rich history, stunning architecture, and a diverse array of attractions. Here’s a list of must-see places and experiences you shouldn’t miss:\n",
      "\n",
      "### Iconic Landmarks:\n",
      "1. **Eiffel Tower** - You can't visit Paris without seeing this iconic structure. Consider going at sunset for breathtaking views.\n",
      "2. **Louvre Museum** - Home to thousands of art pieces, including the Mona Lisa and Venus de Milo; plan your visit as it can be large.\n",
      "3. **Notre-Dame Cathedral** - Though currently under restoration, the exterior and the Île de la Cité are worth seeing.\n",
      "4. **Sacré-Cœur Basilica** - Located on Montmartre Hill, it offers stunning views of the city and a beautiful interior.\n",
      "5. **Arc de Triomphe** - Climb to the top for another great view of the city, and explore the Champs-Élysées.\n",
      "\n",
      "### Museums and Cultural Venues:\n",
      "6. **Musée d’Orsay** - Housed in a former railway station, it features Impressionist masterpieces.\n",
      "7. **Centre Pompidou** - Known for its modern art collections and unique architecture.\n",
      "8. **Musée de l'Orangerie** - Famous for Monet's Water Lilies and other Impressionist works.\n",
      "\n",
      "### Historic Areas:\n",
      "9. **Montmartre** - Explore the charming streets, artists' squares, and the vibrant bohemian atmosphere.\n",
      "10. **Le Marais** - Known for its medieval architecture, trendy shops, and art galleries.\n",
      "\n",
      "### Parks and Gardens:\n",
      "11. **Luxembourg Gardens** - A beautiful park perfect for a leisurely stroll or a picnic.\n",
      "12. **Tuileries Garden** - Located between the Louvre and Place de la Concorde, it’s great for relaxing outdoors.\n",
      "\n",
      "### Unique Experiences:\n",
      "13. **Seine River Cruise** - Consider doing a boat tour (especially at night) for unique views of the city's landmarks.\n",
      "14. **Visit a Parisian Café** - Experience the culture by enjoying coffee and pastries at famous cafés like Café de Flore or Les Deux Magots.\n",
      "15. **Explore the Catacombs** - For something different, visit the underground ossuaries filled with the remains of millions of Parisians.\n",
      "\n",
      "### Shopping and Cuisine:\n",
      "16. **Champs-Élysées** - Great for shopping and people-watching.\n",
      "17. **Le Bon Marché** - One of the first department stores in Paris.\n",
      "18. **Try French Cuisine** - Dine at a traditional bistro or indulge in pastries at a local patisserie.\n",
      "\n",
      "### Day Trips:\n",
      "19. **Versailles** - A short train ride away, the Palace of Versailles is stunning with its gardens and opulent rooms.\n",
      "20. **Giverny** - The home of Claude Monet and his beautiful gardens are perfect for art lovers.\n",
      "\n",
      "Be sure to check the opening hours and any entry requirements for popular attractions, and consider booking tickets in advance where possible. Enjoy your trip to Paris!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "endpoint = \"https://archer222arc.openai.azure.com/\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "deployment = \"gpt-4o-mini\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"https://archer222arc.openai.azure.com/\",\n",
    "    api_key=\"9wiSC2YySp6iDFL45NIPuoJ9Ynm2CcEjPw4FDjGAeCOpRdZjdetdJQQJ99BGACYeBjFXJ3w3AAABACOGqpWV\",\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am going to Paris, what should I see?\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ff1241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /root/WorkflowBench/scale_up\n",
      "初始化 Operation Embedding Index...\n",
      "[OperationEmbeddingIndex] Initializing with unified API client manager\n",
      "[OperationEmbeddingIndex] OpenAI client initialized with model: gpt-4o-mini\n",
      "[OperationEmbeddingIndex] Using embedding model: text-embedding-3-small\n",
      "[OperationEmbeddingIndex] Using embedding dimension: 1536\n",
      "[INFO] Loaded 2973 embeddings from persistent cache\n",
      "[OperationEmbeddingIndex] Initialized with 2973 cached embeddings\n",
      "[INFO] Loaded 14 LLM-enhanced operation definitions from cache\n",
      "[INFO] Loading operation index from cache\n",
      "[INFO] Operation index loaded from .mcp_operation_cache/operation_index.pkl\n",
      "\n",
      "=== 操作定义统计 ===\n",
      "总操作数: 14\n",
      "\n",
      "按类别分组:\n",
      "\n",
      "AGGREGATION (1 operations):\n",
      "  - aggregate\n",
      "\n",
      "AUTOMATION (1 operations):\n",
      "  - schedule\n",
      "\n",
      "COMMUNICATION (1 operations):\n",
      "  - notify\n",
      "\n",
      "COMPUTATION (1 operations):\n",
      "  - calculate\n",
      "\n",
      "DATA TRANSFER (1 operations):\n",
      "  - stream\n",
      "\n",
      "INPUT (1 operations):\n",
      "  - read\n",
      "\n",
      "INTEGRATION (2 operations):\n",
      "  - connect\n",
      "  - expose\n",
      "\n",
      "OUTPUT (1 operations):\n",
      "  - write\n",
      "\n",
      "TRANSFORMATION (2 operations):\n",
      "  - filter\n",
      "  - transform\n",
      "\n",
      "UTILITY (2 operations):\n",
      "  - backup\n",
      "  - log\n",
      "\n",
      "VALIDATION (1 operations):\n",
      "  - validate\n",
      "\n",
      "=== 详细操作定义示例 ===\n",
      "\n",
      "INPUT 示例 - read:\n",
      "  描述: Read or load data from a source\n",
      "  同义词: retrieve, extract, load, get, acquire...\n",
      "  相关操作: validate, transform...\n",
      "\n",
      "VALIDATION 示例 - validate:\n",
      "  描述: Validate or verify data correctness\n",
      "  同义词: validate, audit, check, ensure, cross-check...\n",
      "  相关操作: read, transform...\n",
      "\n",
      "TRANSFORMATION 示例 - transform:\n",
      "  描述: Transform or convert data format\n",
      "  同义词: reshape, normalize, decode, convert, modify...\n",
      "  相关操作: validate, aggregate...\n",
      "\n",
      "AGGREGATION 示例 - aggregate:\n",
      "  描述: Aggregate or combine multiple data items\n",
      "  同义词: merge, consolidate, combine, group, unify...\n",
      "  相关操作: transform, write...\n",
      "\n",
      "OUTPUT 示例 - write:\n",
      "  描述: Write or save data to a destination\n",
      "  同义词: export, write out, publish, persist, archive...\n",
      "  相关操作: aggregate, log...\n",
      "\n",
      "COMPUTATION 示例 - calculate:\n",
      "  描述: Perform calculations or computations\n",
      "  同义词: analyze, evaluate, predict, estimate, solve...\n",
      "  相关操作: transform, aggregate...\n",
      "\n",
      "INTEGRATION 示例 - connect:\n",
      "  描述: Connect to external services or APIs\n",
      "  同义词: link, authenticate, interface, establish connection, attach...\n",
      "  相关操作: read, write...\n",
      "\n",
      "UTILITY 示例 - log:\n",
      "  描述: Log information or track activities\n",
      "  同义词: log, audit, monitor, chronicle, report...\n",
      "  相关操作: connect, validate...\n",
      "\n",
      "AUTOMATION 示例 - schedule:\n",
      "  描述: Schedule operations to run at specific times or intervals\n",
      "  同义词: plan, time, set up, organize, arrange...\n",
      "\n",
      "COMMUNICATION 示例 - notify:\n",
      "  描述: Send notifications or alerts based on events or conditions\n",
      "  同义词: alert, inform, message, advise, signal...\n",
      "\n",
      "DATA TRANSFER 示例 - stream:\n",
      "  描述: Continuously transfer data in real-time from one source to another\n",
      "  同义词: broadcast, send, relay, flow, transmit...\n",
      "\n",
      "=== 测试语义搜索 ===\n",
      "\n",
      "查询: 'read data from csv file'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 10:13:39,538 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 10:13:39,670 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - read (input): 0.347\n",
      "  - parse (transformation): 0.300\n",
      "  - write (output): 0.182\n",
      "\n",
      "查询: 'validate json schema'\n",
      "  - validate (validation): 0.360\n",
      "  - parse (transformation): 0.232\n",
      "  - transform (transformation): 0.226\n",
      "\n",
      "查询: 'merge multiple datasets'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 10:13:39,834 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 10:13:39,967 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - aggregate (aggregation): 0.414\n",
      "  - integrate (integration): 0.353\n",
      "  - transform (transformation): 0.233\n",
      "\n",
      "查询: 'connect to REST API'\n",
      "  - integrate (integration): 0.244\n",
      "  - validate (validation): 0.229\n",
      "  - transform (transformation): 0.190\n",
      "\n",
      "查询: 'calculate statistical metrics'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 10:13:40,101 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 10:13:40,230 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - compute (computation): 0.361\n",
      "  - aggregate (aggregation): 0.257\n",
      "  - validate (validation): 0.199\n",
      "\n",
      "查询: 'save results to database'\n",
      "  - write (output): 0.370\n",
      "  - cache (utility): 0.301\n",
      "  - transform (transformation): 0.221\n",
      "\n",
      "查询: 'monitor system performance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 10:13:40,356 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-11 10:13:40,485 - httpx - INFO - HTTP Request: POST https://archer222arc.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - integrate (integration): 0.260\n",
      "  - compute (computation): 0.254\n",
      "  - validate (validation): 0.207\n",
      "\n",
      "查询: 'parse XML documents'\n",
      "  - parse (transformation): 0.333\n",
      "  - transform (transformation): 0.251\n",
      "  - read (input): 0.225\n",
      "\n",
      "=== 缓存文件状态 ===\n",
      "llm_operation_definitions.json: 4.77 KB\n",
      "operation_index.pkl: 196.93 KB\n",
      "embedding_cache.pkl: 35890.82 KB\n",
      "\n",
      "=== LLM 增强定义验证 ===\n",
      "总操作数: 14\n",
      "\n",
      "LLM 生成的新操作 (6):\n",
      "  - filter: Filter data based on specific criteria or conditions...\n",
      "  - schedule: Schedule operations to run at specific times or intervals...\n",
      "  - notify: Send notifications or alerts based on events or conditions...\n",
      "  - backup: Create a copy of data for recovery or preservation purposes...\n",
      "  - stream: Continuously transfer data in real-time from one source to a...\n",
      "  - expose: Expose data or services through an API for external access...\n",
      "\n",
      "=== 索引统计信息 ===\n",
      "{\n",
      "  \"total_operations\": 10,\n",
      "  \"categories\": {\n",
      "    \"input\": 1,\n",
      "    \"transformation\": 3,\n",
      "    \"validation\": 1,\n",
      "    \"aggregation\": 1,\n",
      "    \"computation\": 1,\n",
      "    \"output\": 1,\n",
      "    \"utility\": 1,\n",
      "    \"integration\": 1\n",
      "  },\n",
      "  \"has_faiss\": true,\n",
      "  \"has_openai\": true,\n",
      "  \"embedding_dim\": 1536\n",
      "}\n",
      "\n",
      "保存所有缓存...\n",
      "[INFO] Operation index saved to .mcp_operation_cache/operation_index.pkl\n",
      "缓存保存完成！\n",
      "\n",
      "操作定义报告已保存到: operation_definitions_report.json\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 创建 Operations Embedding 缓存\n",
    "# 这个 notebook 用于生成新的 operations embedding 缓存文件，包括 LLM 增强的操作定义\n",
    "\n",
    "# %% 导入必要的库\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 确保在正确的目录下运行\n",
    "print(f\"当前工作目录: {os.getcwd()}\")\n",
    "\n",
    "# %% 清理旧缓存（可选）\n",
    "def clean_old_cache(backup=True):\n",
    "    \"\"\"清理旧的缓存文件\"\"\"\n",
    "    cache_dir = Path(\".mcp_operation_cache\")\n",
    "    \n",
    "    if not cache_dir.exists():\n",
    "        print(\"缓存目录不存在，无需清理\")\n",
    "        return\n",
    "    \n",
    "    if backup:\n",
    "        # 创建备份\n",
    "        backup_dir = Path(f\".mcp_operation_cache_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "        shutil.copytree(cache_dir, backup_dir)\n",
    "        print(f\"已备份旧缓存到: {backup_dir}\")\n",
    "    \n",
    "    # 删除特定文件\n",
    "    files_to_remove = [\n",
    "        \"operation_index.pkl\",\n",
    "        \"llm_operation_definitions.json\",\n",
    "        \"embedding_cache.pkl\"\n",
    "    ]\n",
    "    \n",
    "    for file_name in files_to_remove:\n",
    "        file_path = cache_dir / file_name\n",
    "        if file_path.exists():\n",
    "            file_path.unlink()\n",
    "            print(f\"已删除: {file_path}\")\n",
    "    \n",
    "    print(\"缓存清理完成\")\n",
    "\n",
    "# 运行清理（根据需要取消注释）\n",
    "# clean_old_cache(backup=True)\n",
    "\n",
    "# %% 初始化 Operation Embedding Index\n",
    "from operation_embedding_index import OperationEmbeddingIndex, get_operation_index\n",
    "\n",
    "print(\"初始化 Operation Embedding Index...\")\n",
    "# 创建新实例，强制重建索引\n",
    "index = OperationEmbeddingIndex(use_cache=True)\n",
    "\n",
    "# %% 查看生成的操作定义\n",
    "print(\"\\n=== 操作定义统计 ===\")\n",
    "print(f\"总操作数: {len(index.operation_definitions)}\")\n",
    "print(\"\\n按类别分组:\")\n",
    "\n",
    "# 统计各类别的操作数\n",
    "category_stats = {}\n",
    "for op_name, op_def in index.operation_definitions.items():\n",
    "    category = op_def.get('category', 'unknown')\n",
    "    if category not in category_stats:\n",
    "        category_stats[category] = []\n",
    "    category_stats[category].append(op_name)\n",
    "\n",
    "for category, operations in sorted(category_stats.items()):\n",
    "    print(f\"\\n{category.upper()} ({len(operations)} operations):\")\n",
    "    for op in sorted(operations):\n",
    "        print(f\"  - {op}\")\n",
    "\n",
    "# %% 查看详细的操作定义\n",
    "print(\"\\n=== 详细操作定义示例 ===\")\n",
    "\n",
    "# 显示每个类别的一个示例\n",
    "for category, operations in category_stats.items():\n",
    "    if operations:\n",
    "        op_name = operations[0]\n",
    "        op_def = index.operation_definitions[op_name]\n",
    "        print(f\"\\n{category.upper()} 示例 - {op_name}:\")\n",
    "        print(f\"  描述: {op_def['description']}\")\n",
    "        print(f\"  同义词: {', '.join(op_def['synonyms'][:5])}...\")\n",
    "        if 'related_operations' in op_def:\n",
    "            print(f\"  相关操作: {', '.join(op_def.get('related_operations', [])[:3])}...\")\n",
    "\n",
    "# %% 测试语义搜索功能\n",
    "print(\"\\n=== 测试语义搜索 ===\")\n",
    "\n",
    "test_queries = [\n",
    "    \"read data from csv file\",\n",
    "    \"validate json schema\",\n",
    "    \"merge multiple datasets\",\n",
    "    \"connect to REST API\",\n",
    "    \"calculate statistical metrics\",\n",
    "    \"save results to database\",\n",
    "    \"monitor system performance\",\n",
    "    \"parse XML documents\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n查询: '{query}'\")\n",
    "    results = index.search_operation(query, k=3)\n",
    "    for op_name, score in results:\n",
    "        op_def = index.operation_embeddings.get(op_name)\n",
    "        if op_def:\n",
    "            print(f\"  - {op_name} ({op_def.category}): {score:.3f}\")\n",
    "\n",
    "# %% 保存缓存状态\n",
    "print(\"\\n=== 缓存文件状态 ===\")\n",
    "\n",
    "cache_dir = Path(\".mcp_operation_cache\")\n",
    "if cache_dir.exists():\n",
    "    for file_path in cache_dir.iterdir():\n",
    "        if file_path.is_file():\n",
    "            size_kb = file_path.stat().st_size / 1024\n",
    "            print(f\"{file_path.name}: {size_kb:.2f} KB\")\n",
    "\n",
    "# %% 验证 LLM 增强的定义\n",
    "llm_def_path = Path(\".mcp_operation_cache/llm_operation_definitions.json\")\n",
    "if llm_def_path.exists():\n",
    "    with open(llm_def_path, 'r') as f:\n",
    "        llm_definitions = json.load(f)\n",
    "    \n",
    "    print(f\"\\n=== LLM 增强定义验证 ===\")\n",
    "    print(f\"总操作数: {len(llm_definitions)}\")\n",
    "    \n",
    "    # 查找新增的操作（不在基础定义中的）\n",
    "    base_operations = {'read', 'validate', 'transform', 'aggregate', 'write', 'calculate', 'connect', 'log'}\n",
    "    new_operations = [op for op in llm_definitions.keys() if op not in base_operations]\n",
    "    \n",
    "    if new_operations:\n",
    "        print(f\"\\nLLM 生成的新操作 ({len(new_operations)}):\")\n",
    "        for op in new_operations[:10]:  # 只显示前10个\n",
    "            print(f\"  - {op}: {llm_definitions[op]['description'][:60]}...\")\n",
    "\n",
    "# %% 导出统计信息\n",
    "stats = index.get_stats()\n",
    "print(f\"\\n=== 索引统计信息 ===\")\n",
    "print(json.dumps(stats, indent=2))\n",
    "\n",
    "# %% 手动触发缓存保存\n",
    "print(\"\\n保存所有缓存...\")\n",
    "index._save_embedding_cache()\n",
    "cache_path = index._get_cache_path()\n",
    "index.save_index(cache_path)\n",
    "print(\"缓存保存完成！\")\n",
    "\n",
    "# %% 创建操作定义的可读报告\n",
    "report_path = Path(\"operation_definitions_report.json\")\n",
    "report = {\n",
    "    \"generated_at\": datetime.now().isoformat(),\n",
    "    \"total_operations\": len(index.operation_definitions),\n",
    "    \"categories\": category_stats,\n",
    "    \"definitions\": index.operation_definitions,\n",
    "    \"statistics\": stats\n",
    "}\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(f\"\\n操作定义报告已保存到: {report_path}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 下一步\n",
    "# \n",
    "# 1. 检查生成的缓存文件是否正确\n",
    "# 2. 运行其他使用 operation index 的模块，确认兼容性\n",
    "# 3. 如果需要重新生成，可以删除缓存文件并重新运行此 notebook\n",
    "# \n",
    "# ### 缓存文件位置\n",
    "# - `.mcp_operation_cache/operation_index.pkl` - 主索引文件\n",
    "# - `.mcp_operation_cache/llm_operation_definitions.json` - LLM 增强的定义\n",
    "# - `.mcp_operation_cache/embedding_cache.pkl` - 嵌入向量缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "检查OpenAI API余额和使用情况\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from openai import OpenAI\n",
    "\n",
    "def check_openai_usage():\n",
    "    \"\"\"检查OpenAI API的使用情况\"\"\"\n",
    "    \n",
    "    # 获取API密钥\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"错误：未找到OPENAI_API_KEY环境变量\")\n",
    "        return\n",
    "    \n",
    "    # 设置请求头\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # 获取当前日期\n",
    "    today = datetime.now()\n",
    "    start_date = (today - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "    end_date = today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    print(f\"正在检查 {start_date} 到 {end_date} 的使用情况...\\n\")\n",
    "    \n",
    "    # 检查订阅信息\n",
    "    try:\n",
    "        # 注意：OpenAI可能会更改这些端点\n",
    "        subscription_url = \"https://api.openai.com/v1/dashboard/billing/subscription\"\n",
    "        response = requests.get(subscription_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"=== 订阅信息 ===\")\n",
    "            print(f\"计划类型: {data.get('plan', {}).get('title', 'Unknown')}\")\n",
    "            print(f\"硬限制: ${data.get('hard_limit_usd', 0):.2f}\")\n",
    "            print(f\"软限制: ${data.get('soft_limit_usd', 0):.2f}\")\n",
    "            print(f\"系统硬限制: ${data.get('system_hard_limit_usd', 0):.2f}\")\n",
    "        else:\n",
    "            print(f\"无法获取订阅信息: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"获取订阅信息时出错: {e}\")\n",
    "    \n",
    "    # 检查使用情况\n",
    "    try:\n",
    "        usage_url = f\"https://api.openai.com/v1/dashboard/billing/usage?start_date={start_date}&end_date={end_date}\"\n",
    "        response = requests.get(usage_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            total_usage = data.get('total_usage', 0) / 100  # 转换为美元\n",
    "            \n",
    "            print(f\"\\n=== 最近30天使用情况 ===\")\n",
    "            print(f\"总使用金额: ${total_usage:.2f}\")\n",
    "            \n",
    "            # 显示每日使用情况（最近7天）\n",
    "            daily_costs = data.get('daily_costs', [])\n",
    "            if daily_costs:\n",
    "                print(\"\\n最近7天详细使用:\")\n",
    "                for day in daily_costs[-7:]:\n",
    "                    date = day.get('timestamp')\n",
    "                    cost = day.get('line_items', [{}])[0].get('cost', 0) / 100\n",
    "                    print(f\"  {date}: ${cost:.2f}\")\n",
    "        else:\n",
    "            print(f\"无法获取使用情况: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"获取使用情况时出错: {e}\")\n",
    "\n",
    "def test_api_with_simple_request():\n",
    "    \"\"\"用一个简单的请求测试API是否正常工作\"\"\"\n",
    "    print(\"\\n=== 测试API连接 ===\")\n",
    "    \n",
    "    try:\n",
    "        client = OpenAI()\n",
    "        \n",
    "        # 发送一个非常小的请求\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # 使用便宜的模型\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "            max_tokens=1,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        print(\"✅ API连接正常！\")\n",
    "        print(f\"响应: {response.choices[0].message.content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ API测试失败: {type(e).__name__}\")\n",
    "        print(f\"错误信息: {str(e)}\")\n",
    "        \n",
    "        # 判断错误类型\n",
    "        error_str = str(e).lower()\n",
    "        if \"insufficient_quota\" in error_str or \"exceeded your current quota\" in error_str:\n",
    "            print(\"\\n⚠️ 诊断: 您的API额度已用完，需要充值！\")\n",
    "        elif \"invalid api key\" in error_str or \"incorrect api key\" in error_str:\n",
    "            print(\"\\n⚠️ 诊断: API密钥无效！\")\n",
    "        elif \"502\" in error_str or \"bad gateway\" in error_str:\n",
    "            print(\"\\n⚠️ 诊断: OpenAI服务器临时故障，与余额无关\")\n",
    "        else:\n",
    "            print(\"\\n⚠️ 诊断: 其他错误，请检查网络连接和API设置\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    print(\"OpenAI API 状态检查工具\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. 检查环境变量\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"❌ 错误：未设置OPENAI_API_KEY环境变量\")\n",
    "        print(\"\\n请运行：export OPENAI_API_KEY='your-api-key'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ 找到API密钥 (前8位: {api_key[:8]}...)\")\n",
    "    \n",
    "    # 2. 检查使用情况\n",
    "    check_openai_usage()\n",
    "    \n",
    "    # 3. 测试API\n",
    "    test_api_with_simple_request()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"检查完成！\")\n",
    "    \n",
    "    # 给出建议\n",
    "    print(\"\\n💡 建议：\")\n",
    "    print(\"1. 如果是余额不足，请前往 https://platform.openai.com/account/billing 充值\")\n",
    "    print(\"2. 如果是502错误，请等待几分钟后重试\")\n",
    "    print(\"3. 查看OpenAI服务状态: https://status.openai.com/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "并行删除所有任务库中的 original_description 字段\n",
    "使用 ThreadPoolExecutor 高效处理多个文件\n",
    "\n",
    "使用方法:\n",
    "    # 处理默认目录 (./mcp_generated_library/difficulty_versions)\n",
    "    python remove_original_descriptions.py\n",
    "    \n",
    "    # 处理指定目录\n",
    "    python remove_original_descriptions.py -d ./path/to/tasks\n",
    "    \n",
    "    # 同时处理父目录的任务文件\n",
    "    python remove_original_descriptions.py -p\n",
    "    \n",
    "    # 自定义工作线程数\n",
    "    python remove_original_descriptions.py -w 20\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def process_single_file(file_path: Path) -> Tuple[str, int, int]:\n",
    "    \"\"\"\n",
    "    处理单个任务文件，删除所有任务的 original_description 字段\n",
    "    \n",
    "    Args:\n",
    "        file_path: 任务文件路径\n",
    "        \n",
    "    Returns:\n",
    "        (文件名, 原始任务数, 修改的任务数)\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取文件\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 统计信息\n",
    "    total_tasks = 0\n",
    "    modified_tasks = 0\n",
    "    \n",
    "    # 处理不同的数据格式\n",
    "    if isinstance(data, dict):\n",
    "        if 'tasks' in data:\n",
    "            # 格式: {\"tasks\": [...]}\n",
    "            tasks = data['tasks']\n",
    "            total_tasks = len(tasks)\n",
    "            \n",
    "            for task in tasks:\n",
    "                if 'original_description' in task:\n",
    "                    del task['original_description']\n",
    "                    modified_tasks += 1\n",
    "                    \n",
    "        else:\n",
    "            # 可能是其他格式的字典\n",
    "            logger.warning(f\"Unexpected dict format in {file_path}\")\n",
    "            \n",
    "    elif isinstance(data, list):\n",
    "        # 格式: [task1, task2, ...]\n",
    "        tasks = data\n",
    "        total_tasks = len(tasks)\n",
    "        \n",
    "        for task in tasks:\n",
    "            if isinstance(task, dict) and 'original_description' in task:\n",
    "                del task['original_description']\n",
    "                modified_tasks += 1\n",
    "    \n",
    "    # 保存修改后的文件\n",
    "    if modified_tasks > 0:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        logger.info(f\"✅ {file_path.name}: Modified {modified_tasks}/{total_tasks} tasks\")\n",
    "    else:\n",
    "        logger.info(f\"ℹ️ {file_path.name}: No original_description fields found\")\n",
    "    \n",
    "    return (file_path.name, total_tasks, modified_tasks)\n",
    "\n",
    "\n",
    "def find_all_task_files(directory: Path) -> List[Path]:\n",
    "    \"\"\"\n",
    "    查找目录下所有的任务文件\n",
    "    \n",
    "    Args:\n",
    "        directory: 要搜索的目录\n",
    "        \n",
    "    Returns:\n",
    "        任务文件路径列表\n",
    "    \"\"\"\n",
    "    task_files = []\n",
    "    \n",
    "    # 查找所有 .json 文件\n",
    "    for file_path in directory.glob('*.json'):\n",
    "        # 跳过一些明显不是任务文件的\n",
    "        if any(skip in file_path.name.lower() for skip in ['config', 'registry', 'settings']):\n",
    "            continue\n",
    "        task_files.append(file_path)\n",
    "    \n",
    "    return task_files\n",
    "\n",
    "\n",
    "def parallel_remove_original_descriptions(\n",
    "    directory_path: str = \"./mcp_generated_library/difficulty_versions\",\n",
    "    max_workers: int = 10\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    并行处理目录下所有任务文件，删除 original_description 字段\n",
    "    \n",
    "    Args:\n",
    "        directory_path: 任务文件目录路径\n",
    "        max_workers: 最大并行工作线程数\n",
    "        \n",
    "    Returns:\n",
    "        处理结果统计\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    directory = Path(directory_path)\n",
    "    \n",
    "    # 确保目录存在\n",
    "    if not directory.exists():\n",
    "        print(f\"❌ Directory not found: {directory}\")\n",
    "        raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "    \n",
    "    # 查找所有任务文件\n",
    "    task_files = find_all_task_files(directory)\n",
    "    \n",
    "    if not task_files:\n",
    "        print(f\"⚠️ No task files found in {directory}\")\n",
    "        return {\n",
    "            'total_files': 0,\n",
    "            'total_tasks': 0,\n",
    "            'modified_tasks': 0,\n",
    "            'execution_time': 0\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n🔍 Found {len(task_files)} task files to process\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 结果统计\n",
    "    results = {\n",
    "        'total_files': len(task_files),\n",
    "        'total_tasks': 0,\n",
    "        'modified_tasks': 0,\n",
    "        'file_results': []\n",
    "    }\n",
    "    \n",
    "    # 使用线程池并行处理\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # 提交所有任务\n",
    "        future_to_file = {\n",
    "            executor.submit(process_single_file, file_path): file_path \n",
    "            for file_path in task_files\n",
    "        }\n",
    "        \n",
    "        # 处理完成的任务\n",
    "        completed = 0\n",
    "        for future in as_completed(future_to_file):\n",
    "            file_path = future_to_file[future]\n",
    "            completed += 1\n",
    "            \n",
    "            # 获取结果\n",
    "            file_name, total_tasks, modified_tasks = future.result()\n",
    "            \n",
    "            # 更新统计\n",
    "            results['total_tasks'] += total_tasks\n",
    "            results['modified_tasks'] += modified_tasks\n",
    "            results['file_results'].append({\n",
    "                'file': file_name,\n",
    "                'total_tasks': total_tasks,\n",
    "                'modified_tasks': modified_tasks\n",
    "            })\n",
    "            \n",
    "            # 显示进度\n",
    "            progress = (completed / len(task_files)) * 100\n",
    "            print(f\"Progress: {completed}/{len(task_files)} files ({progress:.1f}%)\")\n",
    "    \n",
    "    # 计算执行时间\n",
    "    execution_time = time.time() - start_time\n",
    "    results['execution_time'] = execution_time\n",
    "    \n",
    "    # 显示最终结果\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✨ Processing Complete!\")\n",
    "    print(f\"📊 Total files processed: {results['total_files']}\")\n",
    "    print(f\"📋 Total tasks processed: {results['total_tasks']}\")\n",
    "    print(f\"✏️  Tasks modified: {results['modified_tasks']}\")\n",
    "    print(f\"⏱️  Execution time: {execution_time:.2f} seconds\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 保存处理报告\n",
    "    report_path = directory / f\"original_description_removal_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\n📄 Report saved to: {report_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    # 命令行参数解析\n",
    "    parser = argparse.ArgumentParser(description='并行删除任务文件中的 original_description 字段')\n",
    "    parser.add_argument(\n",
    "        '--directory', '-d',\n",
    "        default='./mcp_generated_library/difficulty_versions',\n",
    "        help='任务文件目录路径 (默认: ./mcp_generated_library/difficulty_versions)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--workers', '-w',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='最大并行工作线程数 (默认: 10)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--include-parent', '-p',\n",
    "        action='store_true',\n",
    "        help='同时处理上级目录的任务文件'\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # 执行主函数\n",
    "    try:\n",
    "        # 处理指定目录\n",
    "        print(f\"🚀 Processing directory: {args.directory}\")\n",
    "        results = parallel_remove_original_descriptions(\n",
    "            directory_path=args.directory,\n",
    "            max_workers=args.workers\n",
    "        )\n",
    "        \n",
    "        # 如果需要，也处理上级目录\n",
    "        if args.include_parent:\n",
    "            parent_dir = Path(args.directory).parent\n",
    "            print(f\"\\n🚀 Processing parent directory: {parent_dir}\")\n",
    "            parent_results = parallel_remove_original_descriptions(\n",
    "                directory_path=str(parent_dir),\n",
    "                max_workers=args.workers\n",
    "            )\n",
    "            \n",
    "            # 合并结果\n",
    "            results['total_files'] += parent_results['total_files']\n",
    "            results['total_tasks'] += parent_results['total_tasks']\n",
    "            results['modified_tasks'] += parent_results['modified_tasks']\n",
    "            results['file_results'].extend(parent_results['file_results'])\n",
    "        \n",
    "        # 显示每个文件的详细结果\n",
    "        print(\"\\n📋 Detailed Results:\")\n",
    "        print(\"-\" * 60)\n",
    "        for file_result in results['file_results']:\n",
    "            if file_result['modified_tasks'] > 0:\n",
    "                print(f\"✅ {file_result['file']}: {file_result['modified_tasks']}/{file_result['total_tasks']} tasks modified\")\n",
    "            else:\n",
    "                print(f\"ℹ️  {file_result['file']}: No modifications needed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error occurred: {str(e)}\")\n",
    "        raise  # 直接抛出异常，方便调试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量（在运行代码前）\n",
    "import os\n",
    "\n",
    "# 然后运行您的代码\n",
    "from tool_and_task_generator import parallel_generate_tasks_from_existing_tools\n",
    "\n",
    "results = parallel_generate_tasks_from_existing_tools(\n",
    "    tool_registry_path=\"mcp_generated_library/tool_registry_consolidated.json\",\n",
    "    num_tasks=1000,\n",
    "    task_distribution={\n",
    "        'basic_task': 0.20,\n",
    "        'simple_task': 0.20,\n",
    "        'data_pipeline': 0.2,\n",
    "        'api_integration': 0.2,\n",
    "        'multi_stage_pipeline': 0.20\n",
    "    },\n",
    "    use_llm=True,  # 确保启用LLM\n",
    "    max_workers=1000,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852bffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 扫描目录: mcp_generated_library/difficulty_versions\n",
      "📁 找到 8 个 JSON 文件\n",
      "==================================================\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_easy.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_easy_biased.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_hard.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_hard_biased.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_medium.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_medium_biased.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_very_easy.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "📄 处理文件: task_library_enhanced_v3_very_hard.json\n",
      "  ✓ 找到 630 个任务\n",
      "\n",
      "==================================================\n",
      "📊 合并统计:\n",
      "  总文件数: 8\n",
      "  总任务数: 5040\n",
      "  去重后任务数: 5040\n",
      "  重复任务数: 0\n",
      "\n",
      "✅ 合并完成！\n",
      "📁 输出文件: mcp_generated_library/task_library_all_difficulties.json\n",
      "\n",
      "📊 详细统计:\n",
      "\n",
      "按文件统计:\n",
      "  task_library_enhanced_v3_easy.json: 630 个任务\n",
      "  task_library_enhanced_v3_easy_biased.json: 630 个任务\n",
      "  task_library_enhanced_v3_hard.json: 630 个任务\n",
      "  task_library_enhanced_v3_hard_biased.json: 630 个任务\n",
      "  task_library_enhanced_v3_medium.json: 630 个任务\n",
      "  task_library_enhanced_v3_medium_biased.json: 630 个任务\n",
      "  task_library_enhanced_v3_very_easy.json: 630 个任务\n",
      "  task_library_enhanced_v3_very_hard.json: 630 个任务\n",
      "\n",
      "按任务类型统计:\n",
      "  api_integration: 1360 个任务\n",
      "  basic_task: 1200 个任务\n",
      "  data_pipeline: 1520 个任务\n",
      "  multi_stage_pipeline: 640 个任务\n",
      "  simple_task: 320 个任务\n",
      "\n",
      "按复杂度统计:\n",
      "  easy: 1520 个任务\n",
      "  hard: 640 个任务\n",
      "  medium: 2880 个任务\n",
      "\n",
      "按难度版本统计:\n",
      "  easy: 630 个任务\n",
      "  easy_biased: 630 个任务\n",
      "  hard: 1260 个任务\n",
      "  hard_biased: 630 个任务\n",
      "  medium: 630 个任务\n",
      "  medium_biased: 630 个任务\n",
      "  very_easy: 630 个任务\n",
      "\n",
      "📋 示例任务（前5个）:\n",
      "\n",
      "任务 1:\n",
      "  ID: N/A\n",
      "  类型: basic_task\n",
      "  复杂度: easy\n",
      "  难度版本: easy\n",
      "  来源文件: task_library_enhanced_v3_easy.json\n",
      "\n",
      "任务 2:\n",
      "  ID: N/A\n",
      "  类型: basic_task\n",
      "  复杂度: easy\n",
      "  难度版本: easy\n",
      "  来源文件: task_library_enhanced_v3_easy.json\n",
      "\n",
      "任务 3:\n",
      "  ID: N/A\n",
      "  类型: basic_task\n",
      "  复杂度: easy\n",
      "  难度版本: easy\n",
      "  来源文件: task_library_enhanced_v3_easy.json\n",
      "\n",
      "任务 4:\n",
      "  ID: N/A\n",
      "  类型: basic_task\n",
      "  复杂度: easy\n",
      "  难度版本: easy\n",
      "  来源文件: task_library_enhanced_v3_easy.json\n",
      "\n",
      "任务 5:\n",
      "  ID: N/A\n",
      "  类型: basic_task\n",
      "  复杂度: easy\n",
      "  难度版本: easy\n",
      "  来源文件: task_library_enhanced_v3_easy.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "def merge_task_libraries(directory_path=\"mcp_generated_library/difficulty_versions\", \n",
    "                        output_file=\"mcp_generated_library/task_library_all_difficulties.json\"):\n",
    "    \"\"\"\n",
    "    合并 difficulty_versions 目录下的所有 JSON 文件到一个文件\n",
    "    \n",
    "    Args:\n",
    "        directory_path: 包含 JSON 文件的目录路径\n",
    "        output_file: 输出合并后的 JSON 文件路径\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"🔍 扫描目录: {directory_path}\")\n",
    "    \n",
    "    # 存储所有任务\n",
    "    all_tasks = []\n",
    "    \n",
    "    # 统计信息\n",
    "    stats = defaultdict(int)\n",
    "    file_task_counts = {}\n",
    "    \n",
    "    # 获取目录下所有 .json 文件\n",
    "    json_files = list(Path(directory_path).glob(\"*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"❌ 在 {directory_path} 中没有找到 JSON 文件\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📁 找到 {len(json_files)} 个 JSON 文件\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 处理每个 JSON 文件\n",
    "    for json_file in sorted(json_files):\n",
    "        file_name = json_file.name\n",
    "        print(f\"\\n📄 处理文件: {file_name}\")\n",
    "        \n",
    "        # 读取文件\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # 提取任务\n",
    "        tasks = []\n",
    "        if isinstance(data, dict):\n",
    "            if 'tasks' in data:\n",
    "                tasks = data['tasks']\n",
    "            else:\n",
    "                # 如果是其他格式的字典，尝试提取值\n",
    "                for value in data.values():\n",
    "                    if isinstance(value, list):\n",
    "                        tasks.extend(value)\n",
    "        elif isinstance(data, list):\n",
    "            tasks = data\n",
    "        \n",
    "        # 为每个任务添加来源文件信息\n",
    "        for task in tasks:\n",
    "            # 添加源文件标记\n",
    "            task['source_file'] = file_name\n",
    "            \n",
    "            # 从文件名推断难度版本\n",
    "            if 'very_easy' in file_name:\n",
    "                task['difficulty_version'] = 'very_easy'\n",
    "            elif 'easy_biased' in file_name:\n",
    "                task['difficulty_version'] = 'easy_biased'\n",
    "            elif 'easy' in file_name:\n",
    "                task['difficulty_version'] = 'easy'\n",
    "            elif 'medium_biased' in file_name:\n",
    "                task['difficulty_version'] = 'medium_biased'\n",
    "            elif 'medium' in file_name:\n",
    "                task['difficulty_version'] = 'medium'\n",
    "            elif 'hard_biased' in file_name:\n",
    "                task['difficulty_version'] = 'hard_biased'\n",
    "            elif 'hard' in file_name:\n",
    "                task['difficulty_version'] = 'hard'\n",
    "            elif 'very_hard' in file_name:\n",
    "                task['difficulty_version'] = 'very_hard'\n",
    "            else:\n",
    "                task['difficulty_version'] = 'unknown'\n",
    "            \n",
    "            # 统计任务类型\n",
    "            task_type = task.get('task_type', 'unknown')\n",
    "            stats[f'task_type_{task_type}'] += 1\n",
    "            \n",
    "            # 统计复杂度\n",
    "            complexity = task.get('complexity', 'unknown')\n",
    "            stats[f'complexity_{complexity}'] += 1\n",
    "            \n",
    "            # 统计难度版本\n",
    "            stats[f'difficulty_{task[\"difficulty_version\"]}'] += 1\n",
    "        \n",
    "        # 添加到总任务列表\n",
    "        all_tasks.extend(tasks)\n",
    "        file_task_counts[file_name] = len(tasks)\n",
    "        \n",
    "        print(f\"  ✓ 找到 {len(tasks)} 个任务\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"📊 合并统计:\")\n",
    "    print(f\"  总文件数: {len(json_files)}\")\n",
    "    print(f\"  总任务数: {len(all_tasks)}\")\n",
    "    \n",
    "    # 去重（基于任务ID）\n",
    "    unique_tasks = {}\n",
    "    duplicate_count = 0\n",
    "    \n",
    "    for task in all_tasks:\n",
    "        task_id = task.get('id', None)\n",
    "        if task_id:\n",
    "            if task_id not in unique_tasks:\n",
    "                unique_tasks[task_id] = task\n",
    "            else:\n",
    "                duplicate_count += 1\n",
    "                # 如果是重复任务，记录所有出现的文件\n",
    "                if 'all_source_files' not in unique_tasks[task_id]:\n",
    "                    unique_tasks[task_id]['all_source_files'] = [unique_tasks[task_id].get('source_file')]\n",
    "                unique_tasks[task_id]['all_source_files'].append(task.get('source_file'))\n",
    "        else:\n",
    "            # 没有ID的任务，使用其他字段生成唯一标识\n",
    "            unique_key = f\"{task.get('task_type', 'unknown')}_{task.get('complexity', 'unknown')}_{len(unique_tasks)}\"\n",
    "            unique_tasks[unique_key] = task\n",
    "    \n",
    "    print(f\"  去重后任务数: {len(unique_tasks)}\")\n",
    "    print(f\"  重复任务数: {duplicate_count}\")\n",
    "    \n",
    "    # 创建最终的数据结构\n",
    "    merged_data = {\n",
    "        \"metadata\": {\n",
    "            \"generated_at\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"source_directory\": directory_path,\n",
    "            \"total_files\": len(json_files),\n",
    "            \"total_tasks\": len(all_tasks),\n",
    "            \"unique_tasks\": len(unique_tasks),\n",
    "            \"duplicates_removed\": duplicate_count,\n",
    "            \"files_processed\": list(file_task_counts.keys())\n",
    "        },\n",
    "        \"statistics\": {\n",
    "            \"by_file\": file_task_counts,\n",
    "            \"by_task_type\": {k.replace('task_type_', ''): v for k, v in stats.items() if k.startswith('task_type_')},\n",
    "            \"by_complexity\": {k.replace('complexity_', ''): v for k, v in stats.items() if k.startswith('complexity_')},\n",
    "            \"by_difficulty_version\": {k.replace('difficulty_', ''): v for k, v in stats.items() if k.startswith('difficulty_')}\n",
    "        },\n",
    "        \"tasks\": list(unique_tasks.values())\n",
    "    }\n",
    "    \n",
    "    # 保存合并后的文件\n",
    "    output_path = Path(output_file)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n✅ 合并完成！\")\n",
    "    print(f\"📁 输出文件: {output_file}\")\n",
    "    \n",
    "    # 显示详细统计\n",
    "    print(\"\\n📊 详细统计:\")\n",
    "    print(\"\\n按文件统计:\")\n",
    "    for file_name, count in sorted(file_task_counts.items()):\n",
    "        print(f\"  {file_name}: {count} 个任务\")\n",
    "    \n",
    "    print(\"\\n按任务类型统计:\")\n",
    "    for task_type, count in sorted(merged_data['statistics']['by_task_type'].items()):\n",
    "        print(f\"  {task_type}: {count} 个任务\")\n",
    "    \n",
    "    print(\"\\n按复杂度统计:\")\n",
    "    for complexity, count in sorted(merged_data['statistics']['by_complexity'].items()):\n",
    "        print(f\"  {complexity}: {count} 个任务\")\n",
    "    \n",
    "    print(\"\\n按难度版本统计:\")\n",
    "    for difficulty, count in sorted(merged_data['statistics']['by_difficulty_version'].items()):\n",
    "        print(f\"  {difficulty}: {count} 个任务\")\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "# 执行合并\n",
    "if __name__ == \"__main__\":\n",
    "    # 使用默认参数运行\n",
    "    result = merge_task_libraries()\n",
    "    \n",
    "    # 可选：显示前5个任务作为示例\n",
    "    if result and 'tasks' in result:\n",
    "        print(\"\\n📋 示例任务（前5个）:\")\n",
    "        for i, task in enumerate(result['tasks'][:5]):\n",
    "            print(f\"\\n任务 {i+1}:\")\n",
    "            print(f\"  ID: {task.get('id', 'N/A')}\")\n",
    "            print(f\"  类型: {task.get('task_type', 'N/A')}\")\n",
    "            print(f\"  复杂度: {task.get('complexity', 'N/A')}\")\n",
    "            print(f\"  难度版本: {task.get('difficulty_version', 'N/A')}\")\n",
    "            print(f\"  来源文件: {task.get('source_file', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822b9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 配置成功! API Key: sk-proj-...\n"
     ]
    }
   ],
   "source": [
    "# 一行命令生成配置文件\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "# 确保设置了环境变量\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-...'  # 取消注释并填入您的 key\n",
    "\n",
    "# 创建配置\n",
    "Path(\"./config\").mkdir(exist_ok=True)\n",
    "config = {\n",
    "    \"api_key\": os.getenv('OPENAI_API_KEY', ''),\n",
    "    \"openai_api_key\": os.getenv('OPENAI_API_KEY', ''),\n",
    "    \"model\": \"gpt-4o-mini\"\n",
    "}\n",
    "\n",
    "# 保存配置\n",
    "with open(\"./config/config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "# 验证\n",
    "if config['api_key']:\n",
    "    print(f\"✅ 配置成功! API Key: {config['api_key'][:8]}...\")\n",
    "else:\n",
    "    print(\"❌ 请先设置 OPENAI_API_KEY 环境变量\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
