# 错开启动策略防止系统过载

## 🎯 策略目标

防止多个模型同时启动造成：
- 系统CPU/内存瞬时峰值
- API同时请求导致的限流
- 电脑死机或性能急剧下降
- 网络带宽瞬间占满

## 🚀 实现的错开启动策略

### 1. 模型间的错开启动（主要策略）

#### 开源模型
```bash
# 每个模型启动间隔180秒
if [ $i -gt 0 ]; then
    echo "⏱️  延迟180秒等待前一个实例完全生成workflow..."
    sleep 180
fi
```

#### 闭源模型  
```bash
# 每个模型启动间隔60秒（API响应更快）
if [ $i -gt 0 ]; then
    echo "⏱️  延迟60秒等待前一个实例启动..."
    sleep 60
fi
```

### 2. API提供商分组延迟（辅助策略）

#### 闭源模型分组
```bash
case $model in
    "gpt-4o-mini"|"gpt-5-mini"|"grok-3-mini")
        sleep 1  # Azure模型组：短延迟
        ;;
    "claude_sonnet4"|"o3-0416-global"|"gemini-2.5-flash-06-17")
        sleep 3  # IdealLab闭源模型组：长延迟（API限制更严）
        ;;
esac
```

#### 开源模型分组
```bash
if [[ "$model" == *"qwen"* ]]; then
    sleep 2  # IdealLab开源模型延迟
fi
```

## 📊 延迟时间配置

| 模型类型 | 主要延迟 | 分组延迟 | 总延迟范围 |
|---------|---------|---------|----------|
| **开源模型** | 180秒 | 0-2秒 | 180-182秒 |
| **Azure闭源** | 60秒 | 1秒 | 61秒 |
| **IdealLab闭源** | 60秒 | 3秒 | 63秒 |

## 🎮 实际启动时序

### 开源模型示例（8个模型）
```
T+0s:   DeepSeek-V3-0324 启动
T+180s: DeepSeek-R1-0528 启动  
T+360s: qwen2.5-72b-instruct 启动 (+2s分组延迟)
T+542s: qwen2.5-32b-instruct 启动 (+2s分组延迟)
T+724s: qwen2.5-14b-instruct 启动 (+2s分组延迟)
T+906s: qwen2.5-7b-instruct 启动 (+2s分组延迟)
T+1088s: qwen2.5-3b-instruct 启动 (+2s分组延迟)
T+1270s: Llama-3.3-70B-Instruct 启动
```

### 闭源模型示例（6个模型）
```
T+0s:   gpt-4o-mini 启动
T+61s:  gpt-5-mini 启动 (+1s分组延迟)
T+122s: grok-3-mini 启动 (+1s分组延迟)  
T+185s: claude_sonnet4 启动 (+3s分组延迟)
T+248s: o3-0416-global 启动 (+3s分组延迟)
T+311s: gemini-2.5-flash-06-17 启动 (+3s分组延迟)
```

## 💡 设计理念

### 开源模型长延迟（180秒）原因
1. **Workflow生成耗时**：开源模型需要更多时间生成复杂workflow
2. **系统稳定性**：给系统足够时间处理前一个实例
3. **资源释放**：确保前一个实例的内存得到释放

### 闭源模型短延迟（60秒）原因  
1. **API响应快**：闭源模型API响应通常更快
2. **无workflow生成**：直接调用API，无需本地生成复杂workflow
3. **提高效率**：在安全的前提下提高测试效率

### 分组延迟作用
1. **API分散**：避免同一API提供商的瞬时压力
2. **细化控制**：对不同限制级别的API分别处理
3. **减少冲突**：最小化并发冲突的可能性

## ⚙️ 系统保护机制

### CPU/内存保护
- 避免8个进程同时启动造成的瞬时负载峰值
- 为每个进程预留充足的启动时间
- 渐进式负载增长而非突发式

### 网络保护
- 避免同时发起大量API请求
- 为API提供商预留处理时间
- 减少触发限流机制的概率

### 磁盘I/O保护
- 避免同时大量写入日志文件
- 减少并发文件操作冲突
- 保护数据库写入完整性

## 🔧 可调优参数

### 如需更激进的并发（风险较高）
```bash
# 开源模型：120秒 -> 100秒
# 闭源模型：60秒 -> 30秒
```

### 如需更保守的策略（更安全）
```bash
# 开源模型：180秒 -> 240秒  
# 闭源模型：60秒 -> 90秒
```

## 📈 性能vs安全平衡

| 策略 | 总耗时（8模型） | 系统安全性 | 推荐场景 |
|-----|---------------|----------|---------|
| **激进并发** | ~4分钟 | ⚠️ 低 | 高配置服务器 |
| **当前策略** | ~6-20分钟 | ✅ 高 | 标准配置（推荐） |
| **保守策略** | ~8-32分钟 | 🔒 极高 | 低配置或不稳定环境 |

## ✅ 最佳实践建议

1. **监控系统资源**：在测试过程中观察CPU、内存使用情况
2. **根据配置调整**：低配置机器可增加延迟时间
3. **网络稳定性**：网络不稳定时适当增加延迟
4. **API限制了解**：了解各API提供商的限制政策
5. **分批测试**：必要时可分批进行，而非一次性测试所有模型