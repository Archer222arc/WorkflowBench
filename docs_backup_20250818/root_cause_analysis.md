# 进程卡死8小时的根本原因分析

## 执行流程分析

### 1. 主循环结构 (interactive_executor.py)
```python
for turn in range(self.max_turns):  # max_turns = 10
    # 1. 获取LLM响应
    response = self._get_llm_response(conversation, state)
    
    # 2. 处理工具搜索（continue）
    # 3. 处理工具详情（continue）
    # 4. 格式检查（continue）
    # 5. 执行工具
    # 6. 检查终止条件
```

## 发现的潜在死循环原因

### 原因1：LLM不断搜索工具或查询详情
**症状**：如果LLM一直返回搜索请求或详情查询，会导致无限continue
- 第422-443行：工具搜索 → continue
- 第446-467行：工具详情 → continue
- 第480-503行：格式错误 → continue

**触发条件**：
- LLM困惑，不知道如何执行任务
- 工具名称不明确，不断搜索
- 格式一直错误，不断重试

**实际表现**：
- 10个turn都在搜索/查询，从不执行实际工具
- 每个turn需要1-2分钟（API调用）
- 10个turn = 10-20分钟，然后进入下一个测试
- 100个测试 × 20分钟 = 2000分钟 ≈ 33小时！

### 原因2：批量测试的累积效应
**问题链**：
1. 单个测试最多10个turn（正常应该2-3个turn完成）
2. 如果LLM表现不佳，每个测试都用满10个turn
3. 批量测试时，问题累积：
   - 100个测试实例
   - 每个测试10个turn
   - 每个turn 1次LLM调用（60秒超时）
   - 最坏情况：100 × 10 × 60秒 = 60,000秒 ≈ 16.7小时

### 原因3：并发执行的阻塞
**并发问题**：
```python
# batch_test_runner.py
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    for future in as_completed(future_to_task, timeout=len(tasks) * 70):
```
- 如果某个线程卡在LLM调用上
- 其他线程也在等待
- 整体超时设置过大：`len(tasks) * 70`秒
- 100个任务 = 7000秒 ≈ 2小时的超时

### 原因4：API重试机制的累积延迟
**重试逻辑**：
```python
max_retries = 5
wait_time = base_wait * (1.5 ** attempt)  # 指数退避
```
- 每次API失败重试5次
- 等待时间：0.5, 0.75, 1.125, 1.69, 2.53秒...
- 如果API不稳定，每个调用都重试
- 累积延迟可观

## 根本原因总结

**不是真正的"卡死"，而是"极慢"**：

1. **LLM迷失方向**：
   - 不知道如何执行任务
   - 不断搜索、查询、格式错误
   - 耗尽10个turn但没有实质进展

2. **缺乏有效的提前终止**：
   - 没有检测"无效循环"
   - 没有"连续失败N次则退出"
   - 没有"搜索超过N次则放弃"

3. **超时设置不合理**：
   - 单个API调用60秒
   - 整体批量超时过大
   - 没有单个测试的总体超时

4. **批量效应放大问题**：
   - 100个测试 × 问题测试 = 大量时间
   - 并发不能缓解，因为都在等API

## 解决方案

### 短期修复（立即可用）
```bash
# 1. 减少测试数量
--num-instances 10  # 不要100个

# 2. 减少max_turns
修改interactive_executor.py：max_turns=5  # 不要10

# 3. 添加更激进的终止条件
```

### 长期修复（需要代码改进）
1. **添加循环检测**：
   - 连续3次搜索/查询则终止
   - 连续3次格式错误则终止
   
2. **添加测试级超时**：
   - 单个测试最多5分钟
   - 超时直接标记失败
   
3. **优化prompt**：
   - 让LLM更清楚任务
   - 减少迷失的可能

4. **添加进度监控**：
   - 实时显示当前turn
   - 显示已用时间
   - 预估剩余时间
