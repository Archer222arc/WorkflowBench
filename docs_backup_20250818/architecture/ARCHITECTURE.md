# WorkflowBench Scale-Up ç³»ç»Ÿæ¶æ„æ–‡æ¡£

## ğŸ—ï¸ æ€»ä½“æ¶æ„

WorkflowBench Scale-Up é‡‡ç”¨åˆ†å±‚æ¨¡å—åŒ–æ¶æ„ï¼ŒåŸºäºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)æ¡†æ¶æ„å»ºçš„æ™ºèƒ½å·¥ä½œæµè‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨å±‚ (Application Layer)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å·¥ä½œæµè´¨é‡æµ‹è¯•å™¨  â”‚  å¯è§†åŒ–åˆ†æå™¨  â”‚  äº¤äº’å¼æ‰§è¡Œå™¨  â”‚  APIç®¡ç†å™¨  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ ¸å¿ƒå±‚ (Core Layer)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     MDPæ¡†æ¶      â”‚   è®­ç»ƒç®¡ç†å™¨   â”‚  å·¥ä½œæµç”Ÿæˆå™¨  â”‚  ç¼ºé™·ç”Ÿæˆå™¨  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æœåŠ¡å±‚ (Service Layer)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åµŒå…¥ç®¡ç†æœåŠ¡  â”‚  å·¥å…·èƒ½åŠ›ç®¡ç†  â”‚  æ“ä½œç´¢å¼•æœåŠ¡  â”‚  æ¨ç†ç”Ÿæˆå™¨   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   åŸºç¡€è®¾æ–½å±‚ (Infrastructure)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   PyTorch    â”‚    FAISS     â”‚   OpenAI API  â”‚   é…ç½®ç®¡ç†   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. MDPæ¡†æ¶å±‚ (generalized_mdp_framework.py)

#### 1.1 çŠ¶æ€ç©ºé—´è®¾è®¡

```python
@dataclass
class TaskState:
    task_id: str
    current_step: int
    tool_states: Dict[str, ToolExecutionStatus]
    workflow_context: Dict[str, Any]
    error_history: List[str]
    execution_trace: List[Dict]
    phase: int
    step_dependencies: Dict[str, List[str]]
```

**çŠ¶æ€ç‰¹å¾:**
- **ä»»åŠ¡æ ‡è¯†**: å”¯ä¸€ä»»åŠ¡IDå’Œå½“å‰æ‰§è¡Œæ­¥éª¤
- **å·¥å…·çŠ¶æ€**: æ¯ä¸ªå·¥å…·çš„æ‰§è¡ŒçŠ¶æ€è¿½è¸ª
- **ä¸Šä¸‹æ–‡ä¿¡æ¯**: å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡å’Œä¾èµ–å…³ç³»
- **é”™è¯¯è¿½è¸ª**: å†å²é”™è¯¯è®°å½•å’Œæ‰§è¡Œè½¨è¿¹
- **é˜¶æ®µç®¡ç†**: å¤šé˜¶æ®µæ‰§è¡ŒçŠ¶æ€ç®¡ç†

#### 1.2 åŠ¨ä½œç©ºé—´å®šä¹‰

```python
class ActionType(Enum):
    INVOKE_TOOL = "invoke_tool"              # è°ƒç”¨å·¥å…·
    VALIDATE_OUTPUT = "validate_output"      # éªŒè¯è¾“å‡º
    RETRY_TOOL = "retry_tool"               # é‡è¯•å·¥å…·
    RECOVER_ERROR = "recover_error"         # é”™è¯¯æ¢å¤
    CHECK_DEPENDENCIES = "check_dependencies" # æ£€æŸ¥ä¾èµ–
    CREATE_CHECKPOINT = "create_checkpoint"  # åˆ›å»ºæ£€æŸ¥ç‚¹
    RESTORE_CHECKPOINT = "restore_checkpoint" # æ¢å¤æ£€æŸ¥ç‚¹
    PARALLEL_EXECUTE = "parallel_execute"    # å¹¶è¡Œæ‰§è¡Œ
    CONDITIONAL_BRANCH = "conditional_branch" # æ¡ä»¶åˆ†æ”¯
```

#### 1.3 å¥–åŠ±å‡½æ•°è®¾è®¡

```python
def calculate_reward(self, state: TaskState, action: MDPAction, 
                    next_state: TaskState, execution_result: Any) -> float:
    """
    å¤šç»´åº¦å¥–åŠ±è®¡ç®—:
    1. æ‰§è¡ŒæˆåŠŸå¥–åŠ± (0-1)
    2. æ•ˆç‡å¥–åŠ± (-0.1 per step)
    3. è´¨é‡å¥–åŠ± (0-0.5)
    4. é”™è¯¯æƒ©ç½š (-0.5 per error)
    """
```

### 2. è®­ç»ƒç®¡ç†å±‚ (unified_training_manager.py)

#### 2.1 æ¶æ„è®¾è®¡

```python
class UnifiedTrainingManager:
    â”œâ”€â”€ PPOTrainer           # PPOç®—æ³•å®ç°
    â”œâ”€â”€ DQNTrainer          # DQNç®—æ³•å®ç°  
    â”œâ”€â”€ ReplayBuffer        # ç»éªŒå›æ”¾ç¼“å†²åŒº
    â”œâ”€â”€ PolicyNetwork       # ç­–ç•¥ç½‘ç»œ
    â”œâ”€â”€ ValueNetwork        # ä»·å€¼ç½‘ç»œ
    â””â”€â”€ TrainingConfig      # è®­ç»ƒé…ç½®ç®¡ç†
```

#### 2.2 ç½‘ç»œæ¶æ„

**ç­–ç•¥ç½‘ç»œ (PolicyNetwork):**
```python
class PolicyNetwork(nn.Module):
    def __init__(self, state_dim=512, action_dim=64, hidden_dim=256):
        self.encoder = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim)
        )
```

**ä»·å€¼ç½‘ç»œ (ValueNetwork):**
```python
class ValueNetwork(nn.Module):
    def __init__(self, state_dim=512, hidden_dim=256):
        self.network = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
```

#### 2.3 è®­ç»ƒæµç¨‹

```mermaid
graph TD
    A[å¼€å§‹è®­ç»ƒ] --> B[åˆå§‹åŒ–ç¯å¢ƒ]
    B --> C[é‡‡æ ·ç»éªŒ]
    C --> D[è®¡ç®—ä¼˜åŠ¿å‡½æ•°]
    D --> E[æ›´æ–°ç­–ç•¥ç½‘ç»œ]
    E --> F[æ›´æ–°ä»·å€¼ç½‘ç»œ]
    F --> G[è¯„ä¼°æ€§èƒ½]
    G --> H{æ”¶æ•›?}
    H -->|å¦| C
    H -->|æ˜¯| I[ä¿å­˜æ¨¡å‹]
```

### 3. å·¥ä½œæµç”Ÿæˆå±‚

#### 3.1 MDPå·¥ä½œæµç”Ÿæˆå™¨ (mdp_workflow_generator.py)

```python
class MDPWorkflowGenerator:
    def generate_workflow(self, task_type: str, difficulty: str) -> Workflow:
        """
        å·¥ä½œæµç”Ÿæˆæµç¨‹:
        1. åˆ†æä»»åŠ¡éœ€æ±‚
        2. é€‰æ‹©åˆé€‚å·¥å…·
        3. æ„å»ºæ‰§è¡Œåºåˆ—
        4. ä¼˜åŒ–ä¾èµ–å…³ç³»
        5. éªŒè¯å·¥ä½œæµå®Œæ•´æ€§
        """
```

**å·¥ä½œæµç±»å‹:**
- `basic_task`: å•æ­¥éª¤åŸºç¡€ä»»åŠ¡
- `simple_task`: 2-3æ­¥éª¤ç®€å•ä»»åŠ¡  
- `data_pipeline`: æ•°æ®å¤„ç†ç®¡é“
- `api_integration`: APIé›†æˆå·¥ä½œæµ
- `multi_stage_pipeline`: å¤šé˜¶æ®µå¤æ‚ç®¡é“

#### 3.2 ç¼ºé™·å·¥ä½œæµç”Ÿæˆå™¨ (flawed_workflow_generator.py)

```python
class FlawedWorkflowGenerator:
    def inject_flaw(self, workflow: Workflow, flaw_type: str, 
                   severity: str) -> FlawedWorkflow:
        """
        ç¼ºé™·æ³¨å…¥ç­–ç•¥:
        1. missing_middle: åˆ é™¤å…³é”®ä¸­é—´æ­¥éª¤
        2. order_flaw_swap: äº¤æ¢æ­¥éª¤é¡ºåº
        3. semantic_mismatch: å¼•å…¥è¯­ä¹‰ä¸ä¸€è‡´
        """
```

**ç¼ºé™·ä¸¥é‡æ€§çº§åˆ«:**
- **Light**: è½»å¾®ç¼ºé™·ï¼Œä¸å½±å“æ ¸å¿ƒåŠŸèƒ½
- **Medium**: ä¸­ç­‰ç¼ºé™·ï¼Œå½±å“éƒ¨åˆ†åŠŸèƒ½
- **Severe**: ä¸¥é‡ç¼ºé™·ï¼Œä¸¥é‡å½±å“æ‰§è¡Œ

### 4. æœåŠ¡æ”¯æ’‘å±‚

#### 4.1 åµŒå…¥ç®¡ç†æœåŠ¡ (mcp_embedding_manager.py)

```python
class MCPEmbeddingManager:
    â”œâ”€â”€ VectorStore          # å‘é‡å­˜å‚¨ (FAISS)
    â”œâ”€â”€ EmbeddingGenerator   # åµŒå…¥ç”Ÿæˆå™¨
    â”œâ”€â”€ SearchEngine        # è¯­ä¹‰æœç´¢å¼•æ“
    â””â”€â”€ CacheManager        # ç¼“å­˜ç®¡ç†å™¨
```

**åŠŸèƒ½ç‰¹æ€§:**
- å·¥å…·å’Œä»»åŠ¡çš„å‘é‡åŒ–è¡¨ç¤º
- åŸºäºFAISSçš„é«˜æ•ˆç›¸ä¼¼åº¦æœç´¢
- æ™ºèƒ½ç¼“å­˜æœºåˆ¶ä¼˜åŒ–æ€§èƒ½
- æ”¯æŒå¢é‡æ›´æ–°å’Œæ‰¹é‡ç´¢å¼•

#### 4.2 å·¥å…·èƒ½åŠ›ç®¡ç† (tool_capability_manager.py)

```python
class ToolCapabilityManager:
    def __init__(self):
        self.tool_registry = {}      # å·¥å…·æ³¨å†Œè¡¨
        self.capability_matrix = {}  # èƒ½åŠ›çŸ©é˜µ
        self.dependency_graph = {}   # ä¾èµ–å›¾
```

**æ ¸å¿ƒåŠŸèƒ½:**
- å·¥å…·èƒ½åŠ›åˆ†æå’Œåˆ†ç±»
- åŠ¨æ€å·¥å…·å‘ç°å’Œæ³¨å†Œ
- ä¾èµ–å…³ç³»ç®¡ç†
- èƒ½åŠ›åŒ¹é…å’Œæ¨è

#### 4.3 æ“ä½œç´¢å¼•æœåŠ¡ (operation_embedding_index.py)

```python
class OperationEmbeddingIndex:
    def build_index(self, operations: List[Operation]) -> FaissIndex:
        """
        æ“ä½œç´¢å¼•æ„å»º:
        1. æ“ä½œç‰¹å¾æå–
        2. å‘é‡åŒ–ç¼–ç 
        3. æ„å»ºFAISSç´¢å¼•
        4. ä¼˜åŒ–æœç´¢æ€§èƒ½
        """
```

### 5. æ‰§è¡Œä¸æµ‹è¯•å±‚

#### 5.1 äº¤äº’å¼æ‰§è¡Œå™¨ (interactive_executor.py)

```python
class InteractiveExecutor:
    async def execute_workflow(self, workflow: Workflow) -> ExecutionResult:
        """
        å¼‚æ­¥å·¥ä½œæµæ‰§è¡Œ:
        1. è§£æå·¥ä½œæµå®šä¹‰
        2. è°ƒåº¦ä»»åŠ¡æ‰§è¡Œ
        3. ç›‘æ§æ‰§è¡ŒçŠ¶æ€
        4. å¤„ç†å¼‚å¸¸å’Œé‡è¯•
        5. ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
        """
```

#### 5.2 å·¥ä½œæµè´¨é‡æµ‹è¯•å™¨ (workflow_quality_test_flawed.py)

```python
class FlawedWorkflowTester:
    def run_comprehensive_test(self) -> TestResults:
        """
        ç»¼åˆæµ‹è¯•æµç¨‹:
        1. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        2. æ‰§è¡Œå¤šç­–ç•¥æµ‹è¯•
        3. æ”¶é›†æ€§èƒ½æŒ‡æ ‡
        4. åˆ†æç¼ºé™·å½±å“
        5. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        """
```

**æµ‹è¯•ç­–ç•¥:**
- **Baseline**: åŸºç¡€æç¤ºç­–ç•¥
- **Optimal**: ä¼˜åŒ–æç¤ºç­–ç•¥
- **Chain-of-Thought**: æ€ç»´é“¾æç¤ºç­–ç•¥

### 6. APIä¸å®¢æˆ·ç«¯ç®¡ç† (api_client_manager.py)

```python
class APIClientManager:
    def __init__(self):
        self.openai_client = None
        self.azure_client = None
        self.rate_limiter = RateLimiter()
        self.retry_handler = RetryHandler()
```

**åŠŸèƒ½ç‰¹æ€§:**
- ç»Ÿä¸€APIå®¢æˆ·ç«¯ç®¡ç†
- æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
- è¯·æ±‚é™æµå’Œé‡è¯•æœºåˆ¶
- æˆæœ¬ä¼˜åŒ–å’Œä½¿ç”¨ç›‘æ§

## ğŸ”„ æ•°æ®æµæ¶æ„

### è®­ç»ƒæ•°æ®æµ

```mermaid
graph LR
    A[ä»»åŠ¡å®šä¹‰] --> B[å·¥ä½œæµç”Ÿæˆ]
    B --> C[ç¼ºé™·æ³¨å…¥]
    C --> D[MDPçŠ¶æ€ç¼–ç ]
    D --> E[ç­–ç•¥ç½‘ç»œ]
    E --> F[åŠ¨ä½œé€‰æ‹©]
    F --> G[æ‰§è¡Œåé¦ˆ]
    G --> H[å¥–åŠ±è®¡ç®—]
    H --> I[ç»éªŒå›æ”¾]
    I --> J[æ¨¡å‹æ›´æ–°]
```

### æ¨ç†æ•°æ®æµ

```mermaid
graph LR
    A[è¾“å…¥ä»»åŠ¡] --> B[çŠ¶æ€ç‰¹å¾æå–]
    B --> C[ç­–ç•¥ç½‘ç»œæ¨ç†]
    C --> D[åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒ]
    D --> E[åŠ¨ä½œé€‰æ‹©]
    E --> F[å·¥å…·æ‰§è¡Œ]
    F --> G[ç»“æœéªŒè¯]
    G --> H[çŠ¶æ€æ›´æ–°]
    H --> I[å®Œæˆåˆ¤æ–­]
```

## ğŸ›ï¸ é…ç½®ç®¡ç†æ¶æ„

### é…ç½®å±‚æ¬¡ç»“æ„

```
config/
â”œâ”€â”€ config.json                    # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ ppo_m1_config.json            # PPO M1ä¼˜åŒ–é…ç½®
â”œâ”€â”€ ppo_m1_overnight_config.json  # é•¿æ—¶é—´è®­ç»ƒé…ç½®
â””â”€â”€ training_config.json          # è®­ç»ƒå‚æ•°é…ç½®
```

### é…ç½®å‚æ•°è¯´æ˜

```json
{
  "api_config": {
    "use_azure_openai": true,
    "model": "gpt-4o-mini",
    "max_tokens": 2048,
    "temperature": 0.7
  },
  "training_config": {
    "algorithm": "ppo",
    "learning_rate": 0.0003,
    "batch_size": 64,
    "episodes": 1000,
    "gamma": 0.99,
    "tau": 0.95
  },
  "mdp_config": {
    "state_dim": 512,
    "action_dim": 64,
    "max_steps": 50,
    "reward_scale": 1.0
  }
}
```

## ğŸ“Š ç›‘æ§ä¸å¯è§†åŒ–æ¶æ„

### ç›‘æ§æŒ‡æ ‡ä½“ç³»

```python
class MetricsCollector:
    def collect_training_metrics(self):
        return {
            "episode_reward": [],
            "loss_policy": [],
            "loss_value": [],
            "success_rate": [],
            "execution_time": []
        }
    
    def collect_quality_metrics(self):
        return {
            "workflow_completeness": [],
            "flaw_detection_accuracy": [],
            "execution_efficiency": [],
            "error_recovery_rate": []
        }
```

### å¯è§†åŒ–ç»„ä»¶ (visualization_utils.py)

```python
class VisualizationUtils:
    def plot_training_curves(self)      # è®­ç»ƒæ›²çº¿
    def plot_quality_analysis(self)     # è´¨é‡åˆ†æå›¾
    def plot_flaw_sensitivity(self)     # ç¼ºé™·æ•æ„Ÿæ€§åˆ†æ
    def generate_comparison_charts(self) # å¯¹æ¯”å›¾è¡¨
```

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–æ¶æ„

### è®¡ç®—ä¼˜åŒ–

```python
# GPU/CPUæ··åˆè®¡ç®—
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¨¡å‹å¹¶è¡ŒåŒ–
model = nn.DataParallel(model)

# æ¢¯åº¦ç´¯ç§¯
accumulate_grad_batches = 4

# æ··åˆç²¾åº¦è®­ç»ƒ
scaler = torch.cuda.amp.GradScaler()
```

### å†…å­˜ä¼˜åŒ–

```python
# æ¢¯åº¦æ£€æŸ¥ç‚¹
torch.utils.checkpoint.checkpoint(model, input)

# åŠ¨æ€æ‰¹å¤„ç†
dynamic_batch_size = min(batch_size, available_memory // memory_per_sample)

# ç¼“å­˜ç®¡ç†
@lru_cache(maxsize=1000)
def cached_embedding(text: str) -> np.ndarray:
    return embedding_model.encode(text)
```

## ğŸ§ª æµ‹è¯•æ¶æ„

### å•å…ƒæµ‹è¯•ç»“æ„

```
tests/
â”œâ”€â”€ test_mdp_framework.py          # MDPæ¡†æ¶æµ‹è¯•
â”œâ”€â”€ test_training_manager.py       # è®­ç»ƒç®¡ç†å™¨æµ‹è¯•
â”œâ”€â”€ test_workflow_generator.py     # å·¥ä½œæµç”Ÿæˆå™¨æµ‹è¯•
â”œâ”€â”€ test_quality_tester.py         # è´¨é‡æµ‹è¯•å™¨æµ‹è¯•
â””â”€â”€ test_integration.py            # é›†æˆæµ‹è¯•
```

### æµ‹è¯•ç­–ç•¥

1. **å•å…ƒæµ‹è¯•**: æµ‹è¯•å„ç»„ä»¶çš„æ ¸å¿ƒåŠŸèƒ½
2. **é›†æˆæµ‹è¯•**: æµ‹è¯•ç»„ä»¶é—´çš„åä½œ
3. **æ€§èƒ½æµ‹è¯•**: æµ‹è¯•ç³»ç»Ÿæ€§èƒ½å’Œæ‰©å±•æ€§
4. **è´¨é‡æµ‹è¯•**: æµ‹è¯•å·¥ä½œæµè´¨é‡è¯„ä¼°å‡†ç¡®æ€§

## ğŸ”’ å®‰å…¨æ¶æ„

### APIå®‰å…¨

```python
class SecurityManager:
    def validate_api_key(self, key: str) -> bool:
        # APIå¯†é’¥éªŒè¯
    
    def encrypt_sensitive_data(self, data: str) -> str:
        # æ•æ„Ÿæ•°æ®åŠ å¯†
    
    def audit_api_usage(self, request: Dict) -> None:
        # APIä½¿ç”¨å®¡è®¡
```

### æ•°æ®å®‰å…¨

- **æ•æ„Ÿä¿¡æ¯è„±æ•**: è‡ªåŠ¨æ£€æµ‹å’Œè„±æ•æ•æ„Ÿæ•°æ®
- **è®¿é—®æ§åˆ¶**: åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶
- **æ•°æ®åŠ å¯†**: ä¼ è¾“å’Œå­˜å‚¨æ•°æ®åŠ å¯†
- **å®¡è®¡æ—¥å¿—**: å®Œæ•´çš„æ“ä½œå®¡è®¡æ—¥å¿—

## ğŸš€ æ‰©å±•æ€§æ¶æ„

### æ¨¡å—åŒ–è®¾è®¡

```python
# æ’ä»¶æ¥å£
class PluginInterface:
    def initialize(self) -> None: pass
    def execute(self, context: Dict) -> Any: pass
    def cleanup(self) -> None: pass

# å·¥å…·æ‰©å±•æ¥å£
class ToolExtension:
    def register_tool(self, tool: Tool) -> None: pass
    def get_capabilities(self) -> List[str]: pass
```

### åˆ†å¸ƒå¼æ”¯æŒ

```python
# åˆ†å¸ƒå¼è®­ç»ƒ
from torch.distributed import init_process_group
from torch.nn.parallel import DistributedDataParallel

# ä»»åŠ¡è°ƒåº¦
class DistributedScheduler:
    def schedule_task(self, task: Task, nodes: List[Node]) -> None: pass
    def balance_load(self, tasks: List[Task]) -> Dict[Node, List[Task]]: pass
```

---

*æ¶æ„æ–‡æ¡£ç‰ˆæœ¬: v2.0*  
*æœ€åæ›´æ–°: 2025-08-02*