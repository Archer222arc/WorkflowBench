#!/usr/bin/env python3
"""
æ·±å…¥åˆ†ææ•°æ®ä¿å­˜æµç¨‹
è¿½è¸ªä»æµ‹è¯•æ‰§è¡Œåˆ°æ•°æ®ä¿å­˜çš„å®Œæ•´è·¯å¾„
"""

import sys
import os
import json
import traceback
from pathlib import Path
from datetime import datetime

def trace_data_flow():
    """è¿½è¸ªæ•°æ®æµ"""
    print("="*60)
    print("ğŸ” è¿½è¸ªæ•°æ®æµ")
    print("="*60)
    
    # 1. æ£€æŸ¥å½“å‰æ•°æ®åº“çŠ¶æ€
    print("\n1. å½“å‰æ•°æ®åº“çŠ¶æ€")
    db_path = Path("pilot_bench_cumulative_results/master_database.json")
    with open(db_path) as f:
        db = json.load(f)
    
    print(f"   Version: {db.get('version')}")
    print(f"   Total tests: {db['summary']['total_tests']}")
    print(f"   Models count: {len(db.get('models', {}))}")
    
    # æ£€æŸ¥modelsç»“æ„
    for model_name in list(db.get('models', {}).keys())[:3]:
        model_data = db['models'][model_name]
        print(f"\n   {model_name}:")
        print(f"     Type: {type(model_data)}")
        if isinstance(model_data, dict):
            print(f"     Keys: {list(model_data.keys())[:5]}")
            print(f"     total_tests: {model_data.get('total_tests', 'N/A')}")
            if 'overall_stats' in model_data:
                print(f"     overall_stats keys: {list(model_data['overall_stats'].keys())[:3]}")

def test_add_test_result():
    """æµ‹è¯•add_test_resultæ–¹æ³•"""
    print("\n" + "="*60)
    print("2. æµ‹è¯•add_test_resultæ–¹æ³•")
    print("="*60)
    
    from cumulative_test_manager import CumulativeTestManager, TestRecord
    
    manager = CumulativeTestManager()
    
    # åˆ›å»ºæµ‹è¯•è®°å½•
    record = TestRecord(
        model="debug-test-model",
        task_type="simple_task",
        prompt_type="baseline",
        difficulty="easy",
        success=True,
        execution_time=2.5,
        turns=5
    )
    
    print(f"\næ·»åŠ æµ‹è¯•è®°å½•: {record.model}")
    
    # è°ƒç”¨add_test_result
    try:
        result = manager.add_test_result(record)
        print(f"âœ… add_test_resultè¿”å›: {result}")
        
        # æ£€æŸ¥å†…å­˜ä¸­çš„æ•°æ®
        if "debug-test-model" in manager.database["models"]:
            model_data = manager.database["models"]["debug-test-model"]
            print(f"\nå†…å­˜ä¸­çš„æ¨¡å‹æ•°æ®:")
            print(f"  Type: {type(model_data)}")
            print(f"  total_tests: {model_data.get('total_tests', 'N/A')}")
            
            # æ£€æŸ¥test_groups
            key = record.get_key()
            if key in manager.database.get("test_groups", {}):
                group = manager.database["test_groups"][key]
                print(f"\ntest_groupç»Ÿè®¡:")
                print(f"  total: {group['statistics']['total']}")
                print(f"  success: {group['statistics']['success']}")
        else:
            print("âŒ æ¨¡å‹æœªæ·»åŠ åˆ°å†…å­˜æ•°æ®åº“")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        traceback.print_exc()
    
    # æ£€æŸ¥ç£ç›˜ä¸Šçš„æ•°æ®
    print("\næ£€æŸ¥ç£ç›˜æ•°æ®...")
    db_path = Path("pilot_bench_cumulative_results/master_database.json")
    with open(db_path) as f:
        db_after = json.load(f)
    
    if "debug-test-model" in db_after["models"]:
        print("âœ… æ¨¡å‹å·²ä¿å­˜åˆ°ç£ç›˜")
        model_data = db_after["models"]["debug-test-model"]
        print(f"  total_tests: {model_data.get('total_tests', 'N/A')}")
    else:
        print("âŒ æ¨¡å‹æœªä¿å­˜åˆ°ç£ç›˜")

def test_enhanced_manager():
    """æµ‹è¯•EnhancedCumulativeManager"""
    print("\n" + "="*60)
    print("3. æµ‹è¯•EnhancedCumulativeManager")
    print("="*60)
    
    try:
        from enhanced_cumulative_manager import EnhancedCumulativeManager
        from cumulative_test_manager import TestRecord
        
        print("\nåˆ›å»ºEnhancedCumulativeManager...")
        manager = EnhancedCumulativeManager()
        
        # åˆ›å»ºæµ‹è¯•è®°å½•
        record = TestRecord(
            model="enhanced-test-model",
            task_type="simple_task",
            prompt_type="baseline",
            difficulty="easy",
            success=True,
            execution_time=2.5,
            turns=5,
            tool_calls=3
        )
        record.tool_reliability = 0.8  # è®¾ç½®æ­£ç¡®çš„å±æ€§
        
        print(f"æ·»åŠ æµ‹è¯•è®°å½•: {record.model}")
        
        # æ·»åŠ è®°å½•
        result = manager.add_test_result_with_classification(record)
        print(f"add_test_result_with_classificationè¿”å›: {result}")
        
        # æ£€æŸ¥update_buffer
        print(f"\nBufferå¤§å°: {len(manager.update_buffer)}")
        
        # æ‰‹åŠ¨åˆ·æ–°
        if manager.update_buffer:
            print("æ‰‹åŠ¨åˆ·æ–°buffer...")
            manager._flush_buffer()
        
        # æ£€æŸ¥å†…å­˜æ•°æ®
        if "enhanced-test-model" in manager.database["models"]:
            print("âœ… æ¨¡å‹åœ¨å†…å­˜æ•°æ®åº“ä¸­")
        else:
            print("âŒ æ¨¡å‹ä¸åœ¨å†…å­˜æ•°æ®åº“ä¸­")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        traceback.print_exc()

def analyze_smart_batch_runner():
    """åˆ†æsmart_batch_runnerçš„è°ƒç”¨é“¾"""
    print("\n" + "="*60)
    print("4. åˆ†æsmart_batch_runnerè°ƒç”¨é“¾")
    print("="*60)
    
    print("\nè°ƒç”¨é“¾åˆ†æ:")
    print("1. smart_batch_runner.py")
    print("   â””â”€> commit_to_database()")
    print("       â””â”€> enhanced_manager.add_test_result_with_classification()")
    print("           â”œâ”€> æ·»åŠ åˆ°update_buffer")
    print("           â””â”€> å¦‚æœbufferæ»¡ï¼Œè°ƒç”¨_flush_buffer()")
    print("               â”œâ”€> è°ƒç”¨parentçš„add_test_result()")
    print("               â”œâ”€> _update_error_metrics()")
    print("               â”œâ”€> _recalculate_total_tests()")
    print("               â””â”€> save_database()")
    
    # æ£€æŸ¥smart_batch_runnerä¸­çš„commit_to_database
    print("\næ£€æŸ¥commit_to_databaseå‡½æ•°...")
    try:
        with open("smart_batch_runner.py", "r") as f:
            content = f.read()
            
        # æŸ¥æ‰¾commit_to_databaseå‡½æ•°
        if "def commit_to_database" in content:
            print("âœ… æ‰¾åˆ°commit_to_databaseå‡½æ•°")
            
            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†_flush_buffer
            if "_flush_buffer()" in content:
                print("âœ… è°ƒç”¨äº†_flush_buffer()")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°_flush_buffer()è°ƒç”¨")
                
            # æ£€æŸ¥æ˜¯å¦æœ‰finalizeè°ƒç”¨
            if ".finalize()" in content:
                print("âœ… è°ƒç”¨äº†finalize()")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°finalize()è°ƒç”¨")
                
    except Exception as e:
        print(f"âŒ æ— æ³•åˆ†æ: {e}")

def check_buffer_settings():
    """æ£€æŸ¥bufferè®¾ç½®"""
    print("\n" + "="*60)
    print("5. æ£€æŸ¥Bufferè®¾ç½®")
    print("="*60)
    
    from enhanced_cumulative_manager import EnhancedCumulativeManager
    
    manager = EnhancedCumulativeManager()
    
    print(f"Bufferå¤§å°è®¾ç½®: {manager.buffer_size}")
    print(f"Flushé—´éš”: {manager.flush_interval}ç§’")
    
    # æµ‹è¯•bufferæ˜¯å¦ä¼šè‡ªåŠ¨åˆ·æ–°
    print("\næµ‹è¯•Bufferåˆ·æ–°...")
    from cumulative_test_manager import TestRecord
    
    for i in range(manager.buffer_size + 1):
        record = TestRecord(
            model=f"buffer-test-{i}",
            task_type="simple_task",
            prompt_type="baseline",
            difficulty="easy",
            success=True
        )
        record.tool_reliability = 0.8
        
        print(f"  æ·»åŠ è®°å½• {i+1}/{manager.buffer_size + 1}")
        manager.add_test_result_with_classification(record)
        
        if i == manager.buffer_size - 1:
            print(f"  Bufferåº”è¯¥æ»¡äº† (å¤§å°={len(manager.update_buffer)})")
            if len(manager.update_buffer) == 0:
                print("  âœ… Bufferå·²è‡ªåŠ¨åˆ·æ–°")
            else:
                print(f"  âŒ Bufferæœªåˆ·æ–°ï¼Œä»æœ‰{len(manager.update_buffer)}æ¡è®°å½•")

def test_direct_save():
    """ç›´æ¥æµ‹è¯•æ•°æ®ä¿å­˜"""
    print("\n" + "="*60)
    print("6. ç›´æ¥æµ‹è¯•æ•°æ®ä¿å­˜")
    print("="*60)
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    test_data = {
        "version": "3.0",
        "test_key": "test_value_" + datetime.now().strftime("%H%M%S"),
        "models": {},
        "summary": {
            "total_tests": 9999  # ç‰¹æ®Šå€¼ç”¨äºéªŒè¯
        }
    }
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = Path("pilot_bench_cumulative_results/test_direct_save.json")
    print(f"\nä¿å­˜æµ‹è¯•æ•°æ®åˆ°: {temp_file}")
    
    with open(temp_file, "w") as f:
        json.dump(test_data, f, indent=2)
    
    # éªŒè¯ä¿å­˜
    with open(temp_file) as f:
        loaded = json.load(f)
    
    if loaded["test_key"] == test_data["test_key"]:
        print("âœ… ç›´æ¥ä¿å­˜æˆåŠŸ")
    else:
        print("âŒ ç›´æ¥ä¿å­˜å¤±è´¥")
    
    # æ¸…ç†
    temp_file.unlink()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ æ·±å…¥åˆ†ææ•°æ®ä¿å­˜é—®é¢˜")
    print(f"æ—¶é—´: {datetime.now()}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    trace_data_flow()
    test_add_test_result()
    test_enhanced_manager()
    analyze_smart_batch_runner()
    check_buffer_settings()
    test_direct_save()
    
    print("\n" + "="*60)
    print("åˆ†æå®Œæˆ")
    print("="*60)

if __name__ == "__main__":
    main()