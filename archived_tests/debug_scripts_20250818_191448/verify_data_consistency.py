#!/usr/bin/env python3
"""
éªŒè¯Parquetå’ŒJSONæ•°æ®ä¸€è‡´æ€§
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import os

class DataConsistencyVerifier:
    """æ•°æ®ä¸€è‡´æ€§éªŒè¯å™¨"""
    
    def __init__(self):
        self.json_path = Path("pilot_bench_cumulative_results/master_database.json")
        self.parquet_path = Path("pilot_bench_parquet_data/test_results.parquet")
        self.results = {
            'json_exists': False,
            'parquet_exists': False,
            'models_match': False,
            'totals_match': False,
            'structure_match': False
        }
    
    def load_json_data(self):
        """åŠ è½½JSONæ•°æ®"""
        if not self.json_path.exists():
            print("âŒ JSONæ•°æ®åº“ä¸å­˜åœ¨")
            return None
        
        with open(self.json_path, 'r') as f:
            data = json.load(f)
        
        self.results['json_exists'] = True
        print(f"âœ… JSONæ•°æ®åº“å·²åŠ è½½")
        return data
    
    def load_parquet_data(self):
        """åŠ è½½Parquetæ•°æ®"""
        if not self.parquet_path.exists():
            print("âŒ Parquetæ–‡ä»¶ä¸å­˜åœ¨")
            # æ£€æŸ¥å¢é‡ç›®å½•
            inc_dir = Path("pilot_bench_parquet_data/incremental")
            if inc_dir.exists():
                inc_files = list(inc_dir.glob("*.parquet"))
                if inc_files:
                    print(f"  æ‰¾åˆ° {len(inc_files)} ä¸ªå¢é‡Parquetæ–‡ä»¶")
                    # åˆå¹¶æ‰€æœ‰å¢é‡æ–‡ä»¶
                    dfs = []
                    for file in inc_files:
                        df = pd.read_parquet(file)
                        dfs.append(df)
                    if dfs:
                        combined_df = pd.concat(dfs, ignore_index=True)
                        self.results['parquet_exists'] = True
                        print(f"  åˆå¹¶äº† {len(combined_df)} æ¡è®°å½•")
                        return combined_df
            return None
        
        df = pd.read_parquet(self.parquet_path)
        self.results['parquet_exists'] = True
        print(f"âœ… Parquetæ–‡ä»¶å·²åŠ è½½ ({len(df)} æ¡è®°å½•)")
        return df
    
    def extract_json_stats(self, json_data):
        """ä»JSONæå–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_tests': 0,
            'models': {},
            'prompt_types': set(),
            'difficulties': set(),
            'task_types': set()
        }
        
        # ä»summaryè·å–æ€»æ•°
        stats['total_tests'] = json_data.get('summary', {}).get('total_tests', 0)
        
        # ä»modelsæå–è¯¦ç»†ä¿¡æ¯
        if 'models' in json_data:
            for model_name, model_data in json_data['models'].items():
                model_total = 0
                
                if 'by_prompt_type' in model_data:
                    for pt, pt_data in model_data['by_prompt_type'].items():
                        stats['prompt_types'].add(pt)
                        
                        if 'by_tool_success_rate' in pt_data:
                            for rate, rate_data in pt_data['by_tool_success_rate'].items():
                                
                                if 'by_difficulty' in rate_data:
                                    for diff, diff_data in rate_data['by_difficulty'].items():
                                        stats['difficulties'].add(diff)
                                        
                                        if 'by_task_type' in diff_data:
                                            for task, task_data in diff_data['by_task_type'].items():
                                                stats['task_types'].add(task)
                                                model_total += task_data.get('total', 0)
                
                stats['models'][model_name] = model_total
        
        return stats
    
    def extract_parquet_stats(self, df):
        """ä»Parquetæå–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_tests': len(df),
            'models': {},
            'prompt_types': set(),
            'difficulties': set(),
            'task_types': set()
        }
        
        # æŒ‰æ¨¡å‹ç»Ÿè®¡
        if 'model' in df.columns:
            model_counts = df['model'].value_counts().to_dict()
            stats['models'] = model_counts
        
        # æ”¶é›†å”¯ä¸€å€¼
        if 'prompt_type' in df.columns:
            stats['prompt_types'] = set(df['prompt_type'].unique())
        
        if 'difficulty' in df.columns:
            stats['difficulties'] = set(df['difficulty'].unique())
        
        if 'task_type' in df.columns:
            stats['task_types'] = set(df['task_type'].unique())
        
        return stats
    
    def compare_stats(self, json_stats, parquet_stats):
        """æ¯”è¾ƒç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("æ•°æ®å¯¹æ¯”")
        print("=" * 60)
        
        # æ¯”è¾ƒæ€»æ•°
        print(f"\nğŸ“Š æ€»æµ‹è¯•æ•°:")
        print(f"  JSON: {json_stats['total_tests']}")
        print(f"  Parquet: {parquet_stats['total_tests']}")
        
        if json_stats['total_tests'] == parquet_stats['total_tests']:
            print("  âœ… æ€»æ•°åŒ¹é…")
            self.results['totals_match'] = True
        else:
            diff = abs(json_stats['total_tests'] - parquet_stats['total_tests'])
            print(f"  âŒ å·®å¼‚: {diff}")
        
        # æ¯”è¾ƒæ¨¡å‹
        print(f"\nğŸ¤– æ¨¡å‹æ•°é‡:")
        print(f"  JSON: {len(json_stats['models'])}")
        print(f"  Parquet: {len(parquet_stats['models'])}")
        
        json_models = set(json_stats['models'].keys())
        parquet_models = set(parquet_stats['models'].keys())
        
        if json_models == parquet_models:
            print("  âœ… æ¨¡å‹åˆ—è¡¨åŒ¹é…")
            self.results['models_match'] = True
        else:
            only_json = json_models - parquet_models
            only_parquet = parquet_models - json_models
            
            if only_json:
                print(f"  ä»…åœ¨JSONä¸­: {only_json}")
            if only_parquet:
                print(f"  ä»…åœ¨Parquetä¸­: {only_parquet}")
        
        # æ¯”è¾ƒç»´åº¦
        print(f"\nğŸ“ æ•°æ®ç»´åº¦:")
        print(f"  Promptç±»å‹ - JSON: {len(json_stats['prompt_types'])}, Parquet: {len(parquet_stats['prompt_types'])}")
        print(f"  éš¾åº¦çº§åˆ« - JSON: {len(json_stats['difficulties'])}, Parquet: {len(parquet_stats['difficulties'])}")
        print(f"  ä»»åŠ¡ç±»å‹ - JSON: {len(json_stats['task_types'])}, Parquet: {len(parquet_stats['task_types'])}")
        
        # è¯¦ç»†æ¨¡å‹å¯¹æ¯”
        print(f"\nğŸ“ˆ æ¨¡å‹æµ‹è¯•æ•°å¯¹æ¯”:")
        common_models = json_models & parquet_models
        
        for model in sorted(common_models):
            json_count = json_stats['models'].get(model, 0)
            parquet_count = parquet_stats['models'].get(model, 0)
            
            if json_count == parquet_count:
                print(f"  âœ… {model}: {json_count}")
            else:
                print(f"  âŒ {model}: JSON={json_count}, Parquet={parquet_count}")
    
    def run_verification(self):
        """è¿è¡ŒéªŒè¯"""
        print("=" * 60)
        print("Parquetå’ŒJSONæ•°æ®ä¸€è‡´æ€§éªŒè¯")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        json_data = self.load_json_data()
        parquet_df = self.load_parquet_data()
        
        if not json_data or parquet_df is None:
            print("\nâŒ æ— æ³•åŠ è½½æ•°æ®è¿›è¡Œå¯¹æ¯”")
            return False
        
        # 2. æå–ç»Ÿè®¡
        print("\nğŸ“Š æå–ç»Ÿè®¡ä¿¡æ¯...")
        json_stats = self.extract_json_stats(json_data)
        parquet_stats = self.extract_parquet_stats(parquet_df)
        
        # 3. å¯¹æ¯”æ•°æ®
        self.compare_stats(json_stats, parquet_stats)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        return self.results['totals_match'] and self.results['models_match']
    
    def generate_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("éªŒè¯æŠ¥å‘Š")
        print("=" * 60)
        
        # æ£€æŸ¥å„é¡¹ç»“æœ
        all_pass = all(self.results.values())
        
        print("\nâœ… é€šè¿‡é¡¹:")
        for key, value in self.results.items():
            if value:
                print(f"  - {key}")
        
        print("\nâŒ å¤±è´¥é¡¹:")
        for key, value in self.results.items():
            if not value:
                print(f"  - {key}")
        
        print(f"\nğŸ“ ç»“è®º:")
        if all_pass:
            print("  âœ… JSONå’ŒParquetæ•°æ®å®Œå…¨ä¸€è‡´")
        elif self.results['json_exists'] and not self.results['parquet_exists']:
            print("  âš ï¸ Parquetå­˜å‚¨æœªå¯ç”¨æˆ–æ•°æ®æœªåŒæ­¥")
            print("  å»ºè®®ï¼šè®¾ç½®STORAGE_FORMAT=parquetå¹¶é‡æ–°è¿è¡Œæµ‹è¯•")
        elif self.results['totals_match']:
            print("  âš ï¸ æ•°æ®åŸºæœ¬ä¸€è‡´ï¼Œä½†æœ‰ç»†èŠ‚å·®å¼‚")
        else:
            print("  âŒ æ•°æ®å­˜åœ¨ä¸ä¸€è‡´ï¼Œéœ€è¦åŒæ­¥")
    
    def sync_recommendation(self):
        """åŒæ­¥å»ºè®®"""
        if not self.results['totals_match']:
            print("\nğŸ’¡ åŒæ­¥å»ºè®®:")
            print("  1. è¿è¡Œ update_summary_totals.py æ›´æ–°JSONç»Ÿè®¡")
            print("  2. è®¾ç½® STORAGE_FORMAT=parquet å¯ç”¨Parquetå­˜å‚¨")
            print("  3. è¿è¡Œä¸€æ¬¡å®Œæ•´æµ‹è¯•ä»¥åŒæ­¥æ•°æ®")

def main():
    """ä¸»å‡½æ•°"""
    verifier = DataConsistencyVerifier()
    success = verifier.run_verification()
    
    if not success:
        verifier.sync_recommendation()
    
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())