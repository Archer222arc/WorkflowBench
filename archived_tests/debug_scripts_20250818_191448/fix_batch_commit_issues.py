#!/usr/bin/env python3
"""
ä¿®å¤batch_commitç›¸å…³é—®é¢˜
1. æ·»åŠ è‡ªåŠ¨flushæœºåˆ¶
2. ä¿®å¤é»˜è®¤ä¿å­˜é€»è¾‘
3. ç¡®ä¿ParquetåŒæ­¥æ›´æ–°
"""

import os
import sys
from pathlib import Path
import shutil
from datetime import datetime

def backup_file(filepath):
    """å¤‡ä»½æ–‡ä»¶"""
    if Path(filepath).exists():
        backup_path = f"{filepath}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.copy2(filepath, backup_path)
        print(f"âœ… å¤‡ä»½: {backup_path}")
        return backup_path
    return None

def fix_batch_test_runner():
    """ä¿®å¤batch_test_runner.pyçš„checkpointé€»è¾‘"""
    print("\nğŸ“ ä¿®å¤batch_test_runner.py...")
    
    filepath = "batch_test_runner.py"
    backup_file(filepath)
    
    with open(filepath, 'r') as f:
        content = f.read()
    
    # ä¿®å¤1: checkpoint_saveé€»è¾‘ - æ·»åŠ ç»“æŸæ—¶çš„å¼ºåˆ¶ä¿å­˜
    old_code = """    def run_concurrent_batch(self, tasks, workers=5, qps=2.0):"""
    
    new_code = """    def run_concurrent_batch(self, tasks, workers=5, qps=2.0):"""
    
    # æŸ¥æ‰¾run_concurrent_batchçš„ç»“å°¾ï¼Œæ·»åŠ å¼ºåˆ¶ä¿å­˜
    if "# æœ€åä¸€æ¬¡checkpointä¿å­˜ï¼ˆå¼ºåˆ¶ï¼‰" in content:
        # ç¡®ä¿æœ€åçš„pending_resultsè¢«ä¿å­˜
        old_end = """        # æœ€åä¸€æ¬¡checkpointä¿å­˜ï¼ˆå¼ºåˆ¶ï¼‰
        if not self.enable_database_updates and self.checkpoint_interval > 0:
            self._checkpoint_save([], force=True)"""
        
        new_end = """        # æœ€åä¸€æ¬¡checkpointä¿å­˜ï¼ˆå¼ºåˆ¶ï¼‰
        if not self.enable_database_updates and self.checkpoint_interval > 0:
            self._checkpoint_save([], force=True)
        
        # ç¡®ä¿æ‰€æœ‰pending_resultséƒ½è¢«ä¿å­˜ï¼ˆå³ä½¿ä¸æ»¡checkpoint_intervalï¼‰
        if self.pending_results and not self.enable_database_updates:
            print(f"\\nğŸ’¾ Final save: ä¿å­˜å‰©ä½™çš„{len(self.pending_results)}ä¸ªç»“æœ...")
            self._checkpoint_save([], force=True)"""
        
        if old_end in content:
            content = content.replace(old_end, new_end)
            print("  âœ… æ·»åŠ äº†æœ€ç»ˆä¿å­˜æœºåˆ¶")
    
    # ä¿®å¤2: æ”¹è¿›checkpointæ¡ä»¶
    old_condition = """        should_save = force or (len(self.pending_results) >= self.checkpoint_interval and self.checkpoint_interval > 0)"""
    
    new_condition = """        # ä¿®æ”¹ä¿å­˜æ¡ä»¶ï¼šforceæ—¶å¼ºåˆ¶ä¿å­˜ï¼Œæˆ–è€…è¾¾åˆ°checkpoint_intervalï¼Œæˆ–è€…intervalä¸º0æ—¶ç«‹å³ä¿å­˜
        should_save = force or (self.checkpoint_interval == 0 and len(self.pending_results) > 0) or \
                     (self.checkpoint_interval > 0 and len(self.pending_results) >= self.checkpoint_interval)"""
    
    if old_condition in content:
        content = content.replace(old_condition, new_condition)
        print("  âœ… ä¿®å¤äº†checkpointä¿å­˜æ¡ä»¶")
    
    with open(filepath, 'w') as f:
        f.write(content)
    
    print("  âœ… batch_test_runner.pyä¿®å¤å®Œæˆ")

def fix_smart_batch_runner():
    """ä¿®å¤smart_batch_runner.pyçš„é»˜è®¤ä¿å­˜é€»è¾‘"""
    print("\nğŸ“ ä¿®å¤smart_batch_runner.py...")
    
    filepath = "smart_batch_runner.py"
    backup_file(filepath)
    
    with open(filepath, 'r') as f:
        content = f.read()
    
    # ä¿®å¤ï¼šå³ä½¿ä¸æ˜¯batch_commitæ¨¡å¼ä¹Ÿè¦ä¿å­˜æ•°æ®
    # æ‰¾åˆ°æ‰€æœ‰"if batch_commit:"çš„ä¿å­˜é€»è¾‘ï¼Œæ”¹ä¸ºæ€»æ˜¯ä¿å­˜
    
    # ä½ç½®1: _run_azure_parallel_taskså‡½æ•°
    old_save1 = """    # å¦‚æœæ˜¯æ‰¹é‡æäº¤æ¨¡å¼ï¼Œä¿å­˜ç»“æœ
    if batch_commit:
        unsaved_results = [r for r in results if r and not r.get('_saved', False)]
        if unsaved_results:
            print(f"\\nğŸ“¤ ä¿å­˜{len(unsaved_results)}ä¸ªæµ‹è¯•ç»“æœ...")"""
    
    new_save1 = """    # ä¿å­˜ç»“æœï¼ˆæ— è®ºæ˜¯å¦batch_commitï¼‰
    unsaved_results = [r for r in results if r and not r.get('_saved', False)]
    if unsaved_results:
        if not batch_commit:
            print(f"\\nğŸ“¤ è‡ªåŠ¨ä¿å­˜{len(unsaved_results)}ä¸ªæµ‹è¯•ç»“æœ...")
        else:
            print(f"\\nğŸ“¤ æ‰¹é‡ä¿å­˜{len(unsaved_results)}ä¸ªæµ‹è¯•ç»“æœ...")"""
    
    if old_save1 in content:
        content = content.replace(old_save1, new_save1)
        print("  âœ… ä¿®å¤äº†Azureå¹¶è¡Œä»»åŠ¡çš„ä¿å­˜é€»è¾‘")
    
    # ä½ç½®2: _run_idealab_parallel_taskså‡½æ•°
    old_save2 = """    # å¦‚æœæ˜¯æ‰¹é‡æäº¤æ¨¡å¼ï¼Œä¿å­˜ç»“æœ
    if batch_commit and all_results:
        unsaved_results = [r for r in all_results if r and not r.get('_saved', False)]
        if unsaved_results:
            print(f"\\nğŸ“¤ ä¿å­˜{len(unsaved_results)}ä¸ªæµ‹è¯•ç»“æœ...")"""
    
    new_save2 = """    # ä¿å­˜ç»“æœï¼ˆæ— è®ºæ˜¯å¦batch_commitï¼‰
    if all_results:
        unsaved_results = [r for r in all_results if r and not r.get('_saved', False)]
        if unsaved_results:
            if not batch_commit:
                print(f"\\nğŸ“¤ è‡ªåŠ¨ä¿å­˜{len(unsaved_results)}ä¸ªæµ‹è¯•ç»“æœ...")
            else:
                print(f"\\nğŸ“¤ æ‰¹é‡ä¿å­˜{len(unsaved_results)}ä¸ªæµ‹è¯•ç»“æœ...")"""
    
    if old_save2 in content:
        content = content.replace(old_save2, new_save2)
        print("  âœ… ä¿®å¤äº†IdealLabå¹¶è¡Œä»»åŠ¡çš„ä¿å­˜é€»è¾‘")
    
    # æ·»åŠ é»˜è®¤batch_commit=True
    old_default = """                         batch_commit: bool = False, checkpoint_interval: int = 20,"""
    new_default = """                         batch_commit: bool = True, checkpoint_interval: int = 10,"""
    
    if old_default in content:
        content = content.replace(old_default, new_default)
        print("  âœ… å°†batch_commité»˜è®¤å€¼æ”¹ä¸ºTrueï¼Œcheckpoint_intervalæ”¹ä¸º10")
    
    with open(filepath, 'w') as f:
        f.write(content)
    
    print("  âœ… smart_batch_runner.pyä¿®å¤å®Œæˆ")

def add_batch_commit_to_scripts():
    """ç»™run_systematic_test_final.shæ·»åŠ --batch-commitå‚æ•°"""
    print("\nğŸ“ ä¿®å¤run_systematic_test_final.sh...")
    
    filepath = "run_systematic_test_final.sh"
    backup_file(filepath)
    
    with open(filepath, 'r') as f:
        content = f.read()
    
    # ç»Ÿè®¡éœ€è¦ä¿®å¤çš„ä½ç½®
    count = 0
    
    # ä¸ºæ‰€æœ‰smart_batch_runner.pyè°ƒç”¨æ·»åŠ --batch-commit
    lines = content.split('\n')
    new_lines = []
    
    for line in lines:
        if 'smart_batch_runner.py' in line and '--batch-commit' not in line:
            # å¦‚æœè¿™è¡Œè°ƒç”¨äº†smart_batch_runner.pyä½†æ²¡æœ‰--batch-commit
            if line.strip().endswith('\\'):
                # å¤šè¡Œå‘½ä»¤ï¼Œåœ¨æœ«å°¾æ·»åŠ 
                new_lines.append(line)
                new_lines.append('            --batch-commit \\')
                count += 1
            elif 'python' in line:
                # å•è¡Œå‘½ä»¤ï¼Œåœ¨æœ«å°¾æ·»åŠ 
                new_lines.append(line + ' --batch-commit')
                count += 1
            else:
                new_lines.append(line)
        else:
            new_lines.append(line)
    
    content = '\n'.join(new_lines)
    
    with open(filepath, 'w') as f:
        f.write(content)
    
    print(f"  âœ… ä¸º{count}å¤„smart_batch_runner.pyè°ƒç”¨æ·»åŠ äº†--batch-commitå‚æ•°")

def enable_parquet_update():
    """ç¡®ä¿Parquetå­˜å‚¨è¢«æ›´æ–°"""
    print("\nğŸ“ æ£€æŸ¥Parquetå­˜å‚¨é…ç½®...")
    
    # æ£€æŸ¥enhanced_cumulative_manager.pyæ˜¯å¦æ­£ç¡®å¤„ç†Parquet
    filepath = "enhanced_cumulative_manager.py"
    
    if not Path(filepath).exists():
        print("  âš ï¸ enhanced_cumulative_manager.pyä¸å­˜åœ¨")
        return
    
    with open(filepath, 'r') as f:
        content = f.read()
    
    # ç¡®ä¿_flush_bufferè°ƒç”¨äº†Parquetä¿å­˜
    if "parquet" in content.lower():
        print("  âœ… enhanced_cumulative_manager.pyå·²æ”¯æŒParquet")
    else:
        print("  âš ï¸ enhanced_cumulative_manager.pyå¯èƒ½ä¸æ”¯æŒParquet")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    storage_format = os.environ.get('STORAGE_FORMAT', 'json')
    print(f"  å½“å‰STORAGE_FORMAT: {storage_format}")
    
    if storage_format == 'parquet':
        print("  âœ… Parquetå­˜å‚¨å·²å¯ç”¨")
    else:
        print("  â„¹ï¸ å½“å‰ä½¿ç”¨JSONå­˜å‚¨ï¼Œå¦‚éœ€å¯ç”¨Parquetï¼Œè¯·è®¾ç½®ï¼š")
        print("     export STORAGE_FORMAT=parquet")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ ä¿®å¤batch_commitç›¸å…³é—®é¢˜")
    print("="*50)
    
    # 1. ä¿®å¤batch_test_runner.py
    fix_batch_test_runner()
    
    # 2. ä¿®å¤smart_batch_runner.py
    fix_smart_batch_runner()
    
    # 3. ä¿®å¤run_systematic_test_final.sh
    add_batch_commit_to_scripts()
    
    # 4. æ£€æŸ¥Parqueté…ç½®
    enable_parquet_update()
    
    print("\n" + "="*50)
    print("âœ… æ‰€æœ‰ä¿®å¤å®Œæˆï¼")
    print("\nå»ºè®®ï¼š")
    print("1. è¿è¡Œæµ‹è¯•éªŒè¯ä¿®å¤ï¼š")
    print("   python smart_batch_runner.py --model gpt-4o-mini --prompt-types baseline \\")
    print("     --difficulty easy --task-types simple_task --num-instances 1")
    print("\n2. å¦‚éœ€å¯ç”¨Parquetå­˜å‚¨ï¼š")
    print("   export STORAGE_FORMAT=parquet")
    print("\n3. è¿è¡Œå®Œæ•´çš„5.3æµ‹è¯•ï¼š")
    print("   ./run_5_3_macos.sh")

if __name__ == "__main__":
    main()