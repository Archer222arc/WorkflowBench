#!/usr/bin/env python3
"""
æµ‹è¯•Parquetå­˜å‚¨ä¿®å¤æ•ˆæœ
"""

import os
import sys
from pathlib import Path

# è®¾ç½®Parquetå­˜å‚¨æ ¼å¼
os.environ['STORAGE_FORMAT'] = 'parquet'

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))
from parquet_cumulative_manager import ParquetCumulativeManager as EnhancedCumulativeManager
from cumulative_test_manager import TestRecord

def test_parquet_storage():
    """æµ‹è¯•Parquetå­˜å‚¨åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•Parquetå­˜å‚¨ä¿®å¤æ•ˆæœ")
    print("=" * 60)
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = EnhancedCumulativeManager()
    print(f"âœ… ç®¡ç†å™¨ç±»å‹: {type(manager).__name__}")
    
    # åˆ›å»ºå¤šä¸ªæµ‹è¯•è®°å½•
    test_models = ['gpt-4o-mini', 'DeepSeek-V3-0324', 'qwen2.5-72b-instruct']
    
    for i, model in enumerate(test_models):
        record = TestRecord(
            model=model,
            task_type='simple_task',
            prompt_type='flawed_sequence_disorder',
            difficulty='easy'
        )
        
        # è®¾ç½®å…¶ä»–å±æ€§
        record.tool_success_rate = 0.8
        record.success = (i % 2 == 0)  # äº¤æ›¿æˆåŠŸ/å¤±è´¥
        record.execution_time = 2.5 + i
        record.turns = 5 + i
        record.tool_calls = 3 + i
        record.is_flawed = True
        record.flaw_type = 'sequence_disorder'
        
        # æ·»åŠ è®°å½•
        success = manager.add_test_result_with_classification(record)
        print(f"  æ·»åŠ {model}: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
    
    # åˆ·æ–°ç¼“å†²åŒº
    if hasattr(manager, '_flush_buffer'):
        manager._flush_buffer()
        print("âœ… ç¼“å†²åŒºå·²åˆ·æ–°")
    
    # æ£€æŸ¥å¢é‡æ–‡ä»¶
    inc_dir = Path('pilot_bench_parquet_data/incremental')
    if inc_dir.exists():
        files = list(inc_dir.glob('*.parquet'))
        print(f"\nğŸ“ å¢é‡æ–‡ä»¶æ•°: {len(files)}")
        
        if files:
            # è¯»å–æ‰€æœ‰æ–‡ä»¶ç»Ÿè®¡
            import pandas as pd
            total_records = 0
            models_found = set()
            
            for file in files:
                df = pd.read_parquet(file)
                total_records += len(df)
                if 'model' in df.columns:
                    models_found.update(df['model'].unique())
            
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {total_records}")
            print(f"ğŸ¤– å‘ç°çš„æ¨¡å‹: {', '.join(models_found)}")
            
            # æ˜¾ç¤ºæœ€æ–°æ–‡ä»¶çš„ç¤ºä¾‹è®°å½•
            latest = max(files, key=lambda f: f.stat().st_mtime)
            df = pd.read_parquet(latest)
            print(f"\nğŸ“ æœ€æ–°æ–‡ä»¶ ({latest.name}) çš„ç¬¬ä¸€æ¡è®°å½•:")
            if len(df) > 0:
                first_record = df.iloc[0]
                for key in ['model', 'task_type', 'prompt_type', 'success', 'flaw_type']:
                    if key in first_record:
                        print(f"  - {key}: {first_record[key]}")
    
    # æ£€æŸ¥ä¸»æ–‡ä»¶
    main_file = Path('pilot_bench_parquet_data/test_results.parquet')
    if main_file.exists():
        df = pd.read_parquet(main_file)
        print(f"\nğŸ“Š ä¸»æ–‡ä»¶ç»Ÿè®¡: {len(df)} æ¡æ±‡æ€»è®°å½•")
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼Parquetå­˜å‚¨åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    print("=" * 60)

if __name__ == "__main__":
    test_parquet_storage()