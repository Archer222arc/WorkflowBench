#\!/usr/bin/env python3
"""
å¢å¼ºçš„AIåˆ†ç±»å™¨ - ä½¿ç”¨å®Œæ•´äº¤äº’æ—¥å¿—è¿›è¡Œé”™è¯¯åˆ†ç±»
ç›¸æ¯”focused_ai_classifier.pyï¼Œè¿™ä¸ªç‰ˆæœ¬ä½¿ç”¨å®Œæ•´çš„log_dataè€Œä¸æ˜¯æœ‰é™çš„ä¸Šä¸‹æ–‡
"""

import json
import logging
import time
import random
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class StandardErrorType(Enum):
    """æ ‡å‡†çš„7ç§é”™è¯¯ç±»å‹"""
    TOOL_CALL_FORMAT = "tool_call_format_errors"
    TIMEOUT = "timeout_errors" 
    MAX_TURNS = "max_turns_errors"
    TOOL_SELECTION = "tool_selection_errors"
    PARAMETER_CONFIG = "parameter_config_errors"
    SEQUENCE_ORDER = "sequence_order_errors"
    DEPENDENCY = "dependency_errors"
    OTHER = "other_errors"


class EnhancedAIClassifier:
    """å¢å¼ºçš„AIåˆ†ç±»å™¨ - ä½¿ç”¨å®Œæ•´äº¤äº’æ—¥å¿—"""
    
    def __init__(self, model_name: str = "gpt-5-nano", max_retries: int = 3, base_delay: float = 1.0):
        """åˆå§‹åŒ–å¢å¼ºçš„AIåˆ†ç±»å™¨"""
        self.model_name = model_name
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.client = None
        
        try:
            from api_client_manager import get_client_for_model
            self.client = get_client_for_model(model_name)
            self.is_gpt5_nano = getattr(self.client, 'is_gpt5_nano', False)
            logger.info(f"Enhanced AI classifier initialized with {model_name}")
        except Exception as e:
            logger.error(f"Failed to initialize enhanced AI classifier: {e}")
            self.client = None
            self.is_gpt5_nano = False
    
    def classify_error_from_log(self, log_data: Dict, error_message: str = None) -> Tuple[StandardErrorType, str, float]:
        """
        ä»å®Œæ•´äº¤äº’æ—¥å¿—åˆ†ç±»é”™è¯¯
        
        Args:
            log_data: å®Œæ•´çš„äº¤äº’æ—¥å¿—æ•°æ®
            error_message: å¯é€‰çš„é”™è¯¯æ¶ˆæ¯
            
        Returns:
            (é”™è¯¯ç±»å‹, åˆ†æåŸå› , ç½®ä¿¡åº¦)
        """
        # å…ˆè¿›è¡Œå¿«é€Ÿè§„åˆ™æ£€æŸ¥
        rule_result = self._quick_rule_check_from_log(log_data, error_message)
        if rule_result:
            return rule_result
        
        # ä½¿ç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ
        if self.client:
            return self._ai_classify_with_full_log(log_data, error_message)
        else:
            return self._fallback_classify_from_log(log_data, error_message)
    
    def _quick_rule_check_from_log(self, log_data: Dict, error_message: str = None) -> Optional[Tuple[StandardErrorType, str, float]]:
        """åŸºäºå®Œæ•´æ—¥å¿—çš„å¿«é€Ÿè§„åˆ™æ£€æŸ¥"""
        
        # é¦–å…ˆæ£€æŸ¥æ‰§è¡Œæ—¶é—´è¶…æ—¶
        execution_time = log_data.get('execution_time', 0)
        error_type = log_data.get('error_type', '')
        
        # æ£€æŸ¥è¶…æ—¶æƒ…å†µï¼šæ‰§è¡Œæ—¶é—´è¾¾åˆ°è¶…æ—¶é˜ˆå€¼(600ç§’)æˆ–error_typeä¸ºtimeout
        if execution_time >= 600 or error_type == 'timeout':
            return StandardErrorType.TIMEOUT, f"Test timeout - execution time: {execution_time}s", 0.98
        
        # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯ä¸­çš„è¶…æ—¶å…³é”®è¯
        if error_message and any(keyword in error_message.lower() for keyword in 
                               ['timeout', 'timed out', 'time limit', 'execution timeout']):
            return StandardErrorType.TIMEOUT, "Timeout detected in error message", 0.95
        
        # æ£€æŸ¥å¯¹è¯å†å²ä¸­çš„æ ¼å¼å¸®åŠ©ä¿¡æ¯
        conversation = log_data.get('conversation_history', [])
        has_format_help = any(
            entry.get('type') == 'format_help' or 'format_help' in entry.get('content', '') 
            for entry in conversation
        )
        
        if has_format_help:
            return StandardErrorType.TOOL_CALL_FORMAT, "Format help provided during conversation - clear format error", 0.95
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ¼å¼é—®é¢˜æ ‡è®°
        has_format_issue = any(
            entry.get('format_issue', False) 
            for entry in conversation
        )
        
        if has_format_issue:
            return StandardErrorType.TOOL_CALL_FORMAT, "Format issue detected in conversation history", 0.90
        
        # åˆ†æå·¥å…·è°ƒç”¨æ¨¡å¼
        tool_calls = [entry for entry in conversation if '<tool_call>' in entry.get('content', '')]
        if len(tool_calls) == 0:
            # æ²¡æœ‰ä»»ä½•å·¥å…·è°ƒç”¨å°è¯•
            if error_message and any(keyword in error_message.lower() for keyword in 
                                   ['connection', 'network', 'api error']):
                return StandardErrorType.OTHER, "No tool calls due to environment issue", 0.85
            else:
                # å¯èƒ½æ˜¯çœŸæ­£çš„æ ¼å¼é—®é¢˜ï¼Œä½†éœ€è¦AIè¿›ä¸€æ­¥åˆ†æ
                return None
        
        # æ£€æŸ¥è¶…æ—¶ç›¸å…³çš„æ˜ç¡®é”™è¯¯
        if error_message:
            error_lower = error_message.lower()
            if ('test timeout after' in error_lower and 'seconds' in error_lower):
                return StandardErrorType.TIMEOUT, "Agent execution timeout detected", 0.98
        
        return None  # éœ€è¦AIæ·±åº¦åˆ†æ
    
    def _ai_classify_with_full_log(self, log_data: Dict, error_message: str = None) -> Tuple[StandardErrorType, str, float]:
        """ä½¿ç”¨å®Œæ•´æ—¥å¿—çš„AIåˆ†ç±»"""
        
        for attempt in range(self.max_retries + 1):
            try:
                prompt = self._build_enhanced_prompt(log_data, error_message)
                
                messages = [{"role": "user", "content": prompt}]
                
                if self.is_gpt5_nano:
                    response = self.client.chat.completions.create(
                        messages=messages,
                        model=self.model_name
                    )
                else:
                    response = self.client.chat.completions.create(
                        model=self.model_name,
                        messages=messages,
                        temperature=0.1,
                        max_tokens=500
                    )
                
                result_text = response.choices[0].message.content
                
                if not result_text or result_text.strip() == "":
                    logger.warning(f"Empty response from {self.model_name}")
                    return self._fallback_classify_from_log(log_data, error_message)
                
                return self._parse_enhanced_response(result_text)
                
            except Exception as e:
                if attempt < self.max_retries:
                    delay = self.base_delay * (2 ** attempt) + random.uniform(0, 1)
                    logger.warning(f"Enhanced AI classification attempt {attempt + 1} failed: {e}. Retrying in {delay:.2f}s...")
                    time.sleep(delay)
                else:
                    logger.error(f"Enhanced AI classification failed after {self.max_retries + 1} attempts: {e}")
        
        return StandardErrorType.OTHER, "AI classification failed after retries", 0.1
    
    def _build_enhanced_prompt(self, log_data: Dict, error_message: str = None) -> str:
        """æ„å»ºåŸºäºå®Œæ•´æ—¥å¿—çš„å¢å¼ºæç¤º"""
        
        task_info = log_data.get('task_instance', {})
        conversation = log_data.get('conversation_history', [])
        required_tools = task_info.get('required_tools', [])
        
        # åˆ†æå¯¹è¯å†å²
        conversation_summary = self._analyze_conversation(conversation)
        
        # åˆ†æå·¥å…·æ‰§è¡Œæƒ…å†µ
        execution_analysis = self._analyze_tool_execution(conversation, required_tools)
        
        # æ·»åŠ æ‰§è¡Œæ—¶é—´å’Œè¶…æ—¶ç›¸å…³ä¿¡æ¯
        execution_time = log_data.get('execution_time', 0)
        error_type = log_data.get('error_type', '')
        
        # æ„å»ºæ‰§è¡Œæ—¶é—´åˆ†æ
        execution_time_analysis = self._analyze_execution_time(execution_time, error_type)
        
        prompt = f"""You are an expert AI workflow analyzer. Analyze this complete interaction log to classify the PRIMARY agent error.

**TASK CONTEXT:**
- Task: {task_info.get('description', 'Unknown task')}
- Required Tools: {', '.join(required_tools)}
- Error Message: {error_message or 'No explicit error message'}

**EXECUTION TIME ANALYSIS:**
{execution_time_analysis}

**INTERACTION ANALYSIS:**
{conversation_summary}

**TOOL EXECUTION ANALYSIS:**
{execution_analysis}

**COMPLETE CONVERSATION LOG:**
```json
{json.dumps(conversation, indent=2)}
```

**CLASSIFY INTO ONE OF THESE 5 ERROR TYPES:**

1. **timeout_errors** - Test execution exceeded time limit
   - Total execution time â‰¥ 600 seconds (10 minutes)
   - Agent was terminated due to timeout
   - Look for execution_time â‰¥ 600s or error_type='timeout'

2. **tool_selection_errors** - Agent chose WRONG tool
   - Selected inappropriate tool when correct tool was available
   - Used wrong tool for the task requirements
   
3. **parameter_config_errors** - Agent provided WRONG parameters  
   - Wrong parameters or arguments by agent
   - Missing required parameters
   
4. **sequence_order_errors** - Agent executed tools in WRONG ORDER
   - Ignored logical workflow dependencies
   - Executed tools out of sequence
   
5. **dependency_errors** - Agent failed DEPENDENCY requirements
   - Used Tool B when Tool A wasn't ready
   - Workflow design ignored dependencies

**IMPORTANT RULES:**
- If the issue is environment/API problems (timeouts, network errors) â†’ classify as "other_errors"
- If agent made correct decisions but tools failed â†’ classify as "other_errors"  
- Only classify as agent error if the AGENT made wrong decisions
- Focus on the PRIMARY agent decision error

**Response Format (JSON only):**
{{
  "category": "exact_category_name",
  "reason": "specific agent decision error identified from the complete log analysis",
  "confidence": 0.85
}}"""
        
        return prompt
    
    def _analyze_conversation(self, conversation: List[Dict]) -> str:
        """åˆ†æå¯¹è¯å†å²"""
        if not conversation:
            return "- No conversation history available"
        
        analysis = []
        tool_calls = []
        format_issues = []
        
        for entry in conversation:
            content = entry.get('content', '')
            turn = entry.get('turn', 0)
            
            if '<tool_call>' in content:
                tool_calls.append(f"Turn {turn}: {content}")
            
            if entry.get('format_issue') or entry.get('type') == 'format_help':
                format_issues.append(f"Turn {turn}: Format issue detected")
        
        analysis.append(f"- Total conversation turns: {len(conversation)}")
        
        if tool_calls:
            analysis.append(f"- Tool call attempts: {len(tool_calls)}")
            analysis.extend(f"  {call}" for call in tool_calls[:3])  # Show first 3
        else:
            analysis.append("- No tool call attempts found")
        
        if format_issues:
            analysis.append(f"- Format issues detected: {len(format_issues)}")
            analysis.extend(f"  {issue}" for issue in format_issues)
        
        return "\n".join(analysis)
    
    def _analyze_tool_execution(self, conversation: List[Dict], required_tools: List[str]) -> str:
        """åˆ†æå·¥å…·æ‰§è¡Œæƒ…å†µ"""
        executed_tools = []
        successful_tools = []
        
        for entry in conversation:
            if entry.get('role') == 'user' and 'âœ…' in entry.get('content', ''):
                # æˆåŠŸæ‰§è¡Œçš„å·¥å…·
                content = entry.get('content', '')
                for tool in required_tools:
                    if tool in content:
                        executed_tools.append(tool)
                        successful_tools.append(tool)
                        break
        
        analysis = []
        analysis.append(f"- Required tools: {len(required_tools)} ({', '.join(required_tools)})")
        analysis.append(f"- Successfully executed: {len(successful_tools)} ({', '.join(successful_tools)})")
        
        missing_tools = set(required_tools) - set(successful_tools)
        if missing_tools:
            analysis.append(f"- Missing tools: {', '.join(missing_tools)}")
        
        # æ£€æŸ¥æ‰§è¡Œé¡ºåº
        if len(successful_tools) > 1:
            expected_order = required_tools[:len(successful_tools)]
            if successful_tools != expected_order:
                analysis.append(f"- Sequence issue: Expected {expected_order}, Got {successful_tools}")
        
        return "\n".join(analysis)
    
    def _analyze_execution_time(self, execution_time: float, error_type: str) -> str:
        """åˆ†ææ‰§è¡Œæ—¶é—´å’Œè¶…æ—¶æƒ…å†µ"""
        analysis = []
        
        # åŸºæœ¬æ‰§è¡Œæ—¶é—´ä¿¡æ¯
        analysis.append(f"- Total execution time: {execution_time:.1f} seconds")
        
        if error_type:
            analysis.append(f"- Error type indicator: '{error_type}'")
        
        # è¶…æ—¶åˆ¤æ–­
        if execution_time >= 600:
            analysis.append(f"âš ï¸ TIMEOUT DETECTED: Execution time ({execution_time:.1f}s) â‰¥ 600s threshold")
            analysis.append("  â†’ This strongly indicates a timeout error")
            analysis.append("  â†’ Agent likely exceeded maximum allowed execution time")
        elif execution_time >= 500:
            analysis.append(f"âš ï¸ NEAR TIMEOUT: Execution time ({execution_time:.1f}s) approaching 600s limit")
            analysis.append("  â†’ Consider if this indicates performance issues")
        elif execution_time >= 300:
            analysis.append(f"ğŸ“Š LONG EXECUTION: Execution time ({execution_time:.1f}s) is relatively long")
            analysis.append("  â†’ Check if agent had difficulty completing task")
        else:
            analysis.append(f"âœ… NORMAL EXECUTION: Execution time ({execution_time:.1f}s) within normal range")
        
        # é”™è¯¯ç±»å‹å»ºè®®
        if error_type == 'timeout' or execution_time >= 600:
            analysis.append("")
            analysis.append("ğŸ¯ CLASSIFICATION GUIDANCE:")
            analysis.append("   â†’ Strong evidence for 'timeout_errors' classification")
            analysis.append("   â†’ Agent was likely terminated due to time limit")
        
        return "\n".join(analysis)
    
    def _parse_enhanced_response(self, response_text: str) -> Tuple[StandardErrorType, str, float]:
        """è§£æå¢å¼ºAIå“åº”"""
        try:
            # æå–JSON
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0].strip()
            elif "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                json_str = response_text[start:end]
            else:
                json_str = response_text.strip()
            
            result = json.loads(json_str)
            
            if isinstance(result, str):
                # æ–‡æœ¬å“åº”å¤„ç†
                if "tool_selection" in result.lower():
                    return StandardErrorType.TOOL_SELECTION, "Inferred from text response", 0.6
                elif "parameter" in result.lower():
                    return StandardErrorType.PARAMETER_CONFIG, "Inferred from text response", 0.6
                elif "sequence" in result.lower():
                    return StandardErrorType.SEQUENCE_ORDER, "Inferred from text response", 0.6
                elif "dependency" in result.lower():
                    return StandardErrorType.DEPENDENCY, "Inferred from text response", 0.6
                else:
                    return StandardErrorType.OTHER, "Text response - could not classify", 0.3
            
            if not isinstance(result, dict):
                return StandardErrorType.OTHER, "Invalid JSON structure", 0.1
            
            category_name = result.get('category', 'other_errors')
            reason = result.get('reason', 'No reason provided')
            confidence = float(result.get('confidence', 0.5))
            
            try:
                category = StandardErrorType(category_name)
            except ValueError:
                logger.warning(f"Unknown category from AI: {category_name}")
                category = StandardErrorType.OTHER
                confidence = 0.2
            
            return category, reason, confidence
            
        except Exception as e:
            logger.error(f"Failed to parse enhanced AI response: {e}")
            return StandardErrorType.OTHER, f"Parse error: {str(e)}", 0.1
    
    def _fallback_classify_from_log(self, log_data: Dict, error_message: str = None) -> Tuple[StandardErrorType, str, float]:
        """åŸºäºå®Œæ•´æ—¥å¿—çš„åå¤‡åˆ†ç±»"""
        conversation = log_data.get('conversation_history', [])
        task_info = log_data.get('task_instance', {})
        required_tools = task_info.get('required_tools', [])
        
        # é¦–å…ˆæ£€æŸ¥è¶…æ—¶ï¼ˆä¸quick_rule_checkä¿æŒä¸€è‡´ï¼‰
        execution_time = log_data.get('execution_time', 0)
        error_type = log_data.get('error_type', '')
        
        if execution_time >= 600 or error_type == 'timeout':
            return StandardErrorType.TIMEOUT, f"Fallback: Test timeout - execution time: {execution_time}s", 0.9
        
        # æ£€æŸ¥æ ¼å¼é—®é¢˜
        has_format_help = any(
            entry.get('type') == 'format_help' 
            for entry in conversation
        )
        
        if has_format_help:
            return StandardErrorType.TOOL_CALL_FORMAT, "Format help detected in conversation log", 0.8
        
        # åˆ†æå·¥å…·æ‰§è¡Œæƒ…å†µ
        successful_tools = []
        for entry in conversation:
            if entry.get('role') == 'user' and 'âœ…' in entry.get('content', ''):
                for tool in required_tools:
                    if tool in entry.get('content', ''):
                        successful_tools.append(tool)
                        break
        
        # æ£€æŸ¥å·¥å…·è¦†ç›–ç‡
        if required_tools:
            coverage = len(set(successful_tools)) / len(required_tools)
            if coverage < 1.0:
                missing = set(required_tools) - set(successful_tools)
                return StandardErrorType.TOOL_SELECTION, f"Missing required tools: {', '.join(missing)}", 0.6
        
        # æ£€æŸ¥æ‰§è¡Œé¡ºåº
        if len(successful_tools) > 1:
            expected_order = required_tools[:len(successful_tools)]
            if successful_tools != expected_order:
                return StandardErrorType.SEQUENCE_ORDER, f"Wrong execution order", 0.6
        
        return StandardErrorType.OTHER, "Could not classify from log analysis", 0.3


def test_enhanced_classifier():
    """æµ‹è¯•å¢å¼ºçš„åˆ†ç±»å™¨"""
    classifier = EnhancedAIClassifier()
    
    # æ¨¡æ‹Ÿä¸€ä¸ªæœ‰æ ¼å¼é—®é¢˜çš„æ—¥å¿—
    sample_log = {
        'task_instance': {
            'description': 'Process data with three tools',
            'required_tools': ['tool1', 'tool2', 'tool3']
        },
        'conversation_history': [
            {'role': 'assistant', 'content': 'I will complete the task', 'turn': 1},
            {'role': 'user', 'content': 'TOOL CALL FORMAT HELP - Use <tool_call>tool_name</tool_call>', 'turn': 1, 'type': 'format_help'},
            {'role': 'assistant', 'content': 'tool1 execute', 'turn': 2, 'format_issue': True}
        ]
    }
    
    category, reason, confidence = classifier.classify_error_from_log(sample_log)
    print(f"Test result: {category.value} - {reason} (confidence: {confidence:.2f})")


if __name__ == "__main__":
    test_enhanced_classifier()
