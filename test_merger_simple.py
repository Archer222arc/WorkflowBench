#!/usr/bin/env python3
"""
æµ‹è¯•ResultMergerçš„ç®€å•è„šæœ¬
"""

import os
import json
import time
import threading
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['USE_RESULT_COLLECTOR'] = 'true'
os.environ['STORAGE_FORMAT'] = 'json'

from result_merger import ResultMerger, start_auto_merge, stop_auto_merge, force_merge

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶"""
    temp_dir = Path("temp_results")
    temp_dir.mkdir(exist_ok=True)
    
    models = ['DeepSeek-V3-0324', 'qwen2.5-72b-instruct', 'gpt-4o-mini']
    created_files = []
    
    for i in range(2):
        for model in models:
            # åˆ›å»ºæµ‹è¯•ç»“æœ
            result = {
                'model': model,
                'results': []
            }
            
            # æ·»åŠ 3ä¸ªæµ‹è¯•ç»“æœ
            for j in range(3):
                test_result = {
                    'model': model,
                    'task_type': 'simple_task',
                    'prompt_type': 'optimal',
                    'difficulty': 'easy',
                    'success': True if j % 2 == 0 else False,
                    'execution_time': 30 + j * 10,
                    'turns': 10,
                    'tool_calls': 5,
                    'workflow_score': 0.8,
                    'phase2_score': 0.85,
                    'quality_score': 0.82,
                    'final_score': 0.85,
                    'tool_success_rate': 0.8,
                    'tool_coverage_rate': 0.9,
                    'timestamp': time.time()
                }
                result['results'].append(test_result)
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            filename = f'test_{model}_{i}_{int(time.time()*1000)}.json'
            filepath = temp_dir / filename
            with open(filepath, 'w') as f:
                json.dump(result, f, indent=2)
            created_files.append(filename)
            print(f'  âœ… åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {filename}')
        
        time.sleep(1)  # ç¨å¾®é—´éš”ä¸€ä¸‹
    
    return created_files

def check_database():
    """æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"""
    db_path = Path('pilot_bench_cumulative_results/master_database.json')
    if db_path.exists():
        with open(db_path, 'r') as f:
            db = json.load(f)
        
        print('\nğŸ“Š æ•°æ®åº“çŠ¶æ€:')
        models = db.get('models', {})
        total_tests = 0
        for model_name in models:
            # ä»æ•´ä¸ªæ¨¡å‹æ•°æ®ä¸­ç»Ÿè®¡æ€»æµ‹è¯•æ•°
            model_data = models[model_name]
            model_total = 0
            
            # éå†æ‰€æœ‰å±‚çº§ç»Ÿè®¡
            if 'by_prompt_type' in model_data:
                for prompt_type, prompt_data in model_data['by_prompt_type'].items():
                    if 'by_tool_success_rate' in prompt_data:
                        for rate, rate_data in prompt_data['by_tool_success_rate'].items():
                            if 'by_difficulty' in rate_data:
                                for diff, diff_data in rate_data['by_difficulty'].items():
                                    if 'by_task_type' in diff_data:
                                        for task_type, task_data in diff_data['by_task_type'].items():
                                            model_total += task_data.get('total', 0)
            
            if model_total > 0:
                print(f'  - {model_name}: {model_total} tests')
                total_tests += model_total
        
        print(f'  ğŸ“ˆ æ€»è®¡: {total_tests} tests')
    else:
        print('âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨')

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æµ‹è¯•ResultMergeråˆå¹¶æœºåˆ¶")
    print("=" * 50)
    
    # æ¸…ç†æ—§æ–‡ä»¶
    print("\n1. æ¸…ç†æ—§çš„ä¸´æ—¶æ–‡ä»¶...")
    temp_dir = Path("temp_results")
    if temp_dir.exists():
        for f in temp_dir.glob("*.json"):
            f.unlink()
        print("  âœ… æ¸…ç†å®Œæˆ")
    
    # æ£€æŸ¥åˆå§‹æ•°æ®åº“çŠ¶æ€
    print("\n2. åˆå§‹æ•°æ®åº“çŠ¶æ€:")
    check_database()
    
    # å¯åŠ¨åˆå¹¶å™¨
    print("\n3. å¯åŠ¨ResultMerger...")
    merger = start_auto_merge(interval=3)  # æ¯3ç§’æ£€æŸ¥ä¸€æ¬¡
    print(f"  âœ… Mergerå·²å¯åŠ¨ï¼Œé—´éš”{merger.merge_interval}ç§’")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    print("\n4. åˆ›å»ºæµ‹è¯•æ•°æ®...")
    files = create_test_data()
    print(f"  ğŸ“ åˆ›å»ºäº†{len(files)}ä¸ªæµ‹è¯•æ–‡ä»¶")
    
    # ç­‰å¾…åˆå¹¶
    print("\n5. ç­‰å¾…åˆå¹¶å¤„ç†...")
    for i in range(3):
        time.sleep(3)
        print(f"  â° ç­‰å¾…ä¸­... {(i+1)*3}ç§’")
    
    # å¼ºåˆ¶åˆå¹¶å‰©ä½™æ–‡ä»¶
    print("\n6. å¼ºåˆ¶åˆå¹¶å‰©ä½™æ–‡ä»¶...")
    count = force_merge()
    print(f"  âœ… åˆå¹¶äº†{count}ä¸ªæ–‡ä»¶")
    
    # åœæ­¢åˆå¹¶å™¨
    print("\n7. åœæ­¢åˆå¹¶å™¨...")
    stop_auto_merge()
    print("  âœ… Mergerå·²åœæ­¢")
    
    # æ£€æŸ¥æœ€ç»ˆæ•°æ®åº“çŠ¶æ€
    print("\n8. æœ€ç»ˆæ•°æ®åº“çŠ¶æ€:")
    check_database()
    
    # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶
    temp_files = list(temp_dir.glob("*.json"))
    print(f"\n9. å‰©ä½™ä¸´æ—¶æ–‡ä»¶: {len(temp_files)}ä¸ª")
    if temp_files:
        for f in temp_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - {f.name}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()