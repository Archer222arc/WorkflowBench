#!/bin/bash

# 5.1 åŸºå‡†æµ‹è¯•é‡æµ‹ä¸“ç”¨è„šæœ¬
# åŸºäºtest_5_3_custom.shä¿®æ”¹ï¼Œä¸“é—¨ç”¨äºé‡æµ‹optimal promptçš„æ¨¡å‹
# è§£å†³DeepSeek-R1åœ¨optimalé…ç½®ä¸‹è¡¨ç°å¼‚å¸¸å·®çš„é—®é¢˜

set -euo pipefail

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# é…ç½®
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_DIR="$SCRIPT_DIR/logs"
mkdir -p "$LOG_DIR"

TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="$LOG_DIR/test_5_1_retest_${TIMESTAMP}.log"

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1" | tee -a "$LOG_FILE"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1" | tee -a "$LOG_FILE"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$LOG_FILE"
}

# ç¯å¢ƒå˜é‡è®¾ç½® - ä¸¥æ ¼åŒ¹é…5.1åŸºå‡†æµ‹è¯•çš„é…ç½®
export USE_RESULT_COLLECTOR=true
export STORAGE_FORMAT=json
export MODEL_TYPE="opensource"  # é»˜è®¤å¼€æºæ¨¡å‹ç±»å‹
export NUM_INSTANCES=20
export RATE_MODE="fixed"
export USE_PARTIAL_LOADING=true
export TASK_LOAD_COUNT=20
export SKIP_MODEL_LOADING=true
export ULTRA_PARALLEL_MODE=true  # å¯ç”¨è¶…å¹¶è¡Œæ¨¡å¼
export CONSERVATIVE_MODE=false   # ä¸ä½¿ç”¨ä¿å®ˆæ¨¡å¼
export CUSTOM_WORKERS=50
export MAX_PARALLEL_PROCESSES=10  # æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°

# 5.1åŸºå‡†æµ‹è¯•ä¸“ç”¨é…ç½®
PROMPT_TYPE="optimal"      # å›ºå®šä¸ºoptimal prompt
DIFFICULTY="easy"          # å›ºå®šä¸ºeasyéš¾åº¦
TOOL_SUCCESS_RATE="0.8"   # å›ºå®šä¸º0.8å·¥å…·æˆåŠŸç‡

# æ¿€æ´»condaç¯å¢ƒ
if [ -f ~/miniconda3/bin/activate ]; then
    source ~/miniconda3/bin/activate
    log_info "âœ… å·²æ¿€æ´»condaç¯å¢ƒ: $(which python)"
else
    log_warning "âš ï¸ æœªæ‰¾åˆ°condaç¯å¢ƒï¼Œä½¿ç”¨ç³»ç»ŸPython"
fi

log_info "=== 5.1 åŸºå‡†æµ‹è¯•é‡æµ‹è„šæœ¬å¯åŠ¨ ==="
log_info "æ—¶é—´æˆ³: $TIMESTAMP"
log_info "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
log_info "æµ‹è¯•é…ç½®: $PROMPT_TYPE prompt, $DIFFICULTY éš¾åº¦, $TOOL_SUCCESS_RATE å·¥å…·æˆåŠŸç‡"

# æ£€æŸ¥å¿…éœ€æ–‡ä»¶
check_files() {
    local required_files=(
        "./ultra_parallel_runner.py"
        "./smart_batch_runner.py" 
        "./config/config.json"
        "./result_collector.py"
    )
    
    for file in "${required_files[@]}"; do
        if [[ ! -f "$file" ]]; then
            log_error "ç¼ºå°‘å¿…éœ€æ–‡ä»¶: $file"
            exit 1
        fi
    done
    log_success "æ‰€æœ‰å¿…éœ€æ–‡ä»¶æ£€æŸ¥å®Œæˆ"
}

# æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
show_model_options() {
    echo -e "\n${CYAN}ğŸ¤– é€‰æ‹©é‡æµ‹æ¨¡å‹:${NC}"
    echo "1) DeepSeek-R1-0528 (ä¸»è¦ç›®æ ‡)"
    echo "2) æ‰€æœ‰å¼€æºæ¨¡å‹"
    echo "3) æ‰€æœ‰æ¨¡å‹ (å¼€æº+é—­æº)"
    echo "4) è‡ªå®šä¹‰æ¨¡å‹åˆ—è¡¨"
    echo
}

# è·å–æ¨¡å‹é€‰æ‹©
get_model_choice() {
    while true; do
        show_model_options
        read -p "è¯·é€‰æ‹©è¦é‡æµ‹çš„æ¨¡å‹ (1-4): " model_choice
        
        case $model_choice in
            1)
                model_type="single"
                single_model="DeepSeek-R1-0528"
                export MODEL_TYPE="opensource"
                log_info "é€‰æ‹©é‡æµ‹ DeepSeek-R1-0528"
                break
                ;;
            2)
                model_type="opensource"
                export MODEL_TYPE="opensource"
                log_info "é€‰æ‹©é‡æµ‹æ‰€æœ‰å¼€æºæ¨¡å‹"
                break
                ;;
            3)
                model_type="all"
                export MODEL_TYPE="all"
                log_info "é€‰æ‹©é‡æµ‹æ‰€æœ‰æ¨¡å‹"
                break
                ;;
            4)
                echo -e "\n${CYAN}å¯ç”¨æ¨¡å‹:${NC}"
                echo "å¼€æº: DeepSeek-V3-0324, DeepSeek-R1-0528, Llama-3.3-70B-Instruct"
                echo "     qwen2.5-72b-instruct, qwen2.5-32b-instruct, qwen2.5-14b-instruct"
                echo "     qwen2.5-7b-instruct, qwen2.5-3b-instruct"
                echo "é—­æº: gpt-4o-mini, gpt-5-mini, o3-0416-global, gemini-2.5-flash-06-17, kimi-k2"
                echo
                read -p "è¯·è¾“å…¥æ¨¡å‹å (ç”¨ç©ºæ ¼åˆ†éš”å¤šä¸ª): " custom_models
                model_type="custom"
                custom_model_list="$custom_models"
                # åˆ¤æ–­ç¬¬ä¸€ä¸ªæ¨¡å‹çš„ç±»å‹
                first_model=$(echo $custom_models | awk '{print $1}')
                if [[ "$first_model" == *"DeepSeek"* ]] || [[ "$first_model" == *"Llama"* ]] || [[ "$first_model" == *"qwen"* ]]; then
                    export MODEL_TYPE="opensource"
                else
                    export MODEL_TYPE="closed_source"
                fi
                log_info "é€‰æ‹©è‡ªå®šä¹‰æ¨¡å‹: $custom_models (ç±»å‹: $MODEL_TYPE)"
                break
                ;;
            *)
                log_warning "æ— æ•ˆé€‰æ‹©: $model_choiceï¼Œè¯·é‡æ–°é€‰æ‹©"
                ;;
        esac
    done
}

# è¿è¡Œå•ä¸ªæ¨¡å‹çš„æµ‹è¯•
run_single_model_test() {
    local model_name="$1"
    
    log_info "ğŸš€ å¼€å§‹é‡æµ‹ - æ¨¡å‹: $model_name, é…ç½®: $PROMPT_TYPE/$DIFFICULTY/$TOOL_SUCCESS_RATE"
    
    local sanitized_model=$(echo "$model_name" | tr '.' '_' | tr '-' '_')
    local test_log="$LOG_DIR/ultra_parallel_${sanitized_model}_${PROMPT_TYPE}_retest_${TIMESTAMP}.log"
    
    # æ„å»ºå‘½ä»¤ - ä½¿ç”¨5.1åŸºå‡†æµ‹è¯•çš„æ ‡å‡†é…ç½®
    # å¯¹äºqwenæ¨¡å‹ï¼Œå¼ºåˆ¶ä½¿ç”¨--max-workers 1é¿å…é™æµ
    local workers_param=""
    if [[ "$model_name" == *"qwen"* ]]; then
        workers_param="--max-workers 1"
        log_info "Qwenæ¨¡å‹æ£€æµ‹ï¼Œä½¿ç”¨é™æµé…ç½®: max-workers=1"
    else
        workers_param="--max-workers $CUSTOM_WORKERS"
        log_info "Azureæ¨¡å‹æ£€æµ‹ï¼Œä½¿ç”¨é«˜å¹¶å‘é…ç½®: max-workers=$CUSTOM_WORKERS"
    fi
    
    local python_cmd=(
        "python3" "./ultra_parallel_runner.py"
        "--model" "$model_name"
        "--prompt-types" "$PROMPT_TYPE"      # optimal
        "--difficulty" "$DIFFICULTY"         # easy
        "--task-types" "all"                 # æ‰€æœ‰5ç§ä»»åŠ¡ç±»å‹
        "--num-instances" "20"
        "--rate-mode" "fixed"
        "--tool-success-rate" "$TOOL_SUCCESS_RATE"  # 0.8
        $workers_param
    )
    
    log_info "æ‰§è¡Œå‘½ä»¤: USE_RESULT_COLLECTOR='$USE_RESULT_COLLECTOR' STORAGE_FORMAT='$STORAGE_FORMAT' KMP_DUPLICATE_LIB_OK=TRUE ${python_cmd[*]}"
    
    # è¿è¡Œæµ‹è¯•
    echo "=== 5.1åŸºå‡†æµ‹è¯•é‡æµ‹å¼€å§‹æ—¶é—´: $(date) ===" | tee "$test_log"
    echo "=== ç¯å¢ƒå˜é‡ ===" | tee -a "$test_log"
    echo "USE_RESULT_COLLECTOR=$USE_RESULT_COLLECTOR" | tee -a "$test_log"
    echo "STORAGE_FORMAT=$STORAGE_FORMAT" | tee -a "$test_log"
    echo "PROMPT_TYPE=$PROMPT_TYPE" | tee -a "$test_log"
    echo "DIFFICULTY=$DIFFICULTY" | tee -a "$test_log"
    echo "TOOL_SUCCESS_RATE=$TOOL_SUCCESS_RATE" | tee -a "$test_log"
    echo "CUSTOM_WORKERS=$CUSTOM_WORKERS" | tee -a "$test_log"
    echo "=== å‘½ä»¤æ‰§è¡Œ ===" | tee -a "$test_log"
    
    # æ‰§è¡Œæµ‹è¯•å‘½ä»¤
    USE_RESULT_COLLECTOR="$USE_RESULT_COLLECTOR" STORAGE_FORMAT="$STORAGE_FORMAT" KMP_DUPLICATE_LIB_OK=TRUE "${python_cmd[@]}" 2>&1 | tee -a "$test_log"
    exit_code=${PIPESTATUS[0]}
    
    echo "=== æµ‹è¯•ç»“æŸæ—¶é—´: $(date) ===" | tee -a "$test_log"
    echo "=== é€€å‡ºç : $exit_code ===" | tee -a "$test_log"
    
    # æ£€æŸ¥ç»“æœ
    if [[ $exit_code -eq 0 ]]; then
        log_success "âœ… æ¨¡å‹ $model_name 5.1åŸºå‡†æµ‹è¯•é‡æµ‹å®Œæˆ"
        log_info "è¯¦ç»†æ—¥å¿—: $test_log"
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤§å°
        if [[ -f "$test_log" ]]; then
            local log_size=$(wc -l < "$test_log")
            log_info "æ—¥å¿—è¡Œæ•°: $log_size"
        fi
        
        # æ˜¾ç¤ºæµ‹è¯•å®Œæˆåçš„æ•°æ®æå–
        log_info "æ­£åœ¨æå–é‡æµ‹åçš„æ•°æ®..."
        python3 extract_experiment_results.py 5.1
        
        return 0
    else
        log_error "âŒ æ¨¡å‹ $model_name 5.1åŸºå‡†æµ‹è¯•é‡æµ‹å¤±è´¥ (é€€å‡ºç : $exit_code)"
        log_error "æ£€æŸ¥æ—¥å¿—: $test_log"
        
        # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
        if [[ -f "$test_log" ]]; then
            log_error "=== æœ€å50è¡Œæ—¥å¿—å†…å®¹ ==="
            tail -50 "$test_log" | while IFS= read -r line; do
                log_error "  $line"
            done
            
            # æ£€æŸ¥Pythoné”™è¯¯
            if grep -q "Traceback\|Error\|Exception" "$test_log"; then
                log_error "=== Pythoné”™è¯¯traceback ==="
                grep -A 20 -B 5 "Traceback\|Error\|Exception" "$test_log" | while IFS= read -r line; do
                    log_error "  $line"
                done
            fi
        fi
        
        return 1
    fi
}

# è¿è¡Œé€‰å®šæ¨¡å‹çš„æµ‹è¯•
run_test() {
    local model_list="$1"
    
    log_info "ğŸš€ å¼€å§‹5.1åŸºå‡†æµ‹è¯•é‡æµ‹ - optimal prompt"
    
    local failed_models=()
    local successful_models=()
    
    # å°†æ¨¡å‹å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°ç»„
    local models=($model_list)
    local total_models=${#models[@]}
    local current=0
    
    for model in "${models[@]}"; do
        ((current++))
        log_info "è¿›åº¦: $current/$total_models - é‡æµ‹æ¨¡å‹: $model"
        
        if run_single_model_test "$model"; then
            successful_models+=("$model")
        else
            failed_models+=("$model")
        fi
        
        # æ¨¡å‹é—´éš”æ—¶é—´
        if [[ $current -lt $total_models ]]; then
            log_info "ç­‰å¾… 5 ç§’åæµ‹è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹..."
            sleep 5
        fi
    done
    
    # æŠ¥å‘Šç»“æœ
    log_info "5.1åŸºå‡†æµ‹è¯•é‡æµ‹å®Œæˆï¼š"
    log_success "æˆåŠŸ: ${#successful_models[@]}/${total_models} æ¨¡å‹"
    
    if [[ ${#successful_models[@]} -gt 0 ]]; then
        log_success "æˆåŠŸçš„æ¨¡å‹: ${successful_models[*]}"
    fi
    
    if [[ ${#failed_models[@]} -gt 0 ]]; then
        log_warning "å¤±è´¥çš„æ¨¡å‹: ${failed_models[*]}"
        return 1
    else
        log_success "æ‰€æœ‰æ¨¡å‹éƒ½é‡æµ‹æˆåŠŸï¼"
        return 0
    fi
}

# è·å–æ¨¡å‹åˆ—è¡¨
get_model_list() {
    case $model_type in
        "single")
            echo "$single_model"
            ;;
        "opensource")
            echo "DeepSeek-V3-0324 DeepSeek-R1-0528 Llama-3.3-70B-Instruct qwen2.5-72b-instruct qwen2.5-32b-instruct qwen2.5-14b-instruct qwen2.5-7b-instruct qwen2.5-3b-instruct"
            ;;
        "all")
            echo "DeepSeek-V3-0324 DeepSeek-R1-0528 Llama-3.3-70B-Instruct qwen2.5-72b-instruct qwen2.5-32b-instruct qwen2.5-14b-instruct qwen2.5-7b-instruct qwen2.5-3b-instruct gpt-4o-mini gpt-5-mini o3-0416-global gemini-2.5-flash-06-17 kimi-k2"
            ;;
        "custom")
            echo "$custom_model_list"
            ;;
    esac
}

# æ¸…ç†æ—§æ•°æ® (å¯é€‰)
cleanup_old_data() {
    local model_name="$1"
    
    echo -e "\n${YELLOW}ğŸ§¹ æ•°æ®æ¸…ç†é€‰é¡¹:${NC}"
    echo "1) ä¿ç•™ç°æœ‰æ•°æ®ï¼Œè¿½åŠ æ–°æµ‹è¯•ç»“æœ"
    echo "2) æ¸…ç†æŒ‡å®šæ¨¡å‹çš„optimalæ•°æ®ï¼Œé‡æ–°å¼€å§‹"
    echo "3) è·³è¿‡æ¸…ç†ï¼Œç›´æ¥å¼€å§‹æµ‹è¯•"
    echo
    
    read -p "è¯·é€‰æ‹©æ•°æ®å¤„ç†æ–¹å¼ (1-3): " cleanup_choice
    
    case $cleanup_choice in
        1)
            log_info "ä¿ç•™ç°æœ‰æ•°æ®ï¼Œå°†è¿½åŠ æ–°çš„æµ‹è¯•ç»“æœ"
            ;;
        2)
            log_warning "å°†æ¸…ç†æ¨¡å‹ $model_name çš„ optimal æ•°æ®"
            read -p "ç¡®è®¤æ¸…ç†? è¿™å°†åˆ é™¤è¯¥æ¨¡å‹æ‰€æœ‰optimalæµ‹è¯•æ•°æ® [y/N]: " confirm_cleanup
            if [[ "$confirm_cleanup" =~ ^[Yy]$ ]]; then
                # åˆ›å»ºæ•°æ®æ¸…ç†è„šæœ¬è°ƒç”¨
                python3 -c "
import json
from pathlib import Path

# å¤‡ä»½å¹¶æ¸…ç†æŒ‡å®šæ¨¡å‹çš„optimalæ•°æ®
db_path = Path('pilot_bench_cumulative_results/master_database.json')
with open(db_path, 'r') as f:
    db = json.load(f)

model_name = '$model_name'
if model_name in db['models']:
    model_data = db['models'][model_name]
    if 'by_prompt_type' in model_data and 'optimal' in model_data['by_prompt_type']:
        # æ¸…ç†optimalæ•°æ®
        del model_data['by_prompt_type']['optimal']
        print(f'âœ… å·²æ¸…ç†æ¨¡å‹ {model_name} çš„ optimal æ•°æ®')
        
        # ä¿å­˜æ¸…ç†åçš„æ•°æ®åº“
        with open(db_path, 'w') as f:
            json.dump(db, f, indent=2, ensure_ascii=False)
        print(f'âœ… æ•°æ®åº“å·²æ›´æ–°')
    else:
        print(f'âš ï¸ æ¨¡å‹ {model_name} æ²¡æœ‰ optimal æ•°æ®éœ€è¦æ¸…ç†')
else:
    print(f'âŒ æ¨¡å‹ {model_name} ä¸å­˜åœ¨äºæ•°æ®åº“ä¸­')
"
                log_success "âœ… æ•°æ®æ¸…ç†å®Œæˆ"
            else
                log_info "å–æ¶ˆæ¸…ç†ï¼Œä¿ç•™ç°æœ‰æ•°æ®"
            fi
            ;;
        3)
            log_info "è·³è¿‡æ¸…ç†ï¼Œç›´æ¥å¼€å§‹æµ‹è¯•"
            ;;
        *)
            log_warning "æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è·³è¿‡æ¸…ç†"
            ;;
    esac
}

# æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€
show_current_data() {
    log_info "å½“å‰æ•°æ®åº“çŠ¶æ€æ£€æŸ¥..."
    python3 -c "
import json
from pathlib import Path

db_path = Path('pilot_bench_cumulative_results/master_database.json')
if db_path.exists():
    with open(db_path, 'r') as f:
        db = json.load(f)
    
    print('ğŸ“Š å½“å‰5.1åŸºå‡†æµ‹è¯•æ•°æ®çŠ¶æ€:')
    models = ['DeepSeek-V3-0324', 'DeepSeek-R1-0528', 'Llama-3.3-70B-Instruct']
    
    for model in models:
        if model in db['models']:
            model_data = db['models'][model]
            try:
                optimal_data = model_data['by_prompt_type']['optimal']['by_tool_success_rate']['0.8']['by_difficulty']['easy']
                total_tests = sum(task_data.get('total', 0) for task_data in optimal_data['by_task_type'].values())
                total_success = sum(task_data.get('success', 0) for task_data in optimal_data['by_task_type'].values())
                success_rate = total_success / total_tests * 100 if total_tests > 0 else 0
                print(f'  {model}: {total_tests} æµ‹è¯•, {success_rate:.1f}% æˆåŠŸç‡')
            except KeyError:
                print(f'  {model}: âŒ ç¼ºå°‘optimalæ•°æ®')
        else:
            print(f'  {model}: âŒ æ¨¡å‹ä¸å­˜åœ¨')
"
}

# ä¸»å‡½æ•°
main() {
    log_info "æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–æ–‡ä»¶..."
    check_files
    
    log_info "æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€..."
    show_current_data
    
    log_info "è·å–ç”¨æˆ·é€‰æ‹©..."
    get_model_choice
    
    local model_list=$(get_model_list)
    local models=($model_list)
    local total_models=${#models[@]}
    
    log_info "å¼€å§‹æ‰§è¡Œ 5.1 åŸºå‡†æµ‹è¯•é‡æµ‹"
    log_info "æµ‹è¯•æ¨¡å‹æ•°: $total_models"
    log_info "é…ç½®: $PROMPT_TYPE prompt, $DIFFICULTY éš¾åº¦, $TOOL_SUCCESS_RATE å·¥å…·æˆåŠŸç‡"
    log_info "æ¨¡å‹é…ç½®: $model_type"
    log_info "å¹¶å‘é…ç½®: $CUSTOM_WORKERS workers, $MAX_PARALLEL_PROCESSES processes"
    log_info "å­˜å‚¨é…ç½®: JSON + ResultCollector"
    
    echo -e "\n${GREEN}ğŸ¯ é‡æµ‹é…ç½®ç¡®è®¤:${NC}"
    echo "- æµ‹è¯•ç±»å‹: 5.1 åŸºå‡†æµ‹è¯• (optimal prompt)"
    echo "- æ¨¡å‹é€‰æ‹©: $model_type ($total_models ä¸ªæ¨¡å‹)"
    echo "- æµ‹è¯•æ¨¡å‹: ${models[*]}"
    echo "- æµ‹è¯•é…ç½®: $PROMPT_TYPE/$DIFFICULTY/$TOOL_SUCCESS_RATE"
    echo "- å¹¶å‘è®¾ç½®: $CUSTOM_WORKERS workers"
    echo "- å­˜å‚¨æ–¹å¼: JSON + ResultCollector"
    echo "- æ—¥å¿—ç›®å½•: $LOG_DIR"
    echo "- æ•°æ®å¤‡ä»½: âœ… å·²å¤‡ä»½åˆ° pilot_bench_cumulative_results/master_database_backup_before_r1_retest_*"
    echo
    
    # å¯¹äºå•ä¸ªæ¨¡å‹ï¼Œæä¾›æ•°æ®æ¸…ç†é€‰é¡¹
    if [[ "$model_type" == "single" ]]; then
        cleanup_old_data "$single_model"
    fi
    
    read -p "ç¡®è®¤å¼€å§‹5.1åŸºå‡†æµ‹è¯•é‡æµ‹? [y/N]: " confirm
    if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
        log_info "æµ‹è¯•å·²å–æ¶ˆ"
        exit 0
    fi
    
    # æ‰§è¡Œæµ‹è¯•
    if run_test "$model_list"; then
        echo -e "\n${GREEN}ğŸ‰ 5.1åŸºå‡†æµ‹è¯•é‡æµ‹æˆåŠŸå®Œæˆ!${NC}"
        log_success "ğŸ‰ æ‰€æœ‰æ¨¡å‹é‡æµ‹å®Œæˆ"
        
        # æ˜¾ç¤ºé‡æµ‹åçš„ç»“æœå¯¹æ¯”
        echo -e "\n${CYAN}ğŸ“Š é‡æµ‹åç»“æœå¯¹æ¯”:${NC}"
        python3 extract_experiment_results.py 5.1
        
        exit 0
    else
        echo -e "\n${RED}âŒ éƒ¨åˆ†æ¨¡å‹é‡æµ‹å¤±è´¥${NC}"
        log_warning "éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
        exit 1
    fi
}

# ä¿¡å·å¤„ç†
cleanup() {
    log_warning "æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†..."
    # æ€æ­»æ‰€æœ‰å­è¿›ç¨‹
    pkill -f "ultra_parallel_runner.py" 2>/dev/null || true
    pkill -f "smart_batch_runner.py" 2>/dev/null || true
    log_info "æ¸…ç†å®Œæˆ"
    exit 130
}

trap cleanup SIGINT SIGTERM

# æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
if [[ $# -gt 0 ]]; then
    case $1 in
        "--deepseek-r1")
            model_type="single"
            single_model="DeepSeek-R1-0528"
            export MODEL_TYPE="opensource"
            log_info "å‘½ä»¤è¡Œæ¨¡å¼: é‡æµ‹ DeepSeek-R1-0528"
            ;;
        "--help"|"-h")
            echo "5.1 åŸºå‡†æµ‹è¯•é‡æµ‹è„šæœ¬"
            echo "ç”¨æ³•:"
            echo "  $0                    # äº¤äº’æ¨¡å¼"
            echo "  $0 --deepseek-r1     # ç›´æ¥é‡æµ‹ DeepSeek-R1-0528"
            echo "  $0 --help            # æ˜¾ç¤ºå¸®åŠ©"
            exit 0
            ;;
        *)
            log_warning "æœªçŸ¥å‚æ•°: $1ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼"
            ;;
    esac
fi

# è¿è¡Œä¸»å‡½æ•°
main "$@"