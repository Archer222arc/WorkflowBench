========================================
批量提交和数据保存机制调试任务清单 v2
生成时间: 2025-08-19 18:15
状态: 活跃开发中
========================================

## 🎯 本次会话成果总结（2025-08-19 15:00-19:45）

### ✅ 完成的修复（12项）：
1. **增强debug日志功能** - 创建ultra_parallel_runner_debug.py捕获子进程详细输出
2. **修复并行部署WARNING** - 添加6个Azure部署实例到SUPPORTED_MODELS
3. **修复日志覆盖问题** - 两次修复：先添加模型名，后添加时间戳+存在性检查
4. **理解CALCULATION_ERROR** - 确认是flawed workflow测试的预期行为
5. **修复任务类型混淆** - file_processing → basic_task (影响1200个任务，24%的总量)
6. **调查DeepSeek数据保存** - 发现JSON/Parquet不同步问题（用户接受仅Parquet）
7. **修改IdealLab workers配置** - qwen和闭源模型都改为max_workers=1
8. **修复qwen模型映射BUG** - 7b/3b模型实际运行的是72b（重大发现！）
9. **验证qwen数据准确性** - 确认7b/3b历史数据无需清理（只有optimal测试）
10. **验证IdealLab API key轮换** - 确认机制正常，但发现并发限制问题
11. **🔥 实现qwen并发优化（5.1/5.2/5.3/5.5）** - 利用3个API keys实现3倍并发提升！
12. **🎯 实现5.4工具可靠性测试优化** - 根据tool_success_rate智能分配到不同keys

### 🔍 关键发现：
- **数据准确性问题**：qwen2.5-7b和3b的700个历史测试结果实际是72b模型的
- **存储同步问题**：使用STORAGE_FORMAT=parquet时，JSON数据库不更新
- **任务覆盖问题**：之前所有测试缺少20%的任务类型（basic_task）

========================================

## 📋 待处理任务优先级列表

### 🔴 高优先级（数据准确性）

#### 1. ✅ 数据分析完成 - qwen 7b/3b数据是准确的！
**好消息**：
- qwen2.5-7b-instruct: 700个optimal测试是准确的（5.1-5.2）
- qwen2.5-3b-instruct: 700个optimal测试是准确的（5.1-5.2）
- **无需清理**：这两个模型没有flawed数据，未受映射错误影响

**原因**：7b和3b没有运行过5.3-5.5的超并发测试，所以没有错误数据

#### 2. 为qwen 7b/3b补充5.3-5.5测试（flawed类型）
**目的**：完成缺失的flawed测试，使用修复后的代码
**步骤**：
```bash
# 补充7b的5.3测试
python ultra_parallel_runner.py --model qwen2.5-7b-instruct \
  --prompt-types flawed_sequence_disorder,flawed_tool_misuse,flawed_parameter_error \
  --difficulty easy --task-types all --num-instances 20

# 补充3b的5.3测试  
python ultra_parallel_runner.py --model qwen2.5-3b-instruct \
  --prompt-types flawed_sequence_disorder,flawed_tool_misuse,flawed_parameter_error \
  --difficulty easy --task-types all --num-instances 20
```

#### 3. ✅ basic_task覆盖验证完成 - 无需补充！
**检查结果**：
- basic_task测试总数：1016个（占20.4%）
- 完全符合预期（5种任务类型，每种约20%）
- 所有主要模型都有basic_task测试

**结论**：虽然代码有file_processing混淆，但实际basic_task都被正确测试了
**原因**：任务库本身就是用basic_task生成的，数据能正确匹配

### 🟡 中优先级（系统稳定性）

#### 4. ✅ 验证IdealLab API key轮换机制 - 已完成
**调查结果**：API key轮换机制工作正常
- 3个API keys正确分配给不同prompt_type
- baseline→Key0, cot→Key1, optimal→Key2
- flawed类型正确轮询使用
**新发现的问题**：max_workers=1限制了并发能力
**建议**：实现智能并发管理，充分利用3个API keys

#### 5. 修复Azure API无限阻塞问题
**症状**：472个CLOSE_WAIT连接，进程卡死
**位置**：unified_training_manager.py的API调用
**方案**：
- 添加timeout参数到所有requests调用
- 实现连接池管理
- 添加重试机制

#### 6. 解决JSON和Parquet数据同步问题
**现状**：STORAGE_FORMAT=parquet时只更新Parquet
**影响**：数据查询不一致
**方案**：
- 选项1：同时更新两种格式
- 选项2：统一使用一种格式
- 选项3：定期同步脚本

### 🟡 待确认方案

#### 7. 开源模型IdealLab并发优化方案（利用3个API keys）
**背景**：
- 开源模型（qwen系列）有3个IdealLab API keys可用
- 闭源模型只有1个IdealLab API key可用
- 当前max_workers=1限制了开源模型的并发能力
- **重要**：同一个key可以多模型并发，不同模型的速率限制是独立的

**方案A：基于模型类型的动态workers设置**
```python
# 在ultra_parallel_runner.py中
if instance.model_family == "qwen":  # 开源模型
    if rate_mode == "fixed":
        max_workers = 3  # 利用3个API keys
        qps = 10
    else:  # adaptive模式
        max_workers = 3  # 可以并发3个
        qps = None
        
elif instance.model_family in ["gemini", "claude", "o3"]:  # 闭源模型
    max_workers = 1  # 只有1个key，保持串行
    qps = 5
```

**方案B：基于prompt_type分组并发**
```python
# 将测试按prompt_type分组，每组使用不同的API key
prompt_groups = {
    'key0': ['baseline'],           # 使用第1个key
    'key1': ['cot'],                # 使用第2个key  
    'key2': ['optimal'],            # 使用第3个key
    'rotate': ['flawed_*']          # 轮询使用
}

# 每个组可以独立并发执行
for group_key, prompt_types in prompt_groups.items():
    # 启动独立的worker处理该组
    worker = create_worker(api_key_index=group_key)
```

**方案C：智能Key池管理（考虑模型独立限速）**
```python
class IdealLabKeyPool:
    def __init__(self):
        self.keys = [key0, key1, key2]
        # 每个key对每个模型的负载是独立的
        self.key_model_load = {
            0: {'qwen2.5-72b': 0, 'qwen2.5-32b': 0, 'qwen2.5-14b': 0, 'qwen2.5-7b': 0, 'qwen2.5-3b': 0},
            1: {'qwen2.5-72b': 0, 'qwen2.5-32b': 0, 'qwen2.5-14b': 0, 'qwen2.5-7b': 0, 'qwen2.5-3b': 0},
            2: {'qwen2.5-72b': 0, 'qwen2.5-32b': 0, 'qwen2.5-14b': 0, 'qwen2.5-7b': 0, 'qwen2.5-3b': 0}
        }
    
    def get_available_key(self, prompt_type, model):
        # 优先使用指定的key
        preferred_key = self.get_preferred_key(prompt_type)
        
        # 检查该key对该模型的负载
        if self.key_model_load[preferred_key][model] < MAX_CONCURRENT_PER_MODEL:
            return preferred_key
        
        # 找对该模型负载最小的key
        best_key = min(self.key_model_load.keys(), 
                      key=lambda k: self.key_model_load[k][model])
        return best_key
```

**方案D：多模型并发策略（新增，利用模型间独立限速）**
```python
# 既然不同模型间速率独立，可以同时测试多个模型
def run_multi_model_parallel():
    models = ['qwen2.5-72b', 'qwen2.5-32b', 'qwen2.5-14b', 'qwen2.5-7b', 'qwen2.5-3b']
    
    # 每个模型可以独立并发，不会互相影响
    for model in models:
        # 为每个模型分配workers
        if model in ['qwen2.5-72b', 'qwen2.5-32b']:
            max_workers = 2  # 大模型保守一点
        else:
            max_workers = 3  # 小模型可以更激进
        
        # 启动模型的测试（异步）
        launch_model_test(model, max_workers)
```

**实施步骤**：
1. 识别模型是开源还是闭源
2. 根据模型类型设置max_workers
3. 实现key池管理逻辑
4. 测试并发稳定性
5. 监控错误率和成功率

**预期收益**：
- 开源模型测试速度提升约3倍（单模型）
- 如果利用模型间独立限速，可以同时测试5个qwen模型，总体提升可达15倍
- 更充分利用API资源
- 闭源模型保持稳定（不变）

**关键洞察**：
由于同一个API key对不同模型的速率限制是独立的，理论上可以：
- 用Key0同时跑：qwen2.5-72b(baseline) + qwen2.5-32b(baseline) + qwen2.5-14b(baseline) + ...
- 用Key1同时跑：qwen2.5-72b(cot) + qwen2.5-32b(cot) + qwen2.5-14b(cot) + ...
- 用Key2同时跑：qwen2.5-72b(optimal) + qwen2.5-32b(optimal) + qwen2.5-14b(optimal) + ...
- 总共可以有15个并发请求（5个模型 × 3个keys）

**🎯 推荐方案：结合A+C策略** ✅ 已实现！
已创建`idealab_optimization_plan.py`演示优化效果
已实现`ultra_parallel_runner.py`中的智能分片策略
已通过`test_qwen_optimization.py`验证效果

1. **5.1/5.2测试（只测optimal）优化** ✅：
   - 现状：所有任务用Key2，Key0和Key1空闲
   - 实现：任务均匀分配到3个key（每key 1/3任务）
   - 效果：并发度从1提升到3（3倍提升）

2. **5.3测试（多个flawed）优化** ✅：
   - 现状：flawed轮询使用3个keys
   - 实现：每个flawed类型分配到独立key
   - 效果：3个flawed并行执行，充分利用3个keys

3. **5.5测试（baseline/cot/optimal）优化** ✅：
   - 现状：固定映射到3个keys
   - 实现：baseline→key0, cot→key1, optimal→key2
   - 效果：3种prompt类型并行，负载均衡

4. **5.4测试（工具可靠性敏感性）优化** ✅：
   - 问题：所有tool_success_rate都用optimal，会挤在key2上
   - 实现：根据rate值智能分配：0.9→key0, 0.8→均匀, 0.7→key2, 0.6→key0
   - 效果：4个rate并行测试，3倍提升

5. **实现细节** ✅：
   - 创建了3个虚拟实例：qwen-key0, qwen-key1, qwen-key2
   - 通过--idealab-key-index参数传递key索引
   - 每个key可以使用3-5个workers（从1个提升）
   - API调用链完整实现：ultra_parallel_runner → smart_batch_runner → batch_test_runner → interactive_executor → api_client_manager
   - 5.4场景特殊处理：检测optimal+非默认tool_success_rate，智能映射

### 🟢 低优先级（优化改进）

#### 8. 验证数据写入可靠性
- 测试并发写入是否有冲突
- 验证checkpoint机制有效性
- 测试异常中断时的数据完整性

#### 7. 检查summary统计自动更新
- 确认master_database.json的summary部分
- 验证总计数是否正确

#### 8. 分析silent模式的影响
- 确认是否隐藏了重要错误
- 考虑添加error-only输出模式

========================================

## 🚀 建议的执行顺序

### 立即执行（今天）：
1. [ ] 重新运行qwen2.5-7b测试（验证修复效果）
2. [ ] 重新运行qwen2.5-3b测试（验证修复效果）
3. [ ] 决定如何处理错误的历史数据

### 明天执行：
4. [ ] 为所有模型补充basic_task测试
5. [ ] 修复Azure API阻塞问题
6. [ ] 实现JSON/Parquet同步机制

### 本周内完成：
7. [ ] 全面的数据可靠性测试
8. [ ] 优化silent模式日志级别
9. [ ] 创建数据验证工具

========================================

## 📊 测试覆盖状态

### 需要重新测试的模型：
- qwen2.5-7b-instruct（历史数据无效）
- qwen2.5-3b-instruct（历史数据无效）
- 所有模型的basic_task（之前被跳过）

### 数据准确性状态：
- ✅ 准确：除qwen 7b/3b外的所有模型
- ⚠️ 不完整：所有模型缺少basic_task
- ❌ 错误：qwen2.5-7b和3b的历史数据

========================================

## 💡 经验教训

1. **模型映射要谨慎**：硬编码的base_model导致错误数据
2. **任务类型要验证**：file_processing vs basic_task混淆
3. **日志要防覆盖**：多模型并发需要唯一文件名
4. **存储格式要同步**：JSON和Parquet分离导致不一致
5. **debug要分层**：需要捕获子进程的详细输出

========================================

## 📝 相关文件清单

### 创建的新文件：
- ultra_parallel_runner_debug.py - 增强调试版本
- fix_task_type_mismatch.py - 批量修复任务类型
- fix_qwen_model_mapping.py - 修复qwen模型映射
- test_log_uniqueness.py - 测试日志唯一性

### 修改的核心文件：
- ultra_parallel_runner.py - 修复qwen映射、日志覆盖
- api_client_manager.py - 添加并行部署实例
- 8个文件的file_processing → basic_task替换

### 备份文件：
- ultra_parallel_runner.py.backup_20250819_173648
- 各修改文件的.backup_*版本

========================================
状态: 🔄 进行中
下一步: 实现IdealLab智能并发管理方案
最后更新: 2025-08-19 18:15
========================================