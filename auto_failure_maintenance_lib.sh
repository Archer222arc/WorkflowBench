#!/bin/bash

# ============================================
# è‡ªåŠ¨å¤±è´¥ç»´æŠ¤å‡½æ•°åº“
# æä¾›bashè„šæœ¬ä¸­çš„å¤±è´¥æ£€æµ‹ã€è®°å½•å’Œé‡æµ‹åŠŸèƒ½
# ============================================

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# å›¾æ ‡å®šä¹‰
ICON_SUCCESS="âœ…"
ICON_FAILURE="âŒ"
ICON_WARNING="âš ï¸"
ICON_INFO="â„¹ï¸"
ICON_RETRY="ğŸ”„"
ICON_MAINTENANCE="ğŸ”§"
ICON_PROGRESS="ğŸ“Š"
ICON_CONFIG="âš™ï¸"

# ==============================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ==============================================

# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
check_auto_maintenance_status() {
    echo -e "${CYAN}${ICON_MAINTENANCE} æ£€æŸ¥è‡ªåŠ¨ç»´æŠ¤ç³»ç»ŸçŠ¶æ€...${NC}"
    
    if python3 auto_failure_maintenance_system.py status >/dev/null 2>&1; then
        echo -e "${GREEN}${ICON_SUCCESS} è‡ªåŠ¨ç»´æŠ¤ç³»ç»Ÿæ­£å¸¸${NC}"
        return 0
    else
        echo -e "${RED}${ICON_FAILURE} è‡ªåŠ¨ç»´æŠ¤ç³»ç»Ÿå¼‚å¸¸${NC}"
        return 1
    fi
}

# è·å–æ¨¡å‹å®Œæˆæƒ…å†µæ¦‚è¦
get_models_completion_summary() {
    local models="$1"
    
    echo -e "${BLUE}${ICON_PROGRESS} åˆ†ææ¨¡å‹å®Œæˆæƒ…å†µ...${NC}"
    
    if [ -n "$models" ]; then
        python3 -c "
import sys
sys.path.insert(0, '.')
from auto_failure_maintenance_system import AutoFailureMaintenanceSystem

system = AutoFailureMaintenanceSystem(enable_auto_retry=False)
models_list = '$models'.split(',') if '$models' else None
analysis = system.analyze_test_completion(models_list)

print(f'åˆ†æäº† {len(analysis[\"models_analyzed\"])} ä¸ªæ¨¡å‹')
print(f'å‘ç°å¤±è´¥æ¨¡å¼: {len(analysis[\"failure_patterns\"])} ä¸ª')
print(f'é‡è¯•å»ºè®®: {len(analysis[\"retry_recommendations\"])} ä¸ª')

for model in analysis['models_analyzed']:
    summary = analysis['completion_summary'][model]
    if summary['status'] == 'analyzed':
        completion_rate = summary['completion_rate']
        avg_exec_time = summary.get('avg_execution_time', 0)
        complete_failure = summary.get('needs_retry_complete_failure', False)
        high_exec_time = summary.get('needs_retry_high_execution_time', False)
        
        status_icon = 'âš ï¸ ' if (complete_failure or high_exec_time) else 'âœ…'
        issues = []
        if complete_failure:
            failure_configs = summary.get('complete_failure_configs', [])
            issues.append(f'å®Œå…¨å¤±è´¥é…ç½®:{len(failure_configs)}ä¸ª')
        if high_exec_time:
            issues.append(f'æ‰§è¡Œæ—¶é—´è¿‡é•¿:{avg_exec_time:.1f}s')
        
        issue_text = f' | {\" | \".join(issues)}' if issues else ''
        print(f'{status_icon} {model}: å®Œæˆç‡ {completion_rate:.1%}, å¹³å‡æ‰§è¡Œæ—¶é—´ {avg_exec_time:.1f}s{issue_text}')
" 2>/dev/null
    else
        echo -e "${YELLOW}${ICON_WARNING} æœªæŒ‡å®šæ¨¡å‹ï¼Œåˆ†ææ‰€æœ‰æ¨¡å‹${NC}"
        python3 -c "
import sys
sys.path.insert(0, '.')
from auto_failure_maintenance_system import AutoFailureMaintenanceSystem

system = AutoFailureMaintenanceSystem(enable_auto_retry=False)
analysis = system.analyze_test_completion()

print(f'åˆ†æäº† {len(analysis[\"models_analyzed\"])} ä¸ªæ¨¡å‹')
print(f'å‘ç°å¤±è´¥æ¨¡å¼: {len(analysis[\"failure_patterns\"])} ä¸ª')
print(f'é‡è¯•å»ºè®®: {len(analysis[\"retry_recommendations\"])} ä¸ª')

for model in analysis['models_analyzed']:
    summary = analysis['completion_summary'][model]
    if summary['status'] == 'analyzed':
        completion_rate = summary['completion_rate']
        avg_exec_time = summary.get('avg_execution_time', 0)
        complete_failure = summary.get('needs_retry_complete_failure', False)
        high_exec_time = summary.get('needs_retry_high_execution_time', False)
        
        status_icon = 'âš ï¸ ' if (complete_failure or high_exec_time) else 'âœ…'
        issues = []
        if complete_failure:
            failure_configs = summary.get('complete_failure_configs', [])
            issues.append(f'å®Œå…¨å¤±è´¥é…ç½®:{len(failure_configs)}ä¸ª')
        if high_exec_time:
            issues.append(f'æ‰§è¡Œæ—¶é—´è¿‡é•¿:{avg_exec_time:.1f}s')
        
        issue_text = f' | {\" | \".join(issues)}' if issues else ''
        print(f'{status_icon} {model}: å®Œæˆç‡ {completion_rate:.1%}, å¹³å‡æ‰§è¡Œæ—¶é—´ {avg_exec_time:.1f}s{issue_text}')
" 2>/dev/null
    fi
}

# æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„æµ‹è¯•
check_incomplete_tests() {
    local models="$1"
    
    echo -e "${BLUE}${ICON_INFO} æ£€æŸ¥æœªå®Œæˆçš„æµ‹è¯•...${NC}"
    
    local incomplete_count
    incomplete_count=$(python3 -c "
import sys
sys.path.insert(0, '.')
from auto_failure_maintenance_system import AutoFailureMaintenanceSystem

system = AutoFailureMaintenanceSystem(enable_auto_retry=False)
models_list = '$models'.split(',') if '$models' else None
incomplete_tests = system.get_incomplete_tests(models_list)

total_missing = 0
for model, configs in incomplete_tests.items():
    missing = sum(config['missing_count'] for config in configs)
    total_missing += missing
    if missing > 0:
        print(f'{model}: {len(configs)} ä¸ªé…ç½®ï¼Œç¼ºå°‘ {missing} ä¸ªæµ‹è¯•')

print(f'æ€»å…±ç¼ºå°‘: {total_missing} ä¸ªæµ‹è¯•')
" 2>/dev/null | tail -1 | grep -o '[0-9]*' | head -1)
    
    if [ -z "$incomplete_count" ] || [ "$incomplete_count" -eq 0 ]; then
        echo -e "${GREEN}${ICON_SUCCESS} æ‰€æœ‰æµ‹è¯•å·²å®Œæˆ${NC}"
        return 1
    else
        echo -e "${YELLOW}${ICON_WARNING} å‘ç° $incomplete_count ä¸ªæœªå®Œæˆæµ‹è¯•${NC}"
        return 0
    fi
}

# ç”Ÿæˆé‡æµ‹è„šæœ¬
generate_retest_script() {
    local models="$1"
    local script_name="${2:-auto_retest_bash_generated.sh}"
    
    echo -e "${CYAN}${ICON_MAINTENANCE} ç”Ÿæˆé‡æµ‹è„šæœ¬...${NC}"
    
    if [ -n "$models" ]; then
        python3 auto_failure_maintenance_system.py retest $models >/dev/null 2>&1
    else
        python3 auto_failure_maintenance_system.py retest >/dev/null 2>&1
    fi
    
    if [ -f "auto_retest_incomplete.sh" ]; then
        mv "auto_retest_incomplete.sh" "$script_name"
        chmod +x "$script_name"
        echo -e "${GREEN}${ICON_SUCCESS} é‡æµ‹è„šæœ¬å·²ç”Ÿæˆ: $script_name${NC}"
        return 0
    else
        echo -e "${RED}${ICON_FAILURE} é‡æµ‹è„šæœ¬ç”Ÿæˆå¤±è´¥${NC}"
        return 1
    fi
}

# æ‰§è¡Œè‡ªåŠ¨ç»´æŠ¤
run_auto_maintenance() {
    local models="$1"
    local dry_run="${2:-false}"
    
    echo -e "${CYAN}${ICON_MAINTENANCE} æ‰§è¡Œè‡ªåŠ¨ç»´æŠ¤...${NC}"
    
    if [ "$dry_run" = "true" ]; then
        echo -e "${YELLOW}${ICON_INFO} ä»…åˆ†ææ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…æµ‹è¯•${NC}"
        python3 auto_failure_maintenance_system.py maintain
    else
        if [ -n "$models" ]; then
            python3 smart_batch_runner.py --auto-maintain --models $models
        else
            python3 smart_batch_runner.py --auto-maintain
        fi
    fi
}

# æ‰§è¡Œå¢é‡é‡æµ‹
run_incremental_retest() {
    local models="$1"
    local threshold="${2:-0.8}"
    local dry_run="${3:-false}"
    
    echo -e "${CYAN}${ICON_RETRY} æ‰§è¡Œå¢é‡é‡æµ‹ (é˜ˆå€¼: ${threshold})...${NC}"
    
    if [ "$dry_run" = "true" ]; then
        echo -e "${YELLOW}${ICON_INFO} ä»…åˆ†ææ¨¡å¼${NC}"
        get_models_completion_summary "$models"
    else
        local cmd="python3 smart_batch_runner.py --incremental-retest --completion-threshold $threshold"
        if [ -n "$models" ]; then
            cmd="$cmd --models $models"
        fi
        eval "$cmd"
    fi
}

# ==============================================
# æµ‹è¯•æ‰§è¡ŒåŒ…è£…å‡½æ•°
# ==============================================

# å¸¦å¤±è´¥æ£€æµ‹çš„æµ‹è¯•æ‰§è¡Œ
execute_test_with_failure_tracking() {
    local test_command="$1"
    local test_description="$2"
    local model="$3"
    local config="$4"
    
    echo -e "${BLUE}${ICON_INFO} æ‰§è¡Œ: $test_description${NC}"
    echo -e "${CYAN}å‘½ä»¤: $test_command${NC}"
    
    local start_time=$(date +%s)
    local success=false
    
    if eval "$test_command"; then
        success=true
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        echo -e "${GREEN}${ICON_SUCCESS} æµ‹è¯•æˆåŠŸ (è€—æ—¶: ${duration}s)${NC}"
        
        # è®°å½•æˆåŠŸ
        if [ -n "$model" ] && [ -n "$config" ]; then
            record_test_success "$model" "$config" "true"
        fi
    else
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        echo -e "${RED}${ICON_FAILURE} æµ‹è¯•å¤±è´¥ (è€—æ—¶: ${duration}s)${NC}"
        
        # è®°å½•å¤±è´¥
        if [ -n "$model" ] && [ -n "$config" ]; then
            record_test_failure "$model" "$config" "$test_description" "Test execution failed"
        fi
    fi
    
    return $([ "$success" = true ] && echo 0 || echo 1)
}

# è®°å½•æµ‹è¯•å¤±è´¥
record_test_failure() {
    local model="$1"
    local group_name="$2"
    local test_type="$3"
    local failure_reason="$4"
    
    python3 -c "
import sys
sys.path.insert(0, '.')
from enhanced_failed_tests_manager import EnhancedFailedTestsManager

manager = EnhancedFailedTestsManager()
manager.record_test_failure(
    model='$model',
    group_name='$group_name',
    prompt_types='bash_execution',
    test_type='$test_type',
    failure_reason='$failure_reason'
)
"
}

# è®°å½•æµ‹è¯•æˆåŠŸ
record_test_success() {
    local model="$1"
    local group_name="$2"
    local was_retry="$3"
    
    python3 -c "
import sys
sys.path.insert(0, '.')
from enhanced_failed_tests_manager import EnhancedFailedTestsManager

manager = EnhancedFailedTestsManager()
manager.record_test_success(
    model='$model',
    group_name='$group_name',
    was_retry=$was_retry
)
"
}

# ==============================================
# ç”¨æˆ·äº¤äº’å‡½æ•°
# ==============================================

# æ˜¾ç¤ºç»´æŠ¤èœå•
show_maintenance_menu() {
    echo -e "${CYAN}========================================${NC}"
    echo -e "${CYAN}${ICON_MAINTENANCE} è‡ªåŠ¨å¤±è´¥ç»´æŠ¤é€‰é¡¹${NC}"
    echo -e "${CYAN}========================================${NC}"
    echo -e "${YELLOW}1.${NC} æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"
    echo -e "${YELLOW}2.${NC} åˆ†ææ¨¡å‹å®Œæˆæƒ…å†µ"
    echo -e "${YELLOW}3.${NC} ç”Ÿæˆé‡æµ‹è„šæœ¬"
    echo -e "${YELLOW}4.${NC} æ‰§è¡Œè‡ªåŠ¨ç»´æŠ¤"
    echo -e "${YELLOW}5.${NC} æ‰§è¡Œå¢é‡é‡æµ‹"
    echo -e "${YELLOW}6.${NC} æŸ¥çœ‹å¤±è´¥æµ‹è¯•æ¦‚è¦"
    echo -e "${YELLOW}0.${NC} è·³è¿‡ç»´æŠ¤ï¼Œç»§ç»­æ‰§è¡Œ"
    echo -e "${CYAN}========================================${NC}"
}

# å¤„ç†ç»´æŠ¤èœå•é€‰æ‹©
handle_maintenance_choice() {
    local choice="$1"
    local models="$2"
    
    case $choice in
        1)
            check_auto_maintenance_status
            ;;
        2)
            get_models_completion_summary "$models"
            ;;
        3)
            generate_retest_script "$models"
            ;;
        4)
            echo -e "${YELLOW}${ICON_WARNING} æ˜¯å¦åªåˆ†æä¸æ‰§è¡Œï¼Ÿ (y/n): ${NC}"
            read -r dry_run_choice
            local dry_run=$([ "$dry_run_choice" = "y" ] && echo "true" || echo "false")
            run_auto_maintenance "$models" "$dry_run"
            ;;
        5)
            echo -e "${YELLOW}å®Œæˆç‡é˜ˆå€¼ (0.0-1.0, é»˜è®¤0.8): ${NC}"
            read -r threshold
            threshold=${threshold:-0.8}
            echo -e "${YELLOW}${ICON_WARNING} æ˜¯å¦åªåˆ†æä¸æ‰§è¡Œï¼Ÿ (y/n): ${NC}"
            read -r dry_run_choice
            local dry_run=$([ "$dry_run_choice" = "y" ] && echo "true" || echo "false")
            run_incremental_retest "$models" "$threshold" "$dry_run"
            ;;
        6)
            if command -v show_failed_tests_summary >/dev/null 2>&1; then
                show_failed_tests_summary
            else
                python3 enhanced_failed_tests_manager.py status
            fi
            ;;
        0)
            echo -e "${GREEN}${ICON_SUCCESS} è·³è¿‡ç»´æŠ¤ï¼Œç»§ç»­æ‰§è¡Œ...${NC}"
            return 0
            ;;
        *)
            echo -e "${RED}${ICON_FAILURE} æ— æ•ˆé€‰æ‹©${NC}"
            return 1
            ;;
    esac
}

# è‡ªåŠ¨ç»´æŠ¤å‘å¯¼
auto_maintenance_wizard() {
    local models="$1"
    local interactive="${2:-true}"
    
    echo -e "${PURPLE}ğŸ§™ è‡ªåŠ¨ç»´æŠ¤å‘å¯¼${NC}"
    echo -e "${BLUE}ç›®æ ‡æ¨¡å‹: ${models:-æ‰€æœ‰æ¨¡å‹}${NC}"
    
    # 1. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    if ! check_auto_maintenance_status; then
        echo -e "${RED}${ICON_FAILURE} ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼Œæ— æ³•ç»§ç»­${NC}"
        return 1
    fi
    
    # 2. åˆ†æå®Œæˆæƒ…å†µ
    get_models_completion_summary "$models"
    
    # 3. æ£€æŸ¥æœªå®Œæˆæµ‹è¯•
    if check_incomplete_tests "$models"; then
        echo -e "${YELLOW}${ICON_WARNING} å‘ç°æœªå®Œæˆçš„æµ‹è¯•${NC}"
        
        if [ "$interactive" = "true" ]; then
            echo -e "${YELLOW}æ˜¯å¦è¦æ‰§è¡Œå¢é‡é‡æµ‹ï¼Ÿ (y/n): ${NC}"
            read -r retest_choice
            if [ "$retest_choice" = "y" ]; then
                run_incremental_retest "$models" "0.8" "false"
            fi
        else
            echo -e "${CYAN}${ICON_INFO} è‡ªåŠ¨æ‰§è¡Œå¢é‡é‡æµ‹...${NC}"
            run_incremental_retest "$models" "0.8" "false"
        fi
    else
        echo -e "${GREEN}${ICON_SUCCESS} æ‰€æœ‰æµ‹è¯•å·²å®Œæˆ${NC}"
    fi
    
    # 4. ç”Ÿæˆé‡æµ‹è„šæœ¬ï¼ˆå¤‡ç”¨ï¼‰
    if [ "$interactive" = "true" ]; then
        echo -e "${YELLOW}æ˜¯å¦ç”Ÿæˆé‡æµ‹è„šæœ¬ï¼Ÿ (y/n): ${NC}"
        read -r script_choice
        if [ "$script_choice" = "y" ]; then
            generate_retest_script "$models"
        fi
    fi
    
    echo -e "${GREEN}${ICON_SUCCESS} ç»´æŠ¤å‘å¯¼å®Œæˆ${NC}"
}

# ==============================================
# è¿›åº¦ç®¡ç†å‡½æ•°
# ==============================================

# æ›´æ–°è¿›åº¦è®°å½•
update_progress() {
    local step="$1"
    local model_index="$2"
    local substep="$3"
    local current_model="$4"
    local current_group="$5"
    
    python3 -c "
import sys
sys.path.insert(0, '.')
from enhanced_progress_manager import EnhancedProgressManager

manager = EnhancedProgressManager()
manager.update_progress(
    step='$step',
    model_index=$model_index,
    substep='$substep',
    current_model='$current_model',
    current_group='$current_group'
)
"
}

# æ˜¾ç¤ºè¿›åº¦æ¦‚è¦
show_progress_summary() {
    echo -e "${CYAN}${ICON_PROGRESS} å½“å‰è¿›åº¦æ¦‚è¦:${NC}"
    python3 enhanced_progress_manager.py summary 2>/dev/null || echo -e "${YELLOW}è¿›åº¦ä¿¡æ¯ä¸å¯ç”¨${NC}"
}

# æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
check_retry_needed() {
    local models="$1"
    
    python3 -c "
import sys
sys.path.insert(0, '.')
from enhanced_progress_manager import EnhancedProgressManager

manager = EnhancedProgressManager()
if manager.has_failed_tests():
    print('true')
else:
    print('false')
" 2>/dev/null
}

# ==============================================
# é…ç½®ç®¡ç†å‡½æ•°
# ==============================================

# åŠ è½½ç»´æŠ¤é…ç½®
load_maintenance_config() {
    if [ -f "auto_maintenance_config.json" ]; then
        echo -e "${GREEN}${ICON_CONFIG} å·²åŠ è½½ç»´æŠ¤é…ç½®${NC}"
        python3 -c "
import json
with open('auto_maintenance_config.json', 'r') as f:
    config = json.load(f)
    retry_config = config.get('retry_strategy', {})
    auto_config = config.get('auto_retest', {})
    print(f'æœ€å¤§é‡è¯•æ¬¡æ•°: {retry_config.get(\"max_retries\", 3)}')
    print(f'æœ€å°å®Œæˆç‡é˜ˆå€¼: {auto_config.get(\"minimum_completion_rate\", 0.8):.0%}')
    print(f'æœ€å¤§å¤±è´¥ç‡é˜ˆå€¼: {auto_config.get(\"maximum_failure_rate\", 0.3):.0%}')
"
    else
        echo -e "${YELLOW}${ICON_WARNING} ä½¿ç”¨é»˜è®¤ç»´æŠ¤é…ç½®${NC}"
    fi
}

# ==============================================
# å®ç”¨å·¥å…·å‡½æ•°
# ==============================================

# å®‰å…¨æ‰§è¡Œå‘½ä»¤ï¼ˆå¸¦è¶…æ—¶ï¼‰
safe_execute() {
    local command="$1"
    local timeout="${2:-300}"  # é»˜è®¤5åˆ†é’Ÿè¶…æ—¶
    local description="$3"
    
    echo -e "${BLUE}${ICON_INFO} æ‰§è¡Œ: ${description:-$command}${NC}"
    
    if timeout "$timeout" bash -c "$command"; then
        echo -e "${GREEN}${ICON_SUCCESS} å‘½ä»¤æ‰§è¡ŒæˆåŠŸ${NC}"
        return 0
    else
        local exit_code=$?
        if [ $exit_code -eq 124 ]; then
            echo -e "${RED}${ICON_FAILURE} å‘½ä»¤è¶…æ—¶ (${timeout}s)${NC}"
        else
            echo -e "${RED}${ICON_FAILURE} å‘½ä»¤æ‰§è¡Œå¤±è´¥ (é€€å‡ºç : $exit_code)${NC}"
        fi
        return $exit_code
    fi
}

# å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ¨¡å‹æµ‹è¯•
parallel_model_testing() {
    local models="$1"
    local test_command_template="$2"
    local max_parallel="${3:-3}"
    
    echo -e "${CYAN}${ICON_INFO} å¹¶è¡Œæµ‹è¯•æ¨¡å‹: $models (æœ€å¤§å¹¶è¡Œæ•°: $max_parallel)${NC}"
    
    # å°†æ¨¡å‹å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°ç»„
    IFS=',' read -ra MODELS_ARRAY <<< "$models"
    
    local pids=()
    local model_count=0
    
    for model in "${MODELS_ARRAY[@]}"; do
        # æ›¿æ¢æ¨¡æ¿ä¸­çš„{MODEL}ä¸ºå®é™…æ¨¡å‹å
        local command=${test_command_template//\{MODEL\}/$model}
        
        echo -e "${BLUE}${ICON_INFO} å¯åŠ¨æ¨¡å‹æµ‹è¯•: $model${NC}"
        
        # åå°æ‰§è¡Œ
        (
            execute_test_with_failure_tracking "$command" "æ¨¡å‹ $model æµ‹è¯•" "$model" "parallel_test"
        ) &
        
        pids+=($!)
        ((model_count++))
        
        # æ§åˆ¶å¹¶è¡Œæ•°
        if [ $model_count -ge $max_parallel ]; then
            # ç­‰å¾…ä¸€ä¸ªä»»åŠ¡å®Œæˆ
            wait ${pids[0]}
            pids=("${pids[@]:1}")  # ç§»é™¤ç¬¬ä¸€ä¸ªPID
            ((model_count--))
        fi
    done
    
    # ç­‰å¾…æ‰€æœ‰å‰©ä½™ä»»åŠ¡å®Œæˆ
    for pid in "${pids[@]}"; do
        wait $pid
    done
    
    echo -e "${GREEN}${ICON_SUCCESS} æ‰€æœ‰æ¨¡å‹æµ‹è¯•å®Œæˆ${NC}"
}

# æ—¥å¿—è®°å½•å‡½æ•°
log_maintenance_action() {
    local action="$1"
    local details="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    echo "[$timestamp] $action: $details" >> "auto_maintenance_log.txt"
}

# ==============================================
# ä¸»è¦å…¥å£å‡½æ•°
# ==============================================

# æ™ºèƒ½ç»´æŠ¤å…¥å£ï¼ˆä¾›å…¶ä»–è„šæœ¬è°ƒç”¨ï¼‰
smart_maintenance_entry() {
    local mode="$1"           # check, auto, incremental, wizard
    local models="$2"         # æ¨¡å‹åˆ—è¡¨ï¼Œé€—å·åˆ†éš”
    local interactive="$3"    # true/false
    local extra_params="$4"   # é¢å¤–å‚æ•°
    
    # åŠ è½½é…ç½®
    load_maintenance_config
    
    case $mode in
        "check")
            check_auto_maintenance_status
            get_models_completion_summary "$models"
            ;;
        "auto")
            local dry_run=$(echo "$extra_params" | grep -q "dry_run" && echo "true" || echo "false")
            run_auto_maintenance "$models" "$dry_run"
            ;;
        "incremental")
            local threshold=$(echo "$extra_params" | grep -o 'threshold=[0-9.]*' | cut -d= -f2)
            threshold=${threshold:-0.8}
            local dry_run=$(echo "$extra_params" | grep -q "dry_run" && echo "true" || echo "false")
            run_incremental_retest "$models" "$threshold" "$dry_run"
            ;;
        "wizard")
            auto_maintenance_wizard "$models" "$interactive"
            ;;
        "menu")
            if [ "$interactive" = "true" ]; then
                show_maintenance_menu
                echo -n "è¯·é€‰æ‹©: "
                read -r choice
                handle_maintenance_choice "$choice" "$models"
            else
                auto_maintenance_wizard "$models" "false"
            fi
            ;;
        *)
            echo -e "${RED}${ICON_FAILURE} æœªçŸ¥ç»´æŠ¤æ¨¡å¼: $mode${NC}"
            echo -e "${YELLOW}æ”¯æŒçš„æ¨¡å¼: check, auto, incremental, wizard, menu${NC}"
            return 1
            ;;
    esac
}

# å¯¼å‡ºä¸»è¦å‡½æ•°
export -f check_auto_maintenance_status
export -f get_models_completion_summary
export -f check_incomplete_tests
export -f generate_retest_script
export -f run_auto_maintenance
export -f run_incremental_retest
export -f execute_test_with_failure_tracking
export -f auto_maintenance_wizard
export -f smart_maintenance_entry
export -f show_progress_summary
export -f update_progress
export -f safe_execute
export -f parallel_model_testing

echo -e "${GREEN}${ICON_SUCCESS} è‡ªåŠ¨å¤±è´¥ç»´æŠ¤å‡½æ•°åº“å·²åŠ è½½${NC}"